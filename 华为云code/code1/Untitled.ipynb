{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "from collections import Counter\nimport numpy as np\nimport tensorflow.contrib.keras as kr\nimport tensorflow as tf\nimport time\nfrom datetime import timedelta\nimport os\nfrom sklearn import metrics\n\nimport moxing as mox\nmox.file.shift('os', 'mox')", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "INFO:root:Using MoXing-v1.14.1-ddfd6c9a\nINFO:root:Using OBS-Python-SDK-3.1.2\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "vocabPath = \"s3://corpus-text-classification1/data/glove.6B.100d.txt\"\nsavePath = \"s3://corpus-text-classification1/c1_cnn_2/c1_cnn_2\"", "execution_count": 2, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def loadGloVe(filename, emb_size=50):\n    vocab = []\n    embd = []\n    print('Loading GloVe!')\n    # vocab.append('unk') #\u88c5\u8f7d\u4e0d\u8ba4\u8bc6\u7684\u8bcd\n    # embd.append([0] * emb_size) #\u8fd9\u4e2aemb_size\u53ef\u80fd\u9700\u8981\u6307\u5b9a\n    file = open(filename,'r',encoding='utf-8')\n    for line in file.readlines():\n        row = line.strip().split(' ')\n        vocab.append(row[0])\n        embd.append([float(ei) for ei in row[1:]])\n    file.close()\n    print('Completed!')\n    return vocab,embd", "execution_count": 3, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "categories = ['Retrieve Value', 'Filter', 'Compute Derived Value', 'Find Extremum', 'Sort', \n                  'Determine Range', 'Characterize Distribution', 'Find Anomalies', 'Cluster', 'Correlate']\nnum_classes = len(categories)\nseq_length = 35", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "vocab, embd = loadGloVe(vocabPath, 100)\nvocab_size = len(vocab)\nembedding_dim = len(embd[0])\nembedding = np.asarray(embd)\nword_to_id = dict(zip(vocab, range(vocab_size)))", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Loading GloVe!\nCompleted!\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# ======================================================CNN Model Start===============================================\n# \u8f93\u5165\u5185\u5bb9\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\ninput_x = tf.placeholder(tf.int32, [None, seq_length], name='input_x')\ninput_y = tf.placeholder(tf.float32, [None, num_classes], name='input_y')\n# dropout\u7684\u635f\u5931\u7387\nkeep_prob = tf.placeholder(tf.float64, name='keep_prob')\n\n# \u8bcd\u5411\u91cf\u6620\u5c04;\u5b9e\u9645\u4e0a\u6b64\u5904\u7684\u8bcd\u5411\u91cf\u5e76\u4e0d\u662f\u7528\u7684\u9884\u8bad\u7ec3\u597d\u7684\u8bcd\u5411\u91cf\uff0c\u800c\u662f\u672a\u7ecf\u4efb\u4f55\u8bad\u7ec3\u76f4\u63a5\u751f\u6210\u4e86\u4e00\u4e2a\u77e9\u9635\uff0c\u5c06\u6b64\u77e9\u9635\u4f5c\u4e3a\u8bcd\u5411\u91cf\u77e9\u9635\u4f7f\u7528\uff0c\u6548\u679c\u4e5f\u8fd8\u4e0d\u9519\u3002\n# \u82e5\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u8bcd\u5411\u91cf\uff0c\u6216\u8bb8\u8bad\u7ec3\u6b64\u6b21\u6587\u672c\u5206\u7c7b\u7684\u6a21\u578b\u65f6\u4f1a\u66f4\u5feb\uff0c\u66f4\u597d\u3002\n# embedding = tf.get_variable('embedding', [vocab_size, embedding_dim])\nembedding_inputs = tf.nn.embedding_lookup(embedding, input_x)\n\n\n\nnum_filters = 256\nkernel_size = 5\nhidden_dim = 128\nlearning_rate = 1e-3\ndropout_keep_prob = 0.5\n\nnum_epochs = 20\nbatch_size = 64\nprint_per_batch = 20  # \u6bcf\u591a\u5c11\u8f6e\u8f93\u51fa\u4e00\u6b21\u7ed3\u679c\n# save_per_batch = 5  # \u6bcf\u591a\u5c11\u8f6e\u5b58\u5165tensorboard\n\n\n# CNN layer\nconv = tf.layers.conv1d(embedding_inputs, num_filters, kernel_size, name='conv')  # num_filters = 256 \u8fd9\u662f\u4e2a\u5565\n''' https://blog.csdn.net/khy19940520/article/details/89934335\ntf.layers.conv1d\uff1a\u4e00\u7ef4\u5377\u79ef\u4e00\u822c\u7528\u4e8e\u5904\u7406\u6587\u672c\u6570\u636e\uff0c\u5e38\u7528\u8bed\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\uff0c\u8f93\u5165\u4e00\u822c\u662f\u6587\u672c\u7ecf\u8fc7embedding\u7684\u4e8c\u7ef4\u6570\u636e\u3002\n    inputs\uff1a \u8f93\u5165tensor\uff0c \u7ef4\u5ea6(batch_size, seq_length, embedding_dim) \u662f\u4e00\u4e2a\u4e09\u7ef4\u7684tensor\uff1b\u5176\u4e2d\uff0c\n        batch_size\u6307\u6bcf\u6b21\u8f93\u5165\u7684\u6587\u672c\u6570\u91cf\uff1b\n        seq_length\u6307\u6bcf\u4e2a\u6587\u672c\u7684\u8bcd\u8bed\u6570\u6216\u8005\u5355\u5b57\u6570\uff1b\n        embedding_dim\u6307\u6bcf\u4e2a\u8bcd\u8bed\u6216\u8005\u6bcf\u4e2a\u5b57\u7684\u5411\u91cf\u957f\u5ea6\uff1b\n        \u4f8b\u5982\u6bcf\u6b21\u8bad\u7ec3\u8f93\u51652\u7bc7\u6587\u672c\uff0c\u6bcf\u7bc7\u6587\u672c\u6709100\u4e2a\u8bcd\uff0c\u6bcf\u4e2a\u8bcd\u7684\u5411\u91cf\u957f\u5ea6\u4e3a20\uff0c\u90a3input\u7ef4\u5ea6\u5373\u4e3a(2, 100, 20)\u3002\n    filters\uff1a\u8fc7\u6ee4\u5668\uff08\u5377\u79ef\u6838\uff09\u7684\u6570\u76ee\n    kernel_size\uff1a\u5377\u79ef\u6838\u7684\u5927\u5c0f\uff0c\u5377\u79ef\u6838\u672c\u8eab\u5e94\u8be5\u662f\u4e8c\u7ef4\u7684\uff0c\u8fd9\u91cc\u53ea\u9700\u8981\u6307\u5b9a\u4e00\u7ef4\uff0c\u56e0\u4e3a\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u5373\u957f\u5ea6\u4e0e\u8bcd\u5411\u91cf\u7684\u957f\u5ea6\u4e00\u81f4\uff0c\u5377\u79ef\u6838\u53ea\u80fd\u4ece\u4e0a\u5f80\u4e0b\u8d70\uff0c\u4e0d\u80fd\u4ece\u5de6\u5f80\u53f3\u8d70\uff0c\u5373\u53ea\u80fd\u6309\u7167\u6587\u672c\u4e2d\u8bcd\u7684\u987a\u5e8f\uff0c\u4e5f\u662f\u5217\u7684\u987a\u5e8f\u3002\n'''\n# global max pooling layer\ngmp = tf.reduce_max(conv, reduction_indices=[1], name='gmp')  # https://blog.csdn.net/lllxxq141592654/article/details/85345864\n\n# \u5168\u8fde\u63a5\u5c42\uff0c\u540e\u9762\u63a5dropout\u4ee5\u53carelu\u6fc0\u6d3b\nfc = tf.layers.dense(gmp, hidden_dim, name='fc1')  # hidden_dim\uff1a128\n''' https://blog.csdn.net/yangfengling1023/article/details/81774580\ndense \uff1a\u5168\u8fde\u63a5\u5c42  inputs\uff1a\u8f93\u5165\u8be5\u7f51\u7edc\u5c42\u7684\u6570\u636e\uff1bunits\uff1a\u8f93\u51fa\u7684\u7ef4\u5ea6\u5927\u5c0f\uff0c\u6539\u53d8inputs\u7684\u6700\u540e\u4e00\u7ef4\n'''\nfc = tf.nn.dropout(fc, keep_prob)\nfc = tf.nn.relu(fc)\n\n# \u5206\u7c7b\u5668\nlogits = tf.layers.dense(fc, num_classes, name='fc2')\ny_pred_cls = tf.argmax(tf.nn.softmax(logits), 1)  # \u9884\u6d4b\u7c7b\u522b tf.argmax\uff1a\u8fd4\u56de\u6bcf\u4e00\u884c\u6216\u6bcf\u4e00\u5217\u7684\u6700\u5927\u503c 1\u4e3a\u91cc\u9762\uff08\u6bcf\u4e00\u884c\uff09\uff0c0\u4e3a\u5916\u9762\uff08\u6bcf\u4e00\u5217\uff09\n\n# \u635f\u5931\u51fd\u6570\uff0c\u4ea4\u53c9\u71b5\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=input_y)\nloss = tf.reduce_mean(cross_entropy)\n# \u4f18\u5316\u5668\noptim = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n\n# \u51c6\u786e\u7387\ncorrect_pred = tf.equal(tf.argmax(input_y, 1), y_pred_cls)\nacc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n# ======================================================CNN Model End============================================", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "WARNING:tensorflow:From <ipython-input-6-46820a3bfea0>:55: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n\n", "name": "stdout"}, {"output_type": "stream", "text": "WARNING:tensorflow:From <ipython-input-6-46820a3bfea0>:55: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# \u521b\u5efasession\nsession = tf.Session()\nsaver = tf.train.Saver()\nsession.run(tf.global_variables_initializer())\nsaver.restore(sess=session, save_path=savePath)", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-text-classification1/c1_cnn_2/c1_cnn_2\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-text-classification1/c1_cnn_2/c1_cnn_2\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def predict(predict_sentences, word_to_id, pad_max_length):\n    \"\"\"\n    \u5c06\u6587\u4ef6\u8f6c\u6362\u4e3aid\u8868\u793a,\u5e76\u4e14\u5c06\u6bcf\u4e2a\u5355\u72ec\u7684\u6837\u672c\u957f\u5ea6\u56fa\u5b9a\u4e3apad_max_lengtn\n    \"\"\"\n    \n    data_id = []\n    # \u5c06\u6587\u672c\u5185\u5bb9\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684id\u5f62\u5f0f\n    for i in range(len(predict_sentences)):\n        data_id.append([word_to_id[x] for x in predict_sentences[i].lower().strip().split() if x in word_to_id])\n        \n    # \u4f7f\u7528keras\u63d0\u4f9b\u7684pad_sequences\u6765\u5c06\u6587\u672cpad\u4e3a\u56fa\u5b9a\u957f\u5ea6\n    x_pad = kr.preprocessing.sequence.pad_sequences(data_id, pad_max_length)\n    ''' https://blog.csdn.net/TH_NUM/article/details/80904900\n    pad_sequences(sequences, maxlen=None, dtype=\u2019int32\u2019, padding=\u2019pre\u2019, truncating=\u2019pre\u2019, value=0.) \n        sequences\uff1a\u6d6e\u70b9\u6570\u6216\u6574\u6570\u6784\u6210\u7684\u4e24\u5c42\u5d4c\u5957\u5217\u8868\n        maxlen\uff1aNone\u6216\u6574\u6570\uff0c\u4e3a\u5e8f\u5217\u7684\u6700\u5927\u957f\u5ea6\u3002\u5927\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u88ab\u622a\u77ed\uff0c\u5c0f\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u5728\u540e\u90e8\u586b0.\n        dtype\uff1a\u8fd4\u56de\u7684numpy array\u7684\u6570\u636e\u7c7b\u578b\n        padding\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u88650\u65f6\uff0c\u5728\u5e8f\u5217\u7684\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u8865\n        truncating\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u622a\u65ad\u5e8f\u5217\u65f6\uff0c\u4ece\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u622a\u65ad\n        value\uff1a\u6d6e\u70b9\u6570\uff0c\u6b64\u503c\u5c06\u5728\u586b\u5145\u65f6\u4ee3\u66ff\u9ed8\u8ba4\u7684\u586b\u5145\u503c0\n    '''\n    feed_dict = {\n        input_x: x_pad,\n        keep_prob: 1.0\n    }\n    predict_result = session.run(y_pred_cls, feed_dict=feed_dict)\n    predict_result = [i+1 for i in predict_result]\n    return predict_result", "execution_count": 8, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "predict_sentences = [\"In the sixtieth ceremony , where were all of the winners from ?\",  #  7\n                    \"On how many devices has the app \\\" CF SHPOP ! \\\" been installed ?\",  # 1\n                    \"List center - backs by what their transfer _ fee was .\"]  # 5\npredict(predict_sentences, word_to_id, seq_length)", "execution_count": 9, "outputs": [{"output_type": "execute_result", "execution_count": 9, "data": {"text/plain": "[7, 1, 5]"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "tensorflow-1.8", "display_name": "TensorFlow-1.8", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}