{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "from collections import Counter\nimport numpy as np\nimport tensorflow.contrib.keras as kr\nimport tensorflow as tf\nimport time\nfrom datetime import timedelta\nimport os\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\n\nimport moxing as mox\nmox.file.shift('os', 'mox')", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "INFO:root:Using MoXing-v1.14.1-ddfd6c9a\nINFO:root:Using OBS-Python-SDK-3.1.2\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "trainDataPath = \"s3://corpus-2/dataset/corpus_5.txt\"\nvocabPath = \"s3://corpus-text-classification1/data/glove.6B.100d.txt\"\nsavePath = \"s3://corpus-2/model/cnn2\"", "execution_count": 2, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def readfile(filePath):\n    \"\"\"\u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9\uff0c\u8fd4\u56de\u6587\u672c\u548c\u6807\u7b7e\u5217\u8868\"\"\"\n    train_data = []\n    with open(filePath, 'r', encoding='utf-8') as f:\n        for line in f.readlines():\n            word = line.split()\n            label = int(word[0].split(\":\")[0])\n            content = word[1:]\n            train_data.append([content,label])\n\n    return np.asarray(train_data)\n\n\ndef readCategory():\n    \"\"\"\u8bfb\u53d6\u5206\u7c7b\u76ee\u5f55\uff0c\u56fa\u5b9aid\"\"\"\n    '''\n    Retrieve Value\n    Filter\n    Compute Derived Value\n    Find Extremum\n    Sort\n    Determine Range\n    Characterize Distribution\n    Find Anomalies\n    Cluster\n    Correlate\n    '''\n    categories = ['Retrieve Value', 'Filter', 'Compute Derived Value', 'Find Extremum', 'Sort', \n                  'Determine Range', 'Characterize Distribution', 'Find Anomalies', 'Cluster', 'Correlate']\n    cat_to_id = dict(zip(categories, range(1,len(categories)+1)))\n    id_to_cat = dict(zip(range(1,len(categories)+1), categories))\n    return id_to_cat, cat_to_id\n\n\ndef loadGloVe(filename, emb_size=50):\n    vocab = []\n    embd = []\n    print('Loading GloVe!')\n    # vocab.append('unk') #\u88c5\u8f7d\u4e0d\u8ba4\u8bc6\u7684\u8bcd\n    # embd.append([0] * emb_size) #\u8fd9\u4e2aemb_size\u53ef\u80fd\u9700\u8981\u6307\u5b9a\n    file = open(filename,'r',encoding='utf-8')\n    for line in file.readlines():\n        row = line.strip().split(' ')\n        vocab.append(row[0])\n        embd.append([float(ei) for ei in row[1:]])\n    file.close()\n    print('Completed!')\n    return vocab,embd", "execution_count": 11, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "train_data = readfile(trainDataPath)", "execution_count": 12, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "len(train_data[0]),len(train_data)", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "(2, 14035)"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "np.random.shuffle(train_data)\nlen(train_data[:,0])", "execution_count": 22, "outputs": [{"output_type": "execute_result", "execution_count": 22, "data": {"text/plain": "14035"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "train_data[0]", "execution_count": 24, "outputs": [{"output_type": "execute_result", "execution_count": 24, "data": {"text/plain": "array([list(['can', 'you', 'find', 'anything', 'unusual', 'about', 'the', 'average', 'yearly', 'rainfall', 'of', 'each', 'chinese', 'province', 'this', 'year', '?']),\n       8], dtype=object)"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "seq_length = 0\nfor content in train_data[:,0]:\n    if seq_length < len(content):\n        seq_length = len(content)   # seq_length = 41", "execution_count": 15, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "seq_length", "execution_count": 16, "outputs": [{"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "41"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "vocab, embd = loadGloVe(vocabPath, 100)\nvocab_size = len(vocab)\nembedding_dim = len(embd[0])\nembedding = np.asarray(embd)", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Loading GloVe!\nCompleted!\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "word_to_id = dict(zip(vocab, range(vocab_size)))", "execution_count": 18, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "len(embedding),embedding_dim,vocab_size", "execution_count": 19, "outputs": [{"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "(400000, 100, 400000)"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def process_file(contents, labels, word_to_id, num_classes, pad_max_length):\n    \"\"\"\n    \u5c06\u6587\u4ef6\u8f6c\u6362\u4e3aid\u8868\u793a,\u5e76\u4e14\u5c06\u6bcf\u4e2a\u5355\u72ec\u7684\u6837\u672c\u957f\u5ea6\u56fa\u5b9a\u4e3apad_max_lengtn\n    \"\"\"\n    # contents, labels = readfile(filePath)\n    data_id, label_id = [], []\n    # \u5c06\u6587\u672c\u5185\u5bb9\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684id\u5f62\u5f0f\n    for i in range(len(contents)):\n        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])\n        label_id.append(labels[i] - 1)\n    # \u4f7f\u7528keras\u63d0\u4f9b\u7684pad_sequences\u6765\u5c06\u6587\u672cpad\u4e3a\u56fa\u5b9a\u957f\u5ea6\n    x_pad = kr.preprocessing.sequence.pad_sequences(data_id, pad_max_length)\n    ''' https://blog.csdn.net/TH_NUM/article/details/80904900\n    pad_sequences(sequences, maxlen=None, dtype=\u2019int32\u2019, padding=\u2019pre\u2019, truncating=\u2019pre\u2019, value=0.) \n        sequences\uff1a\u6d6e\u70b9\u6570\u6216\u6574\u6570\u6784\u6210\u7684\u4e24\u5c42\u5d4c\u5957\u5217\u8868\n        maxlen\uff1aNone\u6216\u6574\u6570\uff0c\u4e3a\u5e8f\u5217\u7684\u6700\u5927\u957f\u5ea6\u3002\u5927\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u88ab\u622a\u77ed\uff0c\u5c0f\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u5728\u540e\u90e8\u586b0.\n        dtype\uff1a\u8fd4\u56de\u7684numpy array\u7684\u6570\u636e\u7c7b\u578b\n        padding\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u88650\u65f6\uff0c\u5728\u5e8f\u5217\u7684\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u8865\n        truncating\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u622a\u65ad\u5e8f\u5217\u65f6\uff0c\u4ece\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u622a\u65ad\n        value\uff1a\u6d6e\u70b9\u6570\uff0c\u6b64\u503c\u5c06\u5728\u586b\u5145\u65f6\u4ee3\u66ff\u9ed8\u8ba4\u7684\u586b\u5145\u503c0\n    '''\n    y_pad = kr.utils.to_categorical(label_id, num_classes=num_classes)  # \u5c06\u6807\u7b7e\u8f6c\u6362\u4e3aone-hot\u8868\u793a\n    ''' https://blog.csdn.net/nima1994/article/details/82468965\n    to_categorical(y, num_classes=None, dtype='float32')\n        \u5c06\u6574\u578b\u6807\u7b7e\u8f6c\u4e3aonehot\u3002y\u4e3aint\u6570\u7ec4\uff0cnum_classes\u4e3a\u6807\u7b7e\u7c7b\u522b\u603b\u6570\uff0c\u5927\u4e8emax(y)\uff08\u6807\u7b7e\u4ece0\u5f00\u59cb\u7684\uff09\u3002\n        \u8fd4\u56de\uff1a\u5982\u679cnum_classes=None\uff0c\u8fd4\u56delen(y) * [max(y)+1]\uff08\u7ef4\u5ea6\uff0cm*n\u8868\u793am\u884cn\u5217\u77e9\u9635\uff0c\u4e0b\u540c\uff09\uff0c\u5426\u5219\u4e3alen(y) * num_classes\u3002\n    '''\n    return x_pad, y_pad\n\n\ndef get_time_dif(start_time):\n    \"\"\"\u83b7\u53d6\u5df2\u4f7f\u7528\u65f6\u95f4\"\"\"\n    end_time = time.time()\n    time_dif = end_time - start_time\n    return timedelta(seconds=int(round(time_dif)))", "execution_count": 20, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "categories = ['Retrieve Value', 'Filter', 'Compute Derived Value', 'Find Extremum', 'Sort', \n                  'Determine Range', 'Characterize Distribution', 'Find Anomalies', 'Cluster', 'Correlate']\n\nnum_classes = len(categories)\n\nprint(\"Loading training and validation and testing data...\")\nstart_time = time.time()\nx_train, y_train = process_file(train_data[:,0], train_data[:,1], word_to_id, num_classes, seq_length)\ntime_dif = get_time_dif(start_time)\nprint(\"Loading data Time usage:\", time_dif)", "execution_count": 25, "outputs": [{"output_type": "stream", "text": "Loading training and validation and testing data...\nLoading data Time usage: 0:00:00\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "x_train[0], y_train[0]", "execution_count": 26, "outputs": [{"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "(array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n           0,    0,   86,   81,  596, 1096, 3217,   59,    0,  641, 8946,\n        8707,    3,  236,  327,  624,   37,   62,  188], dtype=int32),\n array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]))"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "len(x_train)", "execution_count": 16, "outputs": [{"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "14035"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "word_to_id[\"arkansas\"]", "execution_count": 17, "outputs": [{"output_type": "execute_result", "execution_count": 17, "data": {"text/plain": "4791"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "embedding[3]", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "array([-0.1529  , -0.24279 ,  0.89837 ,  0.16996 ,  0.53516 ,  0.48784 ,\n       -0.58826 , -0.17982 , -1.3581  ,  0.42541 ,  0.15377 ,  0.24215 ,\n        0.13474 ,  0.41193 ,  0.67043 , -0.56418 ,  0.42985 , -0.012183,\n       -0.11677 ,  0.31781 ,  0.054177, -0.054273,  0.35516 , -0.30241 ,\n        0.31434 , -0.33846 ,  0.71715 , -0.26855 , -0.15837 , -0.47467 ,\n        0.051581, -0.33252 ,  0.15003 , -0.1299  , -0.54617 , -0.37843 ,\n        0.64261 ,  0.82187 , -0.080006,  0.078479, -0.96976 , -0.57741 ,\n        0.56491 , -0.39873 , -0.057099,  0.19743 ,  0.065706, -0.48092 ,\n       -0.20125 , -0.40834 ,  0.39456 , -0.02642 , -0.11838 ,  1.012   ,\n       -0.53171 , -2.7474  , -0.042981, -0.74849 ,  1.7574  ,  0.59085 ,\n        0.04885 ,  0.78267 ,  0.38497 ,  0.42097 ,  0.67882 ,  0.10337 ,\n        0.6328  , -0.026595,  0.58647 , -0.44332 ,  0.33057 , -0.12022 ,\n       -0.55645 ,  0.073611,  0.20915 ,  0.43395 , -0.012761,  0.089874,\n       -1.7991  ,  0.084808,  0.77112 ,  0.63105 , -0.90685 ,  0.60326 ,\n       -1.7515  ,  0.18596 , -0.50687 , -0.70203 ,  0.66578 , -0.81304 ,\n        0.18712 , -0.018488, -0.26757 ,  0.727   , -0.59363 , -0.34839 ,\n       -0.56094 , -0.591   ,  1.0039  ,  0.20664 ])"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "class rnn_cnn(object):\n    \n    def __init__(self, savePath, num_classes):\n        self.savePath = savePath\n        # \u8f93\u5165\u5185\u5bb9\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\n        self.input_x = tf.placeholder(tf.int32, [None, seq_length], name='input_x')\n        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name='input_y')\n        # dropout\u7684\u635f\u5931\u7387\n        self.keep_prob = tf.placeholder(tf.float64, name='keep_prob')\n        # \u8bcd\u5411\u91cf\u6620\u5c04;\u5b9e\u9645\u4e0a\u6b64\u5904\u7684\u8bcd\u5411\u91cf\u5e76\u4e0d\u662f\u7528\u7684\u9884\u8bad\u7ec3\u597d\u7684\u8bcd\u5411\u91cf\uff0c\u800c\u662f\u672a\u7ecf\u4efb\u4f55\u8bad\u7ec3\u76f4\u63a5\u751f\u6210\u4e86\u4e00\u4e2a\u77e9\u9635\uff0c\u5c06\u6b64\u77e9\u9635\u4f5c\u4e3a\u8bcd\u5411\u91cf\u77e9\u9635\u4f7f\u7528\uff0c\u6548\u679c\u4e5f\u8fd8\u4e0d\u9519\u3002\n        # \u82e5\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u8bcd\u5411\u91cf\uff0c\u6216\u8bb8\u8bad\u7ec3\u6b64\u6b21\u6587\u672c\u5206\u7c7b\u7684\u6a21\u578b\u65f6\u4f1a\u66f4\u5feb\uff0c\u66f4\u597d\u3002\n        # embedding = tf.get_variable('embedding', [vocab_size, embedding_dim])\n        embedding_inputs = tf.nn.embedding_lookup(embedding, self.input_x)\n\n        num_filters = 256\n        kernel_size = 5\n        hidden_dim = 128\n        learning_rate = 1e-3\n\n        # CNN layer\n        conv = tf.layers.conv1d(embedding_inputs, num_filters, kernel_size, name='conv')  # num_filters = 256 \u8fd9\u662f\u4e2a\u5565\n        ''' https://blog.csdn.net/khy19940520/article/details/89934335\n        tf.layers.conv1d\uff1a\u4e00\u7ef4\u5377\u79ef\u4e00\u822c\u7528\u4e8e\u5904\u7406\u6587\u672c\u6570\u636e\uff0c\u5e38\u7528\u8bed\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\uff0c\u8f93\u5165\u4e00\u822c\u662f\u6587\u672c\u7ecf\u8fc7embedding\u7684\u4e8c\u7ef4\u6570\u636e\u3002\n            inputs\uff1a \u8f93\u5165tensor\uff0c \u7ef4\u5ea6(batch_size, seq_length, embedding_dim) \u662f\u4e00\u4e2a\u4e09\u7ef4\u7684tensor\uff1b\u5176\u4e2d\uff0c\n                batch_size\u6307\u6bcf\u6b21\u8f93\u5165\u7684\u6587\u672c\u6570\u91cf\uff1b\n                seq_length\u6307\u6bcf\u4e2a\u6587\u672c\u7684\u8bcd\u8bed\u6570\u6216\u8005\u5355\u5b57\u6570\uff1b\n                embedding_dim\u6307\u6bcf\u4e2a\u8bcd\u8bed\u6216\u8005\u6bcf\u4e2a\u5b57\u7684\u5411\u91cf\u957f\u5ea6\uff1b\n                \u4f8b\u5982\u6bcf\u6b21\u8bad\u7ec3\u8f93\u51652\u7bc7\u6587\u672c\uff0c\u6bcf\u7bc7\u6587\u672c\u6709100\u4e2a\u8bcd\uff0c\u6bcf\u4e2a\u8bcd\u7684\u5411\u91cf\u957f\u5ea6\u4e3a20\uff0c\u90a3input\u7ef4\u5ea6\u5373\u4e3a(2, 100, 20)\u3002\n            filters\uff1a\u8fc7\u6ee4\u5668\uff08\u5377\u79ef\u6838\uff09\u7684\u6570\u76ee\n            kernel_size\uff1a\u5377\u79ef\u6838\u7684\u5927\u5c0f\uff0c\u5377\u79ef\u6838\u672c\u8eab\u5e94\u8be5\u662f\u4e8c\u7ef4\u7684\uff0c\u8fd9\u91cc\u53ea\u9700\u8981\u6307\u5b9a\u4e00\u7ef4\uff0c\u56e0\u4e3a\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u5373\u957f\u5ea6\u4e0e\u8bcd\u5411\u91cf\u7684\u957f\u5ea6\u4e00\u81f4\uff0c\u5377\u79ef\u6838\u53ea\u80fd\u4ece\u4e0a\u5f80\u4e0b\u8d70\uff0c\u4e0d\u80fd\u4ece\u5de6\u5f80\u53f3\u8d70\uff0c\u5373\u53ea\u80fd\u6309\u7167\u6587\u672c\u4e2d\u8bcd\u7684\u987a\u5e8f\uff0c\u4e5f\u662f\u5217\u7684\u987a\u5e8f\u3002\n        '''\n        # global max pooling layer\n        gmp = tf.reduce_max(conv, reduction_indices=[1], name='gmp')  # https://blog.csdn.net/lllxxq141592654/article/details/85345864\n\n        # \u5168\u8fde\u63a5\u5c42\uff0c\u540e\u9762\u63a5dropout\u4ee5\u53carelu\u6fc0\u6d3b\n        fc = tf.layers.dense(gmp, hidden_dim, name='fc1')  # hidden_dim\uff1a128\n        ''' https://blog.csdn.net/yangfengling1023/article/details/81774580\n        dense \uff1a\u5168\u8fde\u63a5\u5c42  inputs\uff1a\u8f93\u5165\u8be5\u7f51\u7edc\u5c42\u7684\u6570\u636e\uff1bunits\uff1a\u8f93\u51fa\u7684\u7ef4\u5ea6\u5927\u5c0f\uff0c\u6539\u53d8inputs\u7684\u6700\u540e\u4e00\u7ef4\n        '''\n        fc = tf.nn.dropout(fc, self.keep_prob)\n        fc = tf.nn.relu(fc)\n\n        # \u5206\u7c7b\u5668\n        logits = tf.layers.dense(fc, num_classes, name='fc2')\n        self.y_pred_cls = tf.argmax(tf.nn.softmax(logits), 1)  # \u9884\u6d4b\u7c7b\u522b tf.argmax\uff1a\u8fd4\u56de\u6bcf\u4e00\u884c\u6216\u6bcf\u4e00\u5217\u7684\u6700\u5927\u503c 1\u4e3a\u91cc\u9762\uff08\u6bcf\u4e00\u884c\uff09\uff0c0\u4e3a\u5916\u9762\uff08\u6bcf\u4e00\u5217\uff09\n\n        # \u635f\u5931\u51fd\u6570\uff0c\u4ea4\u53c9\u71b5\n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=self.input_y)\n        self.loss = tf.reduce_mean(cross_entropy)\n        # \u4f18\u5316\u5668\n        self.optim = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss)\n\n        # \u51c6\u786e\u7387\n        correct_pred = tf.equal(tf.argmax(self.input_y, 1), self.y_pred_cls)\n        self.acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n        \n        self.saver = tf.train.Saver()\n        \n    \n    def train(self, x_train, y_train, split_type, fold_id, num_epochs=20, dropout_keep_prob=0.5, print_per_batch=30, batch_size=64):\n        \n        savePath = \"%s/%s/%s/%s\" % (self.savePath, split_type, fold_id, fold_id)\n        # \u521b\u5efasession\n        session = tf.Session()\n        session.run(tf.global_variables_initializer())\n        \n        print('Training and evaluating...')\n        start_time = time.time()\n        total_batch = 0  # \u603b\u6279\u6b21\n        best_acc_train = 0.0  # \u6700\u4f73\u9a8c\u8bc1\u96c6\u51c6\u786e\u7387\n        last_improved = 0  # \u8bb0\u5f55\u4e0a\u4e00\u6b21\u63d0\u5347\u6279\u6b21\n        require_improvement = 500  # \u5982\u679c\u8d85\u8fc71000\u8f6e\u672a\u63d0\u5347\uff0c\u63d0\u524d\u7ed3\u675f\u8bad\u7ec3\n        flag = False\n\n        for epoch in range(num_epochs):  # 20\n            print('Epoch:', epoch + 1)\n            batch_train = rnn_cnn.batch_iter(x_train, y_train, batch_size)\n            for x_batch, y_batch in batch_train:\n                feed_dict = {self.input_x: x_batch, self.input_y: y_batch, self.keep_prob: dropout_keep_prob}\n                session.run(self.optim, feed_dict=feed_dict)  # \u8fd0\u884c\u4f18\u5316\n                total_batch += 1\n\n                if total_batch % print_per_batch == 0:\n                    # \u6bcf\u591a\u5c11\u8f6e\u6b21\u8f93\u51fa\u5728\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6027\u80fd\n                    feed_dict[self.keep_prob] = 1.0\n                    loss_train, acc_train = session.run([self.loss, self.acc], feed_dict=feed_dict)\n                    # loss_val, acc_val = evaluate(session, x_dev, y_dev, loss, acc)\n                    if acc_train > best_acc_train:\n                        # \u4fdd\u5b58\u6700\u597d\u7ed3\u679c\n                        best_acc_train = acc_train\n                        last_improved = total_batch\n                        self.saver.save(sess=session, save_path=savePath)\n                        improved_str = '*'\n                    else:\n                        improved_str = ''\n\n                    time_dif = get_time_dif(start_time)\n                    msg = 'Iter: {0:>6}, Train Loss: {1:>6.2}, Train Acc: {2:>7.2%}, Time: {3} {4}'\n                    print(msg.format(total_batch, loss_train, acc_train, time_dif, improved_str))\n\n                if total_batch - last_improved > require_improvement:\n                    # \u9a8c\u8bc1\u96c6\u6b63\u786e\u7387\u957f\u671f\u4e0d\u63d0\u5347\uff0c\u63d0\u524d\u7ed3\u675f\u8bad\u7ec3\n                    print(\"No optimization for a long time, auto-stopping...\")\n                    flag = True\n                    break  # \u8df3\u51fa\u5faa\u73af\n            if flag:  # \u540c\u4e0a\n                break\n                \n        session.close()\n        return best_acc_train\n        \n        \n    def evaluate_model(self, x_test, y_test, split_type, fold_id, categories, batch_size=64):\n        \n        savePath = \"%s/%s/%s/%s\" % (self.savePath, split_type, fold_id, fold_id)\n        # \u8bfb\u53d6\u4fdd\u5b58\u7684\u6a21\u578b\n        session = tf.Session()\n        self.saver.restore(sess=session, save_path=savePath)\n        start_time = time.time()\n        print('Testing...')\n        loss_test, acc_test = self.evaluate(session, x_test, y_test, self.loss, self.acc, batch_size)\n        msg = 'Test Loss: {0:>6.2}, Test Acc: {1:>7.2%}'\n        print(msg.format(loss_test, acc_test))\n\n        test_data_len = len(x_test)\n        test_num_batch = int((test_data_len - 1) / batch_size) + 1\n\n        y_test_cls = np.argmax(y_test, 1)  # \u83b7\u5f97\u7c7b\u522b\n        y_test_pred_cls = np.zeros(shape=len(x_test), dtype=np.int32)  # \u4fdd\u5b58\u9884\u6d4b\u7ed3\u679c  len(x_test) \u8868\u793a\u6709\u591a\u5c11\u4e2a\u6587\u672c\n\n        for i in range(test_num_batch):  # \u9010\u6279\u6b21\u5904\u7406\n            start_id = i * batch_size\n            end_id = min((i + 1) * batch_size, test_data_len)\n            feed_dict = {\n                self.input_x: x_test[start_id:end_id],\n                self.keep_prob: 1.0\n            }\n            y_test_pred_cls[start_id:end_id] = session.run(self.y_pred_cls, feed_dict=feed_dict)\n\n        # \u8bc4\u4f30\n        print(\"Precision, Recall and F1-Score...\")\n        print(metrics.classification_report(y_test_cls, y_test_pred_cls, target_names=categories))\n        '''\n        sklearn\u4e2d\u7684classification_report\u51fd\u6570\u7528\u4e8e\u663e\u793a\u4e3b\u8981\u5206\u7c7b\u6307\u6807\u7684\u6587\u672c\u62a5\u544a\uff0e\u5728\u62a5\u544a\u4e2d\u663e\u793a\u6bcf\u4e2a\u7c7b\u7684\u7cbe\u786e\u5ea6\uff0c\u53ec\u56de\u7387\uff0cF1\u503c\u7b49\u4fe1\u606f\u3002\n            y_true\uff1a1\u7ef4\u6570\u7ec4\uff0c\u6216\u6807\u7b7e\u6307\u793a\u5668\u6570\u7ec4/\u7a00\u758f\u77e9\u9635\uff0c\u76ee\u6807\u503c\u3002 \n            y_pred\uff1a1\u7ef4\u6570\u7ec4\uff0c\u6216\u6807\u7b7e\u6307\u793a\u5668\u6570\u7ec4/\u7a00\u758f\u77e9\u9635\uff0c\u5206\u7c7b\u5668\u8fd4\u56de\u7684\u4f30\u8ba1\u503c\u3002 \n            labels\uff1aarray\uff0cshape = [n_labels]\uff0c\u62a5\u8868\u4e2d\u5305\u542b\u7684\u6807\u7b7e\u7d22\u5f15\u7684\u53ef\u9009\u5217\u8868\u3002 \n            target_names\uff1a\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u4e0e\u6807\u7b7e\u5339\u914d\u7684\u53ef\u9009\u663e\u793a\u540d\u79f0\uff08\u76f8\u540c\u987a\u5e8f\uff09\u3002 \n            \u539f\u6587\u94fe\u63a5\uff1ahttps://blog.csdn.net/akadiao/article/details/78788864\n        '''\n\n        # \u6df7\u6dc6\u77e9\u9635\n        print(\"Confusion Matrix...\")\n        cm = metrics.confusion_matrix(y_test_cls, y_test_pred_cls)\n        '''\n        \u6df7\u6dc6\u77e9\u9635\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u603b\u7ed3\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u60c5\u5f62\u5206\u6790\u8868\uff0c\u4ee5\u77e9\u9635\u5f62\u5f0f\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u8bb0\u5f55\u6309\u7167\u771f\u5b9e\u7684\u7c7b\u522b\u4e0e\u5206\u7c7b\u6a21\u578b\u4f5c\u51fa\u7684\u5206\u7c7b\u5224\u65ad\u4e24\u4e2a\u6807\u51c6\u8fdb\u884c\u6c47\u603b\u3002\n        \u8fd9\u4e2a\u540d\u5b57\u6765\u6e90\u4e8e\u5b83\u53ef\u4ee5\u975e\u5e38\u5bb9\u6613\u7684\u8868\u660e\u591a\u4e2a\u7c7b\u522b\u662f\u5426\u6709\u6df7\u6dc6\uff08\u4e5f\u5c31\u662f\u4e00\u4e2aclass\u88ab\u9884\u6d4b\u6210\u53e6\u4e00\u4e2aclass\uff09\n        https://blog.csdn.net/u011734144/article/details/80277225\n        '''\n        print(cm)\n\n        time_dif = get_time_dif(start_time)\n        print(\"Time usage:\", time_dif)\n        session.close()\n        \n        return acc_test\n        \n        \n    def predict(self, predict_sentences, word_to_id, pad_max_length, split_type, fold_id):\n        \"\"\"\n        \u5c06\u6587\u4ef6\u8f6c\u6362\u4e3aid\u8868\u793a,\u5e76\u4e14\u5c06\u6bcf\u4e2a\u5355\u72ec\u7684\u6837\u672c\u957f\u5ea6\u56fa\u5b9a\u4e3apad_max_lengtn\n        \"\"\"\n        savePath = \"%s/%s/%s/%s\" % (self.savePath, split_type, fold_id, fold_id)\n        session = tf.Session()\n        self.saver.restore(sess=session, save_path=savePath)\n        \n        data_id = []\n        # \u5c06\u6587\u672c\u5185\u5bb9\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684id\u5f62\u5f0f\n        for i in range(len(predict_sentences)):\n            data_id.append([word_to_id[x] for x in predict_sentences[i].lower().strip().split() if x in word_to_id])\n\n        # \u4f7f\u7528keras\u63d0\u4f9b\u7684pad_sequences\u6765\u5c06\u6587\u672cpad\u4e3a\u56fa\u5b9a\u957f\u5ea6\n        x_pad = kr.preprocessing.sequence.pad_sequences(data_id, pad_max_length)\n        ''' https://blog.csdn.net/TH_NUM/article/details/80904900\n        pad_sequences(sequences, maxlen=None, dtype=\u2019int32\u2019, padding=\u2019pre\u2019, truncating=\u2019pre\u2019, value=0.) \n            sequences\uff1a\u6d6e\u70b9\u6570\u6216\u6574\u6570\u6784\u6210\u7684\u4e24\u5c42\u5d4c\u5957\u5217\u8868\n            maxlen\uff1aNone\u6216\u6574\u6570\uff0c\u4e3a\u5e8f\u5217\u7684\u6700\u5927\u957f\u5ea6\u3002\u5927\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u88ab\u622a\u77ed\uff0c\u5c0f\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u5728\u540e\u90e8\u586b0.\n            dtype\uff1a\u8fd4\u56de\u7684numpy array\u7684\u6570\u636e\u7c7b\u578b\n            padding\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u88650\u65f6\uff0c\u5728\u5e8f\u5217\u7684\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u8865\n            truncating\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u622a\u65ad\u5e8f\u5217\u65f6\uff0c\u4ece\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u622a\u65ad\n            value\uff1a\u6d6e\u70b9\u6570\uff0c\u6b64\u503c\u5c06\u5728\u586b\u5145\u65f6\u4ee3\u66ff\u9ed8\u8ba4\u7684\u586b\u5145\u503c0\n        '''\n        feed_dict = {\n            self.input_x: x_pad,\n            self.keep_prob: 1.0\n        }\n        predict_result = session.run(self.y_pred_cls, feed_dict=feed_dict)\n        predict_result = [i+1 for i in predict_result]\n        session.close()\n        \n        return predict_result\n    \n    \n    def evaluate(self, sess, x_pad, y_pad, loss1, acc1, batch_size):\n        \"\"\"\u8bc4\u4f30\u5728\u67d0\u4e00\u6570\u636e\u4e0a\u7684\u51c6\u786e\u7387\u548c\u635f\u5931\"\"\"\n        data_len = len(x_pad)\n        batch_eval = rnn_cnn.batch_iter(x_pad, y_pad, batch_size)  \n        total_loss = 0.0\n        total_acc = 0.0\n        # print(dropout_keep_prob)\n        for x_batch1, y_batch1 in batch_eval:\n            batch_len = len(x_batch1)\n            feed_dict1 = {self.input_x: x_batch1, self.input_y: y_batch1, self.keep_prob: 1.0}\n            lossTmp, accTmp = sess.run([loss1, acc1], feed_dict=feed_dict1)\n            total_loss += lossTmp * batch_len\n            total_acc += accTmp * batch_len\n\n        return total_loss / data_len, total_acc / data_len\n    \n    \n    def batch_iter(x_pad, y_pad, batch_size=64):  # 128\n        \"\"\"\u751f\u6210\u6279\u6b21\u6570\u636e\"\"\"\n        data_len = len(x_pad)\n        num_batch = int((data_len - 1) / batch_size) + 1\n        # np.arange()\u751f\u62100\u5230data_len\u7684\u7b49\u5dee\u6570\u5217\uff0c\u9ed8\u8ba4\u7b49\u5dee\u4e3a1\uff1bnp.random.permutation()\u6253\u4e71\u751f\u6210\u7684\u7b49\u5dee\u5e8f\u5217\u7684\u987a\u5e8f\n        # \u4e0b\u9762\u4e09\u53e5\u8bed\u53e5\u662f\u4e3a\u4e86\u5c06\u8bad\u7ec3\u6216\u6d4b\u8bd5\u6587\u672c\u7684\u987a\u5e8f\u6253\u4e71\uff0c\u56e0\u4e3a\u539f\u6587\u672c\u4e2d\u6bcf\u4e2a\u5206\u7c7b\u7684\u6837\u672c\u5168\u90e8\u6328\u5728\u4e00\u8d77\uff0c\u8fd9\u6837\u6bcf\u4e2abatch\u8bad\u7ec3\u7684\u90fd\u662f\u540c\u4e00\u4e2a\u5206\u7c7b\uff0c\u4e0d\u592a\u597d\uff0c\u6253\u4e71\u540e\u6bcf\u4e2abatch\u53ef\u5305\u542b\u4e0d\u540c\u5206\u7c7b\n        indices = np.random.permutation(np.arange(data_len))\n        x_shuffle = x_pad[indices]\n        y_shuffle = y_pad[indices]\n\n        # \u8fd4\u56de\u6240\u6709batch\u7684\u6570\u636e\n        for i in range(num_batch):\n            start_id = i * batch_size\n            end_id = min((i + 1) * batch_size, data_len)\n            yield x_shuffle[start_id:end_id], y_shuffle[start_id:end_id]\n            \n            ", "execution_count": 27, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "kf = KFold(n_splits=10)\nfold_id = 0\nmodel_train_acc = []\nmodel_test_acc = []\nmodel = rnn_cnn(savePath, num_classes)", "execution_count": 29, "outputs": [{"output_type": "stream", "text": "WARNING:tensorflow:From <ipython-input-27-10b7ccfe3726>:48: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n\n", "name": "stdout"}, {"output_type": "stream", "text": "WARNING:tensorflow:From <ipython-input-27-10b7ccfe3726>:48: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "split_type = \"random\"\nfor train_i, test_i in kf.split(x_train):\n    fold_id += 1\n    print(\"Fold: \", fold_id)\n    model_train_acc.append(model.train(x_train[train_i], y_train[train_i],split_type,fold_id))\n    model_test_acc.append(model.evaluate_model(x_train[test_i], y_train[test_i],split_type,fold_id,categories))", "execution_count": 30, "outputs": [{"output_type": "stream", "text": "Fold:  1\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  29.69%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.7, Train Acc:  50.00%, Time: 0:00:12 *\nIter:     90, Train Loss:    1.4, Train Acc:  64.06%, Time: 0:00:17 *\nIter:    120, Train Loss:    1.1, Train Acc:  73.44%, Time: 0:00:22 *\nIter:    150, Train Loss:    1.0, Train Acc:  71.88%, Time: 0:00:23 \nIter:    180, Train Loss:   0.52, Train Acc:  89.06%, Time: 0:00:28 *\nEpoch: 2\nIter:    210, Train Loss:   0.66, Train Acc:  84.38%, Time: 0:00:29 \nIter:    240, Train Loss:   0.84, Train Acc:  82.81%, Time: 0:00:30 \nIter:    270, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:00:34 *\nIter:    300, Train Loss:   0.55, Train Acc:  84.38%, Time: 0:00:35 \nIter:    330, Train Loss:   0.42, Train Acc:  85.94%, Time: 0:00:36 \nIter:    360, Train Loss:    0.6, Train Acc:  81.25%, Time: 0:00:36 \nIter:    390, Train Loss:   0.48, Train Acc:  92.19%, Time: 0:00:43 *\nEpoch: 3\nIter:    420, Train Loss:   0.25, Train Acc:  95.31%, Time: 0:00:48 *\nIter:    450, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:00:49 \nIter:    480, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:00:54 *\nIter:    510, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:00:55 \nIter:    540, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:56 \nIter:    570, Train Loss:  0.099, Train Acc:  96.88%, Time: 0:00:56 \nEpoch: 4\nIter:    600, Train Loss:   0.16, Train Acc:  95.31%, Time: 0:00:57 \nIter:    630, Train Loss:   0.16, Train Acc:  95.31%, Time: 0:00:58 \nIter:    660, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:00:58 \nIter:    690, Train Loss:  0.062, Train Acc: 100.00%, Time: 0:01:04 *\nIter:    720, Train Loss:  0.089, Train Acc:  98.44%, Time: 0:01:05 \nIter:    750, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:06 \nIter:    780, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:06 \nEpoch: 5\nIter:    810, Train Loss:  0.061, Train Acc:  98.44%, Time: 0:01:07 \nIter:    840, Train Loss:  0.042, Train Acc:  98.44%, Time: 0:01:08 \nIter:    870, Train Loss:  0.042, Train Acc: 100.00%, Time: 0:01:08 \nIter:    900, Train Loss:   0.04, Train Acc: 100.00%, Time: 0:01:09 \nIter:    930, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:10 \nIter:    960, Train Loss:  0.065, Train Acc:  98.44%, Time: 0:01:10 \nIter:    990, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:11 \nEpoch: 6\nIter:   1020, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:12 \nIter:   1050, Train Loss:  0.037, Train Acc:  98.44%, Time: 0:01:12 \nIter:   1080, Train Loss:  0.017, Train Acc:  98.44%, Time: 0:01:13 \nIter:   1110, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:14 \nIter:   1140, Train Loss:  0.015, Train Acc: 100.00%, Time: 0:01:14 \nIter:   1170, Train Loss:  0.031, Train Acc:  98.44%, Time: 0:01:15 \nEpoch: 7\nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/1/1\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/1/1\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.27, Test Acc:  91.52%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.89      0.95      0.92       152\n                   Filter       0.79      0.91      0.85       136\n    Compute Derived Value       0.92      0.85      0.88       117\n            Find Extremum       0.95      0.89      0.92       164\n                     Sort       0.94      0.94      0.94       124\n          Determine Range       0.92      0.92      0.92       139\nCharacterize Distribution       0.91      0.88      0.90       130\n           Find Anomalies       0.99      0.89      0.94       141\n                  Cluster       0.95      0.95      0.95       140\n                Correlate       0.91      0.95      0.93       161\n\n                micro avg       0.92      0.92      0.92      1404\n                macro avg       0.92      0.91      0.91      1404\n             weighted avg       0.92      0.92      0.92      1404\n\nConfusion Matrix...\n[[145   2   0   2   1   0   0   1   0   1]\n [  3 124   1   1   1   4   1   0   0   1]\n [  8   2 100   0   0   3   2   0   0   2]\n [  3   7   2 146   1   1   1   0   1   2]\n [  2   1   1   2 116   0   1   0   1   0]\n [  0   4   1   0   2 128   1   0   0   3]\n [  0   3   2   1   1   3 115   0   3   2]\n [  0  10   1   1   0   0   1 125   1   2]\n [  0   2   0   0   1   0   2   0 133   2]\n [  2   1   1   1   0   0   2   0   1 153]]\nTime usage: 0:00:02\nFold:  2\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  40.62%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.8, Train Acc:  46.88%, Time: 0:00:12 *\nIter:     90, Train Loss:    1.3, Train Acc:  67.19%, Time: 0:00:16 *\nIter:    120, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:17 \nIter:    150, Train Loss:    1.1, Train Acc:  71.88%, Time: 0:00:21 *\nIter:    180, Train Loss:   0.91, Train Acc:  68.75%, Time: 0:00:21 \nEpoch: 2\nIter:    210, Train Loss:   0.57, Train Acc:  84.38%, Time: 0:00:26 *\nIter:    240, Train Loss:   0.59, Train Acc:  82.81%, Time: 0:00:27 \nIter:    270, Train Loss:   0.64, Train Acc:  82.81%, Time: 0:00:27 \nIter:    300, Train Loss:   0.49, Train Acc:  87.50%, Time: 0:00:32 *\nIter:    330, Train Loss:   0.45, Train Acc:  82.81%, Time: 0:00:32 \nIter:    360, Train Loss:   0.33, Train Acc:  92.19%, Time: 0:00:37 *\nIter:    390, Train Loss:   0.44, Train Acc:  89.06%, Time: 0:00:37 \nEpoch: 3\nIter:    420, Train Loss:   0.24, Train Acc:  92.19%, Time: 0:00:38 \nIter:    450, Train Loss:   0.19, Train Acc:  95.31%, Time: 0:00:45 *\nIter:    480, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:00:50 *\nIter:    510, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:00:50 \nIter:    540, Train Loss:   0.13, Train Acc:  95.31%, Time: 0:00:51 \nIter:    570, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:00:52 \nEpoch: 4\nIter:    600, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:00:56 *\nIter:    630, Train Loss:  0.055, Train Acc: 100.00%, Time: 0:01:01 *\nIter:    660, Train Loss:   0.26, Train Acc:  96.88%, Time: 0:01:01 \nIter:    690, Train Loss:   0.05, Train Acc: 100.00%, Time: 0:01:02 \nIter:    720, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:01:03 \nIter:    750, Train Loss:  0.098, Train Acc:  96.88%, Time: 0:01:04 \nIter:    780, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:01:04 \nEpoch: 5\nIter:    810, Train Loss:  0.037, Train Acc: 100.00%, Time: 0:01:05 \nIter:    840, Train Loss:  0.048, Train Acc: 100.00%, Time: 0:01:06 \nIter:    870, Train Loss:  0.062, Train Acc:  96.88%, Time: 0:01:06 \nIter:    900, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:07 \nIter:    930, Train Loss:   0.14, Train Acc:  98.44%, Time: 0:01:08 \nIter:    960, Train Loss:  0.071, Train Acc:  96.88%, Time: 0:01:08 \nIter:    990, Train Loss: 0.0065, Train Acc: 100.00%, Time: 0:01:09 \nEpoch: 6\nIter:   1020, Train Loss:  0.056, Train Acc:  98.44%, Time: 0:01:10 \nIter:   1050, Train Loss:  0.026, Train Acc: 100.00%, Time: 0:01:10 \nIter:   1080, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:11 \nIter:   1110, Train Loss:  0.049, Train Acc:  98.44%, Time: 0:01:12 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/2/2\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/2/2\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.32, Test Acc:  89.53%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.93      0.94      0.94       109\n                   Filter       0.95      0.87      0.91       156\n    Compute Derived Value       0.89      0.88      0.88       141\n            Find Extremum       0.89      0.95      0.92       190\n                     Sort       0.96      0.88      0.92       138\n          Determine Range       0.84      0.88      0.86       139\nCharacterize Distribution       0.95      0.83      0.89       148\n           Find Anomalies       0.89      0.87      0.88       141\n                  Cluster       0.80      0.93      0.86       114\n                Correlate       0.87      0.92      0.90       128\n\n                micro avg       0.90      0.90      0.90      1404\n                macro avg       0.90      0.90      0.89      1404\n             weighted avg       0.90      0.90      0.90      1404\n\nConfusion Matrix...\n[[103   0   3   1   0   1   0   0   0   1]\n [  2 136   4   5   0   5   0   4   0   0]\n [  4   1 124   4   1   0   3   1   1   2]\n [  0   0   1 181   0   3   1   0   2   2]\n [  0   0   0   6 121   3   0   0   7   1]\n [  1   1   1   4   2 122   2   0   4   2]\n [  0   1   5   2   2   5 123   1   4   5]\n [  0   3   0   0   0   4   0 123   8   3]\n [  1   0   1   0   0   2   0   3 106   1]\n [  0   1   1   0   0   1   0   6   1 118]]\nTime usage: 0:00:02\nFold:  3\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  46.88%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.6, Train Acc:  51.56%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.2, Train Acc:  64.06%, Time: 0:00:19 *\nIter:    120, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:00:20 \nIter:    150, Train Loss:    0.8, Train Acc:  78.12%, Time: 0:00:26 *\nIter:    180, Train Loss:   0.63, Train Acc:  85.94%, Time: 0:00:31 *\nEpoch: 2\nIter:    210, Train Loss:   0.69, Train Acc:  84.38%, Time: 0:00:31 \nIter:    240, Train Loss:   0.55, Train Acc:  89.06%, Time: 0:00:36 *\nIter:    270, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:00:37 \nIter:    300, Train Loss:   0.74, Train Acc:  75.00%, Time: 0:00:37 \nIter:    330, Train Loss:   0.51, Train Acc:  82.81%, Time: 0:00:38 \nIter:    360, Train Loss:   0.38, Train Acc:  85.94%, Time: 0:00:39 \nIter:    390, Train Loss:   0.29, Train Acc:  92.19%, Time: 0:00:43 *\nEpoch: 3\nIter:    420, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:48 *\nIter:    450, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:00:49 \nIter:    480, Train Loss:   0.14, Train Acc:  95.31%, Time: 0:00:49 \nIter:    510, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:00:50 \nIter:    540, Train Loss:   0.23, Train Acc:  95.31%, Time: 0:00:51 \nIter:    570, Train Loss:   0.32, Train Acc:  89.06%, Time: 0:00:51 \nEpoch: 4\nIter:    600, Train Loss:  0.084, Train Acc:  98.44%, Time: 0:00:58 *\nIter:    630, Train Loss:  0.082, Train Acc: 100.00%, Time: 0:01:03 *\nIter:    660, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:04 \nIter:    690, Train Loss:   0.16, Train Acc:  95.31%, Time: 0:01:05 \nIter:    720, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:01:05 \nIter:    750, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:01:06 \nIter:    780, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:01:07 \nEpoch: 5\nIter:    810, Train Loss:  0.076, Train Acc:  98.44%, Time: 0:01:07 \nIter:    840, Train Loss:  0.046, Train Acc:  98.44%, Time: 0:01:08 \nIter:    870, Train Loss:  0.027, Train Acc: 100.00%, Time: 0:01:09 \nIter:    900, Train Loss:  0.054, Train Acc:  98.44%, Time: 0:01:09 \nIter:    930, Train Loss:  0.058, Train Acc:  98.44%, Time: 0:01:10 \nIter:    960, Train Loss:  0.082, Train Acc:  96.88%, Time: 0:01:11 \nIter:    990, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:11 \nEpoch: 6\nIter:   1020, Train Loss:  0.029, Train Acc:  98.44%, Time: 0:01:12 \nIter:   1050, Train Loss:  0.035, Train Acc: 100.00%, Time: 0:01:13 \nIter:   1080, Train Loss:  0.056, Train Acc:  98.44%, Time: 0:01:13 \nIter:   1110, Train Loss:  0.043, Train Acc:  98.44%, Time: 0:01:14 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/3/3\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/3/3\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.36, Test Acc:  89.32%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.91      0.91      0.91       152\n                   Filter       0.91      0.80      0.85       118\n    Compute Derived Value       0.91      0.89      0.90       168\n            Find Extremum       0.89      0.95      0.92       168\n                     Sort       0.82      0.97      0.89       110\n          Determine Range       0.83      0.81      0.82       118\nCharacterize Distribution       0.94      0.84      0.89       153\n           Find Anomalies       0.87      0.86      0.86       126\n                  Cluster       0.89      0.91      0.90       115\n                Correlate       0.92      0.94      0.93       176\n\n                micro avg       0.89      0.89      0.89      1404\n                macro avg       0.89      0.89      0.89      1404\n             weighted avg       0.89      0.89      0.89      1404\n\nConfusion Matrix...\n[[139   0   4   2   0   1   2   2   1   1]\n [  3  94   3   1   4   5   1   5   1   1]\n [  4   0 150   3   1   5   1   2   0   2]\n [  1   0   0 160   7   0   0   0   0   0]\n [  0   0   0   0 107   1   1   0   1   0]\n [  4   1   1   3   5  96   0   2   4   2]\n [  1   2   5   3   2   4 129   1   2   4]\n [  0   4   1   3   0   3   3 108   0   4]\n [  0   1   0   3   4   0   0   2 105   0]\n [  1   1   1   1   0   0   0   2   4 166]]\nTime usage: 0:00:02\nFold:  4\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.7, Train Acc:  42.19%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.5, Train Acc:  54.69%, Time: 0:00:20 *\nIter:    120, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:26 *\nIter:    150, Train Loss:    1.0, Train Acc:  76.56%, Time: 0:00:32 *\nIter:    180, Train Loss:   0.74, Train Acc:  82.81%, Time: 0:00:37 *\nEpoch: 2\nIter:    210, Train Loss:   0.74, Train Acc:  79.69%, Time: 0:00:38 \nIter:    240, Train Loss:   0.68, Train Acc:  78.12%, Time: 0:00:39 \nIter:    270, Train Loss:   0.56, Train Acc:  87.50%, Time: 0:00:45 *\nIter:    300, Train Loss:   0.62, Train Acc:  76.56%, Time: 0:00:46 \nIter:    330, Train Loss:   0.34, Train Acc:  89.06%, Time: 0:00:50 *\nIter:    360, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:00:51 \nIter:    390, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:00:57 *\nEpoch: 3\nIter:    420, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:03 *\nIter:    450, Train Loss:   0.28, Train Acc:  87.50%, Time: 0:01:04 \nIter:    480, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:04 \nIter:    510, Train Loss:   0.39, Train Acc:  93.75%, Time: 0:01:05 \nIter:    540, Train Loss:   0.15, Train Acc: 100.00%, Time: 0:01:10 *\nIter:    570, Train Loss:   0.17, Train Acc:  95.31%, Time: 0:01:11 \nEpoch: 4\nIter:    600, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:11 \nIter:    630, Train Loss:  0.086, Train Acc:  98.44%, Time: 0:01:12 \nIter:    660, Train Loss:  0.067, Train Acc:  96.88%, Time: 0:01:13 \nIter:    690, Train Loss:  0.081, Train Acc: 100.00%, Time: 0:01:13 \nIter:    720, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:14 \nIter:    750, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:01:15 \nIter:    780, Train Loss:  0.076, Train Acc:  96.88%, Time: 0:01:16 \nEpoch: 5\nIter:    810, Train Loss:  0.061, Train Acc:  98.44%, Time: 0:01:16 \nIter:    840, Train Loss:   0.05, Train Acc: 100.00%, Time: 0:01:17 \nIter:    870, Train Loss:   0.04, Train Acc: 100.00%, Time: 0:01:18 \nIter:    900, Train Loss:  0.025, Train Acc: 100.00%, Time: 0:01:18 \nIter:    930, Train Loss:  0.066, Train Acc:  96.88%, Time: 0:01:19 \nIter:    960, Train Loss:  0.071, Train Acc:  98.44%, Time: 0:01:20 \nIter:    990, Train Loss:  0.013, Train Acc: 100.00%, Time: 0:01:20 \nEpoch: 6\nIter:   1020, Train Loss:  0.015, Train Acc: 100.00%, Time: 0:01:21 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/4/4\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/4/4\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.35, Test Acc:  88.82%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.89      0.88      0.88       139\n                   Filter       0.76      0.92      0.83       144\n    Compute Derived Value       0.87      0.89      0.88       138\n            Find Extremum       0.94      0.90      0.92       169\n                     Sort       0.96      0.90      0.93       125\n          Determine Range       0.91      0.86      0.88       134\nCharacterize Distribution       0.94      0.89      0.91       138\n           Find Anomalies       0.84      0.89      0.86       140\n                  Cluster       0.85      0.89      0.87       121\n                Correlate       0.97      0.86      0.91       156\n\n                micro avg       0.89      0.89      0.89      1404\n                macro avg       0.89      0.89      0.89      1404\n             weighted avg       0.89      0.89      0.89      1404\n\nConfusion Matrix...\n[[122   7   3   1   1   0   2   2   1   0]\n [  2 133   1   1   0   0   0   5   2   0]\n [  3   4 123   0   0   2   1   1   3   1]\n [  2   4   3 152   1   4   0   3   0   0]\n [  0   2   0   3 113   0   2   0   5   0]\n [  1  11   2   2   3 115   0   0   0   0]\n [  2   2   2   1   0   4 123   1   3   0]\n [  2   8   0   1   0   1   1 124   0   3]\n [  1   0   4   0   0   1   1   6 108   0]\n [  2   5   3   0   0   0   1   6   5 134]]\nTime usage: 0:00:02\nFold:  5\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.7, Train Acc:  53.12%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.5, Train Acc:  57.81%, Time: 0:00:19 *\nIter:    120, Train Loss:    1.2, Train Acc:  68.75%, Time: 0:00:23 *\nIter:    150, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:24 \nIter:    180, Train Loss:   0.86, Train Acc:  78.12%, Time: 0:00:31 *\nEpoch: 2\nIter:    210, Train Loss:   0.55, Train Acc:  87.50%, Time: 0:00:37 *\nIter:    240, Train Loss:   0.64, Train Acc:  85.94%, Time: 0:00:38 \nIter:    270, Train Loss:   0.53, Train Acc:  84.38%, Time: 0:00:38 \nIter:    300, Train Loss:   0.57, Train Acc:  81.25%, Time: 0:00:39 \nIter:    330, Train Loss:   0.61, Train Acc:  79.69%, Time: 0:00:40 \nIter:    360, Train Loss:   0.31, Train Acc:  89.06%, Time: 0:00:44 *\nIter:    390, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:00:50 *\nEpoch: 3\nIter:    420, Train Loss:   0.24, Train Acc:  90.62%, Time: 0:00:50 \nIter:    450, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:00:55 *\nIter:    480, Train Loss:   0.23, Train Acc:  95.31%, Time: 0:00:56 \nIter:    510, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:01:00 *\nIter:    540, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:01 \nIter:    570, Train Loss:   0.22, Train Acc:  98.44%, Time: 0:01:02 \nEpoch: 4\nIter:    600, Train Loss:  0.093, Train Acc:  98.44%, Time: 0:01:02 \nIter:    630, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:03 \nIter:    660, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:01:04 \nIter:    690, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:04 \nIter:    720, Train Loss:   0.08, Train Acc: 100.00%, Time: 0:01:10 *\nIter:    750, Train Loss:   0.09, Train Acc: 100.00%, Time: 0:01:11 \nIter:    780, Train Loss:   0.14, Train Acc:  95.31%, Time: 0:01:11 \nEpoch: 5\nIter:    810, Train Loss:  0.052, Train Acc:  98.44%, Time: 0:01:12 \nIter:    840, Train Loss:  0.046, Train Acc:  98.44%, Time: 0:01:13 \nIter:    870, Train Loss:  0.054, Train Acc: 100.00%, Time: 0:01:13 \nIter:    900, Train Loss:  0.074, Train Acc:  98.44%, Time: 0:01:14 \nIter:    930, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:15 \nIter:    960, Train Loss:  0.055, Train Acc:  98.44%, Time: 0:01:15 \nIter:    990, Train Loss:    0.1, Train Acc: 100.00%, Time: 0:01:16 \nEpoch: 6\nIter:   1020, Train Loss:  0.029, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1050, Train Loss:  0.006, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1080, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:18 \nIter:   1110, Train Loss:  0.015, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1140, Train Loss:  0.028, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1170, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:01:20 \nEpoch: 7\nIter:   1200, Train Loss: 0.0067, Train Acc: 100.00%, Time: 0:01:21 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/5/5\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/5/5\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.28, Test Acc:  92.02%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.98      0.93      0.96       130\n                   Filter       0.89      0.84      0.86       151\n    Compute Derived Value       0.89      0.92      0.91       193\n            Find Extremum       0.95      0.92      0.94       159\n                     Sort       0.96      0.94      0.95       122\n          Determine Range       0.79      0.97      0.87       141\nCharacterize Distribution       0.98      0.86      0.92       107\n           Find Anomalies       0.96      0.92      0.94       139\n                  Cluster       0.97      0.89      0.93       119\n                Correlate       0.91      0.99      0.95       143\n\n                micro avg       0.92      0.92      0.92      1404\n                macro avg       0.93      0.92      0.92      1404\n             weighted avg       0.92      0.92      0.92      1404\n\nConfusion Matrix...\n[[121   3   5   0   0   1   0   0   0   0]\n [  1 127   6   4   1   7   0   3   0   2]\n [  1   3 178   0   0   9   0   0   0   2]\n [  0   1   1 147   4   3   1   1   0   1]\n [  0   0   0   1 115   5   0   0   1   0]\n [  0   1   3   0   0 137   0   0   0   0]\n [  0   3   3   0   0   5  92   0   1   3]\n [  0   5   2   1   0   1   1 128   0   1]\n [  0   0   1   1   0   5   0   1 106   5]\n [  0   0   0   0   0   0   0   1   1 141]]\nTime usage: 0:00:02\nFold:  6\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  32.81%, Time: 0:00:09 *\nIter:     60, Train Loss:    1.8, Train Acc:  46.88%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.5, Train Acc:  60.94%, Time: 0:00:18 *\nIter:    120, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:00:24 *\nIter:    150, Train Loss:    1.1, Train Acc:  62.50%, Time: 0:00:25 \nIter:    180, Train Loss:   0.76, Train Acc:  85.94%, Time: 0:00:31 *\nEpoch: 2\nIter:    210, Train Loss:   0.57, Train Acc:  84.38%, Time: 0:00:32 \nIter:    240, Train Loss:   0.58, Train Acc:  82.81%, Time: 0:00:32 \nIter:    270, Train Loss:   0.68, Train Acc:  82.81%, Time: 0:00:33 \nIter:    300, Train Loss:    0.5, Train Acc:  82.81%, Time: 0:00:34 \nIter:    330, Train Loss:   0.34, Train Acc:  89.06%, Time: 0:00:40 *\nIter:    360, Train Loss:   0.56, Train Acc:  79.69%, Time: 0:00:41 \nIter:    390, Train Loss:   0.57, Train Acc:  89.06%, Time: 0:00:42 \nEpoch: 3\nIter:    420, Train Loss:   0.23, Train Acc:  95.31%, Time: 0:00:47 *\nIter:    450, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:48 \nIter:    480, Train Loss:   0.25, Train Acc:  92.19%, Time: 0:00:48 \nIter:    510, Train Loss:   0.17, Train Acc:  98.44%, Time: 0:00:54 *\nIter:    540, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:00:55 \nIter:    570, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:00:56 \nEpoch: 4\nIter:    600, Train Loss:  0.072, Train Acc:  96.88%, Time: 0:00:56 \nIter:    630, Train Loss:   0.13, Train Acc:  98.44%, Time: 0:00:57 \nIter:    660, Train Loss:  0.085, Train Acc: 100.00%, Time: 0:01:03 *\nIter:    690, Train Loss:  0.098, Train Acc:  98.44%, Time: 0:01:04 \nIter:    720, Train Loss:   0.14, Train Acc:  95.31%, Time: 0:01:05 \nIter:    750, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:05 \nIter:    780, Train Loss:  0.059, Train Acc: 100.00%, Time: 0:01:06 \nEpoch: 5\nIter:    810, Train Loss:  0.061, Train Acc:  98.44%, Time: 0:01:07 \nIter:    840, Train Loss:  0.082, Train Acc:  98.44%, Time: 0:01:07 \nIter:    870, Train Loss:  0.085, Train Acc:  98.44%, Time: 0:01:08 \nIter:    900, Train Loss:  0.046, Train Acc:  98.44%, Time: 0:01:09 \nIter:    930, Train Loss:  0.036, Train Acc:  98.44%, Time: 0:01:09 \nIter:    960, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:10 \nIter:    990, Train Loss:  0.024, Train Acc: 100.00%, Time: 0:01:11 \nEpoch: 6\nIter:   1020, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:11 \nIter:   1050, Train Loss:  0.013, Train Acc: 100.00%, Time: 0:01:12 \nIter:   1080, Train Loss:  0.023, Train Acc:  98.44%, Time: 0:01:13 \nIter:   1110, Train Loss:  0.042, Train Acc:  98.44%, Time: 0:01:13 \nIter:   1140, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:14 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/6/6\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/6/6\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.34, Test Acc:  89.59%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.97      0.90      0.93       162\n                   Filter       0.85      0.85      0.85       137\n    Compute Derived Value       0.95      0.86      0.90       172\n            Find Extremum       0.86      0.96      0.91       162\n                     Sort       0.81      0.96      0.88       109\n          Determine Range       0.86      0.90      0.88       126\nCharacterize Distribution       0.89      0.89      0.89       131\n           Find Anomalies       0.88      0.89      0.89       135\n                  Cluster       0.97      0.83      0.89       111\n                Correlate       0.93      0.91      0.92       158\n\n                micro avg       0.90      0.90      0.90      1403\n                macro avg       0.90      0.90      0.89      1403\n             weighted avg       0.90      0.90      0.90      1403\n\nConfusion Matrix...\n[[146   2   3   4   2   4   0   0   0   1]\n [  1 117   0   7   4   2   1   4   0   1]\n [  2   6 148   4   1   4   3   1   0   3]\n [  0   1   1 155   2   2   0   0   0   1]\n [  0   0   0   2 105   1   0   0   1   0]\n [  1   2   0   3   4 114   2   0   0   0]\n [  1   0   1   3   3   4 117   1   0   1]\n [  0   9   1   1   0   0   0 120   1   3]\n [  0   0   0   0   9   1   3   5  92   1]\n [  0   0   2   1   0   0   6   5   1 143]]\nTime usage: 0:00:02\nFold:  7\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:10 *\nIter:     60, Train Loss:    1.7, Train Acc:  46.88%, Time: 0:00:15 *\nIter:     90, Train Loss:    1.3, Train Acc:  60.94%, Time: 0:00:21 *\nIter:    120, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:27 *\nIter:    150, Train Loss:   0.87, Train Acc:  76.56%, Time: 0:00:33 *\nIter:    180, Train Loss:    0.9, Train Acc:  67.19%, Time: 0:00:34 \nEpoch: 2\nIter:    210, Train Loss:   0.76, Train Acc:  76.56%, Time: 0:00:35 \nIter:    240, Train Loss:    0.6, Train Acc:  78.12%, Time: 0:00:41 *\nIter:    270, Train Loss:    0.7, Train Acc:  75.00%, Time: 0:00:42 \nIter:    300, Train Loss:   0.67, Train Acc:  87.50%, Time: 0:00:49 *\nIter:    330, Train Loss:    0.3, Train Acc:  95.31%, Time: 0:00:54 *\nIter:    360, Train Loss:   0.53, Train Acc:  84.38%, Time: 0:00:55 \nIter:    390, Train Loss:    0.4, Train Acc:  92.19%, Time: 0:00:56 \nEpoch: 3\nIter:    420, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:00:56 \nIter:    450, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:57 \nIter:    480, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:00:58 \nIter:    510, Train Loss:   0.27, Train Acc:  96.88%, Time: 0:01:03 *\nIter:    540, Train Loss:   0.26, Train Acc:  92.19%, Time: 0:01:04 \nIter:    570, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:10 *\nEpoch: 4\nIter:    600, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:01:11 \nIter:    630, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:01:11 \nIter:    660, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:01:12 \nIter:    690, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:13 \nIter:    720, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:13 \nIter:    750, Train Loss:  0.091, Train Acc:  96.88%, Time: 0:01:14 \nIter:    780, Train Loss:  0.068, Train Acc:  98.44%, Time: 0:01:15 \nEpoch: 5\nIter:    810, Train Loss:  0.063, Train Acc:  96.88%, Time: 0:01:15 \nIter:    840, Train Loss:  0.026, Train Acc: 100.00%, Time: 0:01:21 *\nIter:    870, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:21 \nIter:    900, Train Loss:  0.079, Train Acc:  98.44%, Time: 0:01:22 \nIter:    930, Train Loss:  0.049, Train Acc: 100.00%, Time: 0:01:23 \nIter:    960, Train Loss:  0.054, Train Acc:  96.88%, Time: 0:01:23 \nIter:    990, Train Loss:  0.011, Train Acc: 100.00%, Time: 0:01:24 \nEpoch: 6\nIter:   1020, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:25 \nIter:   1050, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:25 \nIter:   1080, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:26 \nIter:   1110, Train Loss:  0.053, Train Acc:  96.88%, Time: 0:01:27 \nIter:   1140, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:27 \nIter:   1170, Train Loss:   0.03, Train Acc: 100.00%, Time: 0:01:28 \nEpoch: 7\nIter:   1200, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:29 \nIter:   1230, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:30 \nIter:   1260, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:01:30 \nIter:   1290, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:31 \nIter:   1320, Train Loss:  0.021, Train Acc:  98.44%, Time: 0:01:32 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/7/7\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/7/7\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.28, Test Acc:  92.66%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.93      0.96      0.94       147\n                   Filter       0.89      0.91      0.90       152\n    Compute Derived Value       0.94      0.91      0.92       137\n            Find Extremum       0.97      0.93      0.95       162\n                     Sort       0.89      0.98      0.93       109\n          Determine Range       0.92      0.95      0.93       119\nCharacterize Distribution       0.94      0.89      0.91       136\n           Find Anomalies       0.93      0.88      0.90       155\n                  Cluster       0.93      0.94      0.93       139\n                Correlate       0.93      0.94      0.94       147\n\n                micro avg       0.93      0.93      0.93      1403\n                macro avg       0.93      0.93      0.93      1403\n             weighted avg       0.93      0.93      0.93      1403\n\nConfusion Matrix...\n[[141   2   2   1   1   0   0   0   0   0]\n [  2 139   1   0   3   1   0   4   2   0]\n [  1   3 124   1   2   2   1   0   1   2]\n [  1   4   1 150   2   1   0   2   0   1]\n [  0   0   0   0 107   0   0   0   2   0]\n [  2   2   1   0   1 113   0   0   0   0]\n [  4   1   1   1   0   5 121   0   3   0]\n [  1   5   2   1   1   1   1 137   1   5]\n [  0   1   0   0   2   0   1   3 130   2]\n [  0   0   0   0   1   0   5   2   1 138]]\nTime usage: 0:00:02\nFold:  8\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  34.38%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.5, Train Acc:  54.69%, Time: 0:00:12 *\nIter:     90, Train Loss:    1.3, Train Acc:  75.00%, Time: 0:00:17 *\nIter:    120, Train Loss:   0.95, Train Acc:  76.56%, Time: 0:00:22 *\nIter:    150, Train Loss:   0.92, Train Acc:  73.44%, Time: 0:00:22 \nIter:    180, Train Loss:    0.9, Train Acc:  73.44%, Time: 0:00:23 \nEpoch: 2\nIter:    210, Train Loss:   0.72, Train Acc:  79.69%, Time: 0:00:28 *\nIter:    240, Train Loss:   0.55, Train Acc:  82.81%, Time: 0:00:33 *\nIter:    270, Train Loss:   0.52, Train Acc:  85.94%, Time: 0:00:39 *\nIter:    300, Train Loss:   0.34, Train Acc:  95.31%, Time: 0:00:45 *\nIter:    330, Train Loss:    0.5, Train Acc:  84.38%, Time: 0:00:46 \nIter:    360, Train Loss:    0.5, Train Acc:  85.94%, Time: 0:00:46 \nIter:    390, Train Loss:   0.41, Train Acc:  84.38%, Time: 0:00:47 \nEpoch: 3\nIter:    420, Train Loss:   0.12, Train Acc: 100.00%, Time: 0:00:52 *\nIter:    450, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:00:52 \nIter:    480, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:00:53 \nIter:    510, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:00:54 \nIter:    540, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:00:55 \nIter:    570, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:00:55 \nEpoch: 4\nIter:    600, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:00:56 \nIter:    630, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:00:57 \nIter:    660, Train Loss:  0.044, Train Acc:  98.44%, Time: 0:00:57 \nIter:    690, Train Loss:  0.077, Train Acc: 100.00%, Time: 0:00:58 \nIter:    720, Train Loss:  0.072, Train Acc:  96.88%, Time: 0:00:59 \nIter:    750, Train Loss:   0.05, Train Acc:  98.44%, Time: 0:00:59 \nIter:    780, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:01:00 \nEpoch: 5\nIter:    810, Train Loss:   0.05, Train Acc:  98.44%, Time: 0:01:01 \nIter:    840, Train Loss:  0.049, Train Acc:  98.44%, Time: 0:01:01 \nIter:    870, Train Loss:  0.078, Train Acc:  98.44%, Time: 0:01:02 \nIter:    900, Train Loss:  0.066, Train Acc:  98.44%, Time: 0:01:03 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/8/8\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/8/8\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    0.4, Test Acc:  87.88%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.83      0.93      0.88       136\n                   Filter       0.78      0.89      0.83       139\n    Compute Derived Value       0.92      0.84      0.88       140\n            Find Extremum       0.86      0.95      0.90       159\n                     Sort       0.88      0.98      0.93       129\n          Determine Range       0.85      0.86      0.86       150\nCharacterize Distribution       0.90      0.89      0.90       133\n           Find Anomalies       0.93      0.79      0.85       140\n                  Cluster       0.95      0.81      0.88       151\n                Correlate       0.94      0.85      0.89       126\n\n                micro avg       0.88      0.88      0.88      1403\n                macro avg       0.88      0.88      0.88      1403\n             weighted avg       0.88      0.88      0.88      1403\n\nConfusion Matrix...\n[[126   3   1   2   1   2   1   0   0   0]\n [  4 124   1   4   1   2   1   2   0   0]\n [ 11   3 118   5   0   1   1   1   0   0]\n [  0   1   0 151   3   3   1   0   0   0]\n [  0   0   0   2 126   0   0   0   0   1]\n [  5   5   3   3   4 129   1   0   0   0]\n [  2   4   0   0   0   5 119   0   2   1]\n [  3  10   2   5   0   4   2 110   1   3]\n [  1   6   1   2   8   4   4   0 123   2]\n [  0   4   2   2   0   1   2   5   3 107]]\nTime usage: 0:00:02\nFold:  9\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  43.75%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.6, Train Acc:  59.38%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:18 *\nIter:    120, Train Loss:    1.0, Train Acc:  73.44%, Time: 0:00:24 *\nIter:    150, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:00:25 \nIter:    180, Train Loss:   0.66, Train Acc:  79.69%, Time: 0:00:31 *\nEpoch: 2\nIter:    210, Train Loss:   0.67, Train Acc:  79.69%, Time: 0:00:32 \nIter:    240, Train Loss:   0.51, Train Acc:  84.38%, Time: 0:00:37 *\nIter:    270, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:00:42 *\nIter:    300, Train Loss:   0.44, Train Acc:  81.25%, Time: 0:00:43 \nIter:    330, Train Loss:    0.4, Train Acc:  85.94%, Time: 0:00:44 \nIter:    360, Train Loss:   0.39, Train Acc:  89.06%, Time: 0:00:50 *\nIter:    390, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:00:54 *\nEpoch: 3\nIter:    420, Train Loss:   0.13, Train Acc: 100.00%, Time: 0:01:00 *\nIter:    450, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:01:00 \nIter:    480, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:01 \nIter:    510, Train Loss:   0.26, Train Acc:  96.88%, Time: 0:01:02 \nIter:    540, Train Loss:   0.15, Train Acc:  95.31%, Time: 0:01:03 \nIter:    570, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:01:03 \nEpoch: 4\nIter:    600, Train Loss:  0.078, Train Acc:  98.44%, Time: 0:01:04 \nIter:    630, Train Loss:   0.16, Train Acc:  92.19%, Time: 0:01:05 \nIter:    660, Train Loss:  0.082, Train Acc:  98.44%, Time: 0:01:05 \nIter:    690, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:06 \nIter:    720, Train Loss:  0.063, Train Acc:  98.44%, Time: 0:01:07 \nIter:    750, Train Loss:  0.079, Train Acc:  96.88%, Time: 0:01:07 \nIter:    780, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:08 \nEpoch: 5\nIter:    810, Train Loss:   0.19, Train Acc:  95.31%, Time: 0:01:09 \nIter:    840, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:09 \nIter:    870, Train Loss:  0.046, Train Acc: 100.00%, Time: 0:01:10 \nIter:    900, Train Loss:  0.079, Train Acc:  96.88%, Time: 0:01:11 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/9/9\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/9/9\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.43, Test Acc:  87.67%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.84      0.95      0.89       128\n                   Filter       0.83      0.87      0.85       161\n    Compute Derived Value       0.89      0.87      0.88       185\n            Find Extremum       0.88      0.88      0.88       145\n                     Sort       0.94      0.93      0.93       112\n          Determine Range       0.85      0.83      0.84       136\nCharacterize Distribution       0.87      0.87      0.87       127\n           Find Anomalies       0.80      0.93      0.86       119\n                  Cluster       0.93      0.89      0.91       125\n                Correlate       0.95      0.80      0.87       165\n\n                micro avg       0.88      0.88      0.88      1403\n                macro avg       0.88      0.88      0.88      1403\n             weighted avg       0.88      0.88      0.88      1403\n\nConfusion Matrix...\n[[121   0   1   0   0   2   2   1   0   1]\n [  4 140   4   1   2   3   1   4   1   1]\n [ 13   1 161   4   1   2   1   1   0   1]\n [  2   7   3 127   2   1   1   1   1   0]\n [  0   1   0   5 104   0   1   1   0   0]\n [  1   9   6   4   0 113   0   2   1   0]\n [  1   3   3   1   0   3 110   3   1   2]\n [  0   3   1   1   0   0   2 111   0   1]\n [  1   1   0   0   2   5   1   3 111   1]\n [  1   3   2   1   0   4   7  11   4 132]]\nTime usage: 0:00:02\nFold:  10\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  43.75%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.7, Train Acc:  50.00%, Time: 0:00:11 *\nIter:     90, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:00:15 *\nIter:    120, Train Loss:    1.2, Train Acc:  78.12%, Time: 0:00:19 *\nIter:    150, Train Loss:    1.0, Train Acc:  70.31%, Time: 0:00:20 \nIter:    180, Train Loss:   0.72, Train Acc:  84.38%, Time: 0:00:25 *\nEpoch: 2\nIter:    210, Train Loss:   0.54, Train Acc:  82.81%, Time: 0:00:26 \nIter:    240, Train Loss:   0.53, Train Acc:  84.38%, Time: 0:00:26 \nIter:    270, Train Loss:   0.57, Train Acc:  76.56%, Time: 0:00:27 \nIter:    300, Train Loss:   0.51, Train Acc:  85.94%, Time: 0:00:32 *\nIter:    330, Train Loss:   0.27, Train Acc:  90.62%, Time: 0:00:37 *\nIter:    360, Train Loss:   0.34, Train Acc:  92.19%, Time: 0:00:41 *\nIter:    390, Train Loss:    0.3, Train Acc:  95.31%, Time: 0:00:48 *\nEpoch: 3\nIter:    420, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:00:52 *\nIter:    450, Train Loss:    0.3, Train Acc:  92.19%, Time: 0:00:53 \nIter:    480, Train Loss:   0.29, Train Acc:  95.31%, Time: 0:00:54 \nIter:    510, Train Loss:   0.28, Train Acc:  92.19%, Time: 0:00:54 \nIter:    540, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:00:55 \nIter:    570, Train Loss:   0.21, Train Acc:  92.19%, Time: 0:00:56 \nEpoch: 4\nIter:    600, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:00:57 \nIter:    630, Train Loss:  0.095, Train Acc:  98.44%, Time: 0:01:02 *\nIter:    660, Train Loss:   0.16, Train Acc:  93.75%, Time: 0:01:02 \nIter:    690, Train Loss:  0.099, Train Acc:  96.88%, Time: 0:01:03 \nIter:    720, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:01:04 \nIter:    750, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:04 \nIter:    780, Train Loss:    0.1, Train Acc:  96.88%, Time: 0:01:05 \nEpoch: 5\nIter:    810, Train Loss:  0.037, Train Acc: 100.00%, Time: 0:01:10 *\nIter:    840, Train Loss:  0.038, Train Acc: 100.00%, Time: 0:01:10 \nIter:    870, Train Loss:  0.029, Train Acc: 100.00%, Time: 0:01:11 \nIter:    900, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:12 \nIter:    930, Train Loss:  0.063, Train Acc:  96.88%, Time: 0:01:12 \nIter:    960, Train Loss:   0.07, Train Acc:  98.44%, Time: 0:01:13 \nIter:    990, Train Loss: 0.0063, Train Acc: 100.00%, Time: 0:01:14 \nEpoch: 6\nIter:   1020, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:14 \nIter:   1050, Train Loss:  0.028, Train Acc:  98.44%, Time: 0:01:15 \nIter:   1080, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:16 \nIter:   1110, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1140, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1170, Train Loss:  0.029, Train Acc: 100.00%, Time: 0:01:18 \nEpoch: 7\nIter:   1200, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1230, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1260, Train Loss:  0.015, Train Acc: 100.00%, Time: 0:01:20 \nIter:   1290, Train Loss:  0.011, Train Acc: 100.00%, Time: 0:01:21 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/10/10\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/random/10/10\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.34, Test Acc:  89.95%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.88      0.96      0.92       109\n                   Filter       0.93      0.79      0.86       158\n    Compute Derived Value       0.87      0.92      0.89       144\n            Find Extremum       0.92      0.92      0.92       182\n                     Sort       0.98      0.88      0.93       128\n          Determine Range       0.94      0.89      0.91       120\nCharacterize Distribution       0.96      0.88      0.92       126\n           Find Anomalies       0.82      0.88      0.85       137\n                  Cluster       0.87      0.93      0.90       135\n                Correlate       0.87      0.96      0.91       164\n\n                micro avg       0.90      0.90      0.90      1403\n                macro avg       0.90      0.90      0.90      1403\n             weighted avg       0.90      0.90      0.90      1403\n\nConfusion Matrix...\n[[105   1   1   0   0   0   0   0   0   2]\n [  3 125   4   3   0   1   0  15   2   5]\n [  3   1 132   1   1   0   1   2   1   2]\n [  1   2   2 168   0   1   0   3   2   3]\n [  1   0   1   4 112   3   0   0   6   1]\n [  3   0   3   3   1 107   0   0   2   1]\n [  1   4   4   0   0   1 111   0   2   3]\n [  2   0   4   3   0   0   1 120   1   6]\n [  0   1   1   1   0   1   2   3 125   1]\n [  0   0   0   0   0   0   1   4   2 157]]\nTime usage: 0:00:02\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "model_test_acc", "execution_count": 32, "outputs": [{"output_type": "execute_result", "execution_count": 32, "data": {"text/plain": "[0.9152421642232824,\n 0.8952991454689591,\n 0.8931623935020208,\n 0.8881766376671968,\n 0.920227920397734,\n 0.8959372766257522,\n 0.9265858868318886,\n 0.8788310771997877,\n 0.8766927999508696,\n 0.8995010680329859]"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "np.mean(model_test_acc),np.std(model_test_acc),np.std(model_test_acc,ddof=1),np.var(model_test_acc)", "execution_count": 31, "outputs": [{"output_type": "execute_result", "execution_count": 31, "data": {"text/plain": "(0.8989656369900478,\n 0.015982330737010338,\n 0.016846855815690075,\n 0.0002554348957871854)"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def expert_split():\n    train_data = [[] for i in range(20)]\n    with open(trainDataPath, \"r\", encoding='utf-8') as fp:\n        for line in fp.readlines():\n            word = line.split()\n            info = word[0]\n            index = int(info.split(\":\")[4]) - 1\n            label = int(word[0].split(\":\")[0])\n            content = word[1:]\n            train_data[index].append([content,label])\n            \n    for i in range(20):\n        np.random.shuffle(train_data[i])\n        train_data[i] = np.asarray(train_data[i])\n        \n    np.random.shuffle(train_data)\n        \n    return np.asarray(train_data)", "execution_count": 101, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "train_data_expert = expert_split()", "execution_count": 102, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "train_data_expert[0][:2]", "execution_count": 103, "outputs": [{"output_type": "execute_result", "execution_count": 103, "data": {"text/plain": "array([[list(['which', 'player', \"'s\", 'transfer', '_fee', 'represents', 'an', 'anomaly', '?']),\n        8],\n       [list(['david', 'left', 'what', 'team', 'when', 'he', 'joined', 'the', 'premier', 'league', '?']),\n        1]], dtype=object)"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "len(train_data_expert)", "execution_count": 104, "outputs": [{"output_type": "execute_result", "execution_count": 104, "data": {"text/plain": "20"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "expert_train_acc = []\nexpert_test_acc = []\nsplit_type = \"expert\"\nfold_id = 0\nfor train_i, test_i in kf.split(x_train):\n    fold_id += 1\n    print(\"Fold: \", fold_id)\n    expert_train_acc.append(model.train(x_train[train_i], y_train[train_i],split_type,fold_id))\n    expert_test_acc.append(model.evaluate_model(x_train[test_i], y_train[test_i],split_type,fold_id,categories))", "execution_count": 55, "outputs": [{"output_type": "stream", "text": "Fold:  1\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  37.50%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.6, Train Acc:  62.50%, Time: 0:00:15 *\nIter:     90, Train Loss:    1.2, Train Acc:  59.38%, Time: 0:00:16 \nIter:    120, Train Loss:    1.1, Train Acc:  62.50%, Time: 0:00:16 \nIter:    150, Train Loss:   0.83, Train Acc:  81.25%, Time: 0:00:22 *\nIter:    180, Train Loss:   0.72, Train Acc:  85.94%, Time: 0:00:28 *\nEpoch: 2\nIter:    210, Train Loss:   0.58, Train Acc:  84.38%, Time: 0:00:29 \nIter:    240, Train Loss:   0.61, Train Acc:  82.81%, Time: 0:00:30 \nIter:    270, Train Loss:   0.76, Train Acc:  82.81%, Time: 0:00:30 \nIter:    300, Train Loss:   0.47, Train Acc:  82.81%, Time: 0:00:31 \nIter:    330, Train Loss:   0.52, Train Acc:  84.38%, Time: 0:00:32 \nIter:    360, Train Loss:    0.4, Train Acc:  92.19%, Time: 0:00:39 *\nIter:    390, Train Loss:   0.46, Train Acc:  84.38%, Time: 0:00:39 \nEpoch: 3\nIter:    420, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:00:46 *\nIter:    450, Train Loss:   0.22, Train Acc:  95.31%, Time: 0:00:52 *\nIter:    480, Train Loss:   0.32, Train Acc:  90.62%, Time: 0:00:53 \nIter:    510, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:00:53 \nIter:    540, Train Loss:   0.15, Train Acc:  98.44%, Time: 0:01:00 *\nIter:    570, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:01:00 \nEpoch: 4\nIter:    600, Train Loss:   0.17, Train Acc:  92.19%, Time: 0:01:01 \nIter:    630, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:01:02 \nIter:    660, Train Loss:   0.16, Train Acc:  93.75%, Time: 0:01:02 \nIter:    690, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:03 \nIter:    720, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:01:04 \nIter:    750, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:01:04 \nIter:    780, Train Loss:  0.065, Train Acc: 100.00%, Time: 0:01:15 *\nEpoch: 5\nIter:    810, Train Loss:   0.14, Train Acc:  93.75%, Time: 0:01:15 \nIter:    840, Train Loss:  0.067, Train Acc:  98.44%, Time: 0:01:16 \nIter:    870, Train Loss:  0.028, Train Acc: 100.00%, Time: 0:01:17 \nIter:    900, Train Loss:  0.072, Train Acc:  98.44%, Time: 0:01:17 \nIter:    930, Train Loss:  0.058, Train Acc:  98.44%, Time: 0:01:18 \nIter:    960, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:19 \nIter:    990, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:19 \nEpoch: 6\nIter:   1020, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:01:20 \nIter:   1050, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:21 \nIter:   1080, Train Loss:  0.025, Train Acc: 100.00%, Time: 0:01:21 \nIter:   1110, Train Loss: 0.0099, Train Acc: 100.00%, Time: 0:01:22 \nIter:   1140, Train Loss:  0.054, Train Acc:  98.44%, Time: 0:01:23 \nIter:   1170, Train Loss:  0.038, Train Acc:  98.44%, Time: 0:01:23 \nEpoch: 7\nIter:   1200, Train Loss: 0.0062, Train Acc: 100.00%, Time: 0:01:24 \nIter:   1230, Train Loss:  0.011, Train Acc: 100.00%, Time: 0:01:25 \nIter:   1260, Train Loss:  0.024, Train Acc:  98.44%, Time: 0:01:25 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/1/1\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/1/1\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.35, Test Acc:  89.03%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.97      0.84      0.90       152\n                   Filter       0.85      0.89      0.87       136\n    Compute Derived Value       0.79      0.91      0.85       117\n            Find Extremum       0.92      0.93      0.93       164\n                     Sort       0.97      0.87      0.92       124\n          Determine Range       0.94      0.91      0.93       139\nCharacterize Distribution       0.97      0.87      0.92       130\n           Find Anomalies       0.70      0.97      0.81       141\n                  Cluster       0.94      0.89      0.91       140\n                Correlate       0.96      0.83      0.89       161\n\n                micro avg       0.89      0.89      0.89      1404\n                macro avg       0.90      0.89      0.89      1404\n             weighted avg       0.90      0.89      0.89      1404\n\nConfusion Matrix...\n[[127   7   8   3   0   1   0   6   0   0]\n [  1 121   2   2   0   2   1   7   0   0]\n [  0   1 107   2   0   1   0   5   1   0]\n [  1   3   1 153   2   1   0   3   0   0]\n [  1   1   4   2 108   0   0   4   4   0]\n [  1   5   3   0   1 127   0   0   0   2]\n [  0   2   6   1   0   1 113   5   1   1]\n [  0   1   1   1   0   0   0 137   1   0]\n [  0   2   1   1   0   1   1   8 124   2]\n [  0   0   2   1   0   1   1  22   1 133]]\nTime usage: 0:00:02\nFold:  2\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  42.19%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.9, Train Acc:  32.81%, Time: 0:00:09 \nIter:     90, Train Loss:    1.5, Train Acc:  48.44%, Time: 0:00:14 *\nIter:    120, Train Loss:   0.99, Train Acc:  67.19%, Time: 0:00:20 *\nIter:    150, Train Loss:    0.7, Train Acc:  87.50%, Time: 0:00:25 *\nIter:    180, Train Loss:   0.82, Train Acc:  78.12%, Time: 0:00:26 \nEpoch: 2\nIter:    210, Train Loss:   0.57, Train Acc:  82.81%, Time: 0:00:27 \nIter:    240, Train Loss:   0.49, Train Acc:  85.94%, Time: 0:00:27 \nIter:    270, Train Loss:   0.41, Train Acc:  92.19%, Time: 0:00:32 *\nIter:    300, Train Loss:   0.61, Train Acc:  76.56%, Time: 0:00:33 \nIter:    330, Train Loss:   0.37, Train Acc:  87.50%, Time: 0:00:34 \nIter:    360, Train Loss:   0.37, Train Acc:  84.38%, Time: 0:00:34 \nIter:    390, Train Loss:   0.39, Train Acc:  89.06%, Time: 0:00:35 \nEpoch: 3\nIter:    420, Train Loss:   0.25, Train Acc:  95.31%, Time: 0:00:40 *\nIter:    450, Train Loss:   0.31, Train Acc:  89.06%, Time: 0:00:41 \nIter:    480, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:41 \nIter:    510, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:42 \nIter:    540, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:00:43 \nIter:    570, Train Loss:   0.22, Train Acc:  96.88%, Time: 0:00:47 *\nEpoch: 4\nIter:    600, Train Loss:   0.13, Train Acc:  98.44%, Time: 0:00:53 *\nIter:    630, Train Loss:  0.064, Train Acc: 100.00%, Time: 0:00:59 *\nIter:    660, Train Loss:   0.16, Train Acc:  93.75%, Time: 0:01:00 \nIter:    690, Train Loss:  0.083, Train Acc:  98.44%, Time: 0:01:00 \nIter:    720, Train Loss:  0.044, Train Acc: 100.00%, Time: 0:01:01 \nIter:    750, Train Loss:    0.1, Train Acc:  96.88%, Time: 0:01:02 \nIter:    780, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:03 \nEpoch: 5\nIter:    810, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:03 \nIter:    840, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:04 \nIter:    870, Train Loss:  0.079, Train Acc:  96.88%, Time: 0:01:05 \nIter:    900, Train Loss:  0.024, Train Acc: 100.00%, Time: 0:01:05 \nIter:    930, Train Loss:  0.032, Train Acc:  98.44%, Time: 0:01:06 \nIter:    960, Train Loss:  0.039, Train Acc:  98.44%, Time: 0:01:07 \nIter:    990, Train Loss:  0.052, Train Acc:  95.65%, Time: 0:01:07 \nEpoch: 6\nIter:   1020, Train Loss:   0.08, Train Acc:  98.44%, Time: 0:01:08 \nIter:   1050, Train Loss:  0.036, Train Acc:  98.44%, Time: 0:01:09 \nIter:   1080, Train Loss:  0.025, Train Acc: 100.00%, Time: 0:01:09 \nIter:   1110, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:01:10 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/2/2\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/2/2\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    0.3, Test Acc:  91.03%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.95      0.93      0.94       109\n                   Filter       0.91      0.88      0.90       156\n    Compute Derived Value       0.92      0.91      0.92       141\n            Find Extremum       0.88      0.96      0.92       190\n                     Sort       0.92      0.95      0.94       138\n          Determine Range       0.86      0.93      0.89       139\nCharacterize Distribution       0.98      0.83      0.90       148\n           Find Anomalies       0.91      0.89      0.90       141\n                  Cluster       0.89      0.89      0.89       114\n                Correlate       0.91      0.92      0.91       128\n\n                micro avg       0.91      0.91      0.91      1404\n                macro avg       0.91      0.91      0.91      1404\n             weighted avg       0.91      0.91      0.91      1404\n\nConfusion Matrix...\n[[101   1   1   3   1   1   0   0   0   1]\n [  1 137   1   6   2   5   0   4   0   0]\n [  2   3 129   3   2   0   1   0   0   1]\n [  0   1   0 183   1   3   0   0   1   1]\n [  0   0   0   2 131   1   0   1   3   0]\n [  0   1   1   3   1 129   2   1   1   0]\n [  1   1   4   6   2   5 123   1   2   3]\n [  0   3   1   1   0   4   0 125   2   5]\n [  1   2   0   0   2   2   0   4 102   1]\n [  0   1   3   2   0   0   0   1   3 118]]\nTime usage: 0:00:02\nFold:  3\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  37.50%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.7, Train Acc:  64.06%, Time: 0:00:13 *\nIter:     90, Train Loss:    1.4, Train Acc:  62.50%, Time: 0:00:14 \nIter:    120, Train Loss:    1.5, Train Acc:  57.81%, Time: 0:00:14 \nIter:    150, Train Loss:   0.79, Train Acc:  81.25%, Time: 0:00:20 *\nIter:    180, Train Loss:   0.92, Train Acc:  68.75%, Time: 0:00:21 \nEpoch: 2\nIter:    210, Train Loss:   0.55, Train Acc:  84.38%, Time: 0:00:26 *\nIter:    240, Train Loss:    0.7, Train Acc:  81.25%, Time: 0:00:26 \nIter:    270, Train Loss:   0.51, Train Acc:  79.69%, Time: 0:00:27 \nIter:    300, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:00:34 *\nIter:    330, Train Loss:   0.45, Train Acc:  89.06%, Time: 0:00:34 \nIter:    360, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:00:35 \nIter:    390, Train Loss:   0.28, Train Acc:  92.19%, Time: 0:00:41 *\nEpoch: 3\nIter:    420, Train Loss:   0.24, Train Acc:  96.88%, Time: 0:00:46 *\nIter:    450, Train Loss:    0.3, Train Acc:  92.19%, Time: 0:00:46 \nIter:    480, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:00:47 \nIter:    510, Train Loss:   0.15, Train Acc:  95.31%, Time: 0:00:48 \nIter:    540, Train Loss:   0.42, Train Acc:  89.06%, Time: 0:00:48 \nIter:    570, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:00:53 *\nEpoch: 4\nIter:    600, Train Loss:   0.13, Train Acc:  98.44%, Time: 0:00:54 \nIter:    630, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:00:55 \nIter:    660, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:00:55 \nIter:    690, Train Loss:   0.09, Train Acc:  98.44%, Time: 0:00:56 \nIter:    720, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:00:57 \nIter:    750, Train Loss:   0.16, Train Acc:  90.62%, Time: 0:00:57 \nIter:    780, Train Loss:    0.1, Train Acc:  95.31%, Time: 0:00:58 \nEpoch: 5\nIter:    810, Train Loss:  0.038, Train Acc: 100.00%, Time: 0:01:03 *\nIter:    840, Train Loss:  0.036, Train Acc:  98.44%, Time: 0:01:04 \nIter:    870, Train Loss:  0.072, Train Acc:  96.88%, Time: 0:01:04 \nIter:    900, Train Loss:  0.053, Train Acc: 100.00%, Time: 0:01:05 \nIter:    930, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:06 \nIter:    960, Train Loss:  0.068, Train Acc:  98.44%, Time: 0:01:06 \nIter:    990, Train Loss:  0.046, Train Acc: 100.00%, Time: 0:01:07 \nEpoch: 6\nIter:   1020, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:08 \nIter:   1050, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:08 \nIter:   1080, Train Loss:  0.033, Train Acc: 100.00%, Time: 0:01:09 \nIter:   1110, Train Loss:  0.041, Train Acc: 100.00%, Time: 0:01:10 \nIter:   1140, Train Loss:   0.03, Train Acc: 100.00%, Time: 0:01:10 \nIter:   1170, Train Loss:  0.063, Train Acc:  96.88%, Time: 0:01:11 \nEpoch: 7\nIter:   1200, Train Loss:  0.041, Train Acc: 100.00%, Time: 0:01:12 \nIter:   1230, Train Loss: 0.0095, Train Acc: 100.00%, Time: 0:01:13 \nIter:   1260, Train Loss: 0.0094, Train Acc: 100.00%, Time: 0:01:13 \nIter:   1290, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:14 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/3/3\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/3/3\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.35, Test Acc:  89.46%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.86      0.95      0.90       152\n                   Filter       0.80      0.94      0.87       118\n    Compute Derived Value       0.89      0.89      0.89       168\n            Find Extremum       0.91      0.95      0.93       168\n                     Sort       0.89      0.93      0.91       110\n          Determine Range       0.90      0.83      0.86       118\nCharacterize Distribution       0.98      0.76      0.86       153\n           Find Anomalies       0.93      0.87      0.90       126\n                  Cluster       0.96      0.87      0.91       115\n                Correlate       0.87      0.95      0.91       176\n\n                micro avg       0.89      0.89      0.89      1404\n                macro avg       0.90      0.89      0.89      1404\n             weighted avg       0.90      0.89      0.89      1404\n\nConfusion Matrix...\n[[144   2   4   0   0   0   1   1   0   0]\n [  3 111   1   0   1   0   1   1   0   0]\n [  4   7 149   4   0   2   0   1   0   1]\n [  2   3   2 159   2   0   0   0   0   0]\n [  2   2   1   0 102   2   0   0   1   0]\n [  3   2   3   1   3  98   0   1   2   5]\n [  8   6   5   4   1   5 116   0   1   7]\n [  1   2   1   4   0   0   0 110   0   8]\n [  0   1   0   3   5   1   0   2 100   3]\n [  1   2   2   0   1   1   0   2   0 167]]\nTime usage: 0:00:02\nFold:  4\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  32.81%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.7, Train Acc:  50.00%, Time: 0:00:11 *\nIter:     90, Train Loss:    1.4, Train Acc:  56.25%, Time: 0:00:15 *\nIter:    120, Train Loss:    1.2, Train Acc:  59.38%, Time: 0:00:20 *\nIter:    150, Train Loss:   0.97, Train Acc:  73.44%, Time: 0:00:25 *\nIter:    180, Train Loss:    0.8, Train Acc:  78.12%, Time: 0:00:29 *\nEpoch: 2\nIter:    210, Train Loss:   0.68, Train Acc:  81.25%, Time: 0:00:35 *\nIter:    240, Train Loss:   0.41, Train Acc:  95.31%, Time: 0:00:41 *\nIter:    270, Train Loss:   0.61, Train Acc:  78.12%, Time: 0:00:42 \nIter:    300, Train Loss:   0.58, Train Acc:  90.62%, Time: 0:00:42 \nIter:    330, Train Loss:    0.5, Train Acc:  85.94%, Time: 0:00:43 \nIter:    360, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:00:44 \nIter:    390, Train Loss:   0.36, Train Acc:  84.38%, Time: 0:00:44 \nEpoch: 3\nIter:    420, Train Loss:   0.26, Train Acc:  92.19%, Time: 0:00:45 \nIter:    450, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:00:46 \nIter:    480, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:00:52 *\nIter:    510, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:00:53 \nIter:    540, Train Loss:   0.17, Train Acc:  95.31%, Time: 0:00:54 \nIter:    570, Train Loss:  0.069, Train Acc: 100.00%, Time: 0:00:59 *\nEpoch: 4\nIter:    600, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:00 \nIter:    630, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:01:01 \nIter:    660, Train Loss:  0.066, Train Acc:  98.44%, Time: 0:01:01 \nIter:    690, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:01:02 \nIter:    720, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:03 \nIter:    750, Train Loss:  0.087, Train Acc:  98.44%, Time: 0:01:04 \nIter:    780, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:01:04 \nEpoch: 5\nIter:    810, Train Loss:  0.077, Train Acc:  96.88%, Time: 0:01:05 \nIter:    840, Train Loss:  0.047, Train Acc: 100.00%, Time: 0:01:06 \nIter:    870, Train Loss:  0.059, Train Acc:  96.88%, Time: 0:01:06 \nIter:    900, Train Loss:  0.083, Train Acc:  98.44%, Time: 0:01:07 \nIter:    930, Train Loss:  0.063, Train Acc:  96.88%, Time: 0:01:08 \nIter:    960, Train Loss:  0.064, Train Acc: 100.00%, Time: 0:01:08 \nIter:    990, Train Loss:  0.098, Train Acc:  95.65%, Time: 0:01:09 \nEpoch: 6\nIter:   1020, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:01:10 \nIter:   1050, Train Loss:  0.039, Train Acc:  98.44%, Time: 0:01:10 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/4/4\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/4/4\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.37, Test Acc:  88.96%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.92      0.90      0.91       139\n                   Filter       0.88      0.89      0.88       144\n    Compute Derived Value       0.93      0.83      0.88       138\n            Find Extremum       0.91      0.92      0.91       169\n                     Sort       0.86      0.94      0.90       125\n          Determine Range       0.75      0.90      0.82       134\nCharacterize Distribution       0.97      0.87      0.92       138\n           Find Anomalies       0.98      0.78      0.87       140\n                  Cluster       0.85      0.93      0.89       121\n                Correlate       0.90      0.94      0.92       156\n\n                micro avg       0.89      0.89      0.89      1404\n                macro avg       0.89      0.89      0.89      1404\n             weighted avg       0.90      0.89      0.89      1404\n\nConfusion Matrix...\n[[125   3   2   0   4   3   1   1   0   0]\n [  1 128   0   3   0   7   0   0   4   1]\n [  5   1 115   1   1   9   1   0   3   2]\n [  2   1   0 156   2   6   0   0   1   1]\n [  0   0   1   1 117   2   0   0   4   0]\n [  1   3   1   3   5 120   0   0   0   1]\n [  1   1   3   1   2   5 120   1   3   1]\n [  0   9   1   6   1   2   1 109   3   8]\n [  0   0   1   0   2   3   1   0 112   2]\n [  1   0   0   1   2   3   0   0   2 147]]\nTime usage: 0:00:02\nFold:  5\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  43.75%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.8, Train Acc:  37.50%, Time: 0:00:08 \nIter:     90, Train Loss:    1.7, Train Acc:  42.19%, Time: 0:00:09 \nIter:    120, Train Loss:    1.2, Train Acc:  59.38%, Time: 0:00:14 *\nIter:    150, Train Loss:   0.82, Train Acc:  78.12%, Time: 0:00:18 *\nIter:    180, Train Loss:   0.97, Train Acc:  70.31%, Time: 0:00:19 \nEpoch: 2\nIter:    210, Train Loss:   0.64, Train Acc:  87.50%, Time: 0:00:25 *\nIter:    240, Train Loss:   0.56, Train Acc:  89.06%, Time: 0:00:30 *\nIter:    270, Train Loss:   0.59, Train Acc:  85.94%, Time: 0:00:31 \nIter:    300, Train Loss:   0.42, Train Acc:  89.06%, Time: 0:00:32 \nIter:    330, Train Loss:   0.57, Train Acc:  82.81%, Time: 0:00:32 \nIter:    360, Train Loss:   0.39, Train Acc:  92.19%, Time: 0:00:37 *\nIter:    390, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:00:41 *\nEpoch: 3\nIter:    420, Train Loss:   0.16, Train Acc:  95.31%, Time: 0:00:47 *\nIter:    450, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:00:48 \nIter:    480, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:49 \nIter:    510, Train Loss:   0.23, Train Acc:  92.19%, Time: 0:00:49 \nIter:    540, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:00:55 *\nIter:    570, Train Loss:   0.16, Train Acc:  95.31%, Time: 0:00:56 \nEpoch: 4\nIter:    600, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:00:57 \nIter:    630, Train Loss:  0.076, Train Acc:  98.44%, Time: 0:01:03 *\nIter:    660, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:03 \nIter:    690, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:04 \nIter:    720, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:01:05 \nIter:    750, Train Loss:  0.096, Train Acc:  98.44%, Time: 0:01:05 \nIter:    780, Train Loss:  0.078, Train Acc:  96.88%, Time: 0:01:06 \nEpoch: 5\nIter:    810, Train Loss:  0.036, Train Acc: 100.00%, Time: 0:01:13 *\nIter:    840, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:14 \nIter:    870, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:14 \nIter:    900, Train Loss:  0.066, Train Acc:  98.44%, Time: 0:01:15 \nIter:    930, Train Loss:    0.1, Train Acc:  96.88%, Time: 0:01:16 \nIter:    960, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:16 \nIter:    990, Train Loss:  0.036, Train Acc: 100.00%, Time: 0:01:17 \nEpoch: 6\nIter:   1020, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:18 \nIter:   1050, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1080, Train Loss:  0.039, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1110, Train Loss:  0.064, Train Acc:  98.44%, Time: 0:01:20 \nIter:   1140, Train Loss:  0.063, Train Acc:  96.88%, Time: 0:01:21 \nIter:   1170, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:21 \nEpoch: 7\nIter:   1200, Train Loss:  0.019, Train Acc: 100.00%, Time: 0:01:22 \nIter:   1230, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:23 \nIter:   1260, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:23 \nIter:   1290, Train Loss: 0.0099, Train Acc: 100.00%, Time: 0:01:24 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/5/5\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/5/5\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.27, Test Acc:  91.74%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.91      0.95      0.93       130\n                   Filter       0.85      0.95      0.90       151\n    Compute Derived Value       0.88      0.94      0.91       193\n            Find Extremum       0.92      0.93      0.93       159\n                     Sort       0.97      0.95      0.96       122\n          Determine Range       0.96      0.89      0.92       141\nCharacterize Distribution       0.84      0.92      0.88       107\n           Find Anomalies       0.96      0.86      0.90       139\n                  Cluster       0.97      0.90      0.93       119\n                Correlate       0.97      0.88      0.92       143\n\n                micro avg       0.92      0.92      0.92      1404\n                macro avg       0.92      0.92      0.92      1404\n             weighted avg       0.92      0.92      0.92      1404\n\nConfusion Matrix...\n[[123   3   3   0   0   1   0   0   0   0]\n [  1 144   1   4   0   1   0   0   0   0]\n [  4   3 182   3   0   0   1   0   0   0]\n [  2   0   4 148   2   1   1   1   0   0]\n [  0   1   1   1 116   0   2   0   1   0]\n [  1   4   4   2   0 125   4   1   0   0]\n [  1   3   4   0   0   0  98   0   0   1]\n [  1   8   3   2   1   0   4 119   1   0]\n [  0   2   1   1   0   2   3   0 107   3]\n [  2   2   5   0   1   0   3   3   1 126]]\nTime usage: 0:00:02\nFold:  6\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.6, Train Acc:  53.12%, Time: 0:00:15 *\nIter:     90, Train Loss:    1.5, Train Acc:  57.81%, Time: 0:00:22 *\nIter:    120, Train Loss:    1.2, Train Acc:  68.75%, Time: 0:00:28 *\nIter:    150, Train Loss:    1.0, Train Acc:  73.44%, Time: 0:00:33 *\nIter:    180, Train Loss:    1.1, Train Acc:  67.19%, Time: 0:00:34 \nEpoch: 2\nIter:    210, Train Loss:   0.65, Train Acc:  87.50%, Time: 0:00:40 *\nIter:    240, Train Loss:   0.59, Train Acc:  82.81%, Time: 0:00:40 \nIter:    270, Train Loss:   0.44, Train Acc:  87.50%, Time: 0:00:41 \nIter:    300, Train Loss:   0.57, Train Acc:  82.81%, Time: 0:00:42 \nIter:    330, Train Loss:   0.44, Train Acc:  92.19%, Time: 0:00:47 *\nIter:    360, Train Loss:   0.55, Train Acc:  79.69%, Time: 0:00:48 \nIter:    390, Train Loss:    0.4, Train Acc:  84.38%, Time: 0:00:49 \nEpoch: 3\nIter:    420, Train Loss:   0.31, Train Acc:  89.06%, Time: 0:00:49 \nIter:    450, Train Loss:   0.29, Train Acc:  87.50%, Time: 0:00:50 \nIter:    480, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:00:56 *\nIter:    510, Train Loss:   0.31, Train Acc:  89.06%, Time: 0:00:57 \nIter:    540, Train Loss:   0.28, Train Acc:  95.31%, Time: 0:00:57 \nIter:    570, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:00:58 \nEpoch: 4\nIter:    600, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:00:59 \nIter:    630, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:00:59 \nIter:    660, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:04 *\nIter:    690, Train Loss:  0.078, Train Acc:  98.44%, Time: 0:01:05 \nIter:    720, Train Loss:  0.094, Train Acc:  95.31%, Time: 0:01:05 \nIter:    750, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:06 \nIter:    780, Train Loss:   0.16, Train Acc:  95.31%, Time: 0:01:07 \nEpoch: 5\nIter:    810, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:07 \nIter:    840, Train Loss:  0.066, Train Acc:  98.44%, Time: 0:01:08 \nIter:    870, Train Loss:  0.083, Train Acc:  98.44%, Time: 0:01:09 \nIter:    900, Train Loss:  0.026, Train Acc: 100.00%, Time: 0:01:15 *\nIter:    930, Train Loss:  0.061, Train Acc:  98.44%, Time: 0:01:16 \nIter:    960, Train Loss:   0.07, Train Acc:  98.44%, Time: 0:01:16 \nIter:    990, Train Loss:    0.1, Train Acc:  95.83%, Time: 0:01:17 \nEpoch: 6\nIter:   1020, Train Loss:  0.021, Train Acc: 100.00%, Time: 0:01:18 \nIter:   1050, Train Loss:  0.032, Train Acc: 100.00%, Time: 0:01:18 \nIter:   1080, Train Loss:  0.056, Train Acc:  96.88%, Time: 0:01:19 \nIter:   1110, Train Loss:  0.011, Train Acc: 100.00%, Time: 0:01:20 \nIter:   1140, Train Loss:  0.021, Train Acc: 100.00%, Time: 0:01:20 \nIter:   1170, Train Loss: 0.0098, Train Acc: 100.00%, Time: 0:01:21 \nEpoch: 7\nIter:   1200, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:22 \nIter:   1230, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:22 \nIter:   1260, Train Loss:  0.035, Train Acc:  98.44%, Time: 0:01:23 \nIter:   1290, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:24 \nIter:   1320, Train Loss:  0.034, Train Acc:  98.44%, Time: 0:01:25 \nIter:   1350, Train Loss:  0.049, Train Acc:  98.44%, Time: 0:01:25 \nIter:   1380, Train Loss: 0.0081, Train Acc: 100.00%, Time: 0:01:26 \nEpoch: 8\nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/6/6\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/6/6\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    0.3, Test Acc:  90.52%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.97      0.94      0.95       162\n                   Filter       0.74      0.95      0.83       137\n    Compute Derived Value       0.97      0.85      0.91       172\n            Find Extremum       0.89      0.92      0.91       162\n                     Sort       0.92      0.97      0.95       109\n          Determine Range       0.89      0.87      0.88       126\nCharacterize Distribution       0.97      0.86      0.91       131\n           Find Anomalies       0.86      0.87      0.87       135\n                  Cluster       0.91      0.94      0.92       111\n                Correlate       0.97      0.89      0.93       158\n\n                micro avg       0.91      0.91      0.91      1403\n                macro avg       0.91      0.91      0.91      1403\n             weighted avg       0.91      0.91      0.91      1403\n\nConfusion Matrix...\n[[152   2   2   1   1   2   0   2   0   0]\n [  1 130   1   2   0   2   0   1   0   0]\n [  1  12 147   4   0   3   2   1   0   2]\n [  2   7   0 149   1   0   0   2   1   0]\n [  0   1   0   0 106   1   0   0   1   0]\n [  0   8   1   4   2 110   0   0   1   0]\n [  1   2   0   5   2   4 113   2   1   1]\n [  0  11   0   1   0   0   0 118   3   2]\n [  0   0   0   0   3   1   0   3 104   0]\n [  0   2   0   1   0   1   2   8   3 141]]\nTime usage: 0:00:02\nFold:  7\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  29.69%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.7, Train Acc:  48.44%, Time: 0:00:11 *\nIter:     90, Train Loss:    1.4, Train Acc:  67.19%, Time: 0:00:16 *\nIter:    120, Train Loss:   0.94, Train Acc:  82.81%, Time: 0:00:22 *\nIter:    150, Train Loss:   0.95, Train Acc:  70.31%, Time: 0:00:22 \nIter:    180, Train Loss:    1.2, Train Acc:  67.19%, Time: 0:00:23 \nEpoch: 2\nIter:    210, Train Loss:   0.57, Train Acc:  84.38%, Time: 0:00:29 *\nIter:    240, Train Loss:    0.5, Train Acc:  89.06%, Time: 0:00:35 *\nIter:    270, Train Loss:   0.61, Train Acc:  85.94%, Time: 0:00:36 \nIter:    300, Train Loss:   0.45, Train Acc:  82.81%, Time: 0:00:36 \nIter:    330, Train Loss:   0.46, Train Acc:  90.62%, Time: 0:00:41 *\nIter:    360, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:00:42 \nIter:    390, Train Loss:   0.38, Train Acc:  87.50%, Time: 0:00:42 \nEpoch: 3\nIter:    420, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:00:47 *\nIter:    450, Train Loss:   0.31, Train Acc:  92.19%, Time: 0:00:48 \nIter:    480, Train Loss:   0.23, Train Acc:  95.31%, Time: 0:00:53 *\nIter:    510, Train Loss:   0.17, Train Acc:  95.31%, Time: 0:00:54 \nIter:    540, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:00:59 *\nIter:    570, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:01:00 \nEpoch: 4\nIter:    600, Train Loss:    0.1, Train Acc:  95.31%, Time: 0:01:00 \nIter:    630, Train Loss:  0.062, Train Acc: 100.00%, Time: 0:01:06 *\nIter:    660, Train Loss:  0.076, Train Acc:  98.44%, Time: 0:01:07 \nIter:    690, Train Loss:    0.1, Train Acc:  96.88%, Time: 0:01:08 \nIter:    720, Train Loss:  0.042, Train Acc: 100.00%, Time: 0:01:08 \nIter:    750, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:01:09 \nIter:    780, Train Loss:   0.14, Train Acc:  93.75%, Time: 0:01:10 \nEpoch: 5\nIter:    810, Train Loss:  0.094, Train Acc:  98.44%, Time: 0:01:10 \nIter:    840, Train Loss:  0.072, Train Acc:  96.88%, Time: 0:01:11 \nIter:    870, Train Loss:  0.024, Train Acc: 100.00%, Time: 0:01:12 \nIter:    900, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:12 \nIter:    930, Train Loss:   0.04, Train Acc: 100.00%, Time: 0:01:13 \nIter:    960, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:14 \nIter:    990, Train Loss:   0.18, Train Acc:  95.83%, Time: 0:01:14 \nEpoch: 6\nIter:   1020, Train Loss:  0.044, Train Acc: 100.00%, Time: 0:01:15 \nIter:   1050, Train Loss:   0.04, Train Acc:  98.44%, Time: 0:01:16 \nIter:   1080, Train Loss:  0.044, Train Acc: 100.00%, Time: 0:01:16 \nIter:   1110, Train Loss:  0.025, Train Acc: 100.00%, Time: 0:01:17 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/7/7\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/7/7\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.31, Test Acc:  91.30%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.93      0.97      0.95       147\n                   Filter       0.90      0.87      0.89       152\n    Compute Derived Value       0.85      0.92      0.88       137\n            Find Extremum       0.94      0.93      0.93       162\n                     Sort       1.00      0.87      0.93       109\n          Determine Range       0.92      0.89      0.91       119\nCharacterize Distribution       0.86      0.90      0.88       136\n           Find Anomalies       0.94      0.86      0.90       155\n                  Cluster       0.92      0.94      0.93       139\n                Correlate       0.90      0.96      0.93       147\n\n                micro avg       0.91      0.91      0.91      1403\n                macro avg       0.92      0.91      0.91      1403\n             weighted avg       0.92      0.91      0.91      1403\n\nConfusion Matrix...\n[[143   1   1   1   0   0   1   0   0   0]\n [  3 132  10   0   0   2   1   2   0   2]\n [  1   2 126   3   0   2   0   0   1   2]\n [  1   2   2 151   0   1   1   1   1   2]\n [  1   2   2   3  95   0   2   0   4   0]\n [  1   2   1   2   0 106   6   0   1   0]\n [  2   0   3   0   0   4 123   0   3   1]\n [  2   4   3   1   0   0   3 134   2   6]\n [  0   1   0   0   0   0   3   3 130   2]\n [  0   0   1   0   0   0   3   2   0 141]]\nTime usage: 0:00:02\nFold:  8\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  35.94%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.8, Train Acc:  46.88%, Time: 0:00:13 *\nIter:     90, Train Loss:    1.5, Train Acc:  60.94%, Time: 0:00:19 *\nIter:    120, Train Loss:    1.2, Train Acc:  67.19%, Time: 0:00:24 *\nIter:    150, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:00:25 \nIter:    180, Train Loss:   0.86, Train Acc:  75.00%, Time: 0:00:31 *\nEpoch: 2\nIter:    210, Train Loss:   0.67, Train Acc:  85.94%, Time: 0:00:36 *\nIter:    240, Train Loss:   0.45, Train Acc:  89.06%, Time: 0:00:42 *\nIter:    270, Train Loss:   0.65, Train Acc:  85.94%, Time: 0:00:43 \nIter:    300, Train Loss:   0.57, Train Acc:  81.25%, Time: 0:00:44 \nIter:    330, Train Loss:   0.34, Train Acc:  87.50%, Time: 0:00:44 \nIter:    360, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:00:50 *\nIter:    390, Train Loss:   0.46, Train Acc:  84.38%, Time: 0:00:51 \nEpoch: 3\nIter:    420, Train Loss:   0.23, Train Acc:  95.31%, Time: 0:00:56 *\nIter:    450, Train Loss:   0.35, Train Acc:  89.06%, Time: 0:00:57 \nIter:    480, Train Loss:   0.15, Train Acc:  95.31%, Time: 0:00:58 \nIter:    510, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:00:59 \nIter:    540, Train Loss:   0.21, Train Acc:  95.31%, Time: 0:00:59 \nIter:    570, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:00 \nEpoch: 4\nIter:    600, Train Loss:  0.048, Train Acc: 100.00%, Time: 0:01:06 *\nIter:    630, Train Loss:  0.042, Train Acc: 100.00%, Time: 0:01:07 \nIter:    660, Train Loss:  0.076, Train Acc: 100.00%, Time: 0:01:07 \nIter:    690, Train Loss:  0.087, Train Acc:  98.44%, Time: 0:01:08 \nIter:    720, Train Loss:  0.084, Train Acc:  98.44%, Time: 0:01:09 \nIter:    750, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:09 \nIter:    780, Train Loss:  0.027, Train Acc: 100.00%, Time: 0:01:10 \nEpoch: 5\nIter:    810, Train Loss:  0.033, Train Acc: 100.00%, Time: 0:01:11 \nIter:    840, Train Loss:  0.054, Train Acc:  98.44%, Time: 0:01:11 \nIter:    870, Train Loss:  0.035, Train Acc:  98.44%, Time: 0:01:12 \nIter:    900, Train Loss:  0.045, Train Acc: 100.00%, Time: 0:01:13 \nIter:    930, Train Loss:  0.072, Train Acc:  98.44%, Time: 0:01:13 \nIter:    960, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:14 \nIter:    990, Train Loss:  0.011, Train Acc: 100.00%, Time: 0:01:15 \nEpoch: 6\nIter:   1020, Train Loss:  0.029, Train Acc: 100.00%, Time: 0:01:16 \nIter:   1050, Train Loss:  0.055, Train Acc:  98.44%, Time: 0:01:16 \nIter:   1080, Train Loss:  0.043, Train Acc:  98.44%, Time: 0:01:17 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/8/8\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/8/8\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.29, Test Acc:  91.45%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.96      0.93      0.95       136\n                   Filter       0.83      0.90      0.87       139\n    Compute Derived Value       0.89      0.95      0.92       140\n            Find Extremum       0.93      0.94      0.93       159\n                     Sort       0.94      0.95      0.94       129\n          Determine Range       0.93      0.90      0.92       150\nCharacterize Distribution       0.91      0.89      0.90       133\n           Find Anomalies       0.98      0.86      0.91       140\n                  Cluster       0.94      0.91      0.92       151\n                Correlate       0.85      0.93      0.89       126\n\n                micro avg       0.91      0.91      0.91      1403\n                macro avg       0.92      0.91      0.91      1403\n             weighted avg       0.92      0.91      0.91      1403\n\nConfusion Matrix...\n[[127   3   4   0   0   2   0   0   0   0]\n [  2 125   2   2   1   0   0   1   3   3]\n [  1   3 133   1   0   0   0   0   0   2]\n [  0   2   1 149   3   1   1   1   0   1]\n [  1   0   1   2 122   0   0   0   1   2]\n [  0   2   3   3   2 135   1   0   1   3]\n [  0   5   2   0   0   3 118   1   1   3]\n [  1   6   1   1   0   3   1 120   1   6]\n [  0   1   1   1   2   1   7   0 137   1]\n [  0   3   1   1   0   0   2   0   2 117]]\nTime usage: 0:00:02\nFold:  9\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  57.81%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.6, Train Acc:  60.94%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.3, Train Acc:  68.75%, Time: 0:00:19 *\nIter:    120, Train Loss:    1.1, Train Acc:  70.31%, Time: 0:00:23 *\nIter:    150, Train Loss:   0.89, Train Acc:  78.12%, Time: 0:00:28 *\nIter:    180, Train Loss:    0.8, Train Acc:  75.00%, Time: 0:00:29 \nEpoch: 2\nIter:    210, Train Loss:   0.61, Train Acc:  75.00%, Time: 0:00:30 \nIter:    240, Train Loss:   0.62, Train Acc:  85.94%, Time: 0:00:35 *\nIter:    270, Train Loss:   0.52, Train Acc:  84.38%, Time: 0:00:36 \nIter:    300, Train Loss:   0.35, Train Acc:  92.19%, Time: 0:00:41 *\nIter:    330, Train Loss:   0.36, Train Acc:  92.19%, Time: 0:00:42 \nIter:    360, Train Loss:   0.35, Train Acc:  92.19%, Time: 0:00:43 \nIter:    390, Train Loss:   0.36, Train Acc:  87.50%, Time: 0:00:43 \nEpoch: 3\nIter:    420, Train Loss:   0.41, Train Acc:  84.38%, Time: 0:00:44 \nIter:    450, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:00:50 *\nIter:    480, Train Loss:   0.17, Train Acc:  95.31%, Time: 0:00:56 *\nIter:    510, Train Loss:   0.26, Train Acc:  92.19%, Time: 0:00:57 \nIter:    540, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:01:04 *\nIter:    570, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:04 \nEpoch: 4\nIter:    600, Train Loss:  0.095, Train Acc:  98.44%, Time: 0:01:05 \nIter:    630, Train Loss:   0.16, Train Acc:  95.31%, Time: 0:01:06 \nIter:    660, Train Loss:  0.076, Train Acc: 100.00%, Time: 0:01:12 *\nIter:    690, Train Loss:  0.099, Train Acc:  96.88%, Time: 0:01:12 \nIter:    720, Train Loss:  0.081, Train Acc: 100.00%, Time: 0:01:13 \nIter:    750, Train Loss:  0.078, Train Acc:  96.88%, Time: 0:01:14 \nIter:    780, Train Loss:   0.15, Train Acc:  98.44%, Time: 0:01:14 \nEpoch: 5\nIter:    810, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:15 \nIter:    840, Train Loss:  0.076, Train Acc:  98.44%, Time: 0:01:16 \nIter:    870, Train Loss:  0.041, Train Acc: 100.00%, Time: 0:01:16 \nIter:    900, Train Loss:   0.06, Train Acc:  96.88%, Time: 0:01:17 \nIter:    930, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:18 \nIter:    960, Train Loss:  0.019, Train Acc: 100.00%, Time: 0:01:18 \nIter:    990, Train Loss:   0.14, Train Acc:  95.83%, Time: 0:01:19 \nEpoch: 6\nIter:   1020, Train Loss:  0.034, Train Acc:  98.44%, Time: 0:01:20 \nIter:   1050, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:21 \nIter:   1080, Train Loss:  0.032, Train Acc: 100.00%, Time: 0:01:21 \nIter:   1110, Train Loss:  0.021, Train Acc: 100.00%, Time: 0:01:22 \nIter:   1140, Train Loss:  0.025, Train Acc: 100.00%, Time: 0:01:23 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/9/9\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/9/9\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.34, Test Acc:  90.16%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.76      0.98      0.86       128\n                   Filter       0.92      0.84      0.88       161\n    Compute Derived Value       0.97      0.81      0.88       185\n            Find Extremum       0.86      0.97      0.91       145\n                     Sort       0.94      0.94      0.94       112\n          Determine Range       0.89      0.85      0.87       136\nCharacterize Distribution       0.91      0.87      0.89       127\n           Find Anomalies       0.88      0.95      0.91       119\n                  Cluster       0.98      0.94      0.96       125\n                Correlate       0.94      0.92      0.93       165\n\n                micro avg       0.90      0.90      0.90      1403\n                macro avg       0.91      0.91      0.90      1403\n             weighted avg       0.91      0.90      0.90      1403\n\nConfusion Matrix...\n[[126   0   1   0   0   1   0   0   0   0]\n [ 10 136   0   5   1   1   2   4   0   2]\n [ 19   1 149   6   1   3   1   2   1   2]\n [  1   3   0 140   0   0   1   0   0   0]\n [  1   0   0   5 105   0   1   0   0   0]\n [  2   5   2   4   2 116   2   2   0   1]\n [  2   1   1   2   0   5 110   2   2   2]\n [  1   1   0   0   0   1   2 113   0   1]\n [  1   0   0   0   1   2   1   1 118   1]\n [  3   1   0   1   2   1   1   4   0 152]]\nTime usage: 0:00:02\nFold:  10\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  39.06%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.7, Train Acc:  53.12%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.4, Train Acc:  64.06%, Time: 0:00:18 *\nIter:    120, Train Loss:    1.3, Train Acc:  56.25%, Time: 0:00:19 \nIter:    150, Train Loss:   0.87, Train Acc:  73.44%, Time: 0:00:25 *\nIter:    180, Train Loss:    1.1, Train Acc:  67.19%, Time: 0:00:26 \nEpoch: 2\nIter:    210, Train Loss:   0.59, Train Acc:  81.25%, Time: 0:00:31 *\nIter:    240, Train Loss:   0.68, Train Acc:  78.12%, Time: 0:00:31 \nIter:    270, Train Loss:   0.65, Train Acc:  76.56%, Time: 0:00:32 \nIter:    300, Train Loss:   0.38, Train Acc:  87.50%, Time: 0:00:37 *\nIter:    330, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:00:41 *\nIter:    360, Train Loss:   0.46, Train Acc:  85.94%, Time: 0:00:42 \nIter:    390, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:00:43 \nEpoch: 3\nIter:    420, Train Loss:   0.19, Train Acc:  95.31%, Time: 0:00:47 *\nIter:    450, Train Loss:   0.16, Train Acc:  95.31%, Time: 0:00:48 \nIter:    480, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:00:52 *\nIter:    510, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:00:53 \nIter:    540, Train Loss:   0.24, Train Acc:  92.19%, Time: 0:00:54 \nIter:    570, Train Loss:   0.35, Train Acc:  92.19%, Time: 0:00:55 \nEpoch: 4\nIter:    600, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:00:55 \nIter:    630, Train Loss:  0.074, Train Acc: 100.00%, Time: 0:00:59 *\nIter:    660, Train Loss:  0.052, Train Acc: 100.00%, Time: 0:01:00 \nIter:    690, Train Loss:  0.086, Train Acc:  98.44%, Time: 0:01:01 \nIter:    720, Train Loss:  0.035, Train Acc: 100.00%, Time: 0:01:01 \nIter:    750, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:01:02 \nIter:    780, Train Loss:  0.036, Train Acc: 100.00%, Time: 0:01:03 \nEpoch: 5\nIter:    810, Train Loss:  0.039, Train Acc: 100.00%, Time: 0:01:04 \nIter:    840, Train Loss:  0.063, Train Acc:  98.44%, Time: 0:01:04 \nIter:    870, Train Loss:  0.082, Train Acc:  98.44%, Time: 0:01:05 \nIter:    900, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:06 \nIter:    930, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:06 \nIter:    960, Train Loss:  0.045, Train Acc: 100.00%, Time: 0:01:07 \nIter:    990, Train Loss:   0.14, Train Acc:  95.83%, Time: 0:01:08 \nEpoch: 6\nIter:   1020, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:08 \nIter:   1050, Train Loss:  0.029, Train Acc: 100.00%, Time: 0:01:09 \nIter:   1080, Train Loss:   0.03, Train Acc: 100.00%, Time: 0:01:10 \nIter:   1110, Train Loss:  0.026, Train Acc: 100.00%, Time: 0:01:10 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/10/10\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/10/10\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.34, Test Acc:  89.45%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.82      0.99      0.90       109\n                   Filter       0.89      0.84      0.86       158\n    Compute Derived Value       0.94      0.85      0.89       144\n            Find Extremum       0.86      0.96      0.91       182\n                     Sort       0.98      0.88      0.93       128\n          Determine Range       0.85      0.88      0.87       120\nCharacterize Distribution       0.98      0.86      0.92       126\n           Find Anomalies       0.93      0.79      0.85       137\n                  Cluster       0.93      0.93      0.93       135\n                Correlate       0.82      0.96      0.89       164\n\n                micro avg       0.89      0.89      0.89      1403\n                macro avg       0.90      0.89      0.89      1403\n             weighted avg       0.90      0.89      0.89      1403\n\nConfusion Matrix...\n[[108   0   0   0   0   0   0   0   0   1]\n [  2 132   0   6   0   6   0   4   0   8]\n [  6   5 123   4   0   2   1   0   0   3]\n [  1   2   2 174   0   1   0   0   0   2]\n [  2   2   0   5 112   2   0   0   4   1]\n [  4   0   2   5   1 106   1   0   0   1]\n [  1   4   3   1   0   1 108   0   2   6]\n [  7   1   1   4   0   4   0 108   1  11]\n [  0   1   0   1   1   2   0   3 126   1]\n [  0   1   0   2   0   0   0   1   2 158]]\nTime usage: 0:00:02\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "expert_test_acc", "execution_count": 56, "outputs": [{"output_type": "execute_result", "execution_count": 56, "data": {"text/plain": "[0.8903133894643213,\n 0.9102564092375275,\n 0.8945868935680118,\n 0.8896011385822568,\n 0.9173789175487311,\n 0.9052031355845613,\n 0.9130434781759021,\n 0.914468995945333,\n 0.9016393437100069,\n 0.8945117604282186]"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "np.mean(expert_test_acc),np.std(expert_test_acc),np.std(expert_test_acc,ddof=1),np.var(expert_test_acc)", "execution_count": 57, "outputs": [{"output_type": "execute_result", "execution_count": 57, "data": {"text/plain": "(0.903100346224487,\n 0.009908242579262691,\n 0.010444204719977177,\n 9.817327100951418e-05)"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "ex_train = []\ney_train = []\nfor ti in train_data_expert:\n    x_train, y_train = process_file(ti[:,0], ti[:,1], word_to_id, num_classes, seq_length)\n    ex_train.append(x_train)\n    ey_train.append(y_train)", "execution_count": 105, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "ex_train = np.asarray(ex_train)\ney_train = np.asarray(ey_train)", "execution_count": 106, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "len(ex_train[0]),len(ex_train[1]),len(ex_train[0][0]),len(ex_train)", "execution_count": 107, "outputs": [{"output_type": "execute_result", "execution_count": 107, "data": {"text/plain": "(636, 603, 41, 20)"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def mergeData(data_x, data_y):\n    merge_x = data_x[0]\n    merge_y = data_y[0]\n    for i in range(1,len(data_x)):\n        merge_x = np.r_[merge_x,data_x[i]]\n        merge_y = np.r_[merge_y,data_y[i]]\n        \n    return merge_x, merge_y", "execution_count": 108, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "expert_train_acc = []\nexpert_test_acc = []\nsplit_type = \"expert\"\nfold_id = 0\nfor train_i, test_i in kf.split(ex_train):\n    fold_id += 1\n    print(\"Fold: \", fold_id)\n    train_x, train_y = mergeData(ex_train[train_i],ey_train[train_i])\n    test_x, test_y = mergeData(ex_train[test_i],ey_train[test_i])\n    expert_train_acc.append(model.train(train_x, train_y,split_type,fold_id))\n    expert_test_acc.append(model.evaluate_model(test_x, test_y,split_type,fold_id,categories))", "execution_count": 109, "outputs": [{"output_type": "stream", "text": "Fold:  1\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  31.25%, Time: 0:00:09 *\nIter:     60, Train Loss:    1.7, Train Acc:  50.00%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.4, Train Acc:  60.94%, Time: 0:00:20 *\nIter:    120, Train Loss:    1.2, Train Acc:  59.38%, Time: 0:00:21 \nIter:    150, Train Loss:    1.0, Train Acc:  73.44%, Time: 0:00:26 *\nIter:    180, Train Loss:   0.84, Train Acc:  73.44%, Time: 0:00:27 \nEpoch: 2\nIter:    210, Train Loss:    0.7, Train Acc:  76.56%, Time: 0:00:33 *\nIter:    240, Train Loss:   0.57, Train Acc:  82.81%, Time: 0:00:39 *\nIter:    270, Train Loss:   0.42, Train Acc:  89.06%, Time: 0:00:45 *\nIter:    300, Train Loss:   0.41, Train Acc:  93.75%, Time: 0:00:52 *\nIter:    330, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:00:53 \nIter:    360, Train Loss:   0.35, Train Acc:  85.94%, Time: 0:00:53 \nIter:    390, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:00:59 *\nEpoch: 3\nIter:    420, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:01:00 \nIter:    450, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:01 \nIter:    480, Train Loss:   0.22, Train Acc:  92.19%, Time: 0:01:01 \nIter:    510, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:01:02 \nIter:    540, Train Loss:    0.2, Train Acc:  92.19%, Time: 0:01:03 \nIter:    570, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:01:03 \nIter:    600, Train Loss:   0.13, Train Acc:  98.33%, Time: 0:01:08 *\nEpoch: 4\nIter:    630, Train Loss:  0.067, Train Acc:  98.44%, Time: 0:01:15 *\nIter:    660, Train Loss:  0.055, Train Acc: 100.00%, Time: 0:01:20 *\nIter:    690, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:01:21 \nIter:    720, Train Loss:  0.097, Train Acc:  95.31%, Time: 0:01:22 \nIter:    750, Train Loss:  0.049, Train Acc: 100.00%, Time: 0:01:23 \nIter:    780, Train Loss:  0.095, Train Acc:  96.88%, Time: 0:01:23 \nEpoch: 5\nIter:    810, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:01:24 \nIter:    840, Train Loss:  0.044, Train Acc: 100.00%, Time: 0:01:25 \nIter:    870, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:25 \nIter:    900, Train Loss:  0.048, Train Acc:  98.44%, Time: 0:01:26 \nIter:    930, Train Loss:  0.081, Train Acc:  98.44%, Time: 0:01:27 \nIter:    960, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:27 \nIter:    990, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:01:28 \nEpoch: 6\nIter:   1020, Train Loss:  0.033, Train Acc:  98.44%, Time: 0:01:29 \nIter:   1050, Train Loss:  0.025, Train Acc:  98.44%, Time: 0:01:29 \nIter:   1080, Train Loss:  0.027, Train Acc: 100.00%, Time: 0:01:30 \nIter:   1110, Train Loss:  0.053, Train Acc: 100.00%, Time: 0:01:31 \nIter:   1140, Train Loss:  0.012, Train Acc: 100.00%, Time: 0:01:31 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/1/1\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/1/1\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.3, Test Acc:  63.36%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.66      0.70      0.68       124\n                   Filter       0.53      0.75      0.62       119\n    Compute Derived Value       0.61      0.49      0.54       131\n            Find Extremum       0.80      0.76      0.78       123\n                     Sort       0.88      0.66      0.75       121\n          Determine Range       0.77      0.50      0.60       125\nCharacterize Distribution       0.69      0.89      0.78       127\n           Find Anomalies       0.47      0.40      0.44       121\n                  Cluster       0.62      0.49      0.55       123\n                Correlate       0.48      0.70      0.57       125\n\n                micro avg       0.63      0.63      0.63      1239\n                macro avg       0.65      0.63      0.63      1239\n             weighted avg       0.65      0.63      0.63      1239\n\nConfusion Matrix...\n[[ 87  11   9   0   1   5   8   1   1   1]\n [  0  89   4   2   0   1   2  18   0   3]\n [ 28   2  64   0   5   2   4   7   1  18]\n [  6  13   5  94   0   2   0   0   0   3]\n [  0   1   2  15  80   2   5   3  11   2]\n [  3  16  12   1   1  62   8   1   6  15]\n [  2   0   5   1   0   2 113   0   1   3]\n [  0  35   0   2   3   1   1  49   4  26]\n [  5   0   3   1   0   4  15  12  60  23]\n [  0   2   1   1   1   0   8  13  12  87]]\nTime usage: 0:00:02\nFold:  2\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  34.38%, Time: 0:00:09 *\nIter:     60, Train Loss:    1.7, Train Acc:  57.81%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:20 *\nIter:    120, Train Loss:    1.0, Train Acc:  68.75%, Time: 0:00:25 *\nIter:    150, Train Loss:    1.1, Train Acc:  67.19%, Time: 0:00:26 \nIter:    180, Train Loss:   0.75, Train Acc:  78.12%, Time: 0:00:31 *\nEpoch: 2\nIter:    210, Train Loss:   0.74, Train Acc:  73.44%, Time: 0:00:32 \nIter:    240, Train Loss:   0.46, Train Acc:  89.06%, Time: 0:00:38 *\nIter:    270, Train Loss:   0.61, Train Acc:  76.56%, Time: 0:00:38 \nIter:    300, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:00:44 *\nIter:    330, Train Loss:   0.46, Train Acc:  90.62%, Time: 0:00:45 \nIter:    360, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:00:50 *\nIter:    390, Train Loss:   0.29, Train Acc:  92.68%, Time: 0:00:51 \nEpoch: 3\nIter:    420, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:00:52 \nIter:    450, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:00:57 *\nIter:    480, Train Loss:   0.14, Train Acc:  95.31%, Time: 0:00:57 \nIter:    510, Train Loss:   0.13, Train Acc:  98.44%, Time: 0:01:02 *\nIter:    540, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:03 \nIter:    570, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:01:03 \nEpoch: 4\nIter:    600, Train Loss:   0.15, Train Acc:  95.31%, Time: 0:01:04 \nIter:    630, Train Loss:  0.075, Train Acc: 100.00%, Time: 0:01:08 *\nIter:    660, Train Loss:   0.11, Train Acc:  95.31%, Time: 0:01:09 \nIter:    690, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:10 \nIter:    720, Train Loss:  0.069, Train Acc:  98.44%, Time: 0:01:10 \nIter:    750, Train Loss:  0.075, Train Acc:  98.44%, Time: 0:01:11 \nIter:    780, Train Loss:  0.085, Train Acc:  97.56%, Time: 0:01:12 \nEpoch: 5\nIter:    810, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:12 \nIter:    840, Train Loss:  0.041, Train Acc: 100.00%, Time: 0:01:13 \nIter:    870, Train Loss:  0.053, Train Acc: 100.00%, Time: 0:01:14 \nIter:    900, Train Loss:  0.055, Train Acc:  98.44%, Time: 0:01:15 \nIter:    930, Train Loss:  0.041, Train Acc:  98.44%, Time: 0:01:15 \nIter:    960, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:16 \nEpoch: 6\nIter:    990, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1020, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1050, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:18 \nIter:   1080, Train Loss: 0.0097, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1110, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:19 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/2/2\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/2/2\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.5, Test Acc:  60.52%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.80      0.36      0.50       181\n                   Filter       0.36      0.23      0.28       167\n    Compute Derived Value       0.66      0.44      0.53       250\n            Find Extremum       0.65      0.91      0.76       173\n                     Sort       0.66      0.80      0.72       120\n          Determine Range       0.50      0.74      0.59       178\nCharacterize Distribution       0.70      0.86      0.77        86\n           Find Anomalies       0.48      0.88      0.62       140\n                  Cluster       0.73      0.63      0.68       111\n                Correlate       0.78      0.52      0.62       172\n\n                micro avg       0.61      0.61      0.61      1578\n                macro avg       0.63      0.64      0.61      1578\n             weighted avg       0.63      0.61      0.59      1578\n\nConfusion Matrix...\n[[ 66  20  29  17  10  19   4  13   0   3]\n [  9  38   9  23   7  57   1  20   1   2]\n [  4  15 109  26   8  28  12  34   4  10]\n [  1   3   1 158   1   1   0   4   1   3]\n [  0   3   0   3  96   1   0   8   9   0]\n [  0   3   7   2  10 132   9   6   7   2]\n [  0   0   1   1   2   5  74   1   1   1]\n [  1   3   1   8   0   0   0 123   1   3]\n [  0   5   2   1   6   6   1  19  70   1]\n [  2  15   6   3   5  17   4  29   2  89]]\nTime usage: 0:00:02\nFold:  3\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  42.19%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.6, Train Acc:  56.25%, Time: 0:00:13 *\nIter:     90, Train Loss:    1.3, Train Acc:  64.06%, Time: 0:00:20 *\nIter:    120, Train Loss:    1.1, Train Acc:  75.00%, Time: 0:00:25 *\nIter:    150, Train Loss:   0.77, Train Acc:  78.12%, Time: 0:00:31 *\nIter:    180, Train Loss:   0.79, Train Acc:  78.12%, Time: 0:00:31 \nEpoch: 2\nIter:    210, Train Loss:   0.52, Train Acc:  84.38%, Time: 0:00:37 *\nIter:    240, Train Loss:   0.68, Train Acc:  82.81%, Time: 0:00:37 \nIter:    270, Train Loss:   0.32, Train Acc:  89.06%, Time: 0:00:42 *\nIter:    300, Train Loss:   0.38, Train Acc:  89.06%, Time: 0:00:43 \nIter:    330, Train Loss:   0.44, Train Acc:  85.94%, Time: 0:00:44 \nIter:    360, Train Loss:   0.32, Train Acc:  90.62%, Time: 0:00:49 *\nIter:    390, Train Loss:   0.31, Train Acc:  87.50%, Time: 0:00:50 \nEpoch: 3\nIter:    420, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:00:54 *\nIter:    450, Train Loss:   0.28, Train Acc:  90.62%, Time: 0:00:55 \nIter:    480, Train Loss:   0.17, Train Acc:  95.31%, Time: 0:00:59 *\nIter:    510, Train Loss:   0.11, Train Acc: 100.00%, Time: 0:01:05 *\nIter:    540, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:06 \nIter:    570, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:07 \nIter:    600, Train Loss:   0.23, Train Acc:  92.45%, Time: 0:01:07 \nEpoch: 4\nIter:    630, Train Loss:  0.093, Train Acc:  96.88%, Time: 0:01:08 \nIter:    660, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:01:09 \nIter:    690, Train Loss:  0.049, Train Acc:  98.44%, Time: 0:01:09 \nIter:    720, Train Loss:  0.066, Train Acc: 100.00%, Time: 0:01:10 \nIter:    750, Train Loss:  0.052, Train Acc: 100.00%, Time: 0:01:11 \nIter:    780, Train Loss:  0.085, Train Acc:  96.88%, Time: 0:01:11 \nEpoch: 5\nIter:    810, Train Loss:  0.078, Train Acc:  96.88%, Time: 0:01:12 \nIter:    840, Train Loss:  0.083, Train Acc:  98.44%, Time: 0:01:13 \nIter:    870, Train Loss:  0.012, Train Acc: 100.00%, Time: 0:01:13 \nIter:    900, Train Loss:   0.13, Train Acc:  98.44%, Time: 0:01:14 \nIter:    930, Train Loss:  0.066, Train Acc:  98.44%, Time: 0:01:15 \nIter:    960, Train Loss:   0.09, Train Acc:  96.88%, Time: 0:01:15 \nIter:    990, Train Loss:  0.032, Train Acc: 100.00%, Time: 0:01:16 \nEpoch: 6\nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/3/3\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/3/3\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.0, Test Acc:  75.20%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.73      0.53      0.61       111\n                   Filter       0.75      0.77      0.76       146\n    Compute Derived Value       0.61      0.82      0.70       119\n            Find Extremum       0.61      0.78      0.68       125\n                     Sort       0.88      0.53      0.66       112\n          Determine Range       0.86      0.51      0.65       136\nCharacterize Distribution       0.95      0.77      0.85       126\n           Find Anomalies       0.81      0.92      0.86       124\n                  Cluster       0.74      0.94      0.83       120\n                Correlate       0.77      0.94      0.84       127\n\n                micro avg       0.75      0.75      0.75      1246\n                macro avg       0.77      0.75      0.74      1246\n             weighted avg       0.77      0.75      0.75      1246\n\nConfusion Matrix...\n[[ 59   2  31  13   0   0   0   1   1   4]\n [ 18 112   0   0   1   6   0   2   6   1]\n [  2   6  97   1   0   0   0   4   4   5]\n [  1   2   8  97   0   0   0   2  10   5]\n [  0  10  10  27  59   0   1   2   2   1]\n [  1   9   7  18   7  70   2   7   3  12]\n [  0   7   5   0   0   5  97   1   9   2]\n [  0   1   0   2   0   0   0 114   3   4]\n [  0   0   0   1   0   0   2   2 113   2]\n [  0   0   2   0   0   0   0   5   1 119]]\nTime usage: 0:00:02\nFold:  4\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  35.94%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.6, Train Acc:  45.31%, Time: 0:00:13 *\nIter:     90, Train Loss:    1.2, Train Acc:  73.44%, Time: 0:00:20 *\nIter:    120, Train Loss:    1.2, Train Acc:  60.94%, Time: 0:00:21 \nIter:    150, Train Loss:   0.66, Train Acc:  84.38%, Time: 0:00:27 *\nIter:    180, Train Loss:   0.88, Train Acc:  70.31%, Time: 0:00:28 \nEpoch: 2\nIter:    210, Train Loss:   0.51, Train Acc:  90.62%, Time: 0:00:34 *\nIter:    240, Train Loss:   0.56, Train Acc:  84.38%, Time: 0:00:34 \nIter:    270, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:00:35 \nIter:    300, Train Loss:   0.28, Train Acc:  95.31%, Time: 0:00:41 *\nIter:    330, Train Loss:   0.48, Train Acc:  79.69%, Time: 0:00:42 \nIter:    360, Train Loss:   0.54, Train Acc:  87.50%, Time: 0:00:42 \nIter:    390, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:00:43 \nEpoch: 3\nIter:    420, Train Loss:   0.27, Train Acc:  90.62%, Time: 0:00:44 \nIter:    450, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:44 \nIter:    480, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:00:45 \nIter:    510, Train Loss:    0.3, Train Acc:  90.62%, Time: 0:00:46 \nIter:    540, Train Loss:   0.25, Train Acc:  92.19%, Time: 0:00:47 \nIter:    570, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:47 \nIter:    600, Train Loss:   0.17, Train Acc:  93.55%, Time: 0:00:48 \nEpoch: 4\nIter:    630, Train Loss:  0.049, Train Acc: 100.00%, Time: 0:00:54 *\nIter:    660, Train Loss:  0.086, Train Acc:  98.44%, Time: 0:00:55 \nIter:    690, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:00:56 \nIter:    720, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:00:56 \nIter:    750, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:00:57 \nIter:    780, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:00:58 \nEpoch: 5\nIter:    810, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:00:58 \nIter:    840, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:00:59 \nIter:    870, Train Loss:  0.046, Train Acc:  98.44%, Time: 0:01:00 \nIter:    900, Train Loss:  0.046, Train Acc:  98.44%, Time: 0:01:00 \nIter:    930, Train Loss:  0.058, Train Acc:  98.44%, Time: 0:01:01 \nIter:    960, Train Loss:  0.086, Train Acc:  96.88%, Time: 0:01:02 \nIter:    990, Train Loss:  0.036, Train Acc: 100.00%, Time: 0:01:02 \nEpoch: 6\nIter:   1020, Train Loss: 0.0074, Train Acc: 100.00%, Time: 0:01:03 \nIter:   1050, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:04 \nIter:   1080, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:05 \nIter:   1110, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:05 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/4/4\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/4/4\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.7, Test Acc:  61.36%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.68      0.35      0.46       122\n                   Filter       0.53      0.42      0.47       133\n    Compute Derived Value       0.28      0.34      0.31       122\n            Find Extremum       0.56      0.92      0.70       126\n                     Sort       0.94      0.80      0.87       117\n          Determine Range       0.58      0.95      0.72       129\nCharacterize Distribution       0.62      0.69      0.65       121\n           Find Anomalies       0.73      0.47      0.57       118\n                  Cluster       0.87      0.57      0.69       127\n                Correlate       0.69      0.59      0.64       122\n\n                micro avg       0.61      0.61      0.61      1237\n                macro avg       0.65      0.61      0.61      1237\n             weighted avg       0.65      0.61      0.61      1237\n\nConfusion Matrix...\n[[ 43   3  47   2   0  12  14   0   0   1]\n [  1  56  29  13   0  15   6  10   1   2]\n [  1   0  42  29   0  25  15   0   2   8]\n [  1   0   5 116   0   0   1   3   0   0]\n [  0   0   4  13  94   2   3   0   1   0]\n [  0   0   0   3   1 123   1   0   0   1]\n [  0   1   2  15   3   8  84   0   6   2]\n [  2  23   1   0   0  11   9  56   0  16]\n [ 15  12   2   1   2  14   3   3  73   2]\n [  0  11  17  15   0   1   0   5   1  72]]\nTime usage: 0:00:02\nFold:  5\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  46.88%, Time: 0:00:09 *\nIter:     60, Train Loss:    1.7, Train Acc:  43.75%, Time: 0:00:09 \nIter:     90, Train Loss:    1.3, Train Acc:  71.88%, Time: 0:00:16 *\nIter:    120, Train Loss:    1.1, Train Acc:  71.88%, Time: 0:00:17 \nIter:    150, Train Loss:   0.87, Train Acc:  79.69%, Time: 0:00:23 *\nIter:    180, Train Loss:    0.9, Train Acc:  70.31%, Time: 0:00:23 \nEpoch: 2\nIter:    210, Train Loss:   0.49, Train Acc:  90.62%, Time: 0:00:30 *\nIter:    240, Train Loss:   0.64, Train Acc:  82.81%, Time: 0:00:30 \nIter:    270, Train Loss:   0.36, Train Acc:  92.19%, Time: 0:00:37 *\nIter:    300, Train Loss:   0.28, Train Acc:  92.19%, Time: 0:00:37 \nIter:    330, Train Loss:   0.56, Train Acc:  81.25%, Time: 0:00:38 \nIter:    360, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:00:45 *\nEpoch: 3\nIter:    390, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:00:45 \nIter:    420, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:00:52 *\nIter:    450, Train Loss:   0.22, Train Acc:  95.31%, Time: 0:00:52 \nIter:    480, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:53 \nIter:    510, Train Loss:   0.26, Train Acc:  92.19%, Time: 0:00:54 \nIter:    540, Train Loss:   0.14, Train Acc:  98.44%, Time: 0:01:00 *\nIter:    570, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:01 \nEpoch: 4\nIter:    600, Train Loss:   0.15, Train Acc:  95.31%, Time: 0:01:01 \nIter:    630, Train Loss:  0.072, Train Acc: 100.00%, Time: 0:01:07 *\nIter:    660, Train Loss:  0.069, Train Acc: 100.00%, Time: 0:01:08 \nIter:    690, Train Loss:  0.079, Train Acc:  98.44%, Time: 0:01:08 \nIter:    720, Train Loss:  0.092, Train Acc:  98.44%, Time: 0:01:09 \nIter:    750, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:10 \nEpoch: 5\nIter:    780, Train Loss:  0.024, Train Acc: 100.00%, Time: 0:01:10 \nIter:    810, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:11 \nIter:    840, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:12 \nIter:    870, Train Loss:  0.047, Train Acc: 100.00%, Time: 0:01:13 \nIter:    900, Train Loss:   0.04, Train Acc:  98.44%, Time: 0:01:13 \nIter:    930, Train Loss:  0.098, Train Acc:  95.31%, Time: 0:01:14 \nIter:    960, Train Loss:  0.021, Train Acc: 100.00%, Time: 0:01:15 \nEpoch: 6\nIter:    990, Train Loss:  0.042, Train Acc: 100.00%, Time: 0:01:15 \nIter:   1020, Train Loss:  0.054, Train Acc:  98.44%, Time: 0:01:16 \nIter:   1050, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1080, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1110, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:18 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/5/5\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/5/5\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  68.10%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.67      0.79      0.73       248\n                   Filter       0.51      0.59      0.55       220\n    Compute Derived Value       0.52      0.65      0.58       181\n            Find Extremum       0.76      0.77      0.77       203\n                     Sort       0.81      0.67      0.73       124\n          Determine Range       0.79      0.63      0.70       122\nCharacterize Distribution       0.85      0.83      0.84       145\n           Find Anomalies       0.72      0.53      0.61       204\n                  Cluster       0.69      0.59      0.63       136\n                Correlate       0.74      0.73      0.73       207\n\n                micro avg       0.68      0.68      0.68      1790\n                macro avg       0.71      0.68      0.69      1790\n             weighted avg       0.69      0.68      0.68      1790\n\nConfusion Matrix...\n[[196   2  39   4   0   1   4   0   0   2]\n [ 29 130   6  22   0   0   1  10   6  16]\n [ 39  18 117   0   0   1   0   3   0   3]\n [  5   5   9 156  12   0   7   8   0   1]\n [  4   7   6  12  83   6   0   0   4   2]\n [  0   7  18   5   1  77   4   3   0   7]\n [  1   1   9   0   4   8 121   0   1   0]\n [  7  41   2   0   0   2   1 108  24  19]\n [ 11  29   0   3   3   0   1   5  80   4]\n [  0  16  18   2   0   2   3  14   1 151]]\nTime usage: 0:00:02\nFold:  6\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  48.44%, Time: 0:00:09 *\nIter:     60, Train Loss:    1.6, Train Acc:  53.12%, Time: 0:00:16 *\nIter:     90, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:22 *\nIter:    120, Train Loss:    1.0, Train Acc:  78.12%, Time: 0:00:28 *\nIter:    150, Train Loss:   0.74, Train Acc:  79.69%, Time: 0:00:34 *\nIter:    180, Train Loss:   0.76, Train Acc:  76.56%, Time: 0:00:35 \nEpoch: 2\nIter:    210, Train Loss:   0.84, Train Acc:  75.00%, Time: 0:00:36 \nIter:    240, Train Loss:    0.5, Train Acc:  85.94%, Time: 0:00:42 *\nIter:    270, Train Loss:   0.63, Train Acc:  81.25%, Time: 0:00:43 \nIter:    300, Train Loss:   0.46, Train Acc:  90.62%, Time: 0:00:49 *\nIter:    330, Train Loss:   0.56, Train Acc:  79.69%, Time: 0:00:50 \nIter:    360, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:55 *\nIter:    390, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:01:02 *\nEpoch: 3\nIter:    420, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:01:02 \nIter:    450, Train Loss:   0.19, Train Acc:  92.19%, Time: 0:01:03 \nIter:    480, Train Loss:   0.25, Train Acc:  92.19%, Time: 0:01:04 \nIter:    510, Train Loss:   0.39, Train Acc:  89.06%, Time: 0:01:04 \nIter:    540, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:01:05 \nIter:    570, Train Loss:   0.21, Train Acc:  98.44%, Time: 0:01:06 \nEpoch: 4\nIter:    600, Train Loss:  0.053, Train Acc: 100.00%, Time: 0:01:06 \nIter:    630, Train Loss:  0.065, Train Acc:  98.44%, Time: 0:01:07 \nIter:    660, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:08 \nIter:    690, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:08 \nIter:    720, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:01:09 \nIter:    750, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:01:10 \nIter:    780, Train Loss:  0.029, Train Acc: 100.00%, Time: 0:01:10 \nEpoch: 5\nIter:    810, Train Loss:  0.044, Train Acc:  98.44%, Time: 0:01:11 \nIter:    840, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:12 \nIter:    870, Train Loss:  0.045, Train Acc:  98.44%, Time: 0:01:12 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/6/6\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/6/6\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.93, Test Acc:  71.61%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.63      0.79      0.70       123\n                   Filter       0.61      0.64      0.63       181\n    Compute Derived Value       0.48      0.81      0.60       149\n            Find Extremum       0.94      0.70      0.81       213\n                     Sort       0.87      0.74      0.80       139\n          Determine Range       0.70      0.85      0.77       136\nCharacterize Distribution       0.93      0.65      0.76       162\n           Find Anomalies       0.82      0.69      0.75       149\n                  Cluster       0.83      0.62      0.71       147\n                Correlate       0.66      0.72      0.69       179\n\n                micro avg       0.72      0.72      0.72      1578\n                macro avg       0.75      0.72      0.72      1578\n             weighted avg       0.76      0.72      0.72      1578\n\nConfusion Matrix...\n[[ 97   0  21   1   0   2   0   2   0   0]\n [ 12 116  37   3   0   2   0   4   0   7]\n [ 12   0 121   0   0   9   1   0   1   5]\n [  9  21   9 150   8  13   0   1   0   2]\n [  2  16   7   4 103   1   1   0   1   4]\n [  2   5   2   0   0 115   1   8   1   2]\n [  3  13  10   0   0   0 105   1  15  15]\n [ 10   8  12   0   0   6   0 103   0  10]\n [  1   4   7   0   8   7   3   5  91  21]\n [  5   6  26   1   0   9   2   1   0 129]]\nTime usage: 0:00:02\nFold:  7\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.5, Train Acc:  59.38%, Time: 0:00:13 *\nIter:     90, Train Loss:    1.1, Train Acc:  78.12%, Time: 0:00:18 *\nIter:    120, Train Loss:    0.9, Train Acc:  73.44%, Time: 0:00:19 \nIter:    150, Train Loss:   0.65, Train Acc:  84.38%, Time: 0:00:23 *\nIter:    180, Train Loss:    0.7, Train Acc:  82.81%, Time: 0:00:24 \nEpoch: 2\nIter:    210, Train Loss:   0.47, Train Acc:  89.06%, Time: 0:00:29 *\nIter:    240, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:00:35 *\nIter:    270, Train Loss:   0.45, Train Acc:  89.06%, Time: 0:00:35 \nIter:    300, Train Loss:   0.55, Train Acc:  81.25%, Time: 0:00:36 \nIter:    330, Train Loss:    0.3, Train Acc:  89.06%, Time: 0:00:37 \nIter:    360, Train Loss:   0.44, Train Acc:  87.50%, Time: 0:00:37 \nIter:    390, Train Loss:   0.12, Train Acc:  97.22%, Time: 0:00:42 *\nEpoch: 3\nIter:    420, Train Loss:   0.27, Train Acc:  92.19%, Time: 0:00:43 \nIter:    450, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:00:48 *\nIter:    480, Train Loss:   0.22, Train Acc:  96.88%, Time: 0:00:48 \nIter:    510, Train Loss:   0.39, Train Acc:  85.94%, Time: 0:00:49 \nIter:    540, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:00:50 \nIter:    570, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:00:50 \nEpoch: 4\nIter:    600, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:00:51 \nIter:    630, Train Loss:   0.16, Train Acc:  95.31%, Time: 0:00:52 \nIter:    660, Train Loss:  0.083, Train Acc: 100.00%, Time: 0:01:03 *\nIter:    690, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:04 \nIter:    720, Train Loss:   0.11, Train Acc:  95.31%, Time: 0:01:04 \nIter:    750, Train Loss:  0.075, Train Acc:  98.44%, Time: 0:01:05 \nIter:    780, Train Loss:  0.076, Train Acc:  97.22%, Time: 0:01:06 \nEpoch: 5\nIter:    810, Train Loss:  0.085, Train Acc:  96.88%, Time: 0:01:06 \nIter:    840, Train Loss:  0.055, Train Acc:  98.44%, Time: 0:01:07 \nIter:    870, Train Loss:  0.047, Train Acc:  98.44%, Time: 0:01:08 \nIter:    900, Train Loss:  0.073, Train Acc:  96.88%, Time: 0:01:08 \nIter:    930, Train Loss:  0.079, Train Acc:  96.88%, Time: 0:01:09 \nIter:    960, Train Loss:  0.096, Train Acc:  98.44%, Time: 0:01:10 \nEpoch: 6\nIter:    990, Train Loss:  0.033, Train Acc: 100.00%, Time: 0:01:10 \nIter:   1020, Train Loss:  0.032, Train Acc: 100.00%, Time: 0:01:11 \nIter:   1050, Train Loss:  0.036, Train Acc:  98.44%, Time: 0:01:12 \nIter:   1080, Train Loss:  0.063, Train Acc:  96.88%, Time: 0:01:13 \nIter:   1110, Train Loss:  0.051, Train Acc:  98.44%, Time: 0:01:13 \nIter:   1140, Train Loss:  0.046, Train Acc:  98.44%, Time: 0:01:14 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/7/7\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/7/7\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.6, Test Acc:  61.72%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.39      0.69      0.50       108\n                   Filter       0.45      0.45      0.45       109\n    Compute Derived Value       0.94      0.22      0.36       211\n            Find Extremum       0.71      0.88      0.78       325\n                     Sort       0.86      0.75      0.80       114\n          Determine Range       0.36      0.28      0.31       121\nCharacterize Distribution       0.56      0.62      0.59       173\n           Find Anomalies       0.53      0.47      0.50       126\n                  Cluster       0.78      0.77      0.77       120\n                Correlate       0.68      0.80      0.73       176\n\n                micro avg       0.62      0.62      0.62      1583\n                macro avg       0.62      0.59      0.58      1583\n             weighted avg       0.65      0.62      0.60      1583\n\nConfusion Matrix...\n[[ 75   4   0   1   0   2  11  13   0   2]\n [ 17  49   0   4   5  12   1   2   5  14]\n [ 46  24  47  21   1  23  23  12   3  11]\n [ 20   8   0 287   0   4   2   2   2   0]\n [  0   4   0  20  86   4   0   0   0   0]\n [ 14  17   1  27   4  34  14   2   4   4]\n [ 14   1   1   8   4   4 107   7   5  22]\n [  0   0   0  35   0  11  10  59   3   8]\n [  0   0   1   1   0   1  16   3  92   6]\n [  8   1   0   3   0   0   7  12   4 141]]\nTime usage: 0:00:02\nFold:  8\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  29.69%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.7, Train Acc:  39.06%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.2, Train Acc:  75.00%, Time: 0:00:20 *\nIter:    120, Train Loss:    1.1, Train Acc:  64.06%, Time: 0:00:21 \nIter:    150, Train Loss:   0.95, Train Acc:  75.00%, Time: 0:00:22 \nIter:    180, Train Loss:   0.73, Train Acc:  82.81%, Time: 0:00:28 *\nEpoch: 2\nIter:    210, Train Loss:   0.56, Train Acc:  89.06%, Time: 0:00:34 *\nIter:    240, Train Loss:    0.5, Train Acc:  87.50%, Time: 0:00:35 \nIter:    270, Train Loss:   0.44, Train Acc:  82.81%, Time: 0:00:35 \nIter:    300, Train Loss:   0.51, Train Acc:  85.94%, Time: 0:00:36 \nIter:    330, Train Loss:   0.52, Train Acc:  85.94%, Time: 0:00:37 \nIter:    360, Train Loss:   0.39, Train Acc:  85.94%, Time: 0:00:37 \nIter:    390, Train Loss:   0.33, Train Acc:  89.06%, Time: 0:00:38 \nEpoch: 3\nIter:    420, Train Loss:   0.31, Train Acc:  92.19%, Time: 0:00:43 *\nIter:    450, Train Loss:   0.13, Train Acc:  95.31%, Time: 0:00:48 *\nIter:    480, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:00:53 *\nIter:    510, Train Loss:   0.15, Train Acc:  95.31%, Time: 0:00:54 \nIter:    540, Train Loss:    0.3, Train Acc:  92.19%, Time: 0:00:54 \nIter:    570, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:00:55 \nIter:    600, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:00 *\nEpoch: 4\nIter:    630, Train Loss:  0.096, Train Acc:  96.88%, Time: 0:01:01 \nIter:    660, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:02 \nIter:    690, Train Loss:  0.059, Train Acc: 100.00%, Time: 0:01:02 \nIter:    720, Train Loss:   0.06, Train Acc:  98.44%, Time: 0:01:03 \nIter:    750, Train Loss:   0.13, Train Acc:  95.31%, Time: 0:01:04 \nIter:    780, Train Loss:  0.052, Train Acc:  96.88%, Time: 0:01:04 \nEpoch: 5\nIter:    810, Train Loss:  0.036, Train Acc:  98.44%, Time: 0:01:05 \nIter:    840, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:06 \nIter:    870, Train Loss:   0.04, Train Acc: 100.00%, Time: 0:01:06 \nIter:    900, Train Loss:  0.026, Train Acc: 100.00%, Time: 0:01:07 \nIter:    930, Train Loss:   0.08, Train Acc:  98.44%, Time: 0:01:08 \nIter:    960, Train Loss:  0.033, Train Acc: 100.00%, Time: 0:01:09 \nIter:    990, Train Loss:  0.037, Train Acc:  98.44%, Time: 0:01:09 \nEpoch: 6\nIter:   1020, Train Loss:  0.063, Train Acc:  98.44%, Time: 0:01:10 \nIter:   1050, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:11 \nIter:   1080, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:11 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/8/8\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/8/8\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.3, Test Acc:  65.38%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.69      0.53      0.60       121\n                   Filter       0.46      0.51      0.48       130\n    Compute Derived Value       0.75      0.39      0.51       127\n            Find Extremum       0.61      0.77      0.68       124\n                     Sort       0.82      0.85      0.84       124\n          Determine Range       0.79      0.72      0.76       120\nCharacterize Distribution       0.91      0.60      0.72       135\n           Find Anomalies       0.69      0.48      0.57       143\n                  Cluster       0.82      0.76      0.79       139\n                Correlate       0.44      0.93      0.60       134\n\n                micro avg       0.65      0.65      0.65      1297\n                macro avg       0.70      0.65      0.65      1297\n             weighted avg       0.70      0.65      0.65      1297\n\nConfusion Matrix...\n[[ 64  11   5  18   2   3   0   0   0  18]\n [  1  66   1   1   0  15   0  20   6  20]\n [ 17   9  49  31   3   0   4   0   0  14]\n [  4   7   0  96  12   0   0   2   0   3]\n [  3   0   0   0 106   3   2   0   9   1]\n [  2  19   0   6   2  87   1   1   2   0]\n [  1   5   7   2   0   2  81   2   0  35]\n [  0  23   3   3   0   0   0  69   4  41]\n [  0   1   0   1   4   0   1   3 106  23]\n [  1   4   0   0   0   0   0   3   2 124]]\nTime usage: 0:00:02\nFold:  9\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  37.50%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.8, Train Acc:  48.44%, Time: 0:00:13 *\nIter:     90, Train Loss:    1.6, Train Acc:  53.12%, Time: 0:00:18 *\nIter:    120, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:00:23 *\nIter:    150, Train Loss:    1.0, Train Acc:  68.75%, Time: 0:00:24 \nIter:    180, Train Loss:   0.89, Train Acc:  73.44%, Time: 0:00:30 *\nEpoch: 2\nIter:    210, Train Loss:   0.63, Train Acc:  82.81%, Time: 0:00:35 *\nIter:    240, Train Loss:   0.65, Train Acc:  79.69%, Time: 0:00:36 \nIter:    270, Train Loss:    0.5, Train Acc:  84.38%, Time: 0:00:41 *\nIter:    300, Train Loss:   0.45, Train Acc:  89.06%, Time: 0:00:47 *\nIter:    330, Train Loss:   0.45, Train Acc:  89.06%, Time: 0:00:47 \nIter:    360, Train Loss:   0.35, Train Acc:  87.50%, Time: 0:00:48 \nIter:    390, Train Loss:   0.67, Train Acc:  78.12%, Time: 0:00:49 \nEpoch: 3\nIter:    420, Train Loss:    0.3, Train Acc:  85.94%, Time: 0:00:49 \nIter:    450, Train Loss:   0.32, Train Acc:  90.62%, Time: 0:00:55 *\nIter:    480, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:01:00 *\nIter:    510, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:04 *\nIter:    540, Train Loss:   0.29, Train Acc:  95.31%, Time: 0:01:05 \nIter:    570, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:06 \nIter:    600, Train Loss:   0.16, Train Acc:  95.65%, Time: 0:01:07 \nEpoch: 4\nIter:    630, Train Loss:  0.048, Train Acc: 100.00%, Time: 0:01:12 *\nIter:    660, Train Loss:  0.073, Train Acc: 100.00%, Time: 0:01:13 \nIter:    690, Train Loss:   0.04, Train Acc: 100.00%, Time: 0:01:13 \nIter:    720, Train Loss:  0.027, Train Acc: 100.00%, Time: 0:01:14 \nIter:    750, Train Loss:  0.076, Train Acc:  96.88%, Time: 0:01:15 \nIter:    780, Train Loss:   0.12, Train Acc:  93.75%, Time: 0:01:15 \nEpoch: 5\nIter:    810, Train Loss:  0.055, Train Acc:  98.44%, Time: 0:01:16 \nIter:    840, Train Loss:  0.057, Train Acc:  98.44%, Time: 0:01:17 \nIter:    870, Train Loss:  0.081, Train Acc:  96.88%, Time: 0:01:17 \nIter:    900, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:01:18 \nIter:    930, Train Loss:  0.068, Train Acc:  98.44%, Time: 0:01:19 \nIter:    960, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:19 \nIter:    990, Train Loss:  0.048, Train Acc: 100.00%, Time: 0:01:20 \nEpoch: 6\nIter:   1020, Train Loss:  0.013, Train Acc: 100.00%, Time: 0:01:21 \nIter:   1050, Train Loss:  0.032, Train Acc: 100.00%, Time: 0:01:21 \nIter:   1080, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:22 \nIter:   1110, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:23 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/9/9\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/9/9\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.3, Test Acc:  65.44%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.43      0.61      0.50       120\n                   Filter       0.44      0.71      0.54       126\n    Compute Derived Value       0.47      0.46      0.47       124\n            Find Extremum       0.79      0.82      0.80       129\n                     Sort       0.85      0.85      0.85       124\n          Determine Range       0.32      0.16      0.21       125\nCharacterize Distribution       0.79      0.83      0.81       127\n           Find Anomalies       0.98      0.41      0.58       125\n                  Cluster       0.88      0.75      0.81       125\n                Correlate       0.84      0.92      0.88       128\n\n                micro avg       0.65      0.65      0.65      1253\n                macro avg       0.68      0.65      0.64      1253\n             weighted avg       0.68      0.65      0.65      1253\n\nConfusion Matrix...\n[[ 73  23   5   7   0   8   3   0   0   1]\n [ 12  90   5   1   0  14   2   0   1   1]\n [ 33   6  57   3   0   2   9   0   1  13]\n [  1   1  19 106   1   0   1   0   0   0]\n [  0   2   0   6 106   9   0   0   1   0]\n [ 35  55   7   3   4  20   1   0   0   0]\n [  2   0  14   0   1   5 105   0   0   0]\n [ 14  23  13   0   0   2   8  51   8   6]\n [  0   2   1   7  13   1   4   1  94   2]\n [  1   3   0   2   0   2   0   0   2 118]]\nTime usage: 0:00:02\nFold:  10\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.5, Train Acc:  64.06%, Time: 0:00:12 *\nIter:     90, Train Loss:    1.4, Train Acc:  59.38%, Time: 0:00:13 \nIter:    120, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:00:18 *\nIter:    150, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:00:19 \nIter:    180, Train Loss:   0.63, Train Acc:  79.69%, Time: 0:00:24 *\nEpoch: 2\nIter:    210, Train Loss:   0.53, Train Acc:  90.62%, Time: 0:00:29 *\nIter:    240, Train Loss:   0.81, Train Acc:  76.56%, Time: 0:00:29 \nIter:    270, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:00:30 \nIter:    300, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:00:31 \nIter:    330, Train Loss:   0.29, Train Acc:  92.19%, Time: 0:00:36 *\nIter:    360, Train Loss:   0.52, Train Acc:  81.25%, Time: 0:00:37 \nIter:    390, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:00:37 \nEpoch: 3\nIter:    420, Train Loss:   0.42, Train Acc:  82.81%, Time: 0:00:38 \nIter:    450, Train Loss:    0.3, Train Acc:  92.19%, Time: 0:00:39 \nIter:    480, Train Loss:   0.25, Train Acc:  95.31%, Time: 0:00:45 *\nIter:    510, Train Loss:   0.25, Train Acc:  95.31%, Time: 0:00:45 \nIter:    540, Train Loss:   0.22, Train Acc:  95.31%, Time: 0:00:46 \nIter:    570, Train Loss:   0.37, Train Acc:  93.75%, Time: 0:00:47 \nIter:    600, Train Loss:   0.25, Train Acc:  92.19%, Time: 0:00:47 \nEpoch: 4\nIter:    630, Train Loss:   0.15, Train Acc:  95.31%, Time: 0:00:48 \nIter:    660, Train Loss:   0.14, Train Acc:  95.31%, Time: 0:00:49 \nIter:    690, Train Loss:  0.094, Train Acc:  98.44%, Time: 0:00:54 *\nIter:    720, Train Loss:    0.1, Train Acc:  96.88%, Time: 0:00:55 \nIter:    750, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:00:56 \nIter:    780, Train Loss:  0.093, Train Acc:  98.44%, Time: 0:00:56 \nEpoch: 5\nIter:    810, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:01:02 *\nIter:    840, Train Loss:   0.04, Train Acc: 100.00%, Time: 0:01:02 \nIter:    870, Train Loss:  0.074, Train Acc:  98.44%, Time: 0:01:03 \nIter:    900, Train Loss:   0.04, Train Acc: 100.00%, Time: 0:01:04 \nIter:    930, Train Loss:  0.046, Train Acc:  98.44%, Time: 0:01:04 \nIter:    960, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:05 \nIter:    990, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:06 \nEpoch: 6\nIter:   1020, Train Loss:  0.024, Train Acc: 100.00%, Time: 0:01:06 \nIter:   1050, Train Loss:  0.019, Train Acc: 100.00%, Time: 0:01:07 \nIter:   1080, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:01:08 \nIter:   1110, Train Loss:  0.042, Train Acc:  98.44%, Time: 0:01:08 \nIter:   1140, Train Loss:  0.068, Train Acc:  98.44%, Time: 0:01:09 \nIter:   1170, Train Loss:  0.026, Train Acc: 100.00%, Time: 0:01:10 \nIter:   1200, Train Loss:  0.035, Train Acc: 100.00%, Time: 0:01:10 \nEpoch: 7\nIter:   1230, Train Loss: 0.0094, Train Acc: 100.00%, Time: 0:01:11 \nIter:   1260, Train Loss: 0.0048, Train Acc: 100.00%, Time: 0:01:12 \nIter:   1290, Train Loss:  0.013, Train Acc: 100.00%, Time: 0:01:13 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/10/10\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/expert/10/10\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.2, Test Acc:  67.26%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.85      0.37      0.51       106\n                   Filter       0.72      0.56      0.63       121\n    Compute Derived Value       0.55      0.45      0.49       121\n            Find Extremum       0.53      0.79      0.63       119\n                     Sort       0.73      0.76      0.74       111\n          Determine Range       0.69      0.84      0.75       130\nCharacterize Distribution       0.73      0.74      0.73       127\n           Find Anomalies       0.67      0.71      0.69       123\n                  Cluster       0.68      0.78      0.73       122\n                Correlate       0.73      0.69      0.71       154\n\n                micro avg       0.67      0.67      0.67      1234\n                macro avg       0.69      0.67      0.66      1234\n             weighted avg       0.69      0.67      0.67      1234\n\nConfusion Matrix...\n[[ 39   5  40  10   0   6   6   0   0   0]\n [  1  68   1  22  12   0   1  14   2   0]\n [  0   0  54  23   0  23   4   4   1  12]\n [  1   0   1  94   6   4   2   6   3   2]\n [  0   0   2  16  84   2   3   3   0   1]\n [  2   0   1   5   2 109   1   5   5   0]\n [  2   9   0   4   1   4  94   2   8   3]\n [  0   9   0   2   0   1   0  87   3  21]\n [  0   3   0   0  10   4   2   8  95   0]\n [  1   0   0   2   0   6  16   1  22 106]]\nTime usage: 0:00:02\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "expert_test_acc", "execution_count": 110, "outputs": [{"output_type": "execute_result", "execution_count": 110, "data": {"text/plain": "[0.6335754637952963,\n 0.6051964519595012,\n 0.7520064208327671,\n 0.6135812453329322,\n 0.6810055863923866,\n 0.7160963240836208,\n 0.617182564486903,\n 0.6538164999821412,\n 0.6544293689899033,\n 0.672609400710565]"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "np.mean(expert_test_acc),np.std(expert_test_acc),np.std(expert_test_acc,ddof=1),np.var(expert_test_acc)", "execution_count": 111, "outputs": [{"output_type": "execute_result", "execution_count": 111, "data": {"text/plain": "(0.6599499326566016,\n 0.04468911700992965,\n 0.04710646545771709,\n 0.0019971171791271836)"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def bundle_split():\n    train_data = [[] for i in range(920)]\n    with open(trainDataPath, \"r\", encoding='utf-8') as fp:\n        for line in fp.readlines():\n            word = line.split()\n            info = word[0].split(\":\")\n            index = int(info[1]) - 1\n            label = int(info[0])\n            content = word[1:]\n            train_data[index].append([content,label])\n            \n    for i in range(920):\n        np.random.shuffle(train_data[i])\n        train_data[i] = np.asarray(train_data[i])\n        \n    np.random.shuffle(train_data)   \n    \n    return train_data\n\ntrain_data_bundle = bundle_split()", "execution_count": 112, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "train_data_bundle[0][:5,1]", "execution_count": 113, "outputs": [{"output_type": "execute_result", "execution_count": 113, "data": {"text/plain": "array([7, 7, 7, 7, 7], dtype=object)"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def mergeData(data_x, data_y):\n    merge_x = data_x[0]\n    merge_y = data_y[0]\n    for i in range(1,len(data_x)):\n        merge_x = np.r_[merge_x,data_x[i]]\n        merge_y = np.r_[merge_y,data_y[i]]\n        \n    return merge_x, merge_y\n\n\ndef train_split_data(train_data, split_type):\n    \n    print(split_type)\n    \n    tx = []\n    ty = []\n    for ti in train_data:\n        x_train, y_train = process_file(ti[:,0], ti[:,1], word_to_id, num_classes, seq_length)\n        tx.append(x_train)\n        ty.append(y_train)\n\n    tx = np.asarray(tx)\n    ty = np.asarray(ty)\n    \n    print(len(tx),len(tx[0]),len(tx[1]),len(tx[0][0]))\n    \n    train_acc = []\n    test_acc = []\n    fold_id = 0\n    \n    for train_i, test_i in kf.split(tx):\n        fold_id += 1\n        print(\"Fold: \", fold_id)\n        train_x, train_y = mergeData(tx[train_i],ty[train_i])\n        test_x, test_y = mergeData(tx[test_i],ty[test_i])\n        train_acc.append(model.train(train_x, train_y,split_type,fold_id))\n        test_acc.append(model.evaluate_model(test_x, test_y,split_type,fold_id,categories))\n        \n    print(test_acc)\n    print(np.mean(test_acc),np.std(test_acc),np.std(test_acc,ddof=1),np.var(test_acc))\n    \n    return test_acc", "execution_count": 115, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "bundle_test_acc = train_split_data(train_data_bundle, \"bundle\")", "execution_count": 116, "outputs": [{"output_type": "stream", "text": "bundle\n920 15 13 41\nFold:  1\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  39.06%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.6, Train Acc:  54.69%, Time: 0:00:13 *\nIter:     90, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:18 *\nIter:    120, Train Loss:    1.1, Train Acc:  71.88%, Time: 0:00:24 *\nIter:    150, Train Loss:   0.96, Train Acc:  78.12%, Time: 0:00:29 *\nIter:    180, Train Loss:   0.92, Train Acc:  73.44%, Time: 0:00:30 \nEpoch: 2\nIter:    210, Train Loss:   0.72, Train Acc:  84.38%, Time: 0:00:35 *\nIter:    240, Train Loss:    0.5, Train Acc:  84.38%, Time: 0:00:36 \nIter:    270, Train Loss:   0.61, Train Acc:  85.94%, Time: 0:00:40 *\nIter:    300, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:00:45 *\nIter:    330, Train Loss:   0.44, Train Acc:  87.50%, Time: 0:00:46 \nIter:    360, Train Loss:   0.31, Train Acc:  95.31%, Time: 0:00:50 *\nIter:    390, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:00:51 \nEpoch: 3\nIter:    420, Train Loss:   0.28, Train Acc:  90.62%, Time: 0:00:52 \nIter:    450, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:00:56 *\nIter:    480, Train Loss:   0.26, Train Acc:  92.19%, Time: 0:00:57 \nIter:    510, Train Loss:   0.24, Train Acc:  90.62%, Time: 0:00:58 \nIter:    540, Train Loss:   0.27, Train Acc:  87.50%, Time: 0:00:59 \nIter:    570, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:00:59 \nEpoch: 4\nIter:    600, Train Loss:  0.095, Train Acc:  95.31%, Time: 0:01:00 \nIter:    630, Train Loss:  0.066, Train Acc:  98.44%, Time: 0:01:05 *\nIter:    660, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:05 \nIter:    690, Train Loss:  0.079, Train Acc:  98.44%, Time: 0:01:06 \nIter:    720, Train Loss:   0.16, Train Acc:  95.31%, Time: 0:01:07 \nIter:    750, Train Loss:  0.097, Train Acc:  96.88%, Time: 0:01:07 \nIter:    780, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:08 \nEpoch: 5\nIter:    810, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:01:12 *\nIter:    840, Train Loss:  0.042, Train Acc:  98.44%, Time: 0:01:13 \nIter:    870, Train Loss:   0.14, Train Acc:  92.19%, Time: 0:01:14 \nIter:    900, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:01:15 \nIter:    930, Train Loss:  0.061, Train Acc:  98.44%, Time: 0:01:15 \nIter:    960, Train Loss:   0.04, Train Acc: 100.00%, Time: 0:01:16 \nEpoch: 6\nIter:    990, Train Loss:  0.026, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1020, Train Loss:  0.015, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1050, Train Loss:  0.019, Train Acc: 100.00%, Time: 0:01:18 \nIter:   1080, Train Loss:  0.046, Train Acc:  98.44%, Time: 0:01:19 \nIter:   1110, Train Loss:  0.011, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1140, Train Loss:  0.023, Train Acc:  98.44%, Time: 0:01:20 \nIter:   1170, Train Loss:  0.076, Train Acc:  96.88%, Time: 0:01:21 \nEpoch: 7\nIter:   1200, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:21 \nIter:   1230, Train Loss:   0.02, Train Acc:  98.44%, Time: 0:01:22 \nIter:   1260, Train Loss: 0.0094, Train Acc: 100.00%, Time: 0:01:23 \nIter:   1290, Train Loss:   0.04, Train Acc:  98.44%, Time: 0:01:23 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/1/1\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/1/1\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.88, Test Acc:  75.85%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.84      0.88      0.86       163\n                   Filter       0.84      0.69      0.76       133\n    Compute Derived Value       0.80      0.54      0.65       197\n            Find Extremum       0.61      0.99      0.75        90\n                     Sort       0.86      0.90      0.88       155\n          Determine Range       0.79      0.83      0.81       150\nCharacterize Distribution       0.66      0.77      0.71       119\n           Find Anomalies       0.66      0.73      0.69       131\n                  Cluster       0.77      0.74      0.75       136\n                Correlate       0.75      0.66      0.70       175\n\n                micro avg       0.76      0.76      0.76      1449\n                macro avg       0.76      0.77      0.76      1449\n             weighted avg       0.77      0.76      0.76      1449\n\nConfusion Matrix...\n[[144   0  13   0   1   0   1   4   0   0]\n [  4  92   9   4   2   7   2  11   1   1]\n [ 19   2 107  16   6  13  26   2   3   3]\n [  0   0   0  89   0   0   1   0   0   0]\n [  2   1   1   1 139   4   4   0   3   0]\n [  1   1   1  10   1 124   6   0   5   1]\n [  0   3   1   1   3   1  92   2  13   3]\n [  1   0   2   2   0   3   1  96   3  23]\n [  0   0   0   8  10   2   4   4 101   7]\n [  0  10   0  15   0   3   2  27   3 115]]\nTime usage: 0:00:02\nFold:  2\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    1.9, Train Acc:  40.62%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.7, Train Acc:  51.56%, Time: 0:00:12 *\nIter:     90, Train Loss:    1.3, Train Acc:  56.25%, Time: 0:00:16 *\nIter:    120, Train Loss:   0.98, Train Acc:  76.56%, Time: 0:00:21 *\nIter:    150, Train Loss:   0.92, Train Acc:  76.56%, Time: 0:00:22 \nIter:    180, Train Loss:   0.69, Train Acc:  81.25%, Time: 0:00:26 *\nEpoch: 2\nIter:    210, Train Loss:   0.45, Train Acc:  85.94%, Time: 0:00:32 *\nIter:    240, Train Loss:   0.52, Train Acc:  84.38%, Time: 0:00:32 \nIter:    270, Train Loss:   0.53, Train Acc:  82.81%, Time: 0:00:33 \nIter:    300, Train Loss:   0.39, Train Acc:  89.06%, Time: 0:00:38 *\nIter:    330, Train Loss:   0.45, Train Acc:  85.94%, Time: 0:00:39 \nIter:    360, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:00:43 *\nIter:    390, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:00:44 \nEpoch: 3\nIter:    420, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:00:48 *\nIter:    450, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:00:49 \nIter:    480, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:00:53 *\nIter:    510, Train Loss:   0.17, Train Acc:  92.19%, Time: 0:00:53 \nIter:    540, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:00:54 \nIter:    570, Train Loss:  0.092, Train Acc:  98.44%, Time: 0:00:55 \nEpoch: 4\nIter:    600, Train Loss:   0.07, Train Acc: 100.00%, Time: 0:01:00 *\nIter:    630, Train Loss:   0.11, Train Acc:  95.31%, Time: 0:01:01 \nIter:    660, Train Loss:  0.091, Train Acc:  96.88%, Time: 0:01:02 \nIter:    690, Train Loss:  0.091, Train Acc:  98.44%, Time: 0:01:02 \nIter:    720, Train Loss:  0.062, Train Acc: 100.00%, Time: 0:01:03 \nIter:    750, Train Loss:  0.058, Train Acc:  98.44%, Time: 0:01:04 \nIter:    780, Train Loss:  0.029, Train Acc: 100.00%, Time: 0:01:04 \nEpoch: 5\nIter:    810, Train Loss:  0.089, Train Acc:  98.44%, Time: 0:01:05 \nIter:    840, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:06 \nIter:    870, Train Loss:  0.021, Train Acc: 100.00%, Time: 0:01:06 \nIter:    900, Train Loss:  0.057, Train Acc:  98.44%, Time: 0:01:07 \nIter:    930, Train Loss:   0.05, Train Acc:  96.88%, Time: 0:01:08 \nIter:    960, Train Loss:  0.037, Train Acc: 100.00%, Time: 0:01:08 \nIter:    990, Train Loss:   0.07, Train Acc:  98.41%, Time: 0:01:09 \nEpoch: 6\nIter:   1020, Train Loss:  0.055, Train Acc:  98.44%, Time: 0:01:10 \nIter:   1050, Train Loss:  0.047, Train Acc:  98.44%, Time: 0:01:10 \nIter:   1080, Train Loss:  0.024, Train Acc:  98.44%, Time: 0:01:11 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/2/2\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/2/2\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.4, Test Acc:  63.12%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.64      0.62      0.63        90\n                   Filter       0.50      0.45      0.47       162\n    Compute Derived Value       0.69      0.69      0.69       189\n            Find Extremum       0.53      0.76      0.63        92\n                     Sort       0.78      0.75      0.77        76\n          Determine Range       0.65      0.51      0.57       240\nCharacterize Distribution       0.76      0.71      0.73       137\n           Find Anomalies       0.57      0.42      0.48       109\n                  Cluster       0.86      0.66      0.75       130\n                Correlate       0.52      0.88      0.65       139\n\n                micro avg       0.63      0.63      0.63      1364\n                macro avg       0.65      0.65      0.64      1364\n             weighted avg       0.65      0.63      0.63      1364\n\nConfusion Matrix...\n[[ 56   7  19   2   1   1   0   0   0   4]\n [ 20  73  14   6   1   5   4  12   0  27]\n [  5   1 131   9   0  14   2   2   2  23]\n [  3   0   0  70   1  12   0   0   1   5]\n [  0   0   0  16  57   1   0   1   0   1]\n [  4  39  10  25   5 122   9   1   7  18]\n [  0   3  10   2   2  16  97   0   4   3]\n [  0  23   0   0   0  15   0  46   0  25]\n [  0   0   0   0   6   1  15  13  86   9]\n [  0   0   6   1   0   2   1   6   0 123]]\nTime usage: 0:00:02\nFold:  3\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  39.06%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.7, Train Acc:  56.25%, Time: 0:00:12 *\nIter:     90, Train Loss:    1.7, Train Acc:  42.19%, Time: 0:00:13 \nIter:    120, Train Loss:    1.1, Train Acc:  71.88%, Time: 0:00:17 *\nIter:    150, Train Loss:   0.83, Train Acc:  81.25%, Time: 0:00:22 *\nIter:    180, Train Loss:   0.95, Train Acc:  73.44%, Time: 0:00:22 \nEpoch: 2\nIter:    210, Train Loss:   0.59, Train Acc:  84.38%, Time: 0:00:26 *\nIter:    240, Train Loss:    0.5, Train Acc:  84.38%, Time: 0:00:27 \nIter:    270, Train Loss:   0.41, Train Acc:  92.19%, Time: 0:00:32 *\nIter:    300, Train Loss:   0.45, Train Acc:  87.50%, Time: 0:00:33 \nIter:    330, Train Loss:   0.45, Train Acc:  87.50%, Time: 0:00:34 \nIter:    360, Train Loss:   0.38, Train Acc:  87.50%, Time: 0:00:34 \nIter:    390, Train Loss:   0.21, Train Acc:  95.31%, Time: 0:00:39 *\nEpoch: 3\nIter:    420, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:00:43 *\nIter:    450, Train Loss:   0.19, Train Acc:  95.31%, Time: 0:00:44 \nIter:    480, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:00:44 \nIter:    510, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:00:45 \nIter:    540, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:00:46 \nIter:    570, Train Loss:   0.13, Train Acc:  95.31%, Time: 0:00:46 \nEpoch: 4\nIter:    600, Train Loss:    0.1, Train Acc:  96.88%, Time: 0:00:47 \nIter:    630, Train Loss:  0.036, Train Acc: 100.00%, Time: 0:00:53 *\nIter:    660, Train Loss:  0.041, Train Acc: 100.00%, Time: 0:00:54 \nIter:    690, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:55 \nIter:    720, Train Loss:  0.087, Train Acc:  98.44%, Time: 0:00:55 \nIter:    750, Train Loss:  0.055, Train Acc: 100.00%, Time: 0:00:56 \nIter:    780, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:00:57 \nEpoch: 5\nIter:    810, Train Loss:  0.027, Train Acc: 100.00%, Time: 0:00:57 \nIter:    840, Train Loss:  0.052, Train Acc:  98.44%, Time: 0:00:58 \nIter:    870, Train Loss:  0.054, Train Acc:  98.44%, Time: 0:00:59 \nIter:    900, Train Loss:  0.035, Train Acc: 100.00%, Time: 0:01:00 \nIter:    930, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:00 \nIter:    960, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:01 \nIter:    990, Train Loss:  0.019, Train Acc: 100.00%, Time: 0:01:02 \nEpoch: 6\nIter:   1020, Train Loss:  0.021, Train Acc: 100.00%, Time: 0:01:02 \nIter:   1050, Train Loss:  0.049, Train Acc:  98.44%, Time: 0:01:03 \nIter:   1080, Train Loss:  0.051, Train Acc:  98.44%, Time: 0:01:04 \nIter:   1110, Train Loss: 0.0094, Train Acc: 100.00%, Time: 0:01:04 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/3/3\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/3/3\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.4, Test Acc:  67.66%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.50      0.64      0.56       105\n                   Filter       0.56      0.55      0.55       126\n    Compute Derived Value       0.44      0.49      0.46       120\n            Find Extremum       0.70      0.84      0.77       199\n                     Sort       0.91      0.84      0.87       136\n          Determine Range       0.49      0.50      0.49       151\nCharacterize Distribution       0.73      0.90      0.81       108\n           Find Anomalies       0.71      0.54      0.62       120\n                  Cluster       0.84      0.77      0.80       143\n                Correlate       0.89      0.64      0.75       205\n\n                micro avg       0.68      0.68      0.68      1413\n                macro avg       0.68      0.67      0.67      1413\n             weighted avg       0.69      0.68      0.68      1413\n\nConfusion Matrix...\n[[ 67   4  17  12   2   1   0   0   1   1]\n [  0  69  10   6   2  25   0  10   3   1]\n [ 22  18  59  16   0   5   0   0   0   0]\n [  8   6   0 168   3  12   0   1   0   1]\n [  0   0   7   6 114   5   0   1   3   0]\n [ 31  19  17   5   0  75   2   0   0   2]\n [  1   0   6   1   0   3  97   0   0   0]\n [  2   2   9  23   0   1   1  65  13   4]\n [  0   0   4   1   0  15   3   2 110   8]\n [  2   5   6   2   4  12  29  12   1 132]]\nTime usage: 0:00:02\nFold:  4\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  26.56%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.8, Train Acc:  45.31%, Time: 0:00:13 *\nIter:     90, Train Loss:    1.4, Train Acc:  65.62%, Time: 0:00:19 *\nIter:    120, Train Loss:    1.2, Train Acc:  64.06%, Time: 0:00:19 \nIter:    150, Train Loss:   0.84, Train Acc:  76.56%, Time: 0:00:24 *\nIter:    180, Train Loss:   0.91, Train Acc:  68.75%, Time: 0:00:25 \nEpoch: 2\nIter:    210, Train Loss:   0.74, Train Acc:  84.38%, Time: 0:00:31 *\nIter:    240, Train Loss:   0.52, Train Acc:  93.75%, Time: 0:00:36 *\nIter:    270, Train Loss:   0.47, Train Acc:  85.94%, Time: 0:00:37 \nIter:    300, Train Loss:   0.68, Train Acc:  75.00%, Time: 0:00:38 \nIter:    330, Train Loss:   0.46, Train Acc:  87.50%, Time: 0:00:39 \nIter:    360, Train Loss:   0.46, Train Acc:  85.94%, Time: 0:00:39 \nIter:    390, Train Loss:   0.44, Train Acc:  89.06%, Time: 0:00:40 \nEpoch: 3\nIter:    420, Train Loss:   0.19, Train Acc:  95.31%, Time: 0:00:45 *\nIter:    450, Train Loss:   0.13, Train Acc: 100.00%, Time: 0:00:49 *\nIter:    480, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:00:50 \nIter:    510, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:00:50 \nIter:    540, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:00:51 \nIter:    570, Train Loss:   0.19, Train Acc:  95.31%, Time: 0:00:52 \nEpoch: 4\nIter:    600, Train Loss:  0.065, Train Acc: 100.00%, Time: 0:00:53 \nIter:    630, Train Loss:  0.061, Train Acc:  98.44%, Time: 0:00:53 \nIter:    660, Train Loss:  0.084, Train Acc:  98.44%, Time: 0:00:54 \nIter:    690, Train Loss:  0.051, Train Acc: 100.00%, Time: 0:00:55 \nIter:    720, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:00:55 \nIter:    750, Train Loss:  0.071, Train Acc:  98.44%, Time: 0:00:56 \nIter:    780, Train Loss:   0.11, Train Acc:  95.31%, Time: 0:00:57 \nEpoch: 5\nIter:    810, Train Loss:  0.042, Train Acc: 100.00%, Time: 0:00:57 \nIter:    840, Train Loss:  0.043, Train Acc:  98.44%, Time: 0:00:58 \nIter:    870, Train Loss:  0.081, Train Acc:  96.88%, Time: 0:00:59 \nIter:    900, Train Loss:  0.032, Train Acc: 100.00%, Time: 0:00:59 \nIter:    930, Train Loss:   0.12, Train Acc:  92.19%, Time: 0:01:00 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/4/4\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/4/4\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  65.19%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.41      0.81      0.55        74\n                   Filter       0.71      0.48      0.57       240\n    Compute Derived Value       0.38      0.54      0.45        76\n            Find Extremum       0.83      0.71      0.77       133\n                     Sort       0.52      0.73      0.60       102\n          Determine Range       0.67      0.78      0.72        78\nCharacterize Distribution       0.90      0.86      0.88       139\n           Find Anomalies       0.64      0.69      0.66       218\n                  Cluster       0.86      0.55      0.67       151\n                Correlate       0.67      0.61      0.64       191\n\n                micro avg       0.65      0.65      0.65      1402\n                macro avg       0.66      0.68      0.65      1402\n             weighted avg       0.69      0.65      0.66      1402\n\nConfusion Matrix...\n[[ 60   3   0   0  11   0   0   0   0   0]\n [ 34 115  12   7  12   4   0  42   2  12]\n [ 18   0  41   0   2   0   0   5   0  10]\n [  0   3   5  95  13  12   0   3   0   2]\n [  6   0  10   5  74   1   0   2   4   0]\n [  0   0   5   2   6  61   1   1   1   1]\n [  5   1   1   0   1   7 119   0   1   4]\n [  7  25   7   4   1   2   4 150   1  17]\n [  8  16   1   2   6   3   3  19  83  10]\n [  8   0  26   0  17   1   5  14   4 116]]\nTime usage: 0:00:02\nFold:  5\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  53.12%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.6, Train Acc:  54.69%, Time: 0:00:13 *\nIter:     90, Train Loss:    1.2, Train Acc:  78.12%, Time: 0:00:20 *\nIter:    120, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:20 \nIter:    150, Train Loss:    0.9, Train Acc:  71.88%, Time: 0:00:21 \nIter:    180, Train Loss:    0.7, Train Acc:  81.25%, Time: 0:00:26 *\nEpoch: 2\nIter:    210, Train Loss:   0.64, Train Acc:  79.69%, Time: 0:00:27 \nIter:    240, Train Loss:    0.5, Train Acc:  90.62%, Time: 0:00:33 *\nIter:    270, Train Loss:   0.54, Train Acc:  82.81%, Time: 0:00:33 \nIter:    300, Train Loss:   0.44, Train Acc:  85.94%, Time: 0:00:34 \nIter:    330, Train Loss:   0.58, Train Acc:  79.69%, Time: 0:00:35 \nIter:    360, Train Loss:   0.43, Train Acc:  84.38%, Time: 0:00:35 \nIter:    390, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:41 *\nEpoch: 3\nIter:    420, Train Loss:   0.24, Train Acc:  90.62%, Time: 0:00:41 \nIter:    450, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:42 \nIter:    480, Train Loss:   0.22, Train Acc:  90.62%, Time: 0:00:43 \nIter:    510, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:43 \nIter:    540, Train Loss:  0.087, Train Acc: 100.00%, Time: 0:00:50 *\nIter:    570, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:00:51 \nEpoch: 4\nIter:    600, Train Loss:  0.069, Train Acc:  98.44%, Time: 0:00:51 \nIter:    630, Train Loss:  0.078, Train Acc:  98.44%, Time: 0:00:52 \nIter:    660, Train Loss:   0.16, Train Acc:  98.44%, Time: 0:00:53 \nIter:    690, Train Loss:   0.05, Train Acc: 100.00%, Time: 0:00:53 \nIter:    720, Train Loss:  0.051, Train Acc:  98.44%, Time: 0:00:54 \nIter:    750, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:00:55 \nIter:    780, Train Loss:  0.076, Train Acc:  98.44%, Time: 0:00:55 \nEpoch: 5\nIter:    810, Train Loss:  0.021, Train Acc: 100.00%, Time: 0:00:56 \nIter:    840, Train Loss:  0.024, Train Acc: 100.00%, Time: 0:00:57 \nIter:    870, Train Loss:  0.027, Train Acc: 100.00%, Time: 0:00:57 \nIter:    900, Train Loss:  0.027, Train Acc: 100.00%, Time: 0:00:58 \nIter:    930, Train Loss:  0.012, Train Acc: 100.00%, Time: 0:00:59 \nIter:    960, Train Loss:  0.045, Train Acc:  98.44%, Time: 0:01:00 \nIter:    990, Train Loss:  0.093, Train Acc:  96.43%, Time: 0:01:00 \nEpoch: 6\nIter:   1020, Train Loss:   0.03, Train Acc:  98.44%, Time: 0:01:01 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/5/5\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/5/5\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  67.32%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.63      0.62      0.63       173\n                   Filter       0.53      0.61      0.56        99\n    Compute Derived Value       0.67      0.55      0.61       164\n            Find Extremum       0.70      0.83      0.76       167\n                     Sort       0.73      0.80      0.76       141\n          Determine Range       0.58      0.69      0.63       108\nCharacterize Distribution       0.69      0.86      0.77       107\n           Find Anomalies       0.66      0.45      0.54       127\n                  Cluster       0.62      0.68      0.65        97\n                Correlate       0.87      0.65      0.74       188\n\n                micro avg       0.67      0.67      0.67      1371\n                macro avg       0.67      0.68      0.66      1371\n             weighted avg       0.68      0.67      0.67      1371\n\nConfusion Matrix...\n[[108  28  13  10   2  11   0   0   1   0]\n [  4  60  11   9   1   8   0   2   2   2]\n [ 25   6  91  19   1   2   8   8   3   1]\n [  1   1   0 139   6   4  10   4   1   1]\n [  3   0   0   8 113   3   5   0   9   0]\n [  4   8   0  11   7  75   2   0   1   0]\n [  2   0   3   0   2   5  92   1   2   0]\n [ 15   9  13   3   2   4   9  57  10   5]\n [  0   0   0   0   5   9   1   6  66  10]\n [  9   2   4   0  16   9   6   8  12 122]]\nTime usage: 0:00:02\nFold:  6\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.6, Train Acc:  64.06%, Time: 0:00:13 *\nIter:     90, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:18 *\nIter:    120, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:00:22 *\nIter:    150, Train Loss:   0.84, Train Acc:  81.25%, Time: 0:00:27 *\nIter:    180, Train Loss:   0.91, Train Acc:  70.31%, Time: 0:00:27 \nEpoch: 2\nIter:    210, Train Loss:   0.73, Train Acc:  79.69%, Time: 0:00:28 \nIter:    240, Train Loss:   0.56, Train Acc:  82.81%, Time: 0:00:33 *\nIter:    270, Train Loss:   0.61, Train Acc:  85.94%, Time: 0:00:37 *\nIter:    300, Train Loss:   0.38, Train Acc:  89.06%, Time: 0:00:41 *\nIter:    330, Train Loss:    0.4, Train Acc:  85.94%, Time: 0:00:42 \nIter:    360, Train Loss:   0.51, Train Acc:  89.06%, Time: 0:00:42 \nIter:    390, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:00:47 *\nEpoch: 3\nIter:    420, Train Loss:   0.28, Train Acc:  90.62%, Time: 0:00:48 \nIter:    450, Train Loss:  0.097, Train Acc: 100.00%, Time: 0:00:53 *\nIter:    480, Train Loss:    0.4, Train Acc:  89.06%, Time: 0:00:53 \nIter:    510, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:00:54 \nIter:    540, Train Loss:   0.18, Train Acc:  90.62%, Time: 0:00:55 \nIter:    570, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:00:56 \nEpoch: 4\nIter:    600, Train Loss:   0.13, Train Acc:  95.31%, Time: 0:00:56 \nIter:    630, Train Loss:  0.098, Train Acc:  98.44%, Time: 0:00:57 \nIter:    660, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:58 \nIter:    690, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:00:58 \nIter:    720, Train Loss:  0.045, Train Acc: 100.00%, Time: 0:00:59 \nIter:    750, Train Loss:  0.093, Train Acc:  98.44%, Time: 0:01:00 \nIter:    780, Train Loss:  0.098, Train Acc:  98.44%, Time: 0:01:00 \nEpoch: 5\nIter:    810, Train Loss:  0.059, Train Acc:  96.88%, Time: 0:01:01 \nIter:    840, Train Loss:  0.034, Train Acc:  98.44%, Time: 0:01:02 \nIter:    870, Train Loss:   0.03, Train Acc: 100.00%, Time: 0:01:02 \nIter:    900, Train Loss:  0.048, Train Acc:  98.44%, Time: 0:01:03 \nIter:    930, Train Loss:  0.046, Train Acc: 100.00%, Time: 0:01:04 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/6/6\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/6/6\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.0, Test Acc:  67.83%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.70      0.62      0.66        74\n                   Filter       0.44      0.76      0.56       149\n    Compute Derived Value       0.58      0.34      0.43       153\n            Find Extremum       0.82      0.82      0.82       173\n                     Sort       0.75      0.74      0.74       121\n          Determine Range       0.70      0.89      0.78       142\nCharacterize Distribution       0.80      0.75      0.77       167\n           Find Anomalies       0.66      0.57      0.62       221\n                  Cluster       0.69      0.70      0.69        84\n                Correlate       0.81      0.63      0.71       149\n\n                micro avg       0.68      0.68      0.68      1433\n                macro avg       0.69      0.68      0.68      1433\n             weighted avg       0.70      0.68      0.68      1433\n\nConfusion Matrix...\n[[ 46  10   7   7   0   2   0   2   0   0]\n [  2 113   2   0   2  10   0  18   1   1]\n [ 11  20  52  14   0  11  16  23   1   5]\n [  2  11   8 141   2   3   3   0   0   3]\n [  1  12   1   8  89   4   3   1   1   1]\n [  1   3   0   0   8 126   2   0   0   2]\n [  2  22   3   0   2   8 125   0   5   0]\n [  1  57   2   3   0   5   2 127  14  10]\n [  0   2   2   0  15   2   0   4  59   0]\n [  0   7  12   0   0   9   6  16   5  94]]\nTime usage: 0:00:02\nFold:  7\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  23.44%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.8, Train Acc:  40.62%, Time: 0:00:12 *\nIter:     90, Train Loss:    1.3, Train Acc:  68.75%, Time: 0:00:17 *\nIter:    120, Train Loss:    1.0, Train Acc:  78.12%, Time: 0:00:21 *\nIter:    150, Train Loss:   0.95, Train Acc:  75.00%, Time: 0:00:22 \nIter:    180, Train Loss:   0.76, Train Acc:  78.12%, Time: 0:00:23 \nEpoch: 2\nIter:    210, Train Loss:   0.56, Train Acc:  84.38%, Time: 0:00:27 *\nIter:    240, Train Loss:   0.58, Train Acc:  78.12%, Time: 0:00:28 \nIter:    270, Train Loss:   0.38, Train Acc:  93.75%, Time: 0:00:34 *\nIter:    300, Train Loss:   0.49, Train Acc:  85.94%, Time: 0:00:35 \nIter:    330, Train Loss:   0.44, Train Acc:  84.38%, Time: 0:00:36 \nIter:    360, Train Loss:   0.38, Train Acc:  89.06%, Time: 0:00:36 \nIter:    390, Train Loss:   0.24, Train Acc:  90.62%, Time: 0:00:37 \nEpoch: 3\nIter:    420, Train Loss:    0.3, Train Acc:  92.19%, Time: 0:00:38 \nIter:    450, Train Loss:    0.1, Train Acc:  96.88%, Time: 0:00:44 *\nIter:    480, Train Loss:   0.24, Train Acc:  95.31%, Time: 0:00:44 \nIter:    510, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:45 \nIter:    540, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:00:46 \nIter:    570, Train Loss:   0.22, Train Acc:  95.31%, Time: 0:00:46 \nEpoch: 4\nIter:    600, Train Loss:  0.074, Train Acc:  98.44%, Time: 0:00:51 *\nIter:    630, Train Loss:  0.087, Train Acc:  95.31%, Time: 0:00:52 \nIter:    660, Train Loss:  0.072, Train Acc: 100.00%, Time: 0:00:56 *\nIter:    690, Train Loss:  0.062, Train Acc:  98.44%, Time: 0:00:56 \nIter:    720, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:00:57 \nIter:    750, Train Loss:  0.056, Train Acc: 100.00%, Time: 0:00:58 \nIter:    780, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:00:59 \nEpoch: 5\nIter:    810, Train Loss:  0.071, Train Acc:  98.44%, Time: 0:00:59 \nIter:    840, Train Loss:  0.032, Train Acc:  98.44%, Time: 0:01:00 \nIter:    870, Train Loss:  0.043, Train Acc:  98.44%, Time: 0:01:01 \nIter:    900, Train Loss:  0.026, Train Acc: 100.00%, Time: 0:01:01 \nIter:    930, Train Loss:  0.038, Train Acc: 100.00%, Time: 0:01:02 \nIter:    960, Train Loss:  0.056, Train Acc:  98.44%, Time: 0:01:03 \nEpoch: 6\nIter:    990, Train Loss:  0.051, Train Acc: 100.00%, Time: 0:01:03 \nIter:   1020, Train Loss:  0.051, Train Acc:  98.44%, Time: 0:01:04 \nIter:   1050, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:01:05 \nIter:   1080, Train Loss:  0.053, Train Acc:  98.44%, Time: 0:01:05 \nIter:   1110, Train Loss: 0.0047, Train Acc: 100.00%, Time: 0:01:06 \nIter:   1140, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:01:07 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/7/7\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/7/7\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.6, Test Acc:  60.66%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.32      0.37      0.34       100\n                   Filter       0.37      0.72      0.49       103\n    Compute Derived Value       0.71      0.46      0.55       145\n            Find Extremum       0.67      0.56      0.61       258\n                     Sort       0.77      0.81      0.79       140\n          Determine Range       0.10      0.09      0.10        65\nCharacterize Distribution       0.95      0.53      0.68       180\n           Find Anomalies       0.66      0.81      0.73       137\n                  Cluster       0.71      0.70      0.70       193\n                Correlate       0.61      0.76      0.68       110\n\n                micro avg       0.61      0.61      0.61      1431\n                macro avg       0.59      0.58      0.57      1431\n             weighted avg       0.65      0.61      0.61      1431\n\nConfusion Matrix...\n[[ 37  26  23   2   2   2   0   7   0   1]\n [ 21  74   0   0   0   5   0   0   3   0]\n [ 12   1  66  33   0  23   3   0   1   6]\n [ 21  39   2 145  18  16   1   9   6   1]\n [  2   2   0   1 114   0   0   1  20   0]\n [  9  31   0  16   0   6   0   2   0   1]\n [  2   4   2  16   0   1  96  15  16  28]\n [  0  11   0   2   0   5   1 111   1   6]\n [ 12  12   0   1  12   2   0   9 135  10]\n [  0   1   0   0   3   0   0  14   8  84]]\nTime usage: 0:00:02\nFold:  8\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.6, Train Acc:  57.81%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:15 \nIter:    120, Train Loss:    1.2, Train Acc:  68.75%, Time: 0:00:19 *\nIter:    150, Train Loss:   0.83, Train Acc:  78.12%, Time: 0:00:25 *\nIter:    180, Train Loss:   0.78, Train Acc:  81.25%, Time: 0:00:30 *\nEpoch: 2\nIter:    210, Train Loss:   0.64, Train Acc:  87.50%, Time: 0:00:34 *\nIter:    240, Train Loss:   0.65, Train Acc:  81.25%, Time: 0:00:35 \nIter:    270, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:00:40 *\nIter:    300, Train Loss:    0.5, Train Acc:  84.38%, Time: 0:00:41 \nIter:    330, Train Loss:   0.41, Train Acc:  85.94%, Time: 0:00:42 \nIter:    360, Train Loss:   0.49, Train Acc:  85.94%, Time: 0:00:42 \nIter:    390, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:00:43 \nEpoch: 3\nIter:    420, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:00:47 *\nIter:    450, Train Loss:   0.22, Train Acc:  92.19%, Time: 0:00:48 \nIter:    480, Train Loss:  0.096, Train Acc: 100.00%, Time: 0:00:53 *\nIter:    510, Train Loss:   0.28, Train Acc:  92.19%, Time: 0:00:53 \nIter:    540, Train Loss:   0.16, Train Acc:  98.44%, Time: 0:00:54 \nIter:    570, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:00:55 \nEpoch: 4\nIter:    600, Train Loss:  0.057, Train Acc: 100.00%, Time: 0:00:55 \nIter:    630, Train Loss:  0.083, Train Acc:  98.44%, Time: 0:00:56 \nIter:    660, Train Loss:   0.09, Train Acc:  96.88%, Time: 0:00:57 \nIter:    690, Train Loss:  0.063, Train Acc:  98.44%, Time: 0:00:57 \nIter:    720, Train Loss:  0.091, Train Acc:  98.44%, Time: 0:00:58 \nIter:    750, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:00:59 \nIter:    780, Train Loss:   0.14, Train Acc:  92.19%, Time: 0:00:59 \nEpoch: 5\nIter:    810, Train Loss:  0.033, Train Acc: 100.00%, Time: 0:01:00 \nIter:    840, Train Loss:  0.036, Train Acc: 100.00%, Time: 0:01:01 \nIter:    870, Train Loss:  0.039, Train Acc: 100.00%, Time: 0:01:01 \nIter:    900, Train Loss:  0.046, Train Acc:  98.44%, Time: 0:01:02 \nIter:    930, Train Loss:  0.033, Train Acc: 100.00%, Time: 0:01:03 \nIter:    960, Train Loss:   0.04, Train Acc:  98.44%, Time: 0:01:04 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/8/8\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/8/8\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.91, Test Acc:  75.34%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.71      0.83      0.77       168\n                   Filter       0.72      0.64      0.68       129\n    Compute Derived Value       0.60      0.65      0.62       164\n            Find Extremum       0.81      0.87      0.84       149\n                     Sort       0.91      0.93      0.92       147\n          Determine Range       0.87      0.77      0.82       147\nCharacterize Distribution       0.79      0.74      0.76       156\n           Find Anomalies       0.48      0.77      0.59        65\n                  Cluster       0.76      0.70      0.73       106\n                Correlate       0.88      0.63      0.74       172\n\n                micro avg       0.75      0.75      0.75      1403\n                macro avg       0.75      0.75      0.75      1403\n             weighted avg       0.77      0.75      0.76      1403\n\nConfusion Matrix...\n[[140   3  13   4   2   0   3   1   1   1]\n [  3  83   0  12   0  15   0  15   0   1]\n [ 30  15 106   3   2   1   2   0   2   3]\n [  4   1  11 130   0   0   1   1   0   1]\n [  0   0   0   5 137   0   1   0   3   1]\n [  3   6   2   6   2 113   2   4   6   3]\n [  0   1  32   0   3   0 115   0   3   2]\n [ 10   1   0   0   0   0   1  50   2   1]\n [  6   4   0   1   5   0   7   7  74   2]\n [  1   1  13   0   0   1  13  27   7 109]]\nTime usage: 0:00:02\nFold:  9\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  45.31%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.6, Train Acc:  50.00%, Time: 0:00:11 *\nIter:     90, Train Loss:    1.3, Train Acc:  60.94%, Time: 0:00:17 *\nIter:    120, Train Loss:    1.2, Train Acc:  67.19%, Time: 0:00:23 *\nIter:    150, Train Loss:    1.0, Train Acc:  71.88%, Time: 0:00:28 *\nIter:    180, Train Loss:   0.95, Train Acc:  67.19%, Time: 0:00:29 \nEpoch: 2\nIter:    210, Train Loss:   0.62, Train Acc:  82.81%, Time: 0:00:33 *\nIter:    240, Train Loss:   0.52, Train Acc:  84.38%, Time: 0:00:37 *\nIter:    270, Train Loss:   0.54, Train Acc:  82.81%, Time: 0:00:37 \nIter:    300, Train Loss:   0.43, Train Acc:  89.06%, Time: 0:00:42 *\nIter:    330, Train Loss:   0.43, Train Acc:  85.94%, Time: 0:00:42 \nIter:    360, Train Loss:   0.41, Train Acc:  92.19%, Time: 0:00:47 *\nIter:    390, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:00:51 *\nEpoch: 3\nIter:    420, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:00:52 \nIter:    450, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:00:52 \nIter:    480, Train Loss:   0.45, Train Acc:  89.06%, Time: 0:00:53 \nIter:    510, Train Loss:   0.19, Train Acc:  95.31%, Time: 0:00:57 *\nIter:    540, Train Loss:   0.23, Train Acc:  92.19%, Time: 0:00:58 \nIter:    570, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:01:02 *\nEpoch: 4\nIter:    600, Train Loss:   0.06, Train Acc: 100.00%, Time: 0:01:07 *\nIter:    630, Train Loss:  0.081, Train Acc:  96.88%, Time: 0:01:08 \nIter:    660, Train Loss:  0.057, Train Acc: 100.00%, Time: 0:01:08 \nIter:    690, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:09 \nIter:    720, Train Loss:   0.14, Train Acc:  95.31%, Time: 0:01:10 \nIter:    750, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:01:10 \nIter:    780, Train Loss:  0.095, Train Acc:  96.88%, Time: 0:01:11 \nEpoch: 5\nIter:    810, Train Loss:  0.043, Train Acc:  98.44%, Time: 0:01:12 \nIter:    840, Train Loss:  0.083, Train Acc:  96.88%, Time: 0:01:12 \nIter:    870, Train Loss:  0.058, Train Acc:  98.44%, Time: 0:01:13 \nIter:    900, Train Loss:  0.053, Train Acc:  98.44%, Time: 0:01:14 \nIter:    930, Train Loss:  0.066, Train Acc:  98.44%, Time: 0:01:14 \nIter:    960, Train Loss:  0.052, Train Acc:  96.88%, Time: 0:01:15 \nIter:    990, Train Loss:  0.054, Train Acc: 100.00%, Time: 0:01:16 \nEpoch: 6\nIter:   1020, Train Loss: 0.0095, Train Acc: 100.00%, Time: 0:01:16 \nIter:   1050, Train Loss: 0.0092, Train Acc: 100.00%, Time: 0:01:17 \nIter:   1080, Train Loss:  0.019, Train Acc: 100.00%, Time: 0:01:18 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/9/9\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/9/9\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.0, Test Acc:  71.50%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.83      0.73      0.78       228\n                   Filter       0.53      0.74      0.62       149\n    Compute Derived Value       0.57      0.62      0.59       129\n            Find Extremum       0.89      0.76      0.82       175\n                     Sort       0.80      0.96      0.87        98\n          Determine Range       0.69      0.51      0.58        89\nCharacterize Distribution       0.94      0.85      0.90        96\n           Find Anomalies       0.74      0.66      0.70       165\n                  Cluster       0.84      0.70      0.76       139\n                Correlate       0.45      0.62      0.52       104\n\n                micro avg       0.72      0.72      0.72      1372\n                macro avg       0.73      0.71      0.71      1372\n             weighted avg       0.74      0.72      0.72      1372\n\nConfusion Matrix...\n[[166  23  20   5   1   3   0   1   0   9]\n [  7 110  21   1   3   6   0   1   0   0]\n [  4  18  80   0   0   2   1   1   0  23]\n [ 12   7  13 133   7   2   0   0   0   1]\n [  0   0   0   2  94   1   0   0   0   1]\n [  4  17   0   3   1  45   0  16   0   3]\n [  1   0   1   1   1   3  82   1   0   6]\n [  0  16   1   5   0   0   0 109   1  33]\n [  6   3   0   0  11   2   4  13  97   3]\n [  0  12   4   0   0   1   0   5  17  65]]\nTime usage: 0:00:02\nFold:  10\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    1.9, Train Acc:  40.62%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.6, Train Acc:  53.12%, Time: 0:00:11 *\nIter:     90, Train Loss:    1.3, Train Acc:  68.75%, Time: 0:00:16 *\nIter:    120, Train Loss:    1.2, Train Acc:  64.06%, Time: 0:00:16 \nIter:    150, Train Loss:   0.92, Train Acc:  78.12%, Time: 0:00:21 *\nIter:    180, Train Loss:   0.75, Train Acc:  78.12%, Time: 0:00:22 \nEpoch: 2\nIter:    210, Train Loss:   0.46, Train Acc:  89.06%, Time: 0:00:26 *\nIter:    240, Train Loss:   0.66, Train Acc:  81.25%, Time: 0:00:27 \nIter:    270, Train Loss:   0.43, Train Acc:  89.06%, Time: 0:00:28 \nIter:    300, Train Loss:   0.41, Train Acc:  87.50%, Time: 0:00:28 \nIter:    330, Train Loss:   0.34, Train Acc:  85.94%, Time: 0:00:29 \nIter:    360, Train Loss:   0.57, Train Acc:  84.38%, Time: 0:00:30 \nIter:    390, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:00:35 *\nEpoch: 3\nIter:    420, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:00:35 \nIter:    450, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:00:36 \nIter:    480, Train Loss:   0.24, Train Acc:  92.19%, Time: 0:00:37 \nIter:    510, Train Loss:   0.13, Train Acc:  95.31%, Time: 0:00:37 \nIter:    540, Train Loss:   0.15, Train Acc:  95.31%, Time: 0:00:38 \nIter:    570, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:00:39 \nEpoch: 4\nIter:    600, Train Loss:  0.079, Train Acc: 100.00%, Time: 0:00:44 *\nIter:    630, Train Loss:  0.066, Train Acc:  98.44%, Time: 0:00:44 \nIter:    660, Train Loss:  0.043, Train Acc: 100.00%, Time: 0:00:45 \nIter:    690, Train Loss:  0.095, Train Acc:  96.88%, Time: 0:00:46 \nIter:    720, Train Loss:   0.03, Train Acc: 100.00%, Time: 0:00:46 \nIter:    750, Train Loss:  0.091, Train Acc:  96.88%, Time: 0:00:47 \nIter:    780, Train Loss:  0.054, Train Acc:  98.44%, Time: 0:00:48 \nEpoch: 5\nIter:    810, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:00:48 \nIter:    840, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:00:49 \nIter:    870, Train Loss:  0.038, Train Acc:  98.44%, Time: 0:00:50 \nIter:    900, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:00:50 \nIter:    930, Train Loss:  0.021, Train Acc: 100.00%, Time: 0:00:51 \nIter:    960, Train Loss:  0.047, Train Acc: 100.00%, Time: 0:00:52 \nIter:    990, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:00:52 \nEpoch: 6\nIter:   1020, Train Loss:  0.019, Train Acc: 100.00%, Time: 0:00:53 \nIter:   1050, Train Loss:  0.041, Train Acc:  98.44%, Time: 0:00:54 \nIter:   1080, Train Loss:  0.029, Train Acc:  98.44%, Time: 0:00:54 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/10/10\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/bundle/10/10\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.3, Test Acc:  66.57%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.72      0.67      0.70       189\n                   Filter       0.48      0.36      0.42       162\n    Compute Derived Value       0.78      0.54      0.63       198\n            Find Extremum       0.78      0.82      0.80       224\n                     Sort       0.78      0.58      0.66        90\n          Determine Range       0.76      0.72      0.74       152\nCharacterize Distribution       0.53      0.78      0.63       120\n           Find Anomalies       0.44      0.64      0.52        80\n                  Cluster       0.81      0.77      0.79        91\n                Correlate       0.57      0.86      0.69        91\n\n                micro avg       0.67      0.67      0.67      1397\n                macro avg       0.67      0.67      0.66      1397\n             weighted avg       0.68      0.67      0.66      1397\n\nConfusion Matrix...\n[[127   8   4  15   0   3  16  13   0   3]\n [  1  59   4  24   7  16  21  24   4   2]\n [ 37  16 106   0   0   2  24   5   1   7]\n [  1   7   4 184   7   7   2   4   0   8]\n [  0  15   0   9  52   6   3   0   3   2]\n [  9   5   6   1   0 109   2   8   0  12]\n [  0   0   3   0   0   0  94   1   7  15]\n [  0   2   9   1   0   0  11  51   0   6]\n [  1   0   0   1   1   0   6   9  70   3]\n [  0  10   0   0   0   0   0   2   1  78]]\nTime usage: 0:00:02\n[0.7584541064035983, 0.6312316713794586, 0.6765746639201764, 0.6519258207669442, 0.6732312181759368, 0.6782972782496713, 0.6065688330672322, 0.7533856030455336, 0.7150145774332497, 0.6657122397900652]\n0.6810396012231866 0.0464531385944118 0.048965907473937996 0.0021578940852716314\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def table_split():\n    train_data = [[] for i in range(37)]\n    with open(trainDataPath, \"r\", encoding='utf-8') as fp:\n        for line in fp.readlines():\n            word = line.split()\n            info = word[0].split(\":\")\n            index = int(info[3]) - 1\n            label = int(info[0])\n            content = word[1:]\n            train_data[index].append([content,label])\n            \n    for i in range(37):\n        np.random.shuffle(train_data[i])\n        train_data[i] = np.asarray(train_data[i])\n        \n    np.random.shuffle(train_data)   \n    \n    return train_data\n\ntrain_data_table = table_split()", "execution_count": 117, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "table_test_acc = train_split_data(train_data_table, \"table\")", "execution_count": 118, "outputs": [{"output_type": "stream", "text": "table\n37 610 296 41\nFold:  1\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  40.62%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.7, Train Acc:  43.75%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.3, Train Acc:  71.88%, Time: 0:00:20 *\nIter:    120, Train Loss:    1.1, Train Acc:  67.19%, Time: 0:00:21 \nIter:    150, Train Loss:    1.1, Train Acc:  67.19%, Time: 0:00:22 \nIter:    180, Train Loss:   0.82, Train Acc:  82.81%, Time: 0:00:28 *\nEpoch: 2\nIter:    210, Train Loss:   0.49, Train Acc:  84.38%, Time: 0:00:33 *\nIter:    240, Train Loss:    0.7, Train Acc:  76.56%, Time: 0:00:34 \nIter:    270, Train Loss:   0.45, Train Acc:  90.62%, Time: 0:00:38 *\nIter:    300, Train Loss:   0.53, Train Acc:  84.38%, Time: 0:00:39 \nIter:    330, Train Loss:   0.31, Train Acc:  92.19%, Time: 0:00:43 *\nIter:    360, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:00:44 \nIter:    390, Train Loss:   0.52, Train Acc:  87.50%, Time: 0:00:45 \nEpoch: 3\nIter:    420, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:00:51 *\nIter:    450, Train Loss:   0.25, Train Acc:  92.19%, Time: 0:00:52 \nIter:    480, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:53 \nIter:    510, Train Loss:   0.21, Train Acc:  95.31%, Time: 0:00:53 \nIter:    540, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:00:54 \nIter:    570, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:00:55 \nEpoch: 4\nIter:    600, Train Loss:   0.14, Train Acc:  95.31%, Time: 0:00:55 \nIter:    630, Train Loss:   0.36, Train Acc:  92.19%, Time: 0:00:56 \nIter:    660, Train Loss:   0.19, Train Acc:  90.62%, Time: 0:00:57 \nIter:    690, Train Loss:   0.21, Train Acc:  92.19%, Time: 0:00:57 \nIter:    720, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:05 *\nIter:    750, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:06 \nIter:    780, Train Loss:   0.11, Train Acc:  95.31%, Time: 0:01:06 \nEpoch: 5\nIter:    810, Train Loss:  0.059, Train Acc:  98.44%, Time: 0:01:07 \nIter:    840, Train Loss:  0.073, Train Acc:  95.31%, Time: 0:01:08 \nIter:    870, Train Loss:  0.024, Train Acc: 100.00%, Time: 0:01:14 *\nIter:    900, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:01:15 \nIter:    930, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:15 \nIter:    960, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:16 \nIter:    990, Train Loss:  0.041, Train Acc:  98.44%, Time: 0:01:17 \nEpoch: 6\nIter:   1020, Train Loss:  0.028, Train Acc:  98.44%, Time: 0:01:17 \nIter:   1050, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:18 \nIter:   1080, Train Loss:  0.029, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1110, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1140, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:20 \nIter:   1170, Train Loss:   0.04, Train Acc:  98.44%, Time: 0:01:21 \nEpoch: 7\nIter:   1200, Train Loss: 0.0095, Train Acc: 100.00%, Time: 0:01:21 \nIter:   1230, Train Loss:  0.013, Train Acc: 100.00%, Time: 0:01:22 \nIter:   1260, Train Loss:  0.012, Train Acc: 100.00%, Time: 0:01:23 \nIter:   1290, Train Loss:  0.013, Train Acc: 100.00%, Time: 0:01:23 \nIter:   1320, Train Loss:  0.032, Train Acc:  98.44%, Time: 0:01:24 \nIter:   1350, Train Loss:  0.018, Train Acc:  98.44%, Time: 0:01:25 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/1/1\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/1/1\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.5, Test Acc:  64.30%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.67      0.29      0.40       132\n                   Filter       0.51      0.33      0.40       128\n    Compute Derived Value       0.38      0.59      0.46       138\n            Find Extremum       0.73      0.81      0.77       200\n                     Sort       0.66      0.76      0.71       107\n          Determine Range       0.88      0.48      0.62       125\nCharacterize Distribution       0.77      0.93      0.84       124\n           Find Anomalies       0.87      0.62      0.72       115\n                  Cluster       0.84      0.65      0.73       118\n                Correlate       0.52      0.93      0.66       121\n\n                micro avg       0.64      0.64      0.64      1308\n                macro avg       0.68      0.64      0.63      1308\n             weighted avg       0.68      0.64      0.63      1308\n\nConfusion Matrix...\n[[ 38   7  47   3   2   1  16   3   0  15]\n [  1  42  16   9  20   0   0   1   6  33]\n [ 13   9  81  14   0   2   2   0   0  17]\n [  2   2  28 163   0   0   0   1   0   4]\n [  0   8  11   0  81   0   0   0   2   5]\n [  0  13  14  17  11  60   1   1   0   8]\n [  1   1   3   0   0   1 115   0   2   1]\n [  1   0   2  17   0   0   0  71   4  20]\n [  1   0   4   1   8   4  15   5  77   3]\n [  0   0   6   0   0   0   1   0   1 113]]\nTime usage: 0:00:02\nFold:  2\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.7, Train Acc:  50.00%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.2, Train Acc:  70.31%, Time: 0:00:19 *\nIter:    120, Train Loss:    1.1, Train Acc:  67.19%, Time: 0:00:20 \nIter:    150, Train Loss:   0.85, Train Acc:  76.56%, Time: 0:00:24 *\nIter:    180, Train Loss:   0.81, Train Acc:  73.44%, Time: 0:00:25 \nEpoch: 2\nIter:    210, Train Loss:    0.6, Train Acc:  84.38%, Time: 0:00:30 *\nIter:    240, Train Loss:   0.87, Train Acc:  71.88%, Time: 0:00:31 \nIter:    270, Train Loss:   0.37, Train Acc:  89.06%, Time: 0:00:35 *\nIter:    300, Train Loss:   0.51, Train Acc:  85.94%, Time: 0:00:36 \nIter:    330, Train Loss:   0.36, Train Acc:  87.50%, Time: 0:00:37 \nIter:    360, Train Loss:   0.26, Train Acc:  95.31%, Time: 0:00:42 *\nEpoch: 3\nIter:    390, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:00:47 *\nIter:    420, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:47 \nIter:    450, Train Loss:   0.23, Train Acc:  92.19%, Time: 0:00:48 \nIter:    480, Train Loss:   0.21, Train Acc:  92.19%, Time: 0:00:49 \nIter:    510, Train Loss:   0.13, Train Acc:  95.31%, Time: 0:00:49 \nIter:    540, Train Loss:   0.28, Train Acc:  90.62%, Time: 0:00:50 \nIter:    570, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:00:51 \nEpoch: 4\nIter:    600, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:00:51 \nIter:    630, Train Loss:   0.07, Train Acc:  98.44%, Time: 0:00:56 *\nIter:    660, Train Loss:  0.085, Train Acc:  98.44%, Time: 0:00:57 \nIter:    690, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:58 \nIter:    720, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:00:59 \nIter:    750, Train Loss:  0.096, Train Acc:  96.88%, Time: 0:00:59 \nEpoch: 5\nIter:    780, Train Loss:  0.057, Train Acc: 100.00%, Time: 0:01:04 *\nIter:    810, Train Loss:  0.035, Train Acc: 100.00%, Time: 0:01:05 \nIter:    840, Train Loss:  0.076, Train Acc:  96.88%, Time: 0:01:05 \nIter:    870, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:06 \nIter:    900, Train Loss:  0.029, Train Acc: 100.00%, Time: 0:01:07 \nIter:    930, Train Loss:  0.076, Train Acc:  98.44%, Time: 0:01:07 \nIter:    960, Train Loss:  0.041, Train Acc:  98.44%, Time: 0:01:08 \nEpoch: 6\nIter:    990, Train Loss:  0.036, Train Acc:  98.44%, Time: 0:01:09 \nIter:   1020, Train Loss:  0.015, Train Acc: 100.00%, Time: 0:01:09 \nIter:   1050, Train Loss:  0.044, Train Acc:  98.44%, Time: 0:01:10 \nIter:   1080, Train Loss: 0.0094, Train Acc: 100.00%, Time: 0:01:11 \nIter:   1110, Train Loss:  0.051, Train Acc:  98.44%, Time: 0:01:11 \nIter:   1140, Train Loss:  0.033, Train Acc:  98.44%, Time: 0:01:12 \nEpoch: 7\nIter:   1170, Train Loss:  0.018, Train Acc: 100.00%, Time: 0:01:13 \nIter:   1200, Train Loss:  0.028, Train Acc: 100.00%, Time: 0:01:13 \nIter:   1230, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:14 \nIter:   1260, Train Loss:  0.008, Train Acc: 100.00%, Time: 0:01:15 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/2/2\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/2/2\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.3, Test Acc:  63.42%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.68      0.32      0.43       157\n                   Filter       0.36      0.56      0.44       144\n    Compute Derived Value       0.61      0.36      0.45       158\n            Find Extremum       0.78      0.63      0.70       202\n                     Sort       0.87      0.91      0.89       181\n          Determine Range       0.71      0.58      0.63       158\nCharacterize Distribution       0.86      0.67      0.75       158\n           Find Anomalies       0.44      0.79      0.57       157\n                  Cluster       0.70      0.84      0.76       159\n                Correlate       0.61      0.63      0.62       177\n\n                micro avg       0.63      0.63      0.63      1651\n                macro avg       0.66      0.63      0.63      1651\n             weighted avg       0.67      0.63      0.63      1651\n\nConfusion Matrix...\n[[ 50  54  19   2   1   8   2  14   4   3]\n [  4  81   0   7   5   2   0  27   6  12]\n [ 12  12  57  14   2  15   2  26   9   9]\n [  0  29   3 128   2   4   0  29   2   5]\n [  0   4   0   5 164   1   0   3   2   2]\n [  5  22   1   3   3  91   0  18   4  11]\n [  2  14  12   0   4   2 106   8   8   2]\n [  0   4   0   0   1   1   0 124   1  26]\n [  0   0   0   0   7   2   0  15 134   1]\n [  0   2   2   6   0   3  13  17  22 112]]\nTime usage: 0:00:02\nFold:  3\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  42.19%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.6, Train Acc:  60.94%, Time: 0:00:11 *\nIter:     90, Train Loss:    1.1, Train Acc:  76.56%, Time: 0:00:16 *\nIter:    120, Train Loss:   0.93, Train Acc:  75.00%, Time: 0:00:16 \nIter:    150, Train Loss:   0.84, Train Acc:  78.12%, Time: 0:00:22 *\nIter:    180, Train Loss:    0.8, Train Acc:  81.25%, Time: 0:00:27 *\nEpoch: 2\nIter:    210, Train Loss:   0.65, Train Acc:  78.12%, Time: 0:00:28 \nIter:    240, Train Loss:   0.56, Train Acc:  87.50%, Time: 0:00:32 *\nIter:    270, Train Loss:   0.45, Train Acc:  85.94%, Time: 0:00:33 \nIter:    300, Train Loss:   0.58, Train Acc:  81.25%, Time: 0:00:34 \nIter:    330, Train Loss:   0.48, Train Acc:  93.75%, Time: 0:00:38 *\nIter:    360, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:00:39 \nIter:    390, Train Loss:   0.45, Train Acc:  87.50%, Time: 0:00:39 \nEpoch: 3\nIter:    420, Train Loss:   0.31, Train Acc:  89.06%, Time: 0:00:40 \nIter:    450, Train Loss:   0.31, Train Acc:  92.19%, Time: 0:00:41 \nIter:    480, Train Loss:   0.15, Train Acc:  98.44%, Time: 0:00:46 *\nIter:    510, Train Loss:  0.096, Train Acc:  98.44%, Time: 0:00:46 \nIter:    540, Train Loss:   0.22, Train Acc:  95.31%, Time: 0:00:47 \nIter:    570, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:00:48 \nEpoch: 4\nIter:    600, Train Loss:   0.14, Train Acc:  98.44%, Time: 0:00:48 \nIter:    630, Train Loss:  0.098, Train Acc:  98.44%, Time: 0:00:49 \nIter:    660, Train Loss:  0.065, Train Acc:  98.44%, Time: 0:00:50 \nIter:    690, Train Loss:  0.098, Train Acc:  96.88%, Time: 0:00:50 \nIter:    720, Train Loss:  0.097, Train Acc:  96.88%, Time: 0:00:51 \nIter:    750, Train Loss:  0.078, Train Acc: 100.00%, Time: 0:00:56 *\nIter:    780, Train Loss:   0.19, Train Acc:  95.31%, Time: 0:00:57 \nEpoch: 5\nIter:    810, Train Loss:   0.04, Train Acc:  98.44%, Time: 0:00:57 \nIter:    840, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:00:58 \nIter:    870, Train Loss:  0.037, Train Acc: 100.00%, Time: 0:00:59 \nIter:    900, Train Loss:  0.035, Train Acc: 100.00%, Time: 0:00:59 \nIter:    930, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:01:00 \nIter:    960, Train Loss:  0.051, Train Acc:  98.44%, Time: 0:01:01 \nIter:    990, Train Loss:   0.11, Train Acc:  96.55%, Time: 0:01:01 \nEpoch: 6\nIter:   1020, Train Loss:  0.081, Train Acc:  98.44%, Time: 0:01:02 \nIter:   1050, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:03 \nIter:   1080, Train Loss: 0.0098, Train Acc: 100.00%, Time: 0:01:04 \nIter:   1110, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:04 \nIter:   1140, Train Loss:  0.032, Train Acc: 100.00%, Time: 0:01:05 \nIter:   1170, Train Loss:  0.031, Train Acc:  98.44%, Time: 0:01:06 \nEpoch: 7\nIter:   1200, Train Loss:  0.053, Train Acc:  98.44%, Time: 0:01:06 \nIter:   1230, Train Loss:  0.011, Train Acc: 100.00%, Time: 0:01:07 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/3/3\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/3/3\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.3, Test Acc:  63.55%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.80      0.66      0.72       214\n                   Filter       0.47      0.57      0.51       191\n    Compute Derived Value       0.73      0.36      0.48       174\n            Find Extremum       0.48      0.90      0.63       137\n                     Sort       0.70      0.69      0.70        65\n          Determine Range       0.63      0.64      0.63       103\nCharacterize Distribution       0.80      0.90      0.85        92\n           Find Anomalies       0.70      0.50      0.58       143\n                  Cluster       0.51      0.79      0.62        72\n                Correlate       0.84      0.63      0.72       178\n\n                micro avg       0.64      0.64      0.64      1369\n                macro avg       0.67      0.66      0.65      1369\n             weighted avg       0.68      0.64      0.63      1369\n\nConfusion Matrix...\n[[141  21  15  10   1   5   0   0  16   5]\n [ 11 109   0  42   1   4   2  10   8   4]\n [ 20  34  62  36   0  18   0   3   1   0]\n [  0   3   0 123  10   0   0   1   0   0]\n [  1   5   0  12  45   0   0   1   1   0]\n [  0   5   1  17   7  66   3   2   1   1]\n [  0   0   3   2   0   3  83   0   1   0]\n [  0  26   2   4   0   2  10  71  21   7]\n [  3   4   0   3   0   0   1   0  57   4]\n [  1  27   2   5   0   7   5  13   5 113]]\nTime usage: 0:00:02\nFold:  4\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  28.12%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.7, Train Acc:  56.25%, Time: 0:00:12 *\nIter:     90, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:16 *\nIter:    120, Train Loss:    1.2, Train Acc:  59.38%, Time: 0:00:17 \nIter:    150, Train Loss:   0.95, Train Acc:  75.00%, Time: 0:00:21 *\nEpoch: 2\nIter:    180, Train Loss:   0.68, Train Acc:  85.94%, Time: 0:00:25 *\nIter:    210, Train Loss:    0.6, Train Acc:  82.81%, Time: 0:00:26 \nIter:    240, Train Loss:   0.52, Train Acc:  84.38%, Time: 0:00:26 \nIter:    270, Train Loss:    0.5, Train Acc:  85.94%, Time: 0:00:27 \nIter:    300, Train Loss:   0.45, Train Acc:  87.50%, Time: 0:00:32 *\nIter:    330, Train Loss:   0.41, Train Acc:  85.94%, Time: 0:00:33 \nEpoch: 3\nIter:    360, Train Loss:   0.43, Train Acc:  87.50%, Time: 0:00:34 \nIter:    390, Train Loss:   0.22, Train Acc:  96.88%, Time: 0:00:39 *\nIter:    420, Train Loss:   0.28, Train Acc:  95.31%, Time: 0:00:39 \nIter:    450, Train Loss:   0.26, Train Acc:  90.62%, Time: 0:00:40 \nIter:    480, Train Loss:    0.1, Train Acc:  96.88%, Time: 0:00:41 \nIter:    510, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:00:41 \nEpoch: 4\nIter:    540, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:00:46 *\nIter:    570, Train Loss:   0.18, Train Acc:  95.31%, Time: 0:00:47 \nIter:    600, Train Loss:  0.062, Train Acc: 100.00%, Time: 0:00:52 *\nIter:    630, Train Loss:   0.17, Train Acc:  95.31%, Time: 0:00:53 \nIter:    660, Train Loss:   0.11, Train Acc:  95.31%, Time: 0:00:53 \nIter:    690, Train Loss:  0.093, Train Acc:  96.88%, Time: 0:00:54 \nEpoch: 5\nIter:    720, Train Loss:  0.048, Train Acc: 100.00%, Time: 0:00:55 \nIter:    750, Train Loss:  0.056, Train Acc: 100.00%, Time: 0:00:55 \nIter:    780, Train Loss:  0.047, Train Acc: 100.00%, Time: 0:00:56 \nIter:    810, Train Loss:  0.083, Train Acc:  98.44%, Time: 0:00:57 \nIter:    840, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:00:57 \nIter:    870, Train Loss:  0.072, Train Acc:  98.44%, Time: 0:00:58 \nEpoch: 6\nIter:    900, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:00:59 \nIter:    930, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:00:59 \nIter:    960, Train Loss:  0.029, Train Acc:  98.44%, Time: 0:01:00 \nIter:    990, Train Loss:  0.037, Train Acc:  98.44%, Time: 0:01:01 \nIter:   1020, Train Loss:   0.02, Train Acc: 100.00%, Time: 0:01:01 \nIter:   1050, Train Loss:  0.043, Train Acc:  98.44%, Time: 0:01:02 \nEpoch: 7\nIter:   1080, Train Loss:  0.022, Train Acc: 100.00%, Time: 0:01:03 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/4/4\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/4/4\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.2, Test Acc:  67.07%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.66      0.71      0.68       213\n                   Filter       0.74      0.51      0.60       279\n    Compute Derived Value       0.55      0.59      0.57       302\n            Find Extremum       0.66      0.80      0.72       320\n                     Sort       0.74      0.85      0.79       252\n          Determine Range       0.63      0.73      0.68       223\nCharacterize Distribution       0.79      0.74      0.76       261\n           Find Anomalies       0.82      0.56      0.66       253\n                  Cluster       0.64      0.61      0.62       237\n                Correlate       0.60      0.62      0.61       278\n\n                micro avg       0.67      0.67      0.67      2618\n                macro avg       0.68      0.67      0.67      2618\n             weighted avg       0.68      0.67      0.67      2618\n\nConfusion Matrix...\n[[152   5  32   9   3   3   1   0   3   5]\n [  9 142  46  14   8  19   6  15   9  11]\n [ 13  18 178  39   3  16  22   1  10   2]\n [ 17   4   5 255  18  15   0   2   1   3]\n [  3   3   4  15 215   2   1   0   8   1]\n [ 13   8   5   6   6 163  13   0   4   5]\n [  1   0  13  16   7   9 192   2   7  14]\n [  3   7   6  18   3   8   1 141  24  42]\n [ 16   1   3   0  19  16   4   2 145  31]\n [  5   5  32  17   8   8   3  10  17 173]]\nTime usage: 0:00:02\nFold:  5\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  40.62%, Time: 0:00:07 *\nIter:     60, Train Loss:    1.9, Train Acc:  34.38%, Time: 0:00:08 \nIter:     90, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:13 *\nIter:    120, Train Loss:    1.1, Train Acc:  73.44%, Time: 0:00:18 *\nIter:    150, Train Loss:    1.1, Train Acc:  73.44%, Time: 0:00:19 \nIter:    180, Train Loss:   0.91, Train Acc:  76.56%, Time: 0:00:23 *\nEpoch: 2\nIter:    210, Train Loss:   0.76, Train Acc:  79.69%, Time: 0:00:30 *\nIter:    240, Train Loss:   0.69, Train Acc:  75.00%, Time: 0:00:30 \nIter:    270, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:00:35 *\nIter:    300, Train Loss:   0.43, Train Acc:  84.38%, Time: 0:00:36 \nIter:    330, Train Loss:    0.6, Train Acc:  87.50%, Time: 0:00:37 \nIter:    360, Train Loss:    0.4, Train Acc:  89.06%, Time: 0:00:37 \nIter:    390, Train Loss:   0.41, Train Acc:  87.50%, Time: 0:00:38 \nEpoch: 3\nIter:    420, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:00:43 *\nIter:    450, Train Loss:   0.11, Train Acc: 100.00%, Time: 0:00:47 *\nIter:    480, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:00:48 \nIter:    510, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:49 \nIter:    540, Train Loss:   0.24, Train Acc:  92.19%, Time: 0:00:49 \nIter:    570, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:00:50 \nIter:    600, Train Loss:   0.27, Train Acc:  92.19%, Time: 0:00:51 \nEpoch: 4\nIter:    630, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:00:51 \nIter:    660, Train Loss:  0.095, Train Acc:  96.88%, Time: 0:00:52 \nIter:    690, Train Loss:  0.089, Train Acc:  96.88%, Time: 0:00:53 \nIter:    720, Train Loss:  0.085, Train Acc:  98.44%, Time: 0:00:53 \nIter:    750, Train Loss:  0.052, Train Acc: 100.00%, Time: 0:00:54 \nIter:    780, Train Loss:  0.096, Train Acc:  98.44%, Time: 0:00:55 \nEpoch: 5\nIter:    810, Train Loss:  0.057, Train Acc:  98.44%, Time: 0:00:55 \nIter:    840, Train Loss:  0.029, Train Acc:  98.44%, Time: 0:00:56 \nIter:    870, Train Loss:  0.068, Train Acc:  98.44%, Time: 0:00:57 \nIter:    900, Train Loss:  0.044, Train Acc: 100.00%, Time: 0:00:58 \nIter:    930, Train Loss:   0.06, Train Acc: 100.00%, Time: 0:00:58 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/5/5\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/5/5\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  68.42%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.48      0.89      0.63        84\n                   Filter       0.45      0.76      0.57        93\n    Compute Derived Value       0.66      0.46      0.54       178\n            Find Extremum       0.82      0.78      0.80       173\n                     Sort       0.82      0.98      0.89        92\n          Determine Range       0.89      0.46      0.61       110\nCharacterize Distribution       0.99      0.77      0.87       122\n           Find Anomalies       0.94      0.36      0.52       121\n                  Cluster       0.57      0.80      0.66       108\n                Correlate       0.67      0.78      0.73       116\n\n                micro avg       0.68      0.68      0.68      1197\n                macro avg       0.73      0.71      0.68      1197\n             weighted avg       0.74      0.68      0.68      1197\n\nConfusion Matrix...\n[[ 75   1   3   0   2   0   0   0   3   0]\n [ 18  71   2   1   0   0   0   0   1   0]\n [ 30   0  82  25   3   0   0   1   5  32]\n [  5  10   6 135   2   0   0   0  13   2]\n [  0   0   0   1  90   0   0   0   1   0]\n [ 12  16  23   1   1  51   0   0   1   5]\n [  2   0   3   0   1   2  94   0  16   4]\n [  6  49   1   1   3   4   0  44  12   1]\n [  4  10   1   0   6   0   1   0  86   0]\n [  3   0   4   0   2   0   0   2  14  91]]\nTime usage: 0:00:02\nFold:  6\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  32.81%, Time: 0:00:09 *\nIter:     60, Train Loss:    1.6, Train Acc:  62.50%, Time: 0:00:15 *\nIter:     90, Train Loss:    1.3, Train Acc:  64.06%, Time: 0:00:22 *\nIter:    120, Train Loss:    1.2, Train Acc:  64.06%, Time: 0:00:22 \nIter:    150, Train Loss:   0.84, Train Acc:  76.56%, Time: 0:00:28 *\nIter:    180, Train Loss:   0.88, Train Acc:  75.00%, Time: 0:00:29 \nEpoch: 2\nIter:    210, Train Loss:   0.72, Train Acc:  81.25%, Time: 0:00:35 *\nIter:    240, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:00:42 *\nIter:    270, Train Loss:   0.64, Train Acc:  79.69%, Time: 0:00:42 \nIter:    300, Train Loss:   0.38, Train Acc:  95.31%, Time: 0:00:50 *\nIter:    330, Train Loss:   0.28, Train Acc:  92.19%, Time: 0:00:51 \nIter:    360, Train Loss:   0.32, Train Acc:  89.06%, Time: 0:00:51 \nEpoch: 3\nIter:    390, Train Loss:   0.17, Train Acc:  95.31%, Time: 0:00:52 \nIter:    420, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:00:58 *\nIter:    450, Train Loss:    0.2, Train Acc:  95.31%, Time: 0:00:59 \nIter:    480, Train Loss:   0.17, Train Acc:  95.31%, Time: 0:01:00 \nIter:    510, Train Loss:   0.22, Train Acc:  95.31%, Time: 0:01:01 \nIter:    540, Train Loss:   0.23, Train Acc:  95.31%, Time: 0:01:01 \nEpoch: 4\nIter:    570, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:01:07 *\nIter:    600, Train Loss:  0.098, Train Acc:  96.88%, Time: 0:01:08 \nIter:    630, Train Loss:  0.056, Train Acc: 100.00%, Time: 0:01:14 *\nIter:    660, Train Loss:    0.1, Train Acc:  95.31%, Time: 0:01:14 \nIter:    690, Train Loss:  0.055, Train Acc: 100.00%, Time: 0:01:15 \nIter:    720, Train Loss:   0.08, Train Acc:  96.88%, Time: 0:01:16 \nEpoch: 5\nIter:    750, Train Loss:  0.053, Train Acc:  96.88%, Time: 0:01:16 \nIter:    780, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:17 \nIter:    810, Train Loss:   0.23, Train Acc:  95.31%, Time: 0:01:18 \nIter:    840, Train Loss:  0.027, Train Acc: 100.00%, Time: 0:01:18 \nIter:    870, Train Loss:  0.051, Train Acc: 100.00%, Time: 0:01:19 \nIter:    900, Train Loss:  0.011, Train Acc: 100.00%, Time: 0:01:20 \nEpoch: 6\nIter:    930, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:21 \nIter:    960, Train Loss:   0.01, Train Acc: 100.00%, Time: 0:01:21 \nIter:    990, Train Loss:  0.033, Train Acc: 100.00%, Time: 0:01:22 \nIter:   1020, Train Loss:  0.029, Train Acc:  98.44%, Time: 0:01:23 \nIter:   1050, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:23 \nIter:   1080, Train Loss:  0.021, Train Acc: 100.00%, Time: 0:01:24 \nEpoch: 7\nIter:   1110, Train Loss:  0.024, Train Acc: 100.00%, Time: 0:01:25 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/6/6\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/6/6\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.6, Test Acc:  60.73%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.74      0.31      0.44       264\n                   Filter       0.60      0.33      0.43       272\n    Compute Derived Value       0.37      0.67      0.48       225\n            Find Extremum       0.46      0.87      0.60       215\n                     Sort       0.73      0.78      0.75       205\n          Determine Range       0.70      0.69      0.69       235\nCharacterize Distribution       0.80      0.64      0.71       205\n           Find Anomalies       0.66      0.68      0.67       261\n                  Cluster       0.89      0.64      0.75       224\n                Correlate       0.63      0.59      0.61       257\n\n                micro avg       0.61      0.61      0.61      2363\n                macro avg       0.66      0.62      0.61      2363\n             weighted avg       0.66      0.61      0.60      2363\n\nConfusion Matrix...\n[[ 82   6  65  72  13   5   4   2   0  15]\n [ 15  90  35  41   8  31   0  32   3  17]\n [  9   3 151  35   1   1   5   9   0  11]\n [  0   0   9 187  11   1   0   2   4   1]\n [  0   1  13  22 159   2   5   1   1   1]\n [  0  20  16  18   8 162   4   1   2   4]\n [  1   2  21  11   3  14 131   6   3  13]\n [  0   5  26  17   2   6   1 177   3  24]\n [  0  11  20   1  11   6  11  15 144   5]\n [  4  12  52   3   3   5   2  23   1 152]]\nTime usage: 0:00:02\nFold:  7\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  37.50%, Time: 0:00:09 *\nIter:     60, Train Loss:    1.8, Train Acc:  45.31%, Time: 0:00:15 *\nIter:     90, Train Loss:    1.4, Train Acc:  64.06%, Time: 0:00:21 *\nIter:    120, Train Loss:    1.1, Train Acc:  71.88%, Time: 0:00:28 *\nIter:    150, Train Loss:   0.92, Train Acc:  76.56%, Time: 0:00:34 *\nIter:    180, Train Loss:   0.91, Train Acc:  71.88%, Time: 0:00:35 \nEpoch: 2\nIter:    210, Train Loss:   0.44, Train Acc:  92.19%, Time: 0:00:41 *\nIter:    240, Train Loss:    0.6, Train Acc:  85.94%, Time: 0:00:42 \nIter:    270, Train Loss:   0.38, Train Acc:  89.06%, Time: 0:00:43 \nIter:    300, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:00:43 \nIter:    330, Train Loss:   0.55, Train Acc:  81.25%, Time: 0:00:44 \nIter:    360, Train Loss:   0.79, Train Acc:  78.12%, Time: 0:00:45 \nIter:    390, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:00:51 *\nEpoch: 3\nIter:    420, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:00:52 \nIter:    450, Train Loss:   0.27, Train Acc:  87.50%, Time: 0:00:52 \nIter:    480, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:00:53 \nIter:    510, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:00:59 *\nIter:    540, Train Loss:   0.39, Train Acc:  85.94%, Time: 0:01:00 \nIter:    570, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:01:01 \nIter:    600, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:01 \nEpoch: 4\nIter:    630, Train Loss:  0.066, Train Acc: 100.00%, Time: 0:01:09 *\nIter:    660, Train Loss:  0.082, Train Acc:  98.44%, Time: 0:01:09 \nIter:    690, Train Loss:  0.074, Train Acc: 100.00%, Time: 0:01:10 \nIter:    720, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:11 \nIter:    750, Train Loss:  0.098, Train Acc:  96.88%, Time: 0:01:11 \nIter:    780, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:12 \nIter:    810, Train Loss:  0.058, Train Acc: 100.00%, Time: 0:01:13 \nEpoch: 5\nIter:    840, Train Loss:  0.025, Train Acc: 100.00%, Time: 0:01:13 \nIter:    870, Train Loss:  0.024, Train Acc: 100.00%, Time: 0:01:14 \nIter:    900, Train Loss:  0.083, Train Acc:  96.88%, Time: 0:01:15 \nIter:    930, Train Loss:  0.021, Train Acc: 100.00%, Time: 0:01:15 \nIter:    960, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:16 \nIter:    990, Train Loss:   0.17, Train Acc:  95.31%, Time: 0:01:17 \nIter:   1020, Train Loss:  0.058, Train Acc:  98.44%, Time: 0:01:17 \nEpoch: 6\nIter:   1050, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:18 \nIter:   1080, Train Loss:  0.014, Train Acc: 100.00%, Time: 0:01:19 \nIter:   1110, Train Loss:  0.016, Train Acc: 100.00%, Time: 0:01:20 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/7/7\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/7/7\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.5, Test Acc:  66.14%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.68      0.30      0.42        76\n                   Filter       0.67      0.66      0.67        88\n    Compute Derived Value       0.25      0.61      0.35        83\n            Find Extremum       0.74      0.54      0.62        92\n                     Sort       0.84      0.97      0.90        95\n          Determine Range       0.86      0.68      0.76       130\nCharacterize Distribution       0.94      0.75      0.83       114\n           Find Anomalies       0.80      0.79      0.80        96\n                  Cluster       0.98      0.46      0.63        99\n                Correlate       0.53      0.75      0.62        81\n\n                micro avg       0.66      0.66      0.66       954\n                macro avg       0.73      0.65      0.66       954\n             weighted avg       0.75      0.66      0.68       954\n\nConfusion Matrix...\n[[23 13 38  1  0  0  1  0  0  0]\n [ 2 58 18  2  0  0  0  5  0  3]\n [ 2  0 51  1  0 10  1  1  0 17]\n [ 0  2 40 50  0  0  0  0  0  0]\n [ 0  2  0  1 92  0  0  0  0  0]\n [ 6  1 25  0  5 89  2  0  1  1]\n [ 0  6 10  1  0  0 85  7  0  5]\n [ 1  1  3  0  0  1  0 76  0 14]\n [ 0  2  7 12 12  1  1  4 46 14]\n [ 0  1 15  0  0  2  0  2  0 61]]\nTime usage: 0:00:02\nFold:  8\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  39.06%, Time: 0:00:09 *\nIter:     60, Train Loss:    1.7, Train Acc:  54.69%, Time: 0:00:14 *\nIter:     90, Train Loss:    1.2, Train Acc:  64.06%, Time: 0:00:23 *\nIter:    120, Train Loss:    1.0, Train Acc:  76.56%, Time: 0:00:31 *\nIter:    150, Train Loss:   0.91, Train Acc:  81.25%, Time: 0:00:36 *\nIter:    180, Train Loss:   0.83, Train Acc:  78.12%, Time: 0:00:37 \nEpoch: 2\nIter:    210, Train Loss:   0.57, Train Acc:  79.69%, Time: 0:00:38 \nIter:    240, Train Loss:   0.54, Train Acc:  84.38%, Time: 0:00:44 *\nIter:    270, Train Loss:   0.49, Train Acc:  82.81%, Time: 0:00:45 \nIter:    300, Train Loss:   0.48, Train Acc:  87.50%, Time: 0:00:50 *\nIter:    330, Train Loss:   0.32, Train Acc:  92.19%, Time: 0:00:55 *\nIter:    360, Train Loss:   0.36, Train Acc:  89.06%, Time: 0:00:56 \nIter:    390, Train Loss:   0.51, Train Acc:  89.06%, Time: 0:00:56 \nEpoch: 3\nIter:    420, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:01:02 *\nIter:    450, Train Loss:   0.13, Train Acc:  95.31%, Time: 0:01:03 \nIter:    480, Train Loss:   0.26, Train Acc:  89.06%, Time: 0:01:04 \nIter:    510, Train Loss:   0.23, Train Acc:  92.19%, Time: 0:01:04 \nIter:    540, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:05 \nIter:    570, Train Loss:  0.084, Train Acc:  98.44%, Time: 0:01:10 *\nIter:    600, Train Loss:   0.24, Train Acc:  90.62%, Time: 0:01:11 \nEpoch: 4\nIter:    630, Train Loss:   0.13, Train Acc:  95.31%, Time: 0:01:11 \nIter:    660, Train Loss:   0.05, Train Acc: 100.00%, Time: 0:01:18 *\nIter:    690, Train Loss:  0.065, Train Acc: 100.00%, Time: 0:01:18 \nIter:    720, Train Loss:  0.061, Train Acc:  98.44%, Time: 0:01:19 \nIter:    750, Train Loss:  0.058, Train Acc: 100.00%, Time: 0:01:20 \nIter:    780, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:20 \nIter:    810, Train Loss:  0.055, Train Acc: 100.00%, Time: 0:01:21 \nEpoch: 5\nIter:    840, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:22 \nIter:    870, Train Loss:  0.031, Train Acc: 100.00%, Time: 0:01:23 \nIter:    900, Train Loss:  0.013, Train Acc: 100.00%, Time: 0:01:23 \nIter:    930, Train Loss:  0.028, Train Acc:  98.44%, Time: 0:01:24 \nIter:    960, Train Loss:  0.068, Train Acc:  98.44%, Time: 0:01:25 \nIter:    990, Train Loss:   0.01, Train Acc: 100.00%, Time: 0:01:25 \nEpoch: 6\nIter:   1020, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:26 \nIter:   1050, Train Loss:  0.058, Train Acc:  98.44%, Time: 0:01:27 \nIter:   1080, Train Loss:  0.042, Train Acc: 100.00%, Time: 0:01:27 \nIter:   1110, Train Loss:  0.011, Train Acc: 100.00%, Time: 0:01:28 \nIter:   1140, Train Loss:  0.056, Train Acc:  96.88%, Time: 0:01:29 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/8/8\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/8/8\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.5, Test Acc:  60.58%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.48      0.23      0.31        96\n                   Filter       0.40      0.60      0.48       120\n    Compute Derived Value       0.65      0.37      0.47       128\n            Find Extremum       0.60      0.89      0.72       128\n                     Sort       0.70      0.74      0.72        86\n          Determine Range       0.50      0.23      0.32        91\nCharacterize Distribution       0.53      0.63      0.57       110\n           Find Anomalies       0.90      0.53      0.67       105\n                  Cluster       0.67      0.90      0.76       105\n                Correlate       0.76      0.86      0.81       109\n\n                micro avg       0.61      0.61      0.61      1078\n                macro avg       0.62      0.60      0.58      1078\n             weighted avg       0.62      0.61      0.59      1078\n\nConfusion Matrix...\n[[ 22  18  10  31   1   2   7   0   2   3]\n [  2  72   4  12  11  13   1   0   4   1]\n [ 12  23  47  10   3   0  23   1   3   6]\n [  0  12   0 114   0   0   0   0   2   0]\n [  1   2   0   2  64   3   1   0  13   0]\n [  8  31   0  14  11  21   3   0   1   2]\n [  1  10   2   3   0   3  69   0   6  16]\n [  0  10   9   3   0   0  20  56   7   0]\n [  0   0   0   1   1   0   6   2  94   1]\n [  0   3   0   0   0   0   0   3   9  94]]\nTime usage: 0:00:02\nFold:  9\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  32.81%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.6, Train Acc:  57.81%, Time: 0:00:15 *\nIter:     90, Train Loss:    1.3, Train Acc:  70.31%, Time: 0:00:21 *\nIter:    120, Train Loss:    1.0, Train Acc:  76.56%, Time: 0:00:27 *\nIter:    150, Train Loss:    1.0, Train Acc:  71.88%, Time: 0:00:28 \nIter:    180, Train Loss:   0.78, Train Acc:  82.81%, Time: 0:00:33 *\nEpoch: 2\nIter:    210, Train Loss:   0.77, Train Acc:  78.12%, Time: 0:00:33 \nIter:    240, Train Loss:   0.58, Train Acc:  81.25%, Time: 0:00:34 \nIter:    270, Train Loss:   0.54, Train Acc:  81.25%, Time: 0:00:35 \nIter:    300, Train Loss:    0.6, Train Acc:  82.81%, Time: 0:00:36 \nIter:    330, Train Loss:    0.5, Train Acc:  87.50%, Time: 0:00:41 *\nIter:    360, Train Loss:   0.36, Train Acc:  92.19%, Time: 0:00:46 *\nIter:    390, Train Loss:   0.22, Train Acc:  96.88%, Time: 0:00:52 *\nEpoch: 3\nIter:    420, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:00:53 \nIter:    450, Train Loss:   0.21, Train Acc:  95.31%, Time: 0:00:54 \nIter:    480, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:00:54 \nIter:    510, Train Loss:   0.33, Train Acc:  89.06%, Time: 0:00:55 \nIter:    540, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:00:56 \nIter:    570, Train Loss:   0.29, Train Acc:  87.50%, Time: 0:00:56 \nIter:    600, Train Loss:   0.11, Train Acc:  95.31%, Time: 0:00:57 \nEpoch: 4\nIter:    630, Train Loss:  0.078, Train Acc: 100.00%, Time: 0:01:02 *\nIter:    660, Train Loss:   0.04, Train Acc: 100.00%, Time: 0:01:03 \nIter:    690, Train Loss:   0.07, Train Acc:  98.44%, Time: 0:01:04 \nIter:    720, Train Loss:    0.1, Train Acc:  95.31%, Time: 0:01:04 \nIter:    750, Train Loss:  0.068, Train Acc:  98.44%, Time: 0:01:05 \nIter:    780, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:06 \nIter:    810, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:06 \nEpoch: 5\nIter:    840, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:07 \nIter:    870, Train Loss:  0.045, Train Acc: 100.00%, Time: 0:01:08 \nIter:    900, Train Loss:  0.028, Train Acc: 100.00%, Time: 0:01:08 \nIter:    930, Train Loss:   0.04, Train Acc:  98.44%, Time: 0:01:09 \nIter:    960, Train Loss:  0.046, Train Acc: 100.00%, Time: 0:01:10 \nIter:    990, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:01:10 \nIter:   1020, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:11 \nEpoch: 6\nIter:   1050, Train Loss:  0.023, Train Acc: 100.00%, Time: 0:01:12 \nIter:   1080, Train Loss:  0.017, Train Acc: 100.00%, Time: 0:01:12 \nIter:   1110, Train Loss: 0.0082, Train Acc: 100.00%, Time: 0:01:13 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/9/9\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/9/9\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  69.85%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.55      0.83      0.66        60\n                   Filter       0.54      0.37      0.44        59\n    Compute Derived Value       0.53      0.77      0.62        64\n            Find Extremum       0.88      0.81      0.85       128\n                     Sort       0.74      0.78      0.76        63\n          Determine Range       0.66      0.48      0.56        85\nCharacterize Distribution       0.93      0.53      0.67        80\n           Find Anomalies       0.48      0.92      0.63        60\n                  Cluster       0.83      0.74      0.78        88\n                Correlate       0.85      0.72      0.78       139\n\n                micro avg       0.70      0.70      0.70       826\n                macro avg       0.70      0.69      0.68       826\n             weighted avg       0.74      0.70      0.70       826\n\nConfusion Matrix...\n[[ 50   1   6   0   0   0   0   2   0   1]\n [ 17  22   5   0   0   5   0  10   0   0]\n [  2   3  49   0   0   0   0   3   0   7]\n [  6   4   3 104   1   6   0   4   0   0]\n [  0   0   0   5  49   3   0   5   1   0]\n [  3   2   8   9  15  41   1   2   3   1]\n [  8   0  12   0   0   4  42   3   7   4]\n [  0   3   1   0   0   0   0  55   0   1]\n [  5   5   1   0   0   0   0   8  65   4]\n [  0   1   8   0   1   3   2  22   2 100]]\nTime usage: 0:00:02\nFold:  10\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.0, Train Acc:  46.88%, Time: 0:00:08 *\nIter:     60, Train Loss:    1.7, Train Acc:  50.00%, Time: 0:00:12 *\nIter:     90, Train Loss:    1.4, Train Acc:  59.38%, Time: 0:00:17 *\nIter:    120, Train Loss:   0.88, Train Acc:  73.44%, Time: 0:00:23 *\nIter:    150, Train Loss:   0.85, Train Acc:  78.12%, Time: 0:00:30 *\nIter:    180, Train Loss:   0.91, Train Acc:  73.44%, Time: 0:00:30 \nEpoch: 2\nIter:    210, Train Loss:    0.6, Train Acc:  79.69%, Time: 0:00:38 *\nIter:    240, Train Loss:   0.54, Train Acc:  87.50%, Time: 0:00:45 *\nIter:    270, Train Loss:   0.63, Train Acc:  78.12%, Time: 0:00:45 \nIter:    300, Train Loss:   0.31, Train Acc:  92.19%, Time: 0:00:51 *\nIter:    330, Train Loss:   0.58, Train Acc:  84.38%, Time: 0:00:52 \nIter:    360, Train Loss:   0.38, Train Acc:  89.06%, Time: 0:00:53 \nIter:    390, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:00:53 \nEpoch: 3\nIter:    420, Train Loss:   0.25, Train Acc:  95.31%, Time: 0:01:00 *\nIter:    450, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:01:00 \nIter:    480, Train Loss:   0.17, Train Acc:  95.31%, Time: 0:01:01 \nIter:    510, Train Loss:    0.1, Train Acc:  95.31%, Time: 0:01:02 \nIter:    540, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:09 *\nIter:    570, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:01:10 \nIter:    600, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:10 \nEpoch: 4\nIter:    630, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:11 \nIter:    660, Train Loss:   0.12, Train Acc:  98.44%, Time: 0:01:12 \nIter:    690, Train Loss:   0.12, Train Acc:  95.31%, Time: 0:01:12 \nIter:    720, Train Loss:   0.13, Train Acc:  95.31%, Time: 0:01:13 \nIter:    750, Train Loss:    0.1, Train Acc:  95.31%, Time: 0:01:14 \nIter:    780, Train Loss:    0.1, Train Acc:  98.44%, Time: 0:01:14 \nIter:    810, Train Loss:  0.065, Train Acc:  98.44%, Time: 0:01:15 \nEpoch: 5\nIter:    840, Train Loss:  0.052, Train Acc: 100.00%, Time: 0:01:21 *\nIter:    870, Train Loss:   0.03, Train Acc: 100.00%, Time: 0:01:21 \nIter:    900, Train Loss:  0.041, Train Acc:  98.44%, Time: 0:01:22 \nIter:    930, Train Loss:  0.047, Train Acc: 100.00%, Time: 0:01:23 \nIter:    960, Train Loss:  0.035, Train Acc: 100.00%, Time: 0:01:23 \nIter:    990, Train Loss:  0.034, Train Acc: 100.00%, Time: 0:01:24 \nIter:   1020, Train Loss:  0.055, Train Acc: 100.00%, Time: 0:01:25 \nEpoch: 6\nIter:   1050, Train Loss:  0.013, Train Acc: 100.00%, Time: 0:01:25 \nIter:   1080, Train Loss:  0.013, Train Acc: 100.00%, Time: 0:01:26 \nIter:   1110, Train Loss:  0.015, Train Acc: 100.00%, Time: 0:01:27 \nIter:   1140, Train Loss:  0.013, Train Acc: 100.00%, Time: 0:01:27 \nIter:   1170, Train Loss:   0.11, Train Acc:  98.44%, Time: 0:01:28 \nIter:   1200, Train Loss:  0.027, Train Acc: 100.00%, Time: 0:01:29 \nIter:   1230, Train Loss:  0.049, Train Acc:  98.44%, Time: 0:01:30 \nEpoch: 7\nIter:   1260, Train Loss: 0.0046, Train Acc: 100.00%, Time: 0:01:30 \nIter:   1290, Train Loss:  0.027, Train Acc: 100.00%, Time: 0:01:31 \nIter:   1320, Train Loss: 0.0069, Train Acc: 100.00%, Time: 0:01:32 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/10/10\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/cnn2/table/10/10\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.3, Test Acc:  64.53%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.46      0.69      0.55        68\n                   Filter       0.52      0.64      0.57        78\n    Compute Derived Value       0.54      0.51      0.52        85\n            Find Extremum       0.83      0.91      0.87        65\n                     Sort       0.89      0.55      0.68        60\n          Determine Range       0.84      0.95      0.89        62\nCharacterize Distribution       0.59      0.75      0.66        63\n           Find Anomalies       0.54      0.40      0.46        62\n                  Cluster       0.79      0.52      0.63        60\n                Correlate       0.78      0.57      0.66        68\n\n                micro avg       0.65      0.65      0.65       671\n                macro avg       0.68      0.65      0.65       671\n             weighted avg       0.67      0.65      0.64       671\n\nConfusion Matrix...\n[[47  2 17  0  0  2  0  0  0  0]\n [15 50  7  1  1  0  1  3  0  0]\n [17  1 43  0  0  5 15  1  3  0]\n [ 3  1  1 59  1  0  0  0  0  0]\n [ 0  1  8  7 33  0  9  1  1  0]\n [ 0  0  1  0  0 59  0  0  0  2]\n [11  0  2  1  0  2 47  0  0  0]\n [ 0 29  0  3  0  1  1 25  0  3]\n [ 7  1  1  0  2  1  6  5 31  6]\n [ 3 11  0  0  0  0  0 11  4 39]]\nTime usage: 0:00:02\n[0.6429663608562691, 0.6341611151259138, 0.6355003650559397, 0.6707410235000622, 0.6842105272618949, 0.6072788825743389, 0.6614255760200869, 0.6057513900280883, 0.6985472165066162, 0.6453055134473366]\n0.6485887970376547 0.028954558606539206 0.03052078461383167 0.0008383664640995136\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "expert_train_acc = []\nexpert_test_acc = []\nsplit_type = \"expert\"\nfold_id = 0\nfor train_i, test_i in kf.split(ex_train):\n    fold_id += 1\n    print(\"Fold: \", fold_id)\n    train_x, train_y = mergeData(ex_train[train_i],ey_train[train_i])\n    test_x, test_y = mergeData(ex_train[test_i],ey_train[test_i])\n    expert_train_acc.append(model.train(train_x, train_y,split_type,fold_id))\n    expert_test_acc.append(model.evaluate_model(test_x, test_y,split_type,fold_id,categories))\n\n\nbundle_train_acc = []\nbundle_test_acc = []\nsplit_type = \"bundle\"\nfold_id = 0\nfor train_i, test_i in kf.split(bx_train):\n    fold_id += 1\n    print(\"Fold: \", fold_id)\n    expert_train_acc.append(model.train(x_train[train_i], y_train[train_i],split_type,fold_id))\n    expert_test_acc.append(model.evaluate_model(x_train[test_i], y_train[test_i],split_type,fold_id,categories))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "np.mean(model_test_acc),np.std(model_test_acc),np.std(model_test_acc,ddof=1),np.var(model_test_acc)", "execution_count": 26, "outputs": [{"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "(0.6393368500847791,\n 0.05406597768875925,\n 0.05699054447344181,\n 0.0029231299434414135)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "raw", "source": "predict_sentences = [\"In the sixtieth ceremony , where were all of the winners from ?\",  #  7\n                    \"On how many devices has the app \\\" CF SHPOP ! \\\" been installed ?\",  # 1\n                    \"List center - backs by what their transfer _ fee was .\"]  # 5\npredict(predict_sentences, word_to_id, seq_length)"}], "metadata": {"kernelspec": {"name": "tensorflow-1.8", "display_name": "TensorFlow-1.8", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}