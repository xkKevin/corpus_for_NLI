{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "from collections import Counter\nimport numpy as np\nimport tensorflow.contrib.keras as kr\nimport tensorflow as tf\nimport time\nfrom datetime import timedelta\nimport os\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\n\nimport moxing as mox\nmox.file.shift('os', 'mox')", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "INFO:root:Using MoXing-v1.14.1-ddfd6c9a\nINFO:root:Using OBS-Python-SDK-3.1.2\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "trainDataPath = \"s3://corpus-2/dataset/corpus_5.txt\"\nvocabPath = \"s3://corpus-text-classification1/data/glove.6B.100d.txt\"\nsavePath = \"s3://corpus-2/model/ShinContextual\"", "execution_count": 2, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def loadGloVe(filename, emb_size=50):\n    vocab = []\n    embd = []\n    print('Loading GloVe!')\n    # vocab.append('unk') #\u88c5\u8f7d\u4e0d\u8ba4\u8bc6\u7684\u8bcd\n    # embd.append([0] * emb_size) #\u8fd9\u4e2aemb_size\u53ef\u80fd\u9700\u8981\u6307\u5b9a\n    file = open(filename,'r',encoding='utf-8')\n    for line in file.readlines():\n        row = line.strip().split(' ')\n        vocab.append(row[0])\n        embd.append([float(ei) for ei in row[1:]])\n    file.close()\n    print('Completed!')\n    return vocab,embd\n\n\nsplit_info = {\n    \"random\": False,\n    \"expert\": [20, 4],\n    \"bundle\": [920, 1],\n    \"table\": [37, 3]\n}\n\n\ndef dataset_split(info):\n    if info:\n        [num, pi] = info\n        train_data = [[] for i in range(num)]\n        with open(trainDataPath, \"r\", encoding='utf-8') as fp:\n            for line in fp.readlines():\n                word = line.split()\n                info = word[0].split(\":\")\n                index = int(info[pi]) - 1\n                label = int(info[0])\n                content = word[1:]\n                train_data[index].append([content,label])\n\n        for i in range(num):\n            np.random.shuffle(train_data[i])\n            train_data[i] = np.asarray(train_data[i])\n\n        np.random.shuffle(train_data)   \n        return train_data\n    \n    \n    train_data = []\n    with open(trainDataPath, 'r', encoding='utf-8') as f:\n        for line in f.readlines():\n            word = line.split()\n            label = int(word[0].split(\":\")[0])\n            content = word[1:]\n            train_data.append([content,label])\n    \n    np.random.shuffle(train_data)\n    return np.asarray(train_data)\n\n\ndef mergeData(data_x, data_y):\n    merge_x = data_x[0]\n    merge_y = data_y[0]\n    for i in range(1,len(data_x)):\n        merge_x = np.r_[merge_x,data_x[i]]\n        merge_y = np.r_[merge_y,data_y[i]]\n        \n    return merge_x, merge_y\n\n\ndef train_split_data(train_data, split_type):\n    \n    print(split_type)\n    \n    train_acc = []\n    test_acc = []\n    fold_id = 0\n    \n    if split_type != \"random\":\n        tx = []\n        ty = []\n        for ti in train_data:\n            x_train, y_train = process_file(ti[:,0], ti[:,1], word_to_id, num_classes, seq_length)\n            tx.append(x_train)\n            ty.append(y_train)\n\n        tx = np.asarray(tx)\n        ty = np.asarray(ty)\n\n        print(len(tx),len(tx[0]),len(tx[1]),len(tx[0][0]))\n        \n        for train_i, test_i in kf.split(tx):\n            fold_id += 1\n            print(\"Fold: \", fold_id)\n            train_x, train_y = mergeData(tx[train_i],ty[train_i])\n            test_x, test_y = mergeData(tx[test_i],ty[test_i])\n            train_acc.append(model_train(train_x, train_y,split_type,fold_id))\n            test_acc.append(model_evaluate(test_x, test_y,split_type,fold_id,categories))\n        \n    else:\n        tx, ty = process_file(train_data[:,0], train_data[:,1], word_to_id, num_classes, seq_length)\n        print(len(tx),len(tx[0]),len(tx[1]))\n\n        for train_i, test_i in kf.split(tx):\n            fold_id += 1\n            print(\"Fold: \", fold_id)\n            train_acc.append(model_train(tx[train_i], ty[train_i],split_type,fold_id))\n            test_acc.append(model_evaluate(tx[test_i], ty[test_i],split_type,fold_id,categories))\n        \n    print(test_acc)\n    print(\"%s, %s, %s, %s\" % (np.mean(test_acc),np.std(test_acc),np.std(test_acc,ddof=1),np.var(test_acc)))\n    return test_acc", "execution_count": 3, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "class ShinContextualModel:\n    '''\n    Implementation proposal of: http://milab.snu.ac.kr/pub/BigComp2018.pdf\n    '''\n    def __init__(self, embedding, drop_rate=0.75, conv_size=3, num_layers=2):\n        '''Constructor.\n        # Parameters:\n        embedding: numpy array representing the embedding.\n        conv_size: Size of the convolutions. Number of words that takes each\n            convolution step.\n        num_layers: Number of recurrent convolutions.\n        '''\n        self._embedding = embedding\n        self._conv_size = conv_size\n        self._num_layers = num_layers\n        self.drop_rate = drop_rate\n\n    def __call__(self, input):\n        self._embedding_tf = self._create_embedding_layer(\n            self._embedding, input)\n        self._convolution_tf = self._create_convolutional_layers(\n            self._conv_size, self._num_layers, self._embedding_tf)\n        self._pooling_tf = self._create_maxpooling_layer(self._convolution_tf)\n\n        return self._pooling_tf\n\n    def summary(self):\n        print('embedding:', str(self._embedding_tf.shape))\n        print('conv:', str(self._convolution_tf.shape))\n        print('pool:', str(self._pooling_tf.shape))\n\n    def _create_embedding_layer(self, embedding, input_x):\n        embedding = tf.Variable(initial_value=embedding)\n\n        embedded_chars = tf.nn.embedding_lookup(\n            embedding, tf.cast(input_x, 'int32'))\n\n        return embedded_chars\n\n    def _create_convolutional_layers(self, conv_size, num_layers, embedding):\n        filter_height = conv_size\n        filter_width = embedding.shape[2].value\n\n        filter_shape = [filter_height, filter_width, filter_width]\n\n        W = tf.Variable(\n            initial_value=tf.truncated_normal(\n                shape=filter_shape,\n                stddev=0.1))\n        b = tf.Variable(\n            initial_value=tf.truncated_normal(\n                shape=[filter_width]))\n\n        z = embedding\n        for _ in range(num_layers):\n            conv = tf.nn.conv1d(\n                value=z,\n                filters=W,\n                stride=1,\n                padding='SAME')\n            bias = tf.nn.bias_add(conv, b)\n            c = tf.nn.relu(bias)\n\n            d = tf.nn.dropout(c, self.drop_rate)\n            # Add BatchNormalization or LocalResponseNormalization\n            e = tf.expand_dims(d, 1)\n\n            z = tf.nn.local_response_normalization(\n                e,\n                depth_radius=5,\n                bias=1,\n                alpha=0.001,\n                beta=0.75\n            )\n            z = tf.squeeze(z, 1)\n        # endfor\n        return z\n\n    def _create_maxpooling_layer(self, convolution):\n        conv_size = convolution.shape[1].value\n        embedding_size = convolution.shape[2].value\n\n        convolution = tf.expand_dims(convolution, -1)\n        pooled = tf.nn.max_pool(\n            value=convolution,\n            ksize=[1, conv_size, 1, 1],\n            strides=[1, 1, 1, 1],\n            padding='VALID')\n\n        flat = tf.reshape(pooled, [-1, embedding_size])\n        return flat", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "categories = ['Retrieve Value', 'Filter', 'Compute Derived Value', 'Find Extremum', 'Sort', \n                  'Determine Range', 'Characterize Distribution', 'Find Anomalies', 'Cluster', 'Correlate']\nnum_classes = len(categories)", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "raw", "source": "contents_all = contents_train + contents_dev + contents_test\nseq_length = 0\nfor content in contents_all:\n    if seq_length < len(content):\n        seq_length = len(content)   # seq_length = 35"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "seq_length = 41", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "vocab, embd = loadGloVe(vocabPath, 100)\nvocab_size = len(vocab)\nembedding_dim = len(embd[0])\n# embedding = np.asarray(embd)\nembedding = embd", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Loading GloVe!\nCompleted!\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "word_to_id = dict(zip(vocab, range(vocab_size)))\nlen(embedding),embedding_dim,vocab_size", "execution_count": 8, "outputs": [{"output_type": "execute_result", "execution_count": 8, "data": {"text/plain": "(400000, 100, 400000)"}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def process_file(contents, labels, word_to_id, num_classes, pad_max_length):\n    \"\"\"\n    \u5c06\u6587\u4ef6\u8f6c\u6362\u4e3aid\u8868\u793a,\u5e76\u4e14\u5c06\u6bcf\u4e2a\u5355\u72ec\u7684\u6837\u672c\u957f\u5ea6\u56fa\u5b9a\u4e3apad_max_lengtn\n    \"\"\"\n    # contents, labels = readfile(filePath)\n    data_id, label_id = [], []\n    # \u5c06\u6587\u672c\u5185\u5bb9\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684id\u5f62\u5f0f\n    for i in range(len(contents)):\n        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])\n        label_id.append(labels[i] - 1)\n    # \u4f7f\u7528keras\u63d0\u4f9b\u7684pad_sequences\u6765\u5c06\u6587\u672cpad\u4e3a\u56fa\u5b9a\u957f\u5ea6\n    x_pad = kr.preprocessing.sequence.pad_sequences(data_id, pad_max_length)\n    ''' https://blog.csdn.net/TH_NUM/article/details/80904900\n    pad_sequences(sequences, maxlen=None, dtype=\u2019int32\u2019, padding=\u2019pre\u2019, truncating=\u2019pre\u2019, value=0.) \n        sequences\uff1a\u6d6e\u70b9\u6570\u6216\u6574\u6570\u6784\u6210\u7684\u4e24\u5c42\u5d4c\u5957\u5217\u8868\n        maxlen\uff1aNone\u6216\u6574\u6570\uff0c\u4e3a\u5e8f\u5217\u7684\u6700\u5927\u957f\u5ea6\u3002\u5927\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u88ab\u622a\u77ed\uff0c\u5c0f\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u5728\u540e\u90e8\u586b0.\n        dtype\uff1a\u8fd4\u56de\u7684numpy array\u7684\u6570\u636e\u7c7b\u578b\n        padding\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u88650\u65f6\uff0c\u5728\u5e8f\u5217\u7684\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u8865\n        truncating\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u622a\u65ad\u5e8f\u5217\u65f6\uff0c\u4ece\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u622a\u65ad\n        value\uff1a\u6d6e\u70b9\u6570\uff0c\u6b64\u503c\u5c06\u5728\u586b\u5145\u65f6\u4ee3\u66ff\u9ed8\u8ba4\u7684\u586b\u5145\u503c0\n    '''\n    y_pad = kr.utils.to_categorical(label_id, num_classes=num_classes)  # \u5c06\u6807\u7b7e\u8f6c\u6362\u4e3aone-hot\u8868\u793a\n    ''' https://blog.csdn.net/nima1994/article/details/82468965\n    to_categorical(y, num_classes=None, dtype='float32')\n        \u5c06\u6574\u578b\u6807\u7b7e\u8f6c\u4e3aonehot\u3002y\u4e3aint\u6570\u7ec4\uff0cnum_classes\u4e3a\u6807\u7b7e\u7c7b\u522b\u603b\u6570\uff0c\u5927\u4e8emax(y)\uff08\u6807\u7b7e\u4ece0\u5f00\u59cb\u7684\uff09\u3002\n        \u8fd4\u56de\uff1a\u5982\u679cnum_classes=None\uff0c\u8fd4\u56delen(y) * [max(y)+1]\uff08\u7ef4\u5ea6\uff0cm*n\u8868\u793am\u884cn\u5217\u77e9\u9635\uff0c\u4e0b\u540c\uff09\uff0c\u5426\u5219\u4e3alen(y) * num_classes\u3002\n    '''\n    return x_pad, y_pad\n\n\ndef get_time_dif(start_time):\n    \"\"\"\u83b7\u53d6\u5df2\u4f7f\u7528\u65f6\u95f4\"\"\"\n    end_time = time.time()\n    time_dif = end_time - start_time\n    return timedelta(seconds=int(round(time_dif)))", "execution_count": 9, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "learning_rate = 1e-3\ndropout_keep_prob = 0.75\n\n# \u8f93\u5165\u5185\u5bb9\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\ninput_x = tf.placeholder(tf.int32, [None, seq_length], name='input_x')\ninput_y = tf.placeholder(tf.float32, [None, num_classes], name='input_y')\nkeep_prob = tf.placeholder(tf.float32, name='keep_prob')\n\nmodel = ShinContextualModel(embedding, drop_rate = keep_prob)\nfc = model(input_x)\nmodel.summary()\n\n# \u5206\u7c7b\u5668\nlogits = tf.layers.dense(fc, num_classes, name='fc2')\ny_pred_cls = tf.argmax(tf.nn.softmax(logits), 1)  # \u9884\u6d4b\u7c7b\u522b tf.argmax\uff1a\u8fd4\u56de\u6bcf\u4e00\u884c\u6216\u6bcf\u4e00\u5217\u7684\u6700\u5927\u503c 1\u4e3a\u91cc\u9762\uff08\u6bcf\u4e00\u884c\uff09\uff0c0\u4e3a\u5916\u9762\uff08\u6bcf\u4e00\u5217\uff09\n\n# \u635f\u5931\u51fd\u6570\uff0c\u4ea4\u53c9\u71b5\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=input_y)\nloss = tf.reduce_mean(cross_entropy)\n# \u4f18\u5316\u5668\noptim = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n\n# \u51c6\u786e\u7387\ncorrect_pred = tf.equal(tf.argmax(input_y, 1), y_pred_cls)\nacc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n\nsaver = tf.train.Saver()", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "embedding: (?, 41, 100)\nconv: (?, 41, 100)\npool: (?, 100)\nWARNING:tensorflow:From <ipython-input-10-0d99b152369b>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n\n", "name": "stdout"}, {"output_type": "stream", "text": "WARNING:tensorflow:From <ipython-input-10-0d99b152369b>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def batch_iter(x_pad, y_pad, batch_size):\n    \"\"\"\u751f\u6210\u6279\u6b21\u6570\u636e\"\"\"\n    data_len = len(x_pad)\n    num_batch = int((data_len - 1) / batch_size) + 1\n    # np.arange()\u751f\u62100\u5230data_len\u7684\u7b49\u5dee\u6570\u5217\uff0c\u9ed8\u8ba4\u7b49\u5dee\u4e3a1\uff1bnp.random.permutation()\u6253\u4e71\u751f\u6210\u7684\u7b49\u5dee\u5e8f\u5217\u7684\u987a\u5e8f\n    # \u4e0b\u9762\u4e09\u53e5\u8bed\u53e5\u662f\u4e3a\u4e86\u5c06\u8bad\u7ec3\u6216\u6d4b\u8bd5\u6587\u672c\u7684\u987a\u5e8f\u6253\u4e71\uff0c\u56e0\u4e3a\u539f\u6587\u672c\u4e2d\u6bcf\u4e2a\u5206\u7c7b\u7684\u6837\u672c\u5168\u90e8\u6328\u5728\u4e00\u8d77\uff0c\u8fd9\u6837\u6bcf\u4e2abatch\u8bad\u7ec3\u7684\u90fd\u662f\u540c\u4e00\u4e2a\u5206\u7c7b\uff0c\u4e0d\u592a\u597d\uff0c\u6253\u4e71\u540e\u6bcf\u4e2abatch\u53ef\u5305\u542b\u4e0d\u540c\u5206\u7c7b\n    indices = np.random.permutation(np.arange(data_len))\n    x_shuffle = x_pad[indices]\n    y_shuffle = y_pad[indices]\n\n    # \u8fd4\u56de\u6240\u6709batch\u7684\u6570\u636e\n    for i in range(num_batch):\n        start_id = i * batch_size\n        end_id = min((i + 1) * batch_size, data_len)\n        yield x_shuffle[start_id:end_id], y_shuffle[start_id:end_id]\n        \n        \ndef evaluate(sess, x_pad, y_pad, loss1, acc1, batch_size):\n    \"\"\"\u8bc4\u4f30\u5728\u67d0\u4e00\u6570\u636e\u4e0a\u7684\u51c6\u786e\u7387\u548c\u635f\u5931\"\"\"\n    data_len = len(x_pad)\n    batch_eval = batch_iter(x_pad, y_pad, batch_size)  # 128\n    total_loss = 0.0\n    total_acc = 0.0\n    for x_batch1, y_batch1 in batch_eval:\n        batch_len = len(x_batch1)\n        feed_dict1 = {input_x: x_batch1, input_y: y_batch1, keep_prob: 1.0}\n        lossTmp, accTmp = sess.run([loss1, acc1], feed_dict=feed_dict1)\n        total_loss += lossTmp * batch_len\n        total_acc += accTmp * batch_len\n\n    return total_loss / data_len, total_acc / data_len\n\n\ndef model_train(x_train, y_train, split_type, fold_id):\n    \n    save_path = \"%s/%s/%s/%s\" % (savePath, split_type, fold_id, fold_id)\n    # \u521b\u5efasession\n    session = tf.Session()\n    session.run(tf.global_variables_initializer())\n\n    print('Training and evaluating...')\n    start_time = time.time()\n    total_batch = 0  # \u603b\u6279\u6b21\n    best_acc_train = 0.0  # \u6700\u4f73\u9a8c\u8bc1\u96c6\u51c6\u786e\u7387\n    last_improved = 0  # \u8bb0\u5f55\u4e0a\u4e00\u6b21\u63d0\u5347\u6279\u6b21\n    num_epochs = 50\n    batch_size = 32\n    require_improvement = 500  # \u5982\u679c\u8d85\u8fc71000\u8f6e\u672a\u63d0\u5347\uff0c\u63d0\u524d\u7ed3\u675f\u8bad\u7ec3\n    print_per_batch = 30  # \u6bcf\u591a\u5c11\u8f6e\u8f93\u51fa\u4e00\u6b21\u7ed3\u679c\n    flag = False\n\n    for epoch in range(num_epochs):  # 20\n        print('Epoch:', epoch + 1)\n        batch_train = batch_iter(x_train, y_train, batch_size)\n        for x_batch, y_batch in batch_train:\n            feed_dict = {input_x: x_batch, input_y: y_batch, keep_prob: dropout_keep_prob}\n            session.run(optim, feed_dict=feed_dict)  # \u8fd0\u884c\u4f18\u5316\n            total_batch += 1\n\n            if total_batch % print_per_batch == 0:\n                # \u6bcf\u591a\u5c11\u8f6e\u6b21\u8f93\u51fa\u5728\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6027\u80fd\n                feed_dict[keep_prob] = 1.0\n                loss_train, acc_train = session.run([loss, acc], feed_dict=feed_dict)\n                # loss_val, acc_val = evaluate(session, x_dev, y_dev, loss, acc)\n                if acc_train > best_acc_train:\n                    # \u4fdd\u5b58\u6700\u597d\u7ed3\u679c\n                    best_acc_train = acc_train\n                    last_improved = total_batch\n                    saver.save(sess=session, save_path=save_path)\n                    improved_str = '*'\n                else:\n                    improved_str = ''\n\n                time_dif = get_time_dif(start_time)\n                msg = 'Iter: {0:>6}, Train Loss: {1:>6.2}, Train Acc: {2:>7.2%}, Time: {3} {4}'\n                print(msg.format(total_batch, loss_train, acc_train, time_dif, improved_str))\n\n            if total_batch - last_improved > require_improvement:\n                # \u9a8c\u8bc1\u96c6\u6b63\u786e\u7387\u957f\u671f\u4e0d\u63d0\u5347\uff0c\u63d0\u524d\u7ed3\u675f\u8bad\u7ec3\n                print(\"No optimization for a long time, auto-stopping...\")\n                flag = True\n                break  # \u8df3\u51fa\u5faa\u73af\n        if flag:  # \u540c\u4e0a\n            break\n\n    session.close()\n    return best_acc_train\n\n\ndef model_evaluate(x_test, y_test, split_type, fold_id, categories, batch_size=32):\n        \n    save_path = \"%s/%s/%s/%s\" % (savePath, split_type, fold_id, fold_id)\n    # \u8bfb\u53d6\u4fdd\u5b58\u7684\u6a21\u578b\n    session = tf.Session()\n    saver.restore(sess=session, save_path=save_path)\n    start_time = time.time()\n    print('Testing...')\n    loss_test, acc_test = evaluate(session, x_test, y_test, loss, acc, batch_size)\n    msg = 'Test Loss: {0:>6.2}, Test Acc: {1:>7.2%}'\n    print(msg.format(loss_test, acc_test))\n\n    test_data_len = len(x_test)\n    test_num_batch = int((test_data_len - 1) / batch_size) + 1\n\n    y_test_cls = np.argmax(y_test, 1)  # \u83b7\u5f97\u7c7b\u522b\n    y_test_pred_cls = np.zeros(shape=len(x_test), dtype=np.int32)  # \u4fdd\u5b58\u9884\u6d4b\u7ed3\u679c  len(x_test) \u8868\u793a\u6709\u591a\u5c11\u4e2a\u6587\u672c\n\n    for i in range(test_num_batch):  # \u9010\u6279\u6b21\u5904\u7406\n        start_id = i * batch_size\n        end_id = min((i + 1) * batch_size, test_data_len)\n        feed_dict = {\n            input_x: x_test[start_id:end_id],\n            keep_prob: 1.0\n        }\n        y_test_pred_cls[start_id:end_id] = session.run(y_pred_cls, feed_dict=feed_dict)\n\n    # \u8bc4\u4f30\n    print(\"Precision, Recall and F1-Score...\")\n    print(metrics.classification_report(y_test_cls, y_test_pred_cls, target_names=categories))\n    '''\n    sklearn\u4e2d\u7684classification_report\u51fd\u6570\u7528\u4e8e\u663e\u793a\u4e3b\u8981\u5206\u7c7b\u6307\u6807\u7684\u6587\u672c\u62a5\u544a\uff0e\u5728\u62a5\u544a\u4e2d\u663e\u793a\u6bcf\u4e2a\u7c7b\u7684\u7cbe\u786e\u5ea6\uff0c\u53ec\u56de\u7387\uff0cF1\u503c\u7b49\u4fe1\u606f\u3002\n        y_true\uff1a1\u7ef4\u6570\u7ec4\uff0c\u6216\u6807\u7b7e\u6307\u793a\u5668\u6570\u7ec4/\u7a00\u758f\u77e9\u9635\uff0c\u76ee\u6807\u503c\u3002 \n        y_pred\uff1a1\u7ef4\u6570\u7ec4\uff0c\u6216\u6807\u7b7e\u6307\u793a\u5668\u6570\u7ec4/\u7a00\u758f\u77e9\u9635\uff0c\u5206\u7c7b\u5668\u8fd4\u56de\u7684\u4f30\u8ba1\u503c\u3002 \n        labels\uff1aarray\uff0cshape = [n_labels]\uff0c\u62a5\u8868\u4e2d\u5305\u542b\u7684\u6807\u7b7e\u7d22\u5f15\u7684\u53ef\u9009\u5217\u8868\u3002 \n        target_names\uff1a\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u4e0e\u6807\u7b7e\u5339\u914d\u7684\u53ef\u9009\u663e\u793a\u540d\u79f0\uff08\u76f8\u540c\u987a\u5e8f\uff09\u3002 \n        \u539f\u6587\u94fe\u63a5\uff1ahttps://blog.csdn.net/akadiao/article/details/78788864\n    '''\n\n    # \u6df7\u6dc6\u77e9\u9635\n    print(\"Confusion Matrix...\")\n    cm = metrics.confusion_matrix(y_test_cls, y_test_pred_cls)\n    '''\n    \u6df7\u6dc6\u77e9\u9635\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u603b\u7ed3\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u60c5\u5f62\u5206\u6790\u8868\uff0c\u4ee5\u77e9\u9635\u5f62\u5f0f\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u8bb0\u5f55\u6309\u7167\u771f\u5b9e\u7684\u7c7b\u522b\u4e0e\u5206\u7c7b\u6a21\u578b\u4f5c\u51fa\u7684\u5206\u7c7b\u5224\u65ad\u4e24\u4e2a\u6807\u51c6\u8fdb\u884c\u6c47\u603b\u3002\n    \u8fd9\u4e2a\u540d\u5b57\u6765\u6e90\u4e8e\u5b83\u53ef\u4ee5\u975e\u5e38\u5bb9\u6613\u7684\u8868\u660e\u591a\u4e2a\u7c7b\u522b\u662f\u5426\u6709\u6df7\u6dc6\uff08\u4e5f\u5c31\u662f\u4e00\u4e2aclass\u88ab\u9884\u6d4b\u6210\u53e6\u4e00\u4e2aclass\uff09\n    https://blog.csdn.net/u011734144/article/details/80277225\n    '''\n    print(cm)\n\n    time_dif = get_time_dif(start_time)\n    print(\"Time usage:\", time_dif)\n    session.close()\n\n    return acc_test", "execution_count": 11, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "kf = KFold(n_splits=10)\ntest_acc_split = []\nfor split_type,info in split_info.items():\n    train_data = dataset_split(info)\n    test_acc_split.append(train_split_data(train_data, split_type))", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "random\n14035 41 41\nFold:  1\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  15.62%, Time: 0:00:15 *\nIter:     60, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:25 *\nIter:     90, Train Loss:    2.1, Train Acc:  21.88%, Time: 0:00:25 \nIter:    120, Train Loss:    2.0, Train Acc:  40.62%, Time: 0:00:35 *\nIter:    150, Train Loss:    1.9, Train Acc:  43.75%, Time: 0:00:46 *\nIter:    180, Train Loss:    1.9, Train Acc:  40.62%, Time: 0:00:46 \nIter:    210, Train Loss:    1.7, Train Acc:  43.75%, Time: 0:00:46 \nIter:    240, Train Loss:    1.4, Train Acc:  59.38%, Time: 0:00:56 *\nIter:    270, Train Loss:    1.3, Train Acc:  75.00%, Time: 0:01:06 *\nIter:    300, Train Loss:    1.3, Train Acc:  59.38%, Time: 0:01:06 \nIter:    330, Train Loss:    1.0, Train Acc:  78.12%, Time: 0:01:15 *\nIter:    360, Train Loss:    1.1, Train Acc:  59.38%, Time: 0:01:15 \nIter:    390, Train Loss:   0.88, Train Acc:  87.50%, Time: 0:01:25 *\nEpoch: 2\nIter:    420, Train Loss:   0.72, Train Acc:  81.25%, Time: 0:01:25 \nIter:    450, Train Loss:    1.0, Train Acc:  62.50%, Time: 0:01:25 \nIter:    480, Train Loss:   0.81, Train Acc:  71.88%, Time: 0:01:26 \nIter:    510, Train Loss:   0.65, Train Acc:  81.25%, Time: 0:01:26 \nIter:    540, Train Loss:   0.94, Train Acc:  78.12%, Time: 0:01:26 \nIter:    570, Train Loss:   0.48, Train Acc:  87.50%, Time: 0:01:26 \nIter:    600, Train Loss:   0.82, Train Acc:  81.25%, Time: 0:01:27 \nIter:    630, Train Loss:   0.54, Train Acc:  90.62%, Time: 0:01:36 *\nIter:    660, Train Loss:   0.55, Train Acc:  87.50%, Time: 0:01:37 \nIter:    690, Train Loss:   0.68, Train Acc:  81.25%, Time: 0:01:37 \nIter:    720, Train Loss:   0.47, Train Acc:  93.75%, Time: 0:01:46 *\nIter:    750, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:01:46 \nIter:    780, Train Loss:   0.67, Train Acc:  81.25%, Time: 0:01:47 \nEpoch: 3\nIter:    810, Train Loss:   0.44, Train Acc:  87.50%, Time: 0:01:47 \nIter:    840, Train Loss:    0.4, Train Acc:  90.62%, Time: 0:01:47 \nIter:    870, Train Loss:   0.51, Train Acc:  81.25%, Time: 0:01:47 \nIter:    900, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:01:48 \nIter:    930, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:48 \nIter:    960, Train Loss:   0.39, Train Acc:  90.62%, Time: 0:01:48 \nIter:    990, Train Loss:   0.41, Train Acc:  93.75%, Time: 0:01:49 \nIter:   1020, Train Loss:   0.29, Train Acc:  90.62%, Time: 0:01:49 \nIter:   1050, Train Loss:    0.3, Train Acc:  90.62%, Time: 0:01:49 \nIter:   1080, Train Loss:   0.15, Train Acc: 100.00%, Time: 0:01:56 *\nIter:   1110, Train Loss:   0.41, Train Acc:  84.38%, Time: 0:01:56 \nIter:   1140, Train Loss:    0.3, Train Acc:  87.50%, Time: 0:01:56 \nIter:   1170, Train Loss:   0.52, Train Acc:  84.38%, Time: 0:01:57 \nEpoch: 4\nIter:   1200, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:01:57 \nIter:   1230, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:57 \nIter:   1260, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:58 \nIter:   1290, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:58 \nIter:   1320, Train Loss:    0.3, Train Acc:  90.62%, Time: 0:01:58 \nIter:   1350, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:58 \nIter:   1380, Train Loss:    0.2, Train Acc: 100.00%, Time: 0:01:59 \nIter:   1410, Train Loss:   0.26, Train Acc:  96.88%, Time: 0:01:59 \nIter:   1440, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:59 \nIter:   1470, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:01:59 \nIter:   1500, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:02:00 \nIter:   1530, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:02:00 \nIter:   1560, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:02:00 \nEpoch: 5\nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/1/1\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/1/1\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.43, Test Acc:  87.32%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.84      0.95      0.89       142\n                   Filter       0.76      0.88      0.82       143\n    Compute Derived Value       0.81      0.80      0.81       142\n            Find Extremum       0.95      0.85      0.90       157\n                     Sort       0.93      0.90      0.92       110\n          Determine Range       0.88      0.83      0.85       135\nCharacterize Distribution       0.90      0.87      0.88       139\n           Find Anomalies       0.89      0.84      0.87       126\n                  Cluster       0.86      0.91      0.88       131\n                Correlate       0.94      0.90      0.92       179\n\n                micro avg       0.87      0.87      0.87      1404\n                macro avg       0.88      0.87      0.87      1404\n             weighted avg       0.88      0.87      0.87      1404\n\nConfusion Matrix...\n[[135   0   4   1   1   1   0   0   0   0]\n [  4 126   9   1   1   0   0   0   2   0]\n [  5   7 114   2   1   5   3   1   0   4]\n [  5   7   2 133   2   1   5   1   0   1]\n [  0   2   0   1  99   1   0   1   6   0]\n [  5   9   3   0   1 112   1   1   2   1]\n [  1   2   2   2   0   6 121   0   4   1]\n [  2   8   2   0   0   1   2 106   3   2]\n [  1   4   1   0   1   0   1   2 119   2]\n [  2   0   3   0   0   1   2   7   3 161]]\nTime usage: 0:00:00\nFold:  2\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  12.50%, Time: 0:00:07 *\nIter:     60, Train Loss:    2.1, Train Acc:  18.75%, Time: 0:00:16 *\nIter:     90, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:25 *\nIter:    120, Train Loss:    1.8, Train Acc:  34.38%, Time: 0:00:26 \nIter:    150, Train Loss:    1.9, Train Acc:  31.25%, Time: 0:00:26 \nIter:    180, Train Loss:    1.6, Train Acc:  62.50%, Time: 0:00:36 *\nIter:    210, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:36 \nIter:    240, Train Loss:    1.7, Train Acc:  46.88%, Time: 0:00:36 \nIter:    270, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:46 *\nIter:    300, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:00:46 \nIter:    330, Train Loss:    1.2, Train Acc:  68.75%, Time: 0:00:55 *\nIter:    360, Train Loss:    1.3, Train Acc:  59.38%, Time: 0:00:56 \nIter:    390, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:56 \nEpoch: 2\nIter:    420, Train Loss:   0.97, Train Acc:  84.38%, Time: 0:01:04 *\nIter:    450, Train Loss:   0.79, Train Acc:  75.00%, Time: 0:01:04 \nIter:    480, Train Loss:   0.73, Train Acc:  81.25%, Time: 0:01:04 \nIter:    510, Train Loss:   0.83, Train Acc:  71.88%, Time: 0:01:04 \nIter:    540, Train Loss:   0.58, Train Acc:  87.50%, Time: 0:01:14 *\nIter:    570, Train Loss:   0.86, Train Acc:  78.12%, Time: 0:01:15 \nIter:    600, Train Loss:   0.58, Train Acc:  87.50%, Time: 0:01:15 \nIter:    630, Train Loss:   0.67, Train Acc:  90.62%, Time: 0:01:21 *\nIter:    660, Train Loss:   0.69, Train Acc:  78.12%, Time: 0:01:21 \nIter:    690, Train Loss:   0.56, Train Acc:  87.50%, Time: 0:01:22 \nIter:    720, Train Loss:   0.44, Train Acc:  87.50%, Time: 0:01:22 \nIter:    750, Train Loss:   0.82, Train Acc:  84.38%, Time: 0:01:22 \nIter:    780, Train Loss:    0.5, Train Acc:  81.25%, Time: 0:01:23 \nEpoch: 3\nIter:    810, Train Loss:   0.39, Train Acc:  90.62%, Time: 0:01:23 \nIter:    840, Train Loss:    0.4, Train Acc:  90.62%, Time: 0:01:23 \nIter:    870, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:01:23 \nIter:    900, Train Loss:   0.25, Train Acc:  96.88%, Time: 0:01:30 *\nIter:    930, Train Loss:   0.43, Train Acc:  87.50%, Time: 0:01:30 \nIter:    960, Train Loss:    0.3, Train Acc:  90.62%, Time: 0:01:30 \nIter:    990, Train Loss:   0.62, Train Acc:  84.38%, Time: 0:01:31 \nIter:   1020, Train Loss:   0.36, Train Acc:  93.75%, Time: 0:01:31 \nIter:   1050, Train Loss:   0.49, Train Acc:  87.50%, Time: 0:01:31 \nIter:   1080, Train Loss:    0.4, Train Acc:  90.62%, Time: 0:01:31 \nIter:   1110, Train Loss:   0.26, Train Acc:  96.88%, Time: 0:01:32 \nIter:   1140, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:01:32 \nIter:   1170, Train Loss:   0.39, Train Acc:  84.38%, Time: 0:01:32 \nEpoch: 4\nIter:   1200, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:01:32 \nIter:   1230, Train Loss:   0.46, Train Acc:  87.50%, Time: 0:01:33 \nIter:   1260, Train Loss:   0.37, Train Acc:  87.50%, Time: 0:01:33 \nIter:   1290, Train Loss:   0.41, Train Acc:  96.88%, Time: 0:01:33 \nIter:   1320, Train Loss:   0.12, Train Acc: 100.00%, Time: 0:01:42 *\nIter:   1350, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:42 \nIter:   1380, Train Loss:   0.38, Train Acc:  87.50%, Time: 0:01:42 \nIter:   1410, Train Loss:   0.37, Train Acc:  81.25%, Time: 0:01:43 \nIter:   1440, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:43 \nIter:   1470, Train Loss:   0.15, Train Acc: 100.00%, Time: 0:01:43 \nIter:   1500, Train Loss:   0.34, Train Acc:  87.50%, Time: 0:01:44 \nIter:   1530, Train Loss:   0.15, Train Acc:  93.75%, Time: 0:01:44 \nIter:   1560, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:01:44 \nEpoch: 5\nIter:   1590, Train Loss:  0.064, Train Acc: 100.00%, Time: 0:01:44 \nIter:   1620, Train Loss:  0.083, Train Acc: 100.00%, Time: 0:01:45 \nIter:   1650, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:45 \nIter:   1680, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:45 \nIter:   1710, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:45 \nIter:   1740, Train Loss:  0.079, Train Acc: 100.00%, Time: 0:01:46 \nIter:   1770, Train Loss:   0.27, Train Acc:  90.62%, Time: 0:01:46 \nIter:   1800, Train Loss:  0.072, Train Acc: 100.00%, Time: 0:01:46 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/2/2\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/2/2\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.33, Test Acc:  90.17%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.94      0.96      0.95       127\n                   Filter       0.82      0.93      0.87       148\n    Compute Derived Value       0.96      0.88      0.92       154\n            Find Extremum       0.89      0.98      0.93       176\n                     Sort       0.90      0.91      0.90       107\n          Determine Range       0.88      0.84      0.86       158\nCharacterize Distribution       0.95      0.87      0.91       127\n           Find Anomalies       0.85      0.86      0.86       147\n                  Cluster       0.96      0.90      0.93       117\n                Correlate       0.92      0.88      0.90       143\n\n                micro avg       0.90      0.90      0.90      1404\n                macro avg       0.91      0.90      0.90      1404\n             weighted avg       0.90      0.90      0.90      1404\n\nConfusion Matrix...\n[[122   1   1   0   0   1   0   2   0   0]\n [  2 138   0   2   0   1   0   5   0   0]\n [  2   5 136   4   1   4   0   0   0   2]\n [  1   0   0 172   0   1   0   2   0   0]\n [  1   0   0   5  97   2   0   0   2   0]\n [  1  10   1   6   3 132   2   2   1   0]\n [  0   2   2   2   2   3 111   1   0   4]\n [  0  10   1   0   0   4   0 127   1   4]\n [  0   1   0   0   4   2   4   0 105   1]\n [  1   2   1   2   1   0   0  10   0 126]]\nTime usage: 0:00:00\nFold:  3\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  15.62%, Time: 0:00:07 *\nIter:     60, Train Loss:    2.2, Train Acc:  12.50%, Time: 0:00:07 \nIter:     90, Train Loss:    2.1, Train Acc:  31.25%, Time: 0:00:13 *\nIter:    120, Train Loss:    2.0, Train Acc:  28.12%, Time: 0:00:13 \nIter:    150, Train Loss:    1.7, Train Acc:  53.12%, Time: 0:00:20 *\nIter:    180, Train Loss:    1.6, Train Acc:  50.00%, Time: 0:00:20 \nIter:    210, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:29 *\nIter:    240, Train Loss:    1.4, Train Acc:  62.50%, Time: 0:00:29 \nIter:    270, Train Loss:    1.2, Train Acc:  75.00%, Time: 0:00:39 *\nIter:    300, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:00:39 \nIter:    330, Train Loss:   0.96, Train Acc:  81.25%, Time: 0:00:48 *\nIter:    360, Train Loss:    1.0, Train Acc:  78.12%, Time: 0:00:48 \nIter:    390, Train Loss:   0.95, Train Acc:  78.12%, Time: 0:00:49 \nEpoch: 2\nIter:    420, Train Loss:   0.73, Train Acc:  75.00%, Time: 0:00:49 \nIter:    450, Train Loss:   0.89, Train Acc:  75.00%, Time: 0:00:49 \nIter:    480, Train Loss:   0.88, Train Acc:  68.75%, Time: 0:00:49 \nIter:    510, Train Loss:   0.74, Train Acc:  81.25%, Time: 0:00:50 \nIter:    540, Train Loss:   0.85, Train Acc:  75.00%, Time: 0:00:50 \nIter:    570, Train Loss:   0.67, Train Acc:  84.38%, Time: 0:00:59 *\nIter:    600, Train Loss:   0.62, Train Acc:  84.38%, Time: 0:00:59 \nIter:    630, Train Loss:   0.48, Train Acc:  93.75%, Time: 0:01:09 *\nIter:    660, Train Loss:   0.72, Train Acc:  78.12%, Time: 0:01:09 \nIter:    690, Train Loss:   0.51, Train Acc:  87.50%, Time: 0:01:09 \nIter:    720, Train Loss:   0.54, Train Acc:  81.25%, Time: 0:01:09 \nIter:    750, Train Loss:   0.68, Train Acc:  81.25%, Time: 0:01:10 \nIter:    780, Train Loss:   0.78, Train Acc:  78.12%, Time: 0:01:10 \nEpoch: 3\nIter:    810, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:10 \nIter:    840, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:01:10 \nIter:    870, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:01:11 \nIter:    900, Train Loss:    0.6, Train Acc:  84.38%, Time: 0:01:11 \nIter:    930, Train Loss:   0.33, Train Acc:  96.88%, Time: 0:01:20 *\nIter:    960, Train Loss:   0.42, Train Acc:  84.38%, Time: 0:01:20 \nIter:    990, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:01:20 \nIter:   1020, Train Loss:   0.37, Train Acc:  93.75%, Time: 0:01:20 \nIter:   1050, Train Loss:   0.39, Train Acc:  90.62%, Time: 0:01:21 \nIter:   1080, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:21 \nIter:   1110, Train Loss:   0.29, Train Acc:  87.50%, Time: 0:01:21 \nIter:   1140, Train Loss:   0.18, Train Acc: 100.00%, Time: 0:01:28 *\nIter:   1170, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:28 \nEpoch: 4\nIter:   1200, Train Loss:   0.27, Train Acc:  90.62%, Time: 0:01:28 \nIter:   1230, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:01:28 \nIter:   1260, Train Loss:   0.22, Train Acc:  96.88%, Time: 0:01:29 \nIter:   1290, Train Loss:   0.18, Train Acc: 100.00%, Time: 0:01:29 \nIter:   1320, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:01:29 \nIter:   1350, Train Loss:   0.13, Train Acc: 100.00%, Time: 0:01:29 \nIter:   1380, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:30 \nIter:   1410, Train Loss:   0.13, Train Acc: 100.00%, Time: 0:01:30 \nIter:   1440, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:01:30 \nIter:   1470, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:01:31 \nIter:   1500, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:31 \nIter:   1530, Train Loss:   0.25, Train Acc:  96.88%, Time: 0:01:31 \nIter:   1560, Train Loss:   0.33, Train Acc:  87.50%, Time: 0:01:31 \nEpoch: 5\nIter:   1590, Train Loss:  0.097, Train Acc: 100.00%, Time: 0:01:32 \nIter:   1620, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:32 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/3/3\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/3/3\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.43, Test Acc:  88.60%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.99      0.84      0.91       135\n                   Filter       0.92      0.82      0.87       162\n    Compute Derived Value       0.79      0.93      0.86       137\n            Find Extremum       0.83      0.93      0.88       171\n                     Sort       0.91      0.95      0.93       111\n          Determine Range       0.93      0.88      0.90       124\nCharacterize Distribution       0.91      0.86      0.89       140\n           Find Anomalies       0.90      0.89      0.90       135\n                  Cluster       0.98      0.87      0.92       136\n                Correlate       0.80      0.90      0.85       153\n\n                micro avg       0.89      0.89      0.89      1404\n                macro avg       0.90      0.89      0.89      1404\n             weighted avg       0.89      0.89      0.89      1404\n\nConfusion Matrix...\n[[114   0  12   0   2   1   2   0   0   4]\n [  0 133   7  14   2   1   1   3   0   1]\n [  0   0 127   4   0   2   1   0   0   3]\n [  0   1   1 159   5   1   0   2   1   1]\n [  0   1   0   2 105   0   1   2   0   0]\n [  0   2   2   5   1 109   1   1   0   3]\n [  0   4   5   2   0   1 121   0   0   7]\n [  0   3   1   2   0   1   0 120   1   7]\n [  0   0   0   2   1   1   3   2 118   9]\n [  1   1   5   1   0   0   3   3   1 138]]\nTime usage: 0:00:00\nFold:  4\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  12.50%, Time: 0:00:06 *\nIter:     60, Train Loss:    2.1, Train Acc:  18.75%, Time: 0:00:15 *\nIter:     90, Train Loss:    2.2, Train Acc:  12.50%, Time: 0:00:16 \nIter:    120, Train Loss:    2.0, Train Acc:  34.38%, Time: 0:00:24 *\nIter:    150, Train Loss:    2.0, Train Acc:  25.00%, Time: 0:00:24 \nIter:    180, Train Loss:    1.8, Train Acc:  53.12%, Time: 0:00:31 *\nIter:    210, Train Loss:    2.0, Train Acc:  40.62%, Time: 0:00:31 \nIter:    240, Train Loss:    1.7, Train Acc:  59.38%, Time: 0:00:39 *\nIter:    270, Train Loss:    1.6, Train Acc:  56.25%, Time: 0:00:40 \nIter:    300, Train Loss:    1.4, Train Acc:  62.50%, Time: 0:00:46 *\nIter:    330, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:00:46 \nIter:    360, Train Loss:    1.5, Train Acc:  50.00%, Time: 0:00:47 \nIter:    390, Train Loss:    1.1, Train Acc:  62.50%, Time: 0:00:47 \nEpoch: 2\nIter:    420, Train Loss:    1.1, Train Acc:  59.38%, Time: 0:00:47 \nIter:    450, Train Loss:    1.0, Train Acc:  71.88%, Time: 0:00:53 *\nIter:    480, Train Loss:   0.93, Train Acc:  75.00%, Time: 0:01:00 *\nIter:    510, Train Loss:   0.83, Train Acc:  75.00%, Time: 0:01:00 \nIter:    540, Train Loss:   0.58, Train Acc:  84.38%, Time: 0:01:06 *\nIter:    570, Train Loss:    0.7, Train Acc:  81.25%, Time: 0:01:06 \nIter:    600, Train Loss:   0.67, Train Acc:  78.12%, Time: 0:01:06 \nIter:    630, Train Loss:   0.62, Train Acc:  93.75%, Time: 0:01:12 *\nIter:    660, Train Loss:   0.75, Train Acc:  78.12%, Time: 0:01:13 \nIter:    690, Train Loss:   0.93, Train Acc:  65.62%, Time: 0:01:13 \nIter:    720, Train Loss:   0.57, Train Acc:  87.50%, Time: 0:01:13 \nIter:    750, Train Loss:   0.34, Train Acc:  96.88%, Time: 0:01:21 *\nIter:    780, Train Loss:   0.37, Train Acc:  93.75%, Time: 0:01:21 \nEpoch: 3\nIter:    810, Train Loss:   0.43, Train Acc:  87.50%, Time: 0:01:21 \nIter:    840, Train Loss:   0.48, Train Acc:  84.38%, Time: 0:01:22 \nIter:    870, Train Loss:   0.49, Train Acc:  90.62%, Time: 0:01:22 \nIter:    900, Train Loss:    0.3, Train Acc:  96.88%, Time: 0:01:22 \nIter:    930, Train Loss:   0.34, Train Acc:  96.88%, Time: 0:01:22 \nIter:    960, Train Loss:   0.29, Train Acc:  90.62%, Time: 0:01:23 \nIter:    990, Train Loss:   0.49, Train Acc:  90.62%, Time: 0:01:23 \nIter:   1020, Train Loss:   0.47, Train Acc:  90.62%, Time: 0:01:23 \nIter:   1050, Train Loss:   0.39, Train Acc:  84.38%, Time: 0:01:23 \nIter:   1080, Train Loss:   0.41, Train Acc:  87.50%, Time: 0:01:24 \nIter:   1110, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:01:24 \nIter:   1140, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:01:24 \nIter:   1170, Train Loss:   0.49, Train Acc:  87.50%, Time: 0:01:25 \nEpoch: 4\nIter:   1200, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:25 \nIter:   1230, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:25 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/4/4\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/4/4\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.63, Test Acc:  82.05%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.73      0.93      0.82       123\n                   Filter       0.79      0.67      0.73       140\n    Compute Derived Value       0.74      0.87      0.80       164\n            Find Extremum       0.80      0.88      0.84       163\n                     Sort       0.85      0.90      0.88       135\n          Determine Range       0.94      0.59      0.73       137\nCharacterize Distribution       0.88      0.88      0.88       129\n           Find Anomalies       0.87      0.75      0.80       143\n                  Cluster       0.86      0.86      0.86       118\n                Correlate       0.85      0.88      0.86       152\n\n                micro avg       0.82      0.82      0.82      1404\n                macro avg       0.83      0.82      0.82      1404\n             weighted avg       0.83      0.82      0.82      1404\n\nConfusion Matrix...\n[[114   1   7   0   0   0   1   0   0   0]\n [ 12  94  13   6   3   1   2   7   2   0]\n [  7   4 142   5   0   0   3   1   0   2]\n [  5   1   3 143   6   0   3   0   1   1]\n [  1   2   2   3 122   1   0   0   4   0]\n [ 11   7   7  15   4  81   1   3   4   4]\n [  3   1   4   0   1   2 114   0   2   2]\n [  1   6   6   5   0   0   1 107   3  14]\n [  1   3   3   1   6   0   2   0 101   1]\n [  1   0   6   1   1   1   2   5   1 134]]\nTime usage: 0:00:00\nFold:  5\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  21.88%, Time: 0:00:09 *\nIter:     60, Train Loss:    2.2, Train Acc:  21.88%, Time: 0:00:09 \nIter:     90, Train Loss:    2.1, Train Acc:  34.38%, Time: 0:00:15 *\nIter:    120, Train Loss:    1.9, Train Acc:  28.12%, Time: 0:00:15 \nIter:    150, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:22 *\nIter:    180, Train Loss:    1.7, Train Acc:  53.12%, Time: 0:00:31 *\nIter:    210, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:32 \nIter:    240, Train Loss:    1.5, Train Acc:  59.38%, Time: 0:00:39 *\nIter:    270, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:46 *\nIter:    300, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:00:55 *\nIter:    330, Train Loss:    1.0, Train Acc:  71.88%, Time: 0:00:56 \nIter:    360, Train Loss:    1.4, Train Acc:  62.50%, Time: 0:00:56 \nIter:    390, Train Loss:   0.96, Train Acc:  75.00%, Time: 0:01:03 *\nEpoch: 2\nIter:    420, Train Loss:   0.88, Train Acc:  81.25%, Time: 0:01:09 *\nIter:    450, Train Loss:   0.66, Train Acc:  84.38%, Time: 0:01:16 *\nIter:    480, Train Loss:   0.75, Train Acc:  87.50%, Time: 0:01:25 *\nIter:    510, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:01:25 \nIter:    540, Train Loss:   0.68, Train Acc:  87.50%, Time: 0:01:25 \nIter:    570, Train Loss:   0.68, Train Acc:  71.88%, Time: 0:01:26 \nIter:    600, Train Loss:   0.92, Train Acc:  75.00%, Time: 0:01:26 \nIter:    630, Train Loss:   0.53, Train Acc:  87.50%, Time: 0:01:26 \nIter:    660, Train Loss:   0.73, Train Acc:  78.12%, Time: 0:01:26 \nIter:    690, Train Loss:   0.92, Train Acc:  68.75%, Time: 0:01:27 \nIter:    720, Train Loss:   0.56, Train Acc:  84.38%, Time: 0:01:27 \nIter:    750, Train Loss:   0.69, Train Acc:  84.38%, Time: 0:01:27 \nIter:    780, Train Loss:   0.51, Train Acc:  90.62%, Time: 0:01:34 *\nEpoch: 3\nIter:    810, Train Loss:   0.51, Train Acc:  87.50%, Time: 0:01:34 \nIter:    840, Train Loss:   0.44, Train Acc:  93.75%, Time: 0:01:43 *\nIter:    870, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:43 \nIter:    900, Train Loss:   0.46, Train Acc:  87.50%, Time: 0:01:43 \nIter:    930, Train Loss:   0.48, Train Acc:  81.25%, Time: 0:01:43 \nIter:    960, Train Loss:   0.29, Train Acc:  96.88%, Time: 0:01:49 *\nIter:    990, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:01:50 \nIter:   1020, Train Loss:   0.36, Train Acc:  93.75%, Time: 0:01:50 \nIter:   1050, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:50 \nIter:   1080, Train Loss:   0.22, Train Acc:  96.88%, Time: 0:01:50 \nIter:   1110, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:01:51 \nIter:   1140, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:01:51 \nIter:   1170, Train Loss:   0.36, Train Acc:  93.75%, Time: 0:01:51 \nEpoch: 4\nIter:   1200, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:51 \nIter:   1230, Train Loss:   0.16, Train Acc: 100.00%, Time: 0:01:59 *\nIter:   1260, Train Loss:   0.26, Train Acc:  96.88%, Time: 0:01:59 \nIter:   1290, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:01:59 \nIter:   1320, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:02:00 \nIter:   1350, Train Loss:   0.13, Train Acc: 100.00%, Time: 0:02:00 \nIter:   1380, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:02:00 \nIter:   1410, Train Loss:   0.27, Train Acc:  90.62%, Time: 0:02:00 \nIter:   1440, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:02:01 \nIter:   1470, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:02:01 \nIter:   1500, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:02:01 \nIter:   1530, Train Loss:   0.16, Train Acc:  93.75%, Time: 0:02:01 \nIter:   1560, Train Loss:   0.38, Train Acc:  84.38%, Time: 0:02:02 \nEpoch: 5\nIter:   1590, Train Loss:   0.12, Train Acc: 100.00%, Time: 0:02:02 \nIter:   1620, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:02:02 \nIter:   1650, Train Loss:   0.14, Train Acc:  93.75%, Time: 0:02:02 \nIter:   1680, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:02:03 \nIter:   1710, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:02:03 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/5/5\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/5/5\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.36, Test Acc:  91.03%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.88      0.94      0.91       141\n                   Filter       0.87      0.90      0.88       153\n    Compute Derived Value       0.91      0.91      0.91       150\n            Find Extremum       0.94      0.93      0.94       169\n                     Sort       0.86      0.98      0.92       108\n          Determine Range       0.87      0.89      0.88       123\nCharacterize Distribution       0.95      0.85      0.90       126\n           Find Anomalies       0.92      0.86      0.89       137\n                  Cluster       0.99      0.89      0.94       131\n                Correlate       0.92      0.95      0.93       166\n\n                micro avg       0.91      0.91      0.91      1404\n                macro avg       0.91      0.91      0.91      1404\n             weighted avg       0.91      0.91      0.91      1404\n\nConfusion Matrix...\n[[133   4   1   1   1   0   1   0   0   0]\n [  4 137   3   1   0   4   0   4   0   0]\n [  5   4 136   1   2   1   0   0   0   1]\n [  1   2   0 158   1   2   1   1   1   2]\n [  0   1   1   0 106   0   0   0   0   0]\n [  2   1   5   1   4 110   0   0   0   0]\n [  0   2   3   3   2   6 107   2   0   1]\n [  3   4   0   2   0   1   1 118   0   8]\n [  2   0   0   0   6   1   2   3 116   1]\n [  1   2   1   1   1   2   1   0   0 157]]\nTime usage: 0:00:00\nFold:  6\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:   6.25%, Time: 0:00:09 *\nIter:     60, Train Loss:    2.3, Train Acc:  12.50%, Time: 0:00:19 *\nIter:     90, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:26 *\nIter:    120, Train Loss:    1.8, Train Acc:  50.00%, Time: 0:00:35 *\nIter:    150, Train Loss:    1.8, Train Acc:  37.50%, Time: 0:00:36 \nIter:    180, Train Loss:    1.7, Train Acc:  50.00%, Time: 0:00:36 \nIter:    210, Train Loss:    1.4, Train Acc:  75.00%, Time: 0:00:43 *\nIter:    240, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:00:43 \nIter:    270, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:00:44 \nIter:    300, Train Loss:   0.92, Train Acc:  81.25%, Time: 0:00:52 *\nIter:    330, Train Loss:   0.91, Train Acc:  87.50%, Time: 0:01:02 *\nIter:    360, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:01:02 \nIter:    390, Train Loss:    1.0, Train Acc:  65.62%, Time: 0:01:03 \nEpoch: 2\nIter:    420, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:01:03 \nIter:    450, Train Loss:   0.58, Train Acc:  78.12%, Time: 0:01:03 \nIter:    480, Train Loss:   0.88, Train Acc:  81.25%, Time: 0:01:03 \nIter:    510, Train Loss:    0.7, Train Acc:  84.38%, Time: 0:01:04 \nIter:    540, Train Loss:   0.72, Train Acc:  81.25%, Time: 0:01:04 \nIter:    570, Train Loss:   0.87, Train Acc:  68.75%, Time: 0:01:04 \nIter:    600, Train Loss:   0.87, Train Acc:  62.50%, Time: 0:01:04 \nIter:    630, Train Loss:    0.7, Train Acc:  75.00%, Time: 0:01:05 \nIter:    660, Train Loss:    0.5, Train Acc:  93.75%, Time: 0:01:12 *\nIter:    690, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:01:12 \nIter:    720, Train Loss:   0.37, Train Acc:  87.50%, Time: 0:01:13 \nIter:    750, Train Loss:   0.86, Train Acc:  75.00%, Time: 0:01:13 \nIter:    780, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:01:13 \nEpoch: 3\nIter:    810, Train Loss:   0.45, Train Acc:  90.62%, Time: 0:01:13 \nIter:    840, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:01:19 *\nIter:    870, Train Loss:   0.39, Train Acc:  90.62%, Time: 0:01:19 \nIter:    900, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:01:19 \nIter:    930, Train Loss:   0.24, Train Acc:  96.88%, Time: 0:01:20 \nIter:    960, Train Loss:    0.4, Train Acc:  90.62%, Time: 0:01:20 \nIter:    990, Train Loss:   0.65, Train Acc:  81.25%, Time: 0:01:20 \nIter:   1020, Train Loss:   0.65, Train Acc:  81.25%, Time: 0:01:20 \nIter:   1050, Train Loss:   0.24, Train Acc: 100.00%, Time: 0:01:27 *\nIter:   1080, Train Loss:    0.3, Train Acc:  90.62%, Time: 0:01:27 \nIter:   1110, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:01:28 \nIter:   1140, Train Loss:   0.37, Train Acc:  96.88%, Time: 0:01:28 \nIter:   1170, Train Loss:   0.11, Train Acc: 100.00%, Time: 0:01:28 \nEpoch: 4\nIter:   1200, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:01:28 \nIter:   1230, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:01:29 \nIter:   1260, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:01:29 \nIter:   1290, Train Loss:   0.15, Train Acc: 100.00%, Time: 0:01:29 \nIter:   1320, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:01:29 \nIter:   1350, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:01:30 \nIter:   1380, Train Loss:   0.27, Train Acc:  87.50%, Time: 0:01:30 \nIter:   1410, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:30 \nIter:   1440, Train Loss:   0.12, Train Acc: 100.00%, Time: 0:01:30 \nIter:   1470, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:01:31 \nIter:   1500, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:01:31 \nIter:   1530, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:31 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/6/6\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/6/6\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.44, Test Acc:  86.96%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.87      0.94      0.90       148\n                   Filter       0.95      0.78      0.85       156\n    Compute Derived Value       0.84      0.85      0.85       172\n            Find Extremum       0.79      0.96      0.87       164\n                     Sort       0.89      0.92      0.91       131\n          Determine Range       0.85      0.81      0.83       115\nCharacterize Distribution       0.91      0.82      0.86       160\n           Find Anomalies       0.89      0.86      0.88       110\n                  Cluster       0.91      0.89      0.90       110\n                Correlate       0.85      0.87      0.86       137\n\n                micro avg       0.87      0.87      0.87      1403\n                macro avg       0.87      0.87      0.87      1403\n             weighted avg       0.87      0.87      0.87      1403\n\nConfusion Matrix...\n[[139   0   3   3   0   1   2   0   0   0]\n [  7 121   8   7   0   4   0   4   1   4]\n [  5   1 146   6   2   1   4   1   2   4]\n [  3   0   2 157   0   0   0   1   0   1]\n [  0   0   0   9 121   0   0   0   0   1]\n [  1   3   4   4   7  93   1   0   0   2]\n [  1   2   5   4   4   6 131   2   4   1]\n [  0   1   0   7   0   2   2  95   0   3]\n [  1   0   0   0   0   2   2   2  98   5]\n [  3   0   5   1   2   0   2   2   3 119]]\nTime usage: 0:00:00\nFold:  7\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:   6.25%, Time: 0:00:09 *\nIter:     60, Train Loss:    2.2, Train Acc:  25.00%, Time: 0:00:18 *\nIter:     90, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:18 \nIter:    120, Train Loss:    1.9, Train Acc:  34.38%, Time: 0:00:26 *\nIter:    150, Train Loss:    1.8, Train Acc:  56.25%, Time: 0:00:34 *\nIter:    180, Train Loss:    1.7, Train Acc:  53.12%, Time: 0:00:34 \nIter:    210, Train Loss:    1.5, Train Acc:  46.88%, Time: 0:00:34 \nIter:    240, Train Loss:    1.4, Train Acc:  62.50%, Time: 0:00:44 *\nIter:    270, Train Loss:    1.4, Train Acc:  53.12%, Time: 0:00:44 \nIter:    300, Train Loss:    1.4, Train Acc:  56.25%, Time: 0:00:44 \nIter:    330, Train Loss:    1.2, Train Acc:  59.38%, Time: 0:00:44 \nIter:    360, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:00:54 *\nIter:    390, Train Loss:    1.0, Train Acc:  71.88%, Time: 0:00:54 \nEpoch: 2\nIter:    420, Train Loss:   0.76, Train Acc:  81.25%, Time: 0:01:09 *\nIter:    450, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:01:10 \nIter:    480, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:01:10 \nIter:    510, Train Loss:   0.84, Train Acc:  87.50%, Time: 0:01:19 *\nIter:    540, Train Loss:    1.0, Train Acc:  68.75%, Time: 0:01:19 \nIter:    570, Train Loss:   0.62, Train Acc:  84.38%, Time: 0:01:19 \nIter:    600, Train Loss:    0.9, Train Acc:  71.88%, Time: 0:01:19 \nIter:    630, Train Loss:   0.75, Train Acc:  78.12%, Time: 0:01:20 \nIter:    660, Train Loss:   0.64, Train Acc:  75.00%, Time: 0:01:20 \nIter:    690, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:01:28 *\nIter:    720, Train Loss:   0.56, Train Acc:  78.12%, Time: 0:01:29 \nIter:    750, Train Loss:   0.57, Train Acc:  90.62%, Time: 0:01:29 \nIter:    780, Train Loss:   0.76, Train Acc:  84.38%, Time: 0:01:29 \nEpoch: 3\nIter:    810, Train Loss:   0.33, Train Acc:  96.88%, Time: 0:01:39 *\nIter:    840, Train Loss:   0.45, Train Acc:  93.75%, Time: 0:01:39 \nIter:    870, Train Loss:   0.36, Train Acc:  96.88%, Time: 0:01:40 \nIter:    900, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:01:40 \nIter:    930, Train Loss:   0.54, Train Acc:  81.25%, Time: 0:01:40 \nIter:    960, Train Loss:   0.25, Train Acc:  96.88%, Time: 0:01:40 \nIter:    990, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:01:41 \nIter:   1020, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:01:41 \nIter:   1050, Train Loss:   0.31, Train Acc:  96.88%, Time: 0:01:41 \nIter:   1080, Train Loss:   0.17, Train Acc: 100.00%, Time: 0:01:52 *\nIter:   1110, Train Loss:   0.55, Train Acc:  84.38%, Time: 0:01:52 \nIter:   1140, Train Loss:   0.43, Train Acc:  93.75%, Time: 0:01:52 \nIter:   1170, Train Loss:   0.26, Train Acc:  96.88%, Time: 0:01:53 \nEpoch: 4\nIter:   1200, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:01:53 \nIter:   1230, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:53 \nIter:   1260, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:53 \nIter:   1290, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:01:54 \nIter:   1320, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:54 \nIter:   1350, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:01:54 \nIter:   1380, Train Loss:   0.11, Train Acc: 100.00%, Time: 0:01:54 \nIter:   1410, Train Loss:   0.44, Train Acc:  78.12%, Time: 0:01:55 \nIter:   1440, Train Loss:   0.29, Train Acc:  90.62%, Time: 0:01:55 \nIter:   1470, Train Loss:  0.086, Train Acc: 100.00%, Time: 0:01:55 \nIter:   1500, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:55 \nIter:   1530, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:56 \nIter:   1560, Train Loss:    0.3, Train Acc:  96.88%, Time: 0:01:56 \nEpoch: 5\nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/7/7\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/7/7\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.37, Test Acc:  90.59%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.95      0.96      0.96       141\n                   Filter       0.80      0.88      0.84       157\n    Compute Derived Value       0.91      0.90      0.90       134\n            Find Extremum       0.82      0.98      0.89       170\n                     Sort       0.97      0.94      0.95       130\n          Determine Range       0.90      0.83      0.86       138\nCharacterize Distribution       0.99      0.89      0.94       121\n           Find Anomalies       0.99      0.86      0.92       153\n                  Cluster       0.96      0.91      0.93       118\n                Correlate       0.88      0.91      0.90       141\n\n                micro avg       0.91      0.91      0.91      1403\n                macro avg       0.92      0.90      0.91      1403\n             weighted avg       0.91      0.91      0.91      1403\n\nConfusion Matrix...\n[[136   2   0   3   0   0   0   0   0   0]\n [  2 138   3  10   0   1   0   1   0   2]\n [  2   5 120   3   1   2   0   0   0   1]\n [  0   2   2 166   0   0   0   0   0   0]\n [  1   0   0   5 122   1   0   0   1   0]\n [  1  11   1   9   1 114   0   0   1   0]\n [  0   3   1   2   1   2 108   0   1   3]\n [  1   4   0   5   0   4   0 132   1   6]\n [  0   2   1   0   1   2   0   0 107   5]\n [  0   5   4   0   0   1   1   1   1 128]]\nTime usage: 0:00:00\nFold:  8\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:   9.38%, Time: 0:00:12 *\nIter:     60, Train Loss:    2.3, Train Acc:  12.50%, Time: 0:00:21 *\nIter:     90, Train Loss:    2.1, Train Acc:  31.25%, Time: 0:00:29 *\nIter:    120, Train Loss:    1.9, Train Acc:  31.25%, Time: 0:00:30 \nIter:    150, Train Loss:    1.8, Train Acc:  37.50%, Time: 0:00:38 *\nIter:    180, Train Loss:    1.7, Train Acc:  62.50%, Time: 0:00:45 *\nIter:    210, Train Loss:    1.6, Train Acc:  37.50%, Time: 0:00:45 \nIter:    240, Train Loss:    1.6, Train Acc:  53.12%, Time: 0:00:46 \nIter:    270, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:00:55 *\nIter:    300, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:56 \nIter:    330, Train Loss:    1.3, Train Acc:  56.25%, Time: 0:00:56 \nIter:    360, Train Loss:   0.94, Train Acc:  75.00%, Time: 0:01:05 *\nIter:    390, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:01:05 \nEpoch: 2\nIter:    420, Train Loss:   0.99, Train Acc:  68.75%, Time: 0:01:05 \nIter:    450, Train Loss:   0.99, Train Acc:  65.62%, Time: 0:01:06 \nIter:    480, Train Loss:   0.87, Train Acc:  68.75%, Time: 0:01:06 \nIter:    510, Train Loss:   0.58, Train Acc:  84.38%, Time: 0:01:13 *\nIter:    540, Train Loss:   0.86, Train Acc:  75.00%, Time: 0:01:13 \nIter:    570, Train Loss:   0.76, Train Acc:  78.12%, Time: 0:01:14 \nIter:    600, Train Loss:   0.72, Train Acc:  78.12%, Time: 0:01:14 \nIter:    630, Train Loss:   0.64, Train Acc:  87.50%, Time: 0:01:23 *\nIter:    660, Train Loss:   0.89, Train Acc:  75.00%, Time: 0:01:23 \nIter:    690, Train Loss:   0.87, Train Acc:  81.25%, Time: 0:01:23 \nIter:    720, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:01:33 *\nIter:    750, Train Loss:   0.42, Train Acc:  90.62%, Time: 0:01:34 \nIter:    780, Train Loss:   0.55, Train Acc:  84.38%, Time: 0:01:34 \nEpoch: 3\nIter:    810, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:44 *\nIter:    840, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:01:44 \nIter:    870, Train Loss:   0.48, Train Acc:  90.62%, Time: 0:01:44 \nIter:    900, Train Loss:   0.53, Train Acc:  87.50%, Time: 0:01:44 \nIter:    930, Train Loss:   0.39, Train Acc:  87.50%, Time: 0:01:45 \nIter:    960, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:45 \nIter:    990, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:01:45 \nIter:   1020, Train Loss:   0.46, Train Acc:  90.62%, Time: 0:01:45 \nIter:   1050, Train Loss:   0.15, Train Acc: 100.00%, Time: 0:01:56 *\nIter:   1080, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:01:56 \nIter:   1110, Train Loss:   0.43, Train Acc:  87.50%, Time: 0:01:56 \nIter:   1140, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:57 \nIter:   1170, Train Loss:   0.42, Train Acc:  90.62%, Time: 0:01:57 \nEpoch: 4\nIter:   1200, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:57 \nIter:   1230, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:01:57 \nIter:   1260, Train Loss:  0.054, Train Acc: 100.00%, Time: 0:01:58 \nIter:   1290, Train Loss:   0.42, Train Acc:  90.62%, Time: 0:01:58 \nIter:   1320, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:58 \nIter:   1350, Train Loss:   0.24, Train Acc:  96.88%, Time: 0:01:58 \nIter:   1380, Train Loss:    0.2, Train Acc: 100.00%, Time: 0:01:59 \nIter:   1410, Train Loss:   0.27, Train Acc:  96.88%, Time: 0:01:59 \nIter:   1440, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:01:59 \nIter:   1470, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:02:00 \nIter:   1500, Train Loss:   0.09, Train Acc: 100.00%, Time: 0:02:00 \nIter:   1530, Train Loss:   0.08, Train Acc: 100.00%, Time: 0:02:00 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/8/8\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/8/8\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.44, Test Acc:  88.24%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.91      0.91      0.91       105\n                   Filter       0.81      0.88      0.85       134\n    Compute Derived Value       0.89      0.81      0.85       157\n            Find Extremum       0.89      0.91      0.90       182\n                     Sort       0.85      0.98      0.91       112\n          Determine Range       0.79      0.90      0.85       133\nCharacterize Distribution       0.92      0.89      0.90       127\n           Find Anomalies       0.90      0.85      0.87       144\n                  Cluster       0.93      0.89      0.91       143\n                Correlate       0.93      0.84      0.88       166\n\n                micro avg       0.88      0.88      0.88      1403\n                macro avg       0.88      0.89      0.88      1403\n             weighted avg       0.89      0.88      0.88      1403\n\nConfusion Matrix...\n[[ 96   0   3   3   2   1   0   0   0   0]\n [  1 118   0   1   2  10   0   2   0   0]\n [  4   8 127   8   1   8   0   0   0   1]\n [  1   0   4 166   6   2   0   1   1   1]\n [  0   0   0   0 110   1   0   0   1   0]\n [  1   5   1   1   1 120   1   1   0   2]\n [  1   1   3   1   2   3 113   0   1   2]\n [  0  10   0   4   1   2   1 122   1   3]\n [  0   1   1   0   5   3   2   2 127   2]\n [  1   2   3   2   0   1   6   7   5 139]]\nTime usage: 0:00:00\nFold:  9\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.2, Train Acc:  15.62%, Time: 0:00:09 *\nIter:     60, Train Loss:    2.3, Train Acc:   6.25%, Time: 0:00:09 \nIter:     90, Train Loss:    2.2, Train Acc:  15.62%, Time: 0:00:09 \nIter:    120, Train Loss:    2.0, Train Acc:  43.75%, Time: 0:00:18 *\nIter:    150, Train Loss:    1.8, Train Acc:  53.12%, Time: 0:00:27 *\nIter:    180, Train Loss:    1.8, Train Acc:  40.62%, Time: 0:00:28 \nIter:    210, Train Loss:    1.6, Train Acc:  56.25%, Time: 0:00:36 *\nIter:    240, Train Loss:    1.5, Train Acc:  56.25%, Time: 0:00:36 \nIter:    270, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:44 *\nIter:    300, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:44 \nIter:    330, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:00:44 \nIter:    360, Train Loss:   0.91, Train Acc:  75.00%, Time: 0:00:53 *\nIter:    390, Train Loss:   0.95, Train Acc:  75.00%, Time: 0:00:53 \nEpoch: 2\nIter:    420, Train Loss:   0.93, Train Acc:  78.12%, Time: 0:01:00 *\nIter:    450, Train Loss:    0.9, Train Acc:  68.75%, Time: 0:01:01 \nIter:    480, Train Loss:   0.62, Train Acc:  87.50%, Time: 0:01:07 *\nIter:    510, Train Loss:   0.67, Train Acc:  78.12%, Time: 0:01:08 \nIter:    540, Train Loss:   0.56, Train Acc:  81.25%, Time: 0:01:08 \nIter:    570, Train Loss:   0.72, Train Acc:  84.38%, Time: 0:01:08 \nIter:    600, Train Loss:   0.62, Train Acc:  81.25%, Time: 0:01:08 \nIter:    630, Train Loss:   0.94, Train Acc:  75.00%, Time: 0:01:09 \nIter:    660, Train Loss:   0.46, Train Acc:  90.62%, Time: 0:01:16 *\nIter:    690, Train Loss:   0.75, Train Acc:  84.38%, Time: 0:01:17 \nIter:    720, Train Loss:   0.64, Train Acc:  84.38%, Time: 0:01:17 \nIter:    750, Train Loss:   0.39, Train Acc:  87.50%, Time: 0:01:17 \nIter:    780, Train Loss:   0.54, Train Acc:  84.38%, Time: 0:01:17 \nEpoch: 3\nIter:    810, Train Loss:   0.47, Train Acc:  90.62%, Time: 0:01:18 \nIter:    840, Train Loss:    0.5, Train Acc:  87.50%, Time: 0:01:18 \nIter:    870, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:01:18 \nIter:    900, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:26 *\nIter:    930, Train Loss:   0.23, Train Acc: 100.00%, Time: 0:01:34 *\nIter:    960, Train Loss:    0.3, Train Acc:  90.62%, Time: 0:01:34 \nIter:    990, Train Loss:   0.49, Train Acc:  84.38%, Time: 0:01:35 \nIter:   1020, Train Loss:    0.7, Train Acc:  71.88%, Time: 0:01:35 \nIter:   1050, Train Loss:   0.37, Train Acc:  96.88%, Time: 0:01:35 \nIter:   1080, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:35 \nIter:   1110, Train Loss:   0.45, Train Acc:  84.38%, Time: 0:01:36 \nIter:   1140, Train Loss:   0.34, Train Acc:  93.75%, Time: 0:01:36 \nIter:   1170, Train Loss:   0.19, Train Acc: 100.00%, Time: 0:01:36 \nEpoch: 4\nIter:   1200, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:01:36 \nIter:   1230, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:01:37 \nIter:   1260, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:01:37 \nIter:   1290, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:37 \nIter:   1320, Train Loss:  0.072, Train Acc: 100.00%, Time: 0:01:37 \nIter:   1350, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:01:38 \nIter:   1380, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:01:38 \nIter:   1410, Train Loss:  0.085, Train Acc: 100.00%, Time: 0:01:38 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/9/9\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/9/9\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.46, Test Acc:  88.45%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.88      0.95      0.91       162\n                   Filter       0.91      0.78      0.84       126\n    Compute Derived Value       0.88      0.84      0.86       158\n            Find Extremum       0.89      0.85      0.87       166\n                     Sort       0.90      0.96      0.93       137\n          Determine Range       0.87      0.81      0.84       129\nCharacterize Distribution       0.84      0.90      0.87       114\n           Find Anomalies       0.92      0.90      0.91       134\n                  Cluster       0.95      0.91      0.93       135\n                Correlate       0.82      0.94      0.88       142\n\n                micro avg       0.88      0.88      0.88      1403\n                macro avg       0.89      0.88      0.88      1403\n             weighted avg       0.89      0.88      0.88      1403\n\nConfusion Matrix...\n[[154   0   4   0   0   0   4   0   0   0]\n [  2  98   7   3   2   4   2   4   0   4]\n [  9   1 132   2   0   2   4   1   1   6]\n [  6   2   0 141   8   3   1   1   0   4]\n [  0   0   0   2 132   1   0   0   2   0]\n [  4   4   3   9   1 104   0   1   0   3]\n [  0   0   1   1   0   4 103   1   0   4]\n [  0   2   0   0   0   1   3 120   1   7]\n [  0   1   0   0   3   0   4   2 123   2]\n [  0   0   3   0   0   0   2   1   2 134]]\nTime usage: 0:00:00\nFold:  10\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  12.50%, Time: 0:00:08 *\nIter:     60, Train Loss:    2.2, Train Acc:  21.88%, Time: 0:00:15 *\nIter:     90, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:22 *\nIter:    120, Train Loss:    2.0, Train Acc:  34.38%, Time: 0:00:30 *\nIter:    150, Train Loss:    1.7, Train Acc:  56.25%, Time: 0:00:36 *\nIter:    180, Train Loss:    1.6, Train Acc:  59.38%, Time: 0:00:44 *\nIter:    210, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:51 *\nIter:    240, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:51 \nIter:    270, Train Loss:    1.1, Train Acc:  75.00%, Time: 0:00:58 *\nIter:    300, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:00:58 \nIter:    330, Train Loss:    1.0, Train Acc:  84.38%, Time: 0:01:05 *\nIter:    360, Train Loss:    1.1, Train Acc:  62.50%, Time: 0:01:06 \nIter:    390, Train Loss:   0.88, Train Acc:  81.25%, Time: 0:01:06 \nEpoch: 2\nIter:    420, Train Loss:    0.7, Train Acc:  81.25%, Time: 0:01:06 \nIter:    450, Train Loss:   0.88, Train Acc:  84.38%, Time: 0:01:06 \nIter:    480, Train Loss:   0.95, Train Acc:  75.00%, Time: 0:01:07 \nIter:    510, Train Loss:   0.91, Train Acc:  78.12%, Time: 0:01:07 \nIter:    540, Train Loss:    1.0, Train Acc:  81.25%, Time: 0:01:07 \nIter:    570, Train Loss:   0.57, Train Acc:  81.25%, Time: 0:01:07 \nIter:    600, Train Loss:   0.61, Train Acc:  87.50%, Time: 0:01:15 *\nIter:    630, Train Loss:   0.63, Train Acc:  81.25%, Time: 0:01:15 \nIter:    660, Train Loss:   0.76, Train Acc:  87.50%, Time: 0:01:15 \nIter:    690, Train Loss:   0.53, Train Acc:  84.38%, Time: 0:01:16 \nIter:    720, Train Loss:   0.46, Train Acc:  93.75%, Time: 0:01:25 *\nIter:    750, Train Loss:   0.53, Train Acc:  87.50%, Time: 0:01:25 \nIter:    780, Train Loss:   0.49, Train Acc:  84.38%, Time: 0:01:26 \nEpoch: 3\nIter:    810, Train Loss:   0.33, Train Acc:  96.88%, Time: 0:01:33 *\nIter:    840, Train Loss:   0.52, Train Acc:  90.62%, Time: 0:01:33 \nIter:    870, Train Loss:    0.6, Train Acc:  84.38%, Time: 0:01:33 \nIter:    900, Train Loss:   0.47, Train Acc:  84.38%, Time: 0:01:34 \nIter:    930, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:01:34 \nIter:    960, Train Loss:   0.32, Train Acc:  84.38%, Time: 0:01:34 \nIter:    990, Train Loss:   0.18, Train Acc: 100.00%, Time: 0:01:42 *\nIter:   1020, Train Loss:   0.36, Train Acc:  87.50%, Time: 0:01:42 \nIter:   1050, Train Loss:   0.53, Train Acc:  84.38%, Time: 0:01:42 \nIter:   1080, Train Loss:   0.42, Train Acc:  90.62%, Time: 0:01:43 \nIter:   1110, Train Loss:   0.39, Train Acc:  84.38%, Time: 0:01:43 \nIter:   1140, Train Loss:   0.35, Train Acc:  87.50%, Time: 0:01:43 \nIter:   1170, Train Loss:   0.16, Train Acc: 100.00%, Time: 0:01:43 \nEpoch: 4\nIter:   1200, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:44 \nIter:   1230, Train Loss:   0.25, Train Acc:  96.88%, Time: 0:01:44 \nIter:   1260, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:01:44 \nIter:   1290, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:44 \nIter:   1320, Train Loss:   0.19, Train Acc: 100.00%, Time: 0:01:45 \nIter:   1350, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:01:45 \nIter:   1380, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:01:45 \nIter:   1410, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:01:45 \nIter:   1440, Train Loss:   0.29, Train Acc:  90.62%, Time: 0:01:46 \nIter:   1470, Train Loss:  0.077, Train Acc: 100.00%, Time: 0:01:46 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/10/10\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/random/10/10\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.43, Test Acc:  88.81%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.90      0.89      0.90       140\n                   Filter       0.83      0.81      0.82       133\n    Compute Derived Value       0.88      0.90      0.89       167\n            Find Extremum       0.91      0.94      0.93       142\n                     Sort       0.88      0.96      0.92       125\n          Determine Range       0.90      0.85      0.87       130\nCharacterize Distribution       0.95      0.84      0.89       146\n           Find Anomalies       0.84      0.90      0.87       144\n                  Cluster       0.93      0.83      0.88       131\n                Correlate       0.88      0.95      0.91       145\n\n                micro avg       0.89      0.89      0.89      1403\n                macro avg       0.89      0.89      0.89      1403\n             weighted avg       0.89      0.89      0.89      1403\n\nConfusion Matrix...\n[[125   1   8   1   3   0   0   2   0   0]\n [  3 108   2   4   0   2   0   9   2   3]\n [  5   4 150   2   0   4   0   0   0   2]\n [  0   0   3 134   3   1   0   1   0   0]\n [  1   1   0   2 120   0   0   0   1   0]\n [  2   4   4   2   1 111   2   1   1   2]\n [  1   6   0   1   2   5 122   5   2   2]\n [  2   4   1   1   0   1   0 129   1   5]\n [  0   2   2   0   8   0   1   4 109   5]\n [  0   0   0   0   0   0   4   2   1 138]]\nTime usage: 0:00:00\n[0.8732193730495594, 0.9017094011999603, 0.8860398862096999, 0.8205128200033791, 0.9102564102564102, 0.8695652179435925, 0.9059158949365976, 0.8823948679697659, 0.8845331438167215, 0.8880969356912761]\n0.8822243951076963, 0.024147079072436475, 0.02545325623636175, 0.0005830814277304995\nexpert\n20 636 617 41\nFold:  1\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:  18.75%, Time: 0:00:08 *\nIter:     60, Train Loss:    2.6, Train Acc:   0.00%, Time: 0:00:08 \nIter:     90, Train Loss:    2.2, Train Acc:  15.62%, Time: 0:00:09 \nIter:    120, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:16 *\nIter:    150, Train Loss:    2.0, Train Acc:  31.25%, Time: 0:00:23 *\nIter:    180, Train Loss:    2.0, Train Acc:  28.12%, Time: 0:00:23 \nIter:    210, Train Loss:    1.7, Train Acc:  50.00%, Time: 0:00:30 *\nIter:    240, Train Loss:    1.6, Train Acc:  62.50%, Time: 0:00:38 *\nIter:    270, Train Loss:    1.5, Train Acc:  56.25%, Time: 0:00:38 \nIter:    300, Train Loss:    1.4, Train Acc:  65.62%, Time: 0:00:46 *\nIter:    330, Train Loss:    1.3, Train Acc:  56.25%, Time: 0:00:46 \nIter:    360, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:00:47 \nIter:    390, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:00:47 \nEpoch: 2\nIter:    420, Train Loss:   0.81, Train Acc:  75.00%, Time: 0:00:54 *\nIter:    450, Train Loss:   0.65, Train Acc:  84.38%, Time: 0:01:01 *\nIter:    480, Train Loss:   0.99, Train Acc:  71.88%, Time: 0:01:02 \nIter:    510, Train Loss:   0.69, Train Acc:  90.62%, Time: 0:01:09 *\nIter:    540, Train Loss:   0.84, Train Acc:  81.25%, Time: 0:01:09 \nIter:    570, Train Loss:   0.78, Train Acc:  78.12%, Time: 0:01:09 \nIter:    600, Train Loss:   0.91, Train Acc:  68.75%, Time: 0:01:10 \nIter:    630, Train Loss:   0.62, Train Acc:  84.38%, Time: 0:01:10 \nIter:    660, Train Loss:    0.5, Train Acc:  93.75%, Time: 0:01:18 *\nIter:    690, Train Loss:   0.39, Train Acc:  96.88%, Time: 0:01:26 *\nIter:    720, Train Loss:   0.47, Train Acc:  81.25%, Time: 0:01:27 \nIter:    750, Train Loss:   0.51, Train Acc:  84.38%, Time: 0:01:27 \nIter:    780, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:01:27 \nEpoch: 3\nIter:    810, Train Loss:   0.58, Train Acc:  81.25%, Time: 0:01:27 \nIter:    840, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:01:28 \nIter:    870, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:01:28 \nIter:    900, Train Loss:   0.31, Train Acc:  96.88%, Time: 0:01:28 \nIter:    930, Train Loss:   0.48, Train Acc:  90.62%, Time: 0:01:29 \nIter:    960, Train Loss:    0.4, Train Acc:  93.75%, Time: 0:01:29 \nIter:    990, Train Loss:   0.45, Train Acc:  84.38%, Time: 0:01:29 \nIter:   1020, Train Loss:   0.54, Train Acc:  84.38%, Time: 0:01:29 \nIter:   1050, Train Loss:   0.38, Train Acc:  87.50%, Time: 0:01:30 \nIter:   1080, Train Loss:   0.43, Train Acc:  78.12%, Time: 0:01:30 \nIter:   1110, Train Loss:   0.47, Train Acc:  87.50%, Time: 0:01:30 \nIter:   1140, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:01:30 \nIter:   1170, Train Loss:    0.4, Train Acc:  90.62%, Time: 0:01:31 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/1/1\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/1/1\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.98, Test Acc:  69.51%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.48      0.63      0.55       127\n                   Filter       0.63      0.60      0.62       129\n    Compute Derived Value       0.57      0.63      0.60       131\n            Find Extremum       0.83      0.64      0.72       127\n                     Sort       0.91      0.57      0.70       119\n          Determine Range       0.76      0.89      0.82       125\nCharacterize Distribution       0.79      0.86      0.83       133\n           Find Anomalies       0.56      0.74      0.64       113\n                  Cluster       0.83      0.74      0.78       124\n                Correlate       0.83      0.63      0.72       125\n\n                micro avg       0.70      0.70      0.70      1253\n                macro avg       0.72      0.69      0.70      1253\n             weighted avg       0.72      0.70      0.70      1253\n\nConfusion Matrix...\n[[ 80   3  30   2   2   0  10   0   0   0]\n [  2  78   2   0   1   7   1  30   5   3]\n [ 41   1  83   0   0   5   0   0   0   1]\n [ 29   1  10  81   0   4   1   1   0   0]\n [  0  10  13  13  68  10   2   0   3   0]\n [  1   2   1   0   1 111   3   1   4   1]\n [  5   1   4   1   0   2 115   1   1   3]\n [  5  13   0   1   0   2   1  84   3   4]\n [  2   0   0   0   0   4   4  18  92   4]\n [  0  14   3   0   3   1   8  14   3  79]]\nTime usage: 0:00:00\nFold:  2\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  15.62%, Time: 0:00:11 *\nIter:     60, Train Loss:    2.2, Train Acc:  25.00%, Time: 0:00:19 *\nIter:     90, Train Loss:    2.0, Train Acc:  25.00%, Time: 0:00:19 \nIter:    120, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:19 \nIter:    150, Train Loss:    1.8, Train Acc:  34.38%, Time: 0:00:28 *\nIter:    180, Train Loss:    1.8, Train Acc:  37.50%, Time: 0:00:36 *\nIter:    210, Train Loss:    1.5, Train Acc:  62.50%, Time: 0:00:44 *\nIter:    240, Train Loss:    1.7, Train Acc:  43.75%, Time: 0:00:44 \nIter:    270, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:44 \nIter:    300, Train Loss:    1.0, Train Acc:  71.88%, Time: 0:00:51 *\nIter:    330, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:00:52 \nIter:    360, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:00:52 \nIter:    390, Train Loss:   0.92, Train Acc:  65.62%, Time: 0:00:52 \nEpoch: 2\nIter:    420, Train Loss:   0.86, Train Acc:  81.25%, Time: 0:00:59 *\nIter:    450, Train Loss:   0.96, Train Acc:  65.62%, Time: 0:00:59 \nIter:    480, Train Loss:   0.57, Train Acc:  87.50%, Time: 0:01:05 *\nIter:    510, Train Loss:    0.7, Train Acc:  71.88%, Time: 0:01:05 \nIter:    540, Train Loss:   0.96, Train Acc:  68.75%, Time: 0:01:06 \nIter:    570, Train Loss:   0.71, Train Acc:  87.50%, Time: 0:01:06 \nIter:    600, Train Loss:   0.49, Train Acc:  90.62%, Time: 0:01:12 *\nIter:    630, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:01:13 \nIter:    660, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:01:13 \nIter:    690, Train Loss:   0.77, Train Acc:  78.12%, Time: 0:01:13 \nIter:    720, Train Loss:   0.49, Train Acc:  90.62%, Time: 0:01:13 \nIter:    750, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:01:14 \nIter:    780, Train Loss:   0.51, Train Acc:  93.75%, Time: 0:01:21 *\nEpoch: 3\nIter:    810, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:01:21 \nIter:    840, Train Loss:   0.29, Train Acc:  90.62%, Time: 0:01:21 \nIter:    870, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:21 \nIter:    900, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:01:22 \nIter:    930, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:01:22 \nIter:    960, Train Loss:   0.27, Train Acc:  96.88%, Time: 0:01:29 *\nIter:    990, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:01:30 \nIter:   1020, Train Loss:   0.37, Train Acc:  87.50%, Time: 0:01:30 \nIter:   1050, Train Loss:   0.38, Train Acc:  87.50%, Time: 0:01:30 \nIter:   1080, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:01:30 \nIter:   1110, Train Loss:   0.28, Train Acc:  96.88%, Time: 0:01:31 \nIter:   1140, Train Loss:   0.25, Train Acc:  96.88%, Time: 0:01:31 \nIter:   1170, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:31 \nIter:   1200, Train Loss:   0.28, Train Acc:  96.88%, Time: 0:01:31 \nEpoch: 4\nIter:   1230, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:01:32 \nIter:   1260, Train Loss:   0.15, Train Acc: 100.00%, Time: 0:01:41 *\nIter:   1290, Train Loss:    0.4, Train Acc:  93.75%, Time: 0:01:41 \nIter:   1320, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:41 \nIter:   1350, Train Loss:   0.13, Train Acc:  93.75%, Time: 0:01:42 \nIter:   1380, Train Loss:   0.22, Train Acc:  96.88%, Time: 0:01:42 \nIter:   1410, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:01:42 \nIter:   1440, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:01:42 \nIter:   1470, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:43 \nIter:   1500, Train Loss:   0.13, Train Acc: 100.00%, Time: 0:01:43 \nIter:   1530, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:01:43 \nIter:   1560, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:01:43 \nIter:   1590, Train Loss:   0.26, Train Acc:  90.62%, Time: 0:01:44 \nEpoch: 5\nIter:   1620, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:01:44 \nIter:   1650, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:44 \nIter:   1680, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:01:44 \nIter:   1710, Train Loss:  0.098, Train Acc:  96.88%, Time: 0:01:45 \nIter:   1740, Train Loss:  0.068, Train Acc: 100.00%, Time: 0:01:45 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/2/2\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/2/2\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  66.97%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.70      0.62      0.66       110\n                   Filter       0.67      0.47      0.55       122\n    Compute Derived Value       0.70      0.57      0.63       127\n            Find Extremum       0.63      0.64      0.64       115\n                     Sort       0.84      0.89      0.86       114\n          Determine Range       0.50      0.76      0.60        97\nCharacterize Distribution       0.62      0.80      0.70        92\n           Find Anomalies       0.59      0.85      0.70        94\n                  Cluster       0.65      0.71      0.68        98\n                Correlate       0.94      0.51      0.66       142\n\n                micro avg       0.67      0.67      0.67      1111\n                macro avg       0.68      0.68      0.67      1111\n             weighted avg       0.70      0.67      0.67      1111\n\nConfusion Matrix...\n[[ 68   5  14   6   0   8   4   3   0   2]\n [ 13  57   1  22   5  18   0   3   3   0]\n [  2  11  73   5   0  17   0  18   0   1]\n [ 13   1   5  74   3  13   0   4   1   1]\n [  0   1   0   7 101   2   0   0   3   0]\n [  0   0   6   0   5  74   2   0  10   0]\n [  0   7   0   1   0   7  74   2   1   0]\n [  0   1   1   1   0   1   6  80   3   1]\n [  0   0   0   0   6   4   4  14  70   0]\n [  1   2   4   1   0   5  29  11  16  73]]\nTime usage: 0:00:00\nFold:  3\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  15.62%, Time: 0:00:09 *\nIter:     60, Train Loss:    2.3, Train Acc:  21.88%, Time: 0:00:17 *\nIter:     90, Train Loss:    2.0, Train Acc:  34.38%, Time: 0:00:25 *\nIter:    120, Train Loss:    2.1, Train Acc:  31.25%, Time: 0:00:25 \nIter:    150, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:32 *\nIter:    180, Train Loss:    1.7, Train Acc:  46.88%, Time: 0:00:40 *\nIter:    210, Train Loss:    1.7, Train Acc:  43.75%, Time: 0:00:41 \nIter:    240, Train Loss:    1.7, Train Acc:  37.50%, Time: 0:00:41 \nIter:    270, Train Loss:    1.4, Train Acc:  71.88%, Time: 0:00:50 *\nIter:    300, Train Loss:    1.3, Train Acc:  53.12%, Time: 0:00:51 \nIter:    330, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:00:51 \nIter:    360, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:51 \nIter:    390, Train Loss:    1.1, Train Acc:  71.88%, Time: 0:00:51 \nEpoch: 2\nIter:    420, Train Loss:   0.91, Train Acc:  78.12%, Time: 0:00:58 *\nIter:    450, Train Loss:   0.71, Train Acc:  84.38%, Time: 0:01:08 *\nIter:    480, Train Loss:   0.84, Train Acc:  68.75%, Time: 0:01:08 \nIter:    510, Train Loss:   0.71, Train Acc:  81.25%, Time: 0:01:08 \nIter:    540, Train Loss:    1.0, Train Acc:  68.75%, Time: 0:01:08 \nIter:    570, Train Loss:    1.0, Train Acc:  59.38%, Time: 0:01:09 \nIter:    600, Train Loss:   0.75, Train Acc:  71.88%, Time: 0:01:09 \nIter:    630, Train Loss:   0.44, Train Acc:  84.38%, Time: 0:01:09 \nIter:    660, Train Loss:    0.5, Train Acc:  90.62%, Time: 0:01:17 *\nIter:    690, Train Loss:   0.54, Train Acc:  84.38%, Time: 0:01:17 \nIter:    720, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:01:25 *\nIter:    750, Train Loss:   0.64, Train Acc:  84.38%, Time: 0:01:25 \nIter:    780, Train Loss:   0.62, Train Acc:  90.62%, Time: 0:01:26 \nEpoch: 3\nIter:    810, Train Loss:   0.67, Train Acc:  75.00%, Time: 0:01:26 \nIter:    840, Train Loss:   0.27, Train Acc:  96.88%, Time: 0:01:34 *\nIter:    870, Train Loss:   0.47, Train Acc:  87.50%, Time: 0:01:34 \nIter:    900, Train Loss:   0.58, Train Acc:  87.50%, Time: 0:01:35 \nIter:    930, Train Loss:   0.39, Train Acc:  84.38%, Time: 0:01:35 \nIter:    960, Train Loss:   0.58, Train Acc:  78.12%, Time: 0:01:35 \nIter:    990, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:01:35 \nIter:   1020, Train Loss:   0.45, Train Acc:  87.50%, Time: 0:01:36 \nIter:   1050, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:36 \nIter:   1080, Train Loss:   0.39, Train Acc:  87.50%, Time: 0:01:36 \nIter:   1110, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:01:37 \nIter:   1140, Train Loss:   0.42, Train Acc:  93.75%, Time: 0:01:37 \nIter:   1170, Train Loss:   0.63, Train Acc:  90.62%, Time: 0:01:37 \nIter:   1200, Train Loss:   0.11, Train Acc: 100.00%, Time: 0:01:45 *\nEpoch: 4\nIter:   1230, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:45 \nIter:   1260, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:01:46 \nIter:   1290, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:01:46 \nIter:   1320, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:46 \nIter:   1350, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:01:46 \nIter:   1380, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:01:47 \nIter:   1410, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:01:47 \nIter:   1440, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:01:47 \nIter:   1470, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:47 \nIter:   1500, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:48 \nIter:   1530, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:48 \nIter:   1560, Train Loss:  0.061, Train Acc: 100.00%, Time: 0:01:48 \nIter:   1590, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:48 \nEpoch: 5\nIter:   1620, Train Loss:  0.065, Train Acc: 100.00%, Time: 0:01:49 \nIter:   1650, Train Loss:   0.16, Train Acc: 100.00%, Time: 0:01:49 \nIter:   1680, Train Loss:   0.24, Train Acc:  96.88%, Time: 0:01:49 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/3/3\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/3/3\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  72.65%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.67      0.54      0.60       130\n                   Filter       0.43      0.54      0.48       139\n    Compute Derived Value       0.77      0.72      0.74       128\n            Find Extremum       0.78      0.80      0.79       123\n                     Sort       0.69      0.80      0.74       113\n          Determine Range       0.86      0.59      0.70       132\nCharacterize Distribution       0.81      0.81      0.81       113\n           Find Anomalies       0.82      0.86      0.84       126\n                  Cluster       0.91      0.74      0.82       135\n                Correlate       0.70      0.92      0.79       126\n\n                micro avg       0.73      0.73      0.73      1265\n                macro avg       0.74      0.73      0.73      1265\n             weighted avg       0.74      0.73      0.73      1265\n\nConfusion Matrix...\n[[ 70  22  17   6   3   4   1   0   0   7]\n [ 28  75   6  12  13   3   0   1   0   1]\n [  3  17  92   0   3   0   5   1   0   7]\n [  3   5   0  99   4   0   1   4   5   2]\n [  0  13   0   2  90   1   2   0   2   3]\n [  0   9   3   7  12  78   1   5   1  16]\n [  0   9   2   0   4   4  91   0   2   1]\n [  0   9   0   0   0   0   0 108   0   9]\n [  0  14   0   1   2   1   8   5 100   4]\n [  0   0   0   0   0   0   3   7   0 116]]\nTime usage: 0:00:00\nFold:  4\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:   6.25%, Time: 0:00:09 *\nIter:     60, Train Loss:    2.3, Train Acc:  15.62%, Time: 0:00:17 *\nIter:     90, Train Loss:    2.0, Train Acc:  28.12%, Time: 0:00:23 *\nIter:    120, Train Loss:    2.0, Train Acc:  31.25%, Time: 0:00:31 *\nIter:    150, Train Loss:    1.8, Train Acc:  37.50%, Time: 0:00:38 *\nIter:    180, Train Loss:    1.8, Train Acc:  25.00%, Time: 0:00:39 \nIter:    210, Train Loss:    1.7, Train Acc:  40.62%, Time: 0:00:45 *\nIter:    240, Train Loss:    1.5, Train Acc:  59.38%, Time: 0:00:53 *\nIter:    270, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:53 \nIter:    300, Train Loss:    1.3, Train Acc:  56.25%, Time: 0:00:53 \nIter:    330, Train Loss:   0.84, Train Acc:  78.12%, Time: 0:01:00 *\nIter:    360, Train Loss:   0.92, Train Acc:  81.25%, Time: 0:01:07 *\nEpoch: 2\nIter:    390, Train Loss:   0.78, Train Acc:  84.38%, Time: 0:01:15 *\nIter:    420, Train Loss:   0.92, Train Acc:  84.38%, Time: 0:01:16 \nIter:    450, Train Loss:   0.98, Train Acc:  68.75%, Time: 0:01:16 \nIter:    480, Train Loss:   0.55, Train Acc:  93.75%, Time: 0:01:24 *\nIter:    510, Train Loss:   0.75, Train Acc:  81.25%, Time: 0:01:24 \nIter:    540, Train Loss:   0.56, Train Acc:  84.38%, Time: 0:01:25 \nIter:    570, Train Loss:   0.63, Train Acc:  84.38%, Time: 0:01:25 \nIter:    600, Train Loss:   0.81, Train Acc:  78.12%, Time: 0:01:25 \nIter:    630, Train Loss:   0.67, Train Acc:  90.62%, Time: 0:01:25 \nIter:    660, Train Loss:   0.44, Train Acc:  87.50%, Time: 0:01:26 \nIter:    690, Train Loss:   0.39, Train Acc:  93.75%, Time: 0:01:26 \nIter:    720, Train Loss:   0.57, Train Acc:  78.12%, Time: 0:01:26 \nIter:    750, Train Loss:   0.53, Train Acc:  90.62%, Time: 0:01:26 \nEpoch: 3\nIter:    780, Train Loss:   0.27, Train Acc:  96.88%, Time: 0:01:33 *\nIter:    810, Train Loss:   0.74, Train Acc:  78.12%, Time: 0:01:34 \nIter:    840, Train Loss:   0.39, Train Acc:  93.75%, Time: 0:01:34 \nIter:    870, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:34 \nIter:    900, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:01:34 \nIter:    930, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:01:35 \nIter:    960, Train Loss:   0.56, Train Acc:  81.25%, Time: 0:01:35 \nIter:    990, Train Loss:    0.4, Train Acc:  87.50%, Time: 0:01:35 \nIter:   1020, Train Loss:   0.57, Train Acc:  81.25%, Time: 0:01:35 \nIter:   1050, Train Loss:   0.59, Train Acc:  90.62%, Time: 0:01:36 \nIter:   1080, Train Loss:   0.19, Train Acc: 100.00%, Time: 0:01:43 *\nIter:   1110, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:01:43 \nIter:   1140, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:43 \nEpoch: 4\nIter:   1170, Train Loss:   0.27, Train Acc:  90.62%, Time: 0:01:44 \nIter:   1200, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:01:44 \nIter:   1230, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:01:44 \nIter:   1260, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:44 \nIter:   1290, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:45 \nIter:   1320, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:01:45 \nIter:   1350, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:45 \nIter:   1380, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:01:45 \nIter:   1410, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:46 \nIter:   1440, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:01:46 \nIter:   1470, Train Loss:   0.12, Train Acc: 100.00%, Time: 0:01:46 \nIter:   1500, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:47 \nIter:   1530, Train Loss:   0.15, Train Acc:  93.75%, Time: 0:01:47 \nEpoch: 5\nIter:   1560, Train Loss:   0.24, Train Acc:  90.62%, Time: 0:01:47 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/4/4\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/4/4\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.2, Test Acc:  65.30%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.35      0.42      0.38       113\n                   Filter       0.59      0.44      0.50       116\n    Compute Derived Value       0.52      0.46      0.49       206\n            Find Extremum       0.82      0.84      0.83       329\n                     Sort       0.85      0.86      0.85       115\n          Determine Range       0.46      0.59      0.52       121\nCharacterize Distribution       0.60      0.67      0.63       173\n           Find Anomalies       0.77      0.50      0.60       121\n                  Cluster       0.80      0.77      0.79       127\n                Correlate       0.68      0.74      0.71       184\n\n                micro avg       0.65      0.65      0.65      1605\n                macro avg       0.64      0.63      0.63      1605\n             weighted avg       0.66      0.65      0.65      1605\n\nConfusion Matrix...\n[[ 48   2  18   2   0  16  16   9   0   2]\n [  4  51  28   0   3  12   6   4   0   8]\n [ 30   2  94   9   7  27  25   0   1  11]\n [ 13   2  16 275   2  17   3   1   0   0]\n [  0   0   1  13  99   2   0   0   0   0]\n [ 11  12   1  17   2  71   0   0   2   5]\n [ 19   1   0   1   0   6 116   1   7  22]\n [  0  17   2  18   0   2   3  60  11   8]\n [  0   0   2   0   4   1  13   1  98   8]\n [ 12   0  18   2   0   0  11   2   3 136]]\nTime usage: 0:00:00\nFold:  5\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:   9.38%, Time: 0:00:08 *\nIter:     60, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:16 *\nIter:     90, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:26 *\nIter:    120, Train Loss:    1.8, Train Acc:  43.75%, Time: 0:00:36 *\nIter:    150, Train Loss:    1.8, Train Acc:  37.50%, Time: 0:00:36 \nIter:    180, Train Loss:    1.9, Train Acc:  40.62%, Time: 0:00:37 \nIter:    210, Train Loss:    1.5, Train Acc:  59.38%, Time: 0:00:47 *\nIter:    240, Train Loss:    1.5, Train Acc:  56.25%, Time: 0:00:47 \nIter:    270, Train Loss:    1.1, Train Acc:  75.00%, Time: 0:00:58 *\nIter:    300, Train Loss:    1.3, Train Acc:  50.00%, Time: 0:00:58 \nIter:    330, Train Loss:    1.1, Train Acc:  59.38%, Time: 0:00:59 \nIter:    360, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:59 \nEpoch: 2\nIter:    390, Train Loss:   0.77, Train Acc:  84.38%, Time: 0:01:11 *\nIter:    420, Train Loss:   0.57, Train Acc:  90.62%, Time: 0:01:22 *\nIter:    450, Train Loss:    0.6, Train Acc:  93.75%, Time: 0:01:32 *\nIter:    480, Train Loss:   0.74, Train Acc:  84.38%, Time: 0:01:32 \nIter:    510, Train Loss:    1.0, Train Acc:  75.00%, Time: 0:01:33 \nIter:    540, Train Loss:   0.94, Train Acc:  68.75%, Time: 0:01:33 \nIter:    570, Train Loss:   0.54, Train Acc: 100.00%, Time: 0:01:43 *\nIter:    600, Train Loss:   0.61, Train Acc:  87.50%, Time: 0:01:43 \nIter:    630, Train Loss:    0.7, Train Acc:  75.00%, Time: 0:01:44 \nIter:    660, Train Loss:   0.54, Train Acc:  81.25%, Time: 0:01:44 \nIter:    690, Train Loss:    1.1, Train Acc:  62.50%, Time: 0:01:44 \nIter:    720, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:01:44 \nIter:    750, Train Loss:   0.39, Train Acc:  90.62%, Time: 0:01:45 \nEpoch: 3\nIter:    780, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:01:45 \nIter:    810, Train Loss:   0.45, Train Acc:  90.62%, Time: 0:01:45 \nIter:    840, Train Loss:    0.4, Train Acc:  84.38%, Time: 0:01:46 \nIter:    870, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:01:46 \nIter:    900, Train Loss:   0.27, Train Acc:  87.50%, Time: 0:01:46 \nIter:    930, Train Loss:   0.35, Train Acc:  96.88%, Time: 0:01:46 \nIter:    960, Train Loss:   0.56, Train Acc:  84.38%, Time: 0:01:47 \nIter:    990, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:47 \nIter:   1020, Train Loss:    0.6, Train Acc:  84.38%, Time: 0:01:47 \nIter:   1050, Train Loss:   0.39, Train Acc:  96.88%, Time: 0:01:47 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/5/5\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/5/5\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.3, Test Acc:  59.38%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.55      0.62      0.58       185\n                   Filter       0.42      0.36      0.38       180\n    Compute Derived Value       0.59      0.27      0.37       249\n            Find Extremum       0.54      0.83      0.65       183\n                     Sort       0.73      0.74      0.73       117\n          Determine Range       0.46      0.45      0.46       206\nCharacterize Distribution       0.53      0.88      0.66       117\n           Find Anomalies       0.81      0.73      0.77       170\n                  Cluster       0.64      0.74      0.69       129\n                Correlate       0.84      0.65      0.73       192\n\n                micro avg       0.59      0.59      0.59      1728\n                macro avg       0.61      0.63      0.60      1728\n             weighted avg       0.60      0.59      0.58      1728\n\nConfusion Matrix...\n[[115   8   6  33   3  16   0   0   3   1]\n [  3  64  26  24   7  34   3   8   9   2]\n [ 26  10  68  35   1  32  62   4   1  10]\n [ 22   3   0 152   4   1   0   0   0   1]\n [  0   9   2   5  86   8   0   1   5   1]\n [ 23  34   5  17  11  93   6   1  15   1]\n [  1   0   1   3   1   6 103   0   1   1]\n [ 12   5   4   4   0   3   8 124   6   4]\n [  0   8   1   3   4   3   6   5  96   3]\n [  8  12   3   6   1   6   5  11  15 125]]\nTime usage: 0:00:00\nFold:  6\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:   6.25%, Time: 0:00:11 *\nIter:     60, Train Loss:    2.3, Train Acc:  12.50%, Time: 0:00:18 *\nIter:     90, Train Loss:    2.1, Train Acc:  21.88%, Time: 0:00:26 *\nIter:    120, Train Loss:    1.9, Train Acc:  37.50%, Time: 0:00:33 *\nIter:    150, Train Loss:    1.9, Train Acc:  34.38%, Time: 0:00:34 \nIter:    180, Train Loss:    1.6, Train Acc:  56.25%, Time: 0:00:48 *\nIter:    210, Train Loss:    1.7, Train Acc:  40.62%, Time: 0:00:48 \nIter:    240, Train Loss:    1.6, Train Acc:  53.12%, Time: 0:00:48 \nIter:    270, Train Loss:    1.5, Train Acc:  62.50%, Time: 0:00:59 *\nIter:    300, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:01:11 *\nIter:    330, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:01:11 \nIter:    360, Train Loss:   0.88, Train Acc:  81.25%, Time: 0:01:21 *\nIter:    390, Train Loss:    1.1, Train Acc:  62.50%, Time: 0:01:21 \nEpoch: 2\nIter:    420, Train Loss:   0.75, Train Acc:  87.50%, Time: 0:01:31 *\nIter:    450, Train Loss:   0.85, Train Acc:  81.25%, Time: 0:01:32 \nIter:    480, Train Loss:   0.78, Train Acc:  78.12%, Time: 0:01:32 \nIter:    510, Train Loss:   0.83, Train Acc:  75.00%, Time: 0:01:32 \nIter:    540, Train Loss:   0.85, Train Acc:  75.00%, Time: 0:01:32 \nIter:    570, Train Loss:   0.81, Train Acc:  71.88%, Time: 0:01:33 \nIter:    600, Train Loss:   0.88, Train Acc:  71.88%, Time: 0:01:33 \nIter:    630, Train Loss:   0.65, Train Acc:  84.38%, Time: 0:01:33 \nIter:    660, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:01:40 *\nIter:    690, Train Loss:   0.49, Train Acc:  87.50%, Time: 0:01:40 \nIter:    720, Train Loss:   0.61, Train Acc:  78.12%, Time: 0:01:40 \nIter:    750, Train Loss:    0.6, Train Acc:  90.62%, Time: 0:01:40 \nIter:    780, Train Loss:    0.6, Train Acc:  87.50%, Time: 0:01:41 \nEpoch: 3\nIter:    810, Train Loss:    0.3, Train Acc:  96.88%, Time: 0:01:48 *\nIter:    840, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:01:48 \nIter:    870, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:01:49 \nIter:    900, Train Loss:   0.29, Train Acc:  96.88%, Time: 0:01:49 \nIter:    930, Train Loss:   0.42, Train Acc:  90.62%, Time: 0:01:49 \nIter:    960, Train Loss:   0.25, Train Acc:  96.88%, Time: 0:01:49 \nIter:    990, Train Loss:   0.24, Train Acc:  90.62%, Time: 0:01:50 \nIter:   1020, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:50 \nIter:   1050, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:01:50 \nIter:   1080, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:01:50 \nIter:   1110, Train Loss:    0.4, Train Acc:  87.50%, Time: 0:01:51 \nIter:   1140, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:01:51 \nIter:   1170, Train Loss:   0.32, Train Acc:  96.88%, Time: 0:01:51 \nIter:   1200, Train Loss:  0.099, Train Acc: 100.00%, Time: 0:02:03 *\nEpoch: 4\nIter:   1230, Train Loss:  0.075, Train Acc: 100.00%, Time: 0:02:04 \nIter:   1260, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:02:04 \nIter:   1290, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:02:04 \nIter:   1320, Train Loss:   0.22, Train Acc:  90.62%, Time: 0:02:04 \nIter:   1350, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:02:05 \nIter:   1380, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:02:05 \nIter:   1410, Train Loss:    0.3, Train Acc:  90.62%, Time: 0:02:05 \nIter:   1440, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:02:05 \nIter:   1470, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:02:06 \nIter:   1500, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:02:06 \nIter:   1530, Train Loss:    0.4, Train Acc:  84.38%, Time: 0:02:06 \nIter:   1560, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:02:07 \nIter:   1590, Train Loss:   0.09, Train Acc: 100.00%, Time: 0:02:07 \nEpoch: 5\nIter:   1620, Train Loss:  0.086, Train Acc: 100.00%, Time: 0:02:07 \nIter:   1650, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:02:07 \nIter:   1680, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:02:08 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/6/6\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/6/6\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.4, Test Acc:  61.41%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.60      0.66      0.63       114\n                   Filter       0.50      0.70      0.58       129\n    Compute Derived Value       0.46      0.33      0.38       120\n            Find Extremum       0.51      0.81      0.62       120\n                     Sort       0.84      0.90      0.87       119\n          Determine Range       0.67      0.71      0.69       129\nCharacterize Distribution       0.84      0.70      0.77       121\n           Find Anomalies       0.68      0.31      0.43       128\n                  Cluster       0.75      0.50      0.60       121\n                Correlate       0.48      0.54      0.51       117\n\n                micro avg       0.61      0.61      0.61      1218\n                macro avg       0.63      0.62      0.61      1218\n             weighted avg       0.63      0.61      0.61      1218\n\nConfusion Matrix...\n[[ 75   5  13   1   2   1  11   0   0   6]\n [  5  90  13  10   0   3   1   7   0   0]\n [  1   9  39  36   0   1   0   4   0  30]\n [  1  19   1  97   0   1   0   0   0   1]\n [  0   0   3   3 107   1   1   0   4   0]\n [ 10   8   8   5   1  92   0   0   0   5]\n [  0   0   6  15   2   7  85   1   2   3]\n [ 17  26   0   8   1  15   0  40   4  17]\n [ 15  13   0   0   8  15   1   3  60   6]\n [  1  11   2  16   7   1   2   4  10  63]]\nTime usage: 0:00:00\nFold:  7\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:10 *\nIter:     60, Train Loss:    2.3, Train Acc:  12.50%, Time: 0:00:10 \nIter:     90, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:10 \nIter:    120, Train Loss:    1.9, Train Acc:  46.88%, Time: 0:00:19 *\nIter:    150, Train Loss:    1.8, Train Acc:  50.00%, Time: 0:00:30 *\nIter:    180, Train Loss:    1.8, Train Acc:  46.88%, Time: 0:00:30 \nIter:    210, Train Loss:    1.4, Train Acc:  59.38%, Time: 0:00:40 *\nIter:    240, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:40 \nIter:    270, Train Loss:    1.5, Train Acc:  59.38%, Time: 0:00:40 \nIter:    300, Train Loss:    1.1, Train Acc:  71.88%, Time: 0:00:49 *\nIter:    330, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:50 \nIter:    360, Train Loss:    1.0, Train Acc:  68.75%, Time: 0:00:50 \nIter:    390, Train Loss:    0.9, Train Acc:  78.12%, Time: 0:00:59 *\nEpoch: 2\nIter:    420, Train Loss:   0.81, Train Acc:  87.50%, Time: 0:01:09 *\nIter:    450, Train Loss:    0.8, Train Acc:  81.25%, Time: 0:01:10 \nIter:    480, Train Loss:   0.71, Train Acc:  78.12%, Time: 0:01:10 \nIter:    510, Train Loss:   0.69, Train Acc:  84.38%, Time: 0:01:10 \nIter:    540, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:01:10 \nIter:    570, Train Loss:   0.76, Train Acc:  75.00%, Time: 0:01:11 \nIter:    600, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:01:18 *\nIter:    630, Train Loss:    0.8, Train Acc:  75.00%, Time: 0:01:19 \nIter:    660, Train Loss:    0.5, Train Acc:  90.62%, Time: 0:01:19 \nIter:    690, Train Loss:   0.49, Train Acc:  90.62%, Time: 0:01:19 \nIter:    720, Train Loss:   0.59, Train Acc:  81.25%, Time: 0:01:20 \nIter:    750, Train Loss:   0.54, Train Acc:  90.62%, Time: 0:01:20 \nIter:    780, Train Loss:   0.44, Train Acc:  93.75%, Time: 0:01:30 *\nEpoch: 3\nIter:    810, Train Loss:    0.5, Train Acc:  78.12%, Time: 0:01:30 \nIter:    840, Train Loss:   0.59, Train Acc:  75.00%, Time: 0:01:30 \nIter:    870, Train Loss:    0.2, Train Acc: 100.00%, Time: 0:01:38 *\nIter:    900, Train Loss:    0.4, Train Acc:  90.62%, Time: 0:01:38 \nIter:    930, Train Loss:    0.5, Train Acc:  81.25%, Time: 0:01:38 \nIter:    960, Train Loss:   0.47, Train Acc:  93.75%, Time: 0:01:39 \nIter:    990, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:39 \nIter:   1020, Train Loss:   0.34, Train Acc:  96.88%, Time: 0:01:39 \nIter:   1050, Train Loss:   0.39, Train Acc:  87.50%, Time: 0:01:39 \nIter:   1080, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:40 \nIter:   1110, Train Loss:   0.47, Train Acc:  84.38%, Time: 0:01:40 \nIter:   1140, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:01:40 \nIter:   1170, Train Loss:   0.36, Train Acc:  93.75%, Time: 0:01:40 \nIter:   1200, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:41 \nEpoch: 4\nIter:   1230, Train Loss:   0.16, Train Acc: 100.00%, Time: 0:01:41 \nIter:   1260, Train Loss:   0.29, Train Acc:  90.62%, Time: 0:01:41 \nIter:   1290, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:41 \nIter:   1320, Train Loss:   0.13, Train Acc: 100.00%, Time: 0:01:42 \nIter:   1350, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:42 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/7/7\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/7/7\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.4, Test Acc:  61.22%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.46      0.44      0.45       117\n                   Filter       0.35      0.33      0.34       112\n    Compute Derived Value       0.51      0.22      0.31       130\n            Find Extremum       0.49      0.85      0.62       120\n                     Sort       0.76      0.89      0.82       118\n          Determine Range       0.64      0.53      0.58       123\nCharacterize Distribution       0.83      0.49      0.62       128\n           Find Anomalies       0.74      0.50      0.60       124\n                  Cluster       0.82      0.92      0.87       118\n                Correlate       0.60      0.97      0.74       127\n\n                micro avg       0.61      0.61      0.61      1217\n                macro avg       0.62      0.61      0.59      1217\n             weighted avg       0.62      0.61      0.59      1217\n\nConfusion Matrix...\n[[ 51   5   0  34  16   2   0   0   0   9]\n [ 16  37   1   2   5  12   0  17   9  13]\n [ 32  16  29  41   0   3   1   0   0   8]\n [  1   8   0 102   7   1   0   0   1   0]\n [  1   2   0   6 105   1   0   0   3   0]\n [  9  23  11   5   2  65   2   0   0   6]\n [  0   2  12  14   1   5  63   1   0  30]\n [  1  12   4   2   0  12  10  62   8  13]\n [  0   0   0   0   2   0   0   4 108   4]\n [  0   0   0   1   0   1   0   0   2 123]]\nTime usage: 0:00:00\nFold:  8\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:  15.62%, Time: 0:00:10 *\nIter:     60, Train Loss:    2.4, Train Acc:  21.88%, Time: 0:00:22 *\nIter:     90, Train Loss:    2.2, Train Acc:  12.50%, Time: 0:00:22 \nIter:    120, Train Loss:    2.0, Train Acc:  46.88%, Time: 0:00:31 *\nIter:    150, Train Loss:    1.8, Train Acc:  43.75%, Time: 0:00:32 \nIter:    180, Train Loss:    1.9, Train Acc:  34.38%, Time: 0:00:32 \nIter:    210, Train Loss:    1.5, Train Acc:  65.62%, Time: 0:00:38 *\nIter:    240, Train Loss:    1.4, Train Acc:  59.38%, Time: 0:00:38 \nIter:    270, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:39 \nIter:    300, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:39 \nIter:    330, Train Loss:    1.3, Train Acc:  50.00%, Time: 0:00:39 \nIter:    360, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:00:39 \nIter:    390, Train Loss:    1.0, Train Acc:  75.00%, Time: 0:00:50 *\nEpoch: 2\nIter:    420, Train Loss:    0.9, Train Acc:  84.38%, Time: 0:01:00 *\nIter:    450, Train Loss:    1.0, Train Acc:  68.75%, Time: 0:01:00 \nIter:    480, Train Loss:   0.54, Train Acc:  96.88%, Time: 0:01:09 *\nIter:    510, Train Loss:   0.64, Train Acc:  84.38%, Time: 0:01:10 \nIter:    540, Train Loss:    0.6, Train Acc:  81.25%, Time: 0:01:10 \nIter:    570, Train Loss:   0.62, Train Acc:  93.75%, Time: 0:01:10 \nIter:    600, Train Loss:   0.61, Train Acc:  90.62%, Time: 0:01:11 \nIter:    630, Train Loss:   0.85, Train Acc:  75.00%, Time: 0:01:11 \nIter:    660, Train Loss:   0.57, Train Acc:  84.38%, Time: 0:01:11 \nIter:    690, Train Loss:   0.59, Train Acc:  84.38%, Time: 0:01:11 \nIter:    720, Train Loss:   0.81, Train Acc:  78.12%, Time: 0:01:12 \nIter:    750, Train Loss:   0.46, Train Acc:  93.75%, Time: 0:01:12 \nIter:    780, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:01:12 \nEpoch: 3\nIter:    810, Train Loss:   0.51, Train Acc:  87.50%, Time: 0:01:12 \nIter:    840, Train Loss:   0.36, Train Acc:  93.75%, Time: 0:01:13 \nIter:    870, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:01:13 \nIter:    900, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:01:13 \nIter:    930, Train Loss:   0.23, Train Acc:  90.62%, Time: 0:01:13 \nIter:    960, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:14 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/8/8\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/8/8\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.2, Test Acc:  61.70%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.39      0.53      0.45       119\n                   Filter       0.51      0.54      0.53       128\n    Compute Derived Value       0.38      0.63      0.47       125\n            Find Extremum       0.67      0.66      0.66       131\n                     Sort       0.85      0.74      0.79       129\n          Determine Range       0.62      0.41      0.50       123\nCharacterize Distribution       0.96      0.75      0.84       134\n           Find Anomalies       0.76      0.38      0.51       144\n                  Cluster       0.95      0.70      0.80       148\n                Correlate       0.54      0.83      0.65       127\n\n                micro avg       0.62      0.62      0.62      1308\n                macro avg       0.66      0.62      0.62      1308\n             weighted avg       0.67      0.62      0.63      1308\n\nConfusion Matrix...\n[[ 63  13  18   8   0   6   0   0   0  11]\n [ 20  69  28   0   4   3   0   1   0   3]\n [ 19   4  79   4   4   0   0   0   0  15]\n [  1   1  35  86   4   2   1   1   0   0]\n [  2   4   9   7  95   8   0   0   1   3]\n [ 47   2   2  16   2  51   1   0   1   1]\n [  5   0  12   1   3   9 100   0   1   3]\n [  0  34  15   3   0   0   0  55   1  36]\n [  5   1   1   2   0   2   2  12 103  20]\n [  0   6   9   1   0   1   0   3   1 106]]\nTime usage: 0:00:00\nFold:  9\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  15.62%, Time: 0:00:10 *\nIter:     60, Train Loss:    2.3, Train Acc:   9.38%, Time: 0:00:11 \nIter:     90, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:17 *\nIter:    120, Train Loss:    2.2, Train Acc:  18.75%, Time: 0:00:18 \nIter:    150, Train Loss:    1.8, Train Acc:  43.75%, Time: 0:00:25 *\nIter:    180, Train Loss:    1.9, Train Acc:  40.62%, Time: 0:00:25 \nIter:    210, Train Loss:    1.6, Train Acc:  50.00%, Time: 0:00:35 *\nIter:    240, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:49 *\nIter:    270, Train Loss:    1.3, Train Acc:  71.88%, Time: 0:00:58 *\nIter:    300, Train Loss:    1.4, Train Acc:  62.50%, Time: 0:00:59 \nIter:    330, Train Loss:    1.4, Train Acc:  56.25%, Time: 0:00:59 \nIter:    360, Train Loss:   0.96, Train Acc:  78.12%, Time: 0:01:06 *\nEpoch: 2\nIter:    390, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:01:07 \nIter:    420, Train Loss:    1.0, Train Acc:  71.88%, Time: 0:01:07 \nIter:    450, Train Loss:    0.8, Train Acc:  81.25%, Time: 0:01:15 *\nIter:    480, Train Loss:   0.67, Train Acc:  81.25%, Time: 0:01:16 \nIter:    510, Train Loss:   0.87, Train Acc:  78.12%, Time: 0:01:16 \nIter:    540, Train Loss:   0.69, Train Acc:  71.88%, Time: 0:01:16 \nIter:    570, Train Loss:    1.0, Train Acc:  78.12%, Time: 0:01:16 \nIter:    600, Train Loss:    0.6, Train Acc:  84.38%, Time: 0:01:24 *\nIter:    630, Train Loss:   0.76, Train Acc:  81.25%, Time: 0:01:24 \nIter:    660, Train Loss:   0.64, Train Acc:  84.38%, Time: 0:01:25 \nIter:    690, Train Loss:   0.43, Train Acc:  96.88%, Time: 0:01:33 *\nIter:    720, Train Loss:    0.6, Train Acc:  81.25%, Time: 0:01:33 \nIter:    750, Train Loss:   0.49, Train Acc:  87.50%, Time: 0:01:33 \nEpoch: 3\nIter:    780, Train Loss:   0.44, Train Acc:  87.50%, Time: 0:01:34 \nIter:    810, Train Loss:   0.51, Train Acc:  84.38%, Time: 0:01:34 \nIter:    840, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:01:34 \nIter:    870, Train Loss:   0.48, Train Acc:  84.38%, Time: 0:01:34 \nIter:    900, Train Loss:   0.69, Train Acc:  75.00%, Time: 0:01:35 \nIter:    930, Train Loss:   0.66, Train Acc:  81.25%, Time: 0:01:35 \nIter:    960, Train Loss:   0.49, Train Acc:  84.38%, Time: 0:01:35 \nIter:    990, Train Loss:   0.46, Train Acc:  87.50%, Time: 0:01:35 \nIter:   1020, Train Loss:   0.51, Train Acc:  90.62%, Time: 0:01:36 \nIter:   1050, Train Loss:    0.5, Train Acc:  84.38%, Time: 0:01:36 \nIter:   1080, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:36 \nIter:   1110, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:01:37 \nIter:   1140, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:01:37 \nEpoch: 4\nIter:   1170, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:37 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/9/9\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/9/9\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.95, Test Acc:  71.29%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.72      0.90      0.80       236\n                   Filter       0.53      0.61      0.57       218\n    Compute Derived Value       0.75      0.52      0.62       168\n            Find Extremum       0.73      0.86      0.79       201\n                     Sort       0.94      0.65      0.77       128\n          Determine Range       0.59      0.68      0.63       128\nCharacterize Distribution       1.00      0.67      0.80       172\n           Find Anomalies       0.60      0.78      0.68       216\n                  Cluster       0.68      0.71      0.69       124\n                Correlate       0.97      0.65      0.78       206\n\n                micro avg       0.71      0.71      0.71      1797\n                macro avg       0.75      0.70      0.71      1797\n             weighted avg       0.75      0.71      0.71      1797\n\nConfusion Matrix...\n[[213   1   6   7   0   2   0   6   1   0]\n [ 14 132   5  24   0  14   0  29   0   0]\n [ 29  27  88   3   0   9   0  10   2   0]\n [  5  12   0 172   4   3   0   5   0   0]\n [  9  11   0  10  83   7   0   0   8   0]\n [  3   5   8  16   0  87   0   5   3   1]\n [  3  17   4   1   0  10 115   1  21   0]\n [  2  24   2   1   0  14   0 169   3   1]\n [ 11   3   3   3   1   0   0  13  88   2]\n [  8  15   1   0   0   2   0  42   4 134]]\nTime usage: 0:00:00\nFold:  10\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:   6.25%, Time: 0:00:08 *\nIter:     60, Train Loss:    2.3, Train Acc:   6.25%, Time: 0:00:08 \nIter:     90, Train Loss:    2.2, Train Acc:  25.00%, Time: 0:00:15 *\nIter:    120, Train Loss:    2.0, Train Acc:  46.88%, Time: 0:00:23 *\nIter:    150, Train Loss:    1.9, Train Acc:  43.75%, Time: 0:00:23 \nIter:    180, Train Loss:    1.9, Train Acc:  34.38%, Time: 0:00:23 \nIter:    210, Train Loss:    1.6, Train Acc:  59.38%, Time: 0:00:32 *\nIter:    240, Train Loss:    1.8, Train Acc:  34.38%, Time: 0:00:32 \nIter:    270, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:39 *\nIter:    300, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:39 \nIter:    330, Train Loss:    1.4, Train Acc:  56.25%, Time: 0:00:39 \nIter:    360, Train Loss:    1.0, Train Acc:  75.00%, Time: 0:00:52 *\nIter:    390, Train Loss:    0.9, Train Acc:  78.12%, Time: 0:01:02 *\nEpoch: 2\nIter:    420, Train Loss:   0.99, Train Acc:  68.75%, Time: 0:01:02 \nIter:    450, Train Loss:    1.0, Train Acc:  68.75%, Time: 0:01:03 \nIter:    480, Train Loss:   0.57, Train Acc:  90.62%, Time: 0:01:13 *\nIter:    510, Train Loss:   0.96, Train Acc:  75.00%, Time: 0:01:13 \nIter:    540, Train Loss:   0.58, Train Acc:  87.50%, Time: 0:01:13 \nIter:    570, Train Loss:   0.77, Train Acc:  81.25%, Time: 0:01:14 \nIter:    600, Train Loss:   0.51, Train Acc:  90.62%, Time: 0:01:14 \nIter:    630, Train Loss:   0.65, Train Acc:  84.38%, Time: 0:01:14 \nIter:    660, Train Loss:   0.48, Train Acc:  87.50%, Time: 0:01:14 \nIter:    690, Train Loss:   0.55, Train Acc:  84.38%, Time: 0:01:15 \nIter:    720, Train Loss:    0.5, Train Acc:  81.25%, Time: 0:01:15 \nIter:    750, Train Loss:   0.37, Train Acc:  93.75%, Time: 0:01:22 *\nIter:    780, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:01:22 \nEpoch: 3\nIter:    810, Train Loss:   0.33, Train Acc:  87.50%, Time: 0:01:23 \nIter:    840, Train Loss:   0.78, Train Acc:  81.25%, Time: 0:01:23 \nIter:    870, Train Loss:   0.57, Train Acc:  78.12%, Time: 0:01:23 \nIter:    900, Train Loss:   0.62, Train Acc:  84.38%, Time: 0:01:23 \nIter:    930, Train Loss:   0.52, Train Acc:  81.25%, Time: 0:01:24 \nIter:    960, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:01:24 \nIter:    990, Train Loss:   0.47, Train Acc:  90.62%, Time: 0:01:24 \nIter:   1020, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:01:24 \nIter:   1050, Train Loss:   0.44, Train Acc:  87.50%, Time: 0:01:25 \nIter:   1080, Train Loss:   0.34, Train Acc:  87.50%, Time: 0:01:25 \nIter:   1110, Train Loss:    0.4, Train Acc:  87.50%, Time: 0:01:25 \nIter:   1140, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:01:33 *\nIter:   1170, Train Loss:   0.43, Train Acc:  84.38%, Time: 0:01:33 \nEpoch: 4\nIter:   1200, Train Loss:   0.35, Train Acc:  81.25%, Time: 0:01:33 \nIter:   1230, Train Loss:   0.16, Train Acc:  93.75%, Time: 0:01:34 \nIter:   1260, Train Loss:   0.39, Train Acc:  90.62%, Time: 0:01:34 \nIter:   1290, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:01:34 \nIter:   1320, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:34 \nIter:   1350, Train Loss:   0.26, Train Acc:  96.88%, Time: 0:01:35 \nIter:   1380, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:01:35 \nIter:   1410, Train Loss:   0.15, Train Acc: 100.00%, Time: 0:01:45 *\nIter:   1440, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:01:45 \nIter:   1470, Train Loss:   0.13, Train Acc:  93.75%, Time: 0:01:45 \nIter:   1500, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:01:45 \nIter:   1530, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:01:46 \nIter:   1560, Train Loss:   0.22, Train Acc: 100.00%, Time: 0:01:46 \nEpoch: 5\nIter:   1590, Train Loss:    0.1, Train Acc: 100.00%, Time: 0:01:46 \nIter:   1620, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:01:46 \nIter:   1650, Train Loss:  0.078, Train Acc: 100.00%, Time: 0:01:47 \nIter:   1680, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:47 \nIter:   1710, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:47 \nIter:   1740, Train Loss:  0.086, Train Acc: 100.00%, Time: 0:01:47 \nIter:   1770, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:48 \nIter:   1800, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:48 \nIter:   1830, Train Loss:   0.12, Train Acc: 100.00%, Time: 0:01:48 \nIter:   1860, Train Loss:   0.35, Train Acc:  93.75%, Time: 0:01:49 \nIter:   1890, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:01:49 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/10/10\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/expert/10/10\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.96, Test Acc:  71.56%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.64      0.42      0.51       113\n                   Filter       0.77      0.65      0.70       179\n    Compute Derived Value       0.48      0.95      0.64       151\n            Find Extremum       0.81      0.62      0.70       211\n                     Sort       0.83      0.60      0.70       134\n          Determine Range       0.72      0.77      0.74       138\nCharacterize Distribution       0.87      0.80      0.84       146\n           Find Anomalies       0.69      0.66      0.68       137\n                  Cluster       0.91      0.88      0.90       146\n                Correlate       0.68      0.77      0.72       178\n\n                micro avg       0.72      0.72      0.72      1533\n                macro avg       0.74      0.71      0.71      1533\n             weighted avg       0.74      0.72      0.72      1533\n\nConfusion Matrix...\n[[ 47   0  49   1   0   4   5   7   0   0]\n [  4 116  32   6   0   3   1  10   1   6]\n [  1   1 143   0   0   3   1   0   1   1]\n [ 10   9   5 130   8  23   1  20   1   4]\n [  8   1   8  14  81   1   3   0   7  11]\n [  2   9   3   9   0 106   3   0   0   6]\n [  0   2   7   0   0   1 117   3   1  15]\n [  1   9  16   0   1   0   1  91   1  17]\n [  0   0   2   0   8   3   0   0 129   4]\n [  0   4  30   0   0   4   2   1   0 137]]\nTime usage: 0:00:00\n[0.6951316840060692, 0.6696669667503192, 0.726482213721445, 0.6529595016319061, 0.59375, 0.6141215106732348, 0.6121610517666393, 0.6169724766996658, 0.7128547579298832, 0.7155903451829974]\n0.660969050836216, 0.04722868953965354, 0.04978340995009147, 0.00223054911563298\nbundle\n920 15 14 41\nFold:  1\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.2, Train Acc:  15.62%, Time: 0:00:08 *\nIter:     60, Train Loss:    2.1, Train Acc:  34.38%, Time: 0:00:14 *\nIter:     90, Train Loss:    2.1, Train Acc:  31.25%, Time: 0:00:14 \nIter:    120, Train Loss:    2.0, Train Acc:  31.25%, Time: 0:00:15 \nIter:    150, Train Loss:    1.9, Train Acc:  34.38%, Time: 0:00:15 \nIter:    180, Train Loss:    1.4, Train Acc:  68.75%, Time: 0:00:22 *\nIter:    210, Train Loss:    1.4, Train Acc:  53.12%, Time: 0:00:22 \nIter:    240, Train Loss:    1.5, Train Acc:  56.25%, Time: 0:00:22 \nIter:    270, Train Loss:    1.3, Train Acc:  56.25%, Time: 0:00:23 \nIter:    300, Train Loss:    1.3, Train Acc:  56.25%, Time: 0:00:23 \nIter:    330, Train Loss:    1.1, Train Acc:  62.50%, Time: 0:00:23 \nIter:    360, Train Loss:    0.8, Train Acc:  87.50%, Time: 0:00:30 *\nIter:    390, Train Loss:   0.98, Train Acc:  65.62%, Time: 0:00:31 \nEpoch: 2\nIter:    420, Train Loss:   0.86, Train Acc:  68.75%, Time: 0:00:31 \nIter:    450, Train Loss:   0.68, Train Acc:  87.50%, Time: 0:00:31 \nIter:    480, Train Loss:   0.83, Train Acc:  81.25%, Time: 0:00:31 \nIter:    510, Train Loss:   0.75, Train Acc:  81.25%, Time: 0:00:32 \nIter:    540, Train Loss:   0.59, Train Acc:  87.50%, Time: 0:00:32 \nIter:    570, Train Loss:   0.72, Train Acc:  87.50%, Time: 0:00:32 \nIter:    600, Train Loss:   0.61, Train Acc:  81.25%, Time: 0:00:32 \nIter:    630, Train Loss:   0.67, Train Acc:  75.00%, Time: 0:00:33 \nIter:    660, Train Loss:    0.3, Train Acc:  96.88%, Time: 0:00:40 *\nIter:    690, Train Loss:   0.44, Train Acc:  93.75%, Time: 0:00:40 \nIter:    720, Train Loss:   0.36, Train Acc:  93.75%, Time: 0:00:41 \nIter:    750, Train Loss:   0.35, Train Acc:  93.75%, Time: 0:00:41 \nIter:    780, Train Loss:    0.5, Train Acc:  87.50%, Time: 0:00:41 \nEpoch: 3\nIter:    810, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:00:42 \nIter:    840, Train Loss:   0.41, Train Acc:  93.75%, Time: 0:00:42 \nIter:    870, Train Loss:   0.48, Train Acc:  84.38%, Time: 0:00:42 \nIter:    900, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:00:42 \nIter:    930, Train Loss:   0.63, Train Acc:  84.38%, Time: 0:00:43 \nIter:    960, Train Loss:   0.37, Train Acc:  87.50%, Time: 0:00:43 \nIter:    990, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:00:43 \nIter:   1020, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:00:43 \nIter:   1050, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:00:44 \nIter:   1080, Train Loss:   0.32, Train Acc:  90.62%, Time: 0:00:44 \nIter:   1110, Train Loss:   0.56, Train Acc:  90.62%, Time: 0:00:44 \nIter:   1140, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:00:44 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/1/1\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/1/1\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.0, Test Acc:  68.23%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.75      0.82      0.79       157\n                   Filter       0.54      0.60      0.57       150\n    Compute Derived Value       0.69      0.74      0.71       156\n            Find Extremum       0.63      0.71      0.66       130\n                     Sort       0.81      0.80      0.81       148\n          Determine Range       0.59      0.57      0.58       132\nCharacterize Distribution       0.84      0.81      0.82       153\n           Find Anomalies       0.64      0.39      0.49       125\n                  Cluster       0.65      0.78      0.71       118\n                Correlate       0.66      0.54      0.59       135\n\n                micro avg       0.68      0.68      0.68      1404\n                macro avg       0.68      0.68      0.67      1404\n             weighted avg       0.68      0.68      0.68      1404\n\nConfusion Matrix...\n[[129   3  19   4   1   1   0   0   0   0]\n [  9  90  11   0   3  12   1  13   2   9]\n [ 11  17 115   1   2   7   1   1   1   0]\n [  4   9   0  92   5  14   0   5   0   1]\n [  6   2   0  15 119   1   0   0   4   1]\n [  5  16   1  22   3  75   1   0   6   3]\n [  3   0  18   0   1   2 124   1   2   2]\n [  1  19   3  11   1   1   0  49  23  17]\n [  2  11   0   0   4   0   3   1  92   5]\n [  1   1   0   2   8  14  18   7  11  73]]\nTime usage: 0:00:00\nFold:  2\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.2, Train Acc:  25.00%, Time: 0:00:09 *\nIter:     60, Train Loss:    2.2, Train Acc:  12.50%, Time: 0:00:10 \nIter:     90, Train Loss:    2.0, Train Acc:  25.00%, Time: 0:00:10 \nIter:    120, Train Loss:    2.0, Train Acc:  31.25%, Time: 0:00:20 *\nIter:    150, Train Loss:    1.9, Train Acc:  40.62%, Time: 0:00:31 *\nIter:    180, Train Loss:    1.7, Train Acc:  46.88%, Time: 0:00:38 *\nIter:    210, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:45 *\nIter:    240, Train Loss:    1.4, Train Acc:  56.25%, Time: 0:00:52 *\nIter:    270, Train Loss:    1.4, Train Acc:  65.62%, Time: 0:01:02 *\nIter:    300, Train Loss:    1.5, Train Acc:  50.00%, Time: 0:01:02 \nIter:    330, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:01:03 \nIter:    360, Train Loss:    1.2, Train Acc:  68.75%, Time: 0:01:10 *\nIter:    390, Train Loss:   0.84, Train Acc:  78.12%, Time: 0:01:20 *\nEpoch: 2\nIter:    420, Train Loss:   0.52, Train Acc:  93.75%, Time: 0:01:28 *\nIter:    450, Train Loss:   0.81, Train Acc:  78.12%, Time: 0:01:29 \nIter:    480, Train Loss:   0.79, Train Acc:  81.25%, Time: 0:01:29 \nIter:    510, Train Loss:   0.64, Train Acc:  84.38%, Time: 0:01:29 \nIter:    540, Train Loss:   0.67, Train Acc:  90.62%, Time: 0:01:29 \nIter:    570, Train Loss:   0.72, Train Acc:  78.12%, Time: 0:01:30 \nIter:    600, Train Loss:   0.73, Train Acc:  87.50%, Time: 0:01:30 \nIter:    630, Train Loss:   0.61, Train Acc:  87.50%, Time: 0:01:30 \nIter:    660, Train Loss:   0.44, Train Acc:  84.38%, Time: 0:01:30 \nIter:    690, Train Loss:   0.38, Train Acc:  96.88%, Time: 0:01:42 *\nIter:    720, Train Loss:   0.52, Train Acc:  81.25%, Time: 0:01:43 \nIter:    750, Train Loss:   0.45, Train Acc:  90.62%, Time: 0:01:43 \nIter:    780, Train Loss:   0.56, Train Acc:  87.50%, Time: 0:01:43 \nEpoch: 3\nIter:    810, Train Loss:   0.63, Train Acc:  84.38%, Time: 0:01:43 \nIter:    840, Train Loss:   0.36, Train Acc:  93.75%, Time: 0:01:44 \nIter:    870, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:01:44 \nIter:    900, Train Loss:   0.32, Train Acc:  87.50%, Time: 0:01:44 \nIter:    930, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:01:44 \nIter:    960, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:45 \nIter:    990, Train Loss:    0.2, Train Acc: 100.00%, Time: 0:01:55 *\nIter:   1020, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:55 \nIter:   1050, Train Loss:   0.27, Train Acc:  96.88%, Time: 0:01:55 \nIter:   1080, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:01:55 \nIter:   1110, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:01:56 \nIter:   1140, Train Loss:  0.076, Train Acc: 100.00%, Time: 0:01:56 \nIter:   1170, Train Loss:   0.28, Train Acc:  87.50%, Time: 0:01:56 \nEpoch: 4\nIter:   1200, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:56 \nIter:   1230, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:01:57 \nIter:   1260, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:01:57 \nIter:   1290, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:57 \nIter:   1320, Train Loss:   0.16, Train Acc:  93.75%, Time: 0:01:57 \nIter:   1350, Train Loss:   0.14, Train Acc:  93.75%, Time: 0:01:58 \nIter:   1380, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:01:58 \nIter:   1410, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:01:58 \nIter:   1440, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:01:59 \nIter:   1470, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:01:59 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/2/2\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/2/2\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  68.75%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.87      0.74      0.80       174\n                   Filter       0.70      0.56      0.62       206\n    Compute Derived Value       0.81      0.51      0.62       174\n            Find Extremum       0.55      0.88      0.68        92\n                     Sort       0.61      0.94      0.74        85\n          Determine Range       0.64      0.82      0.71       115\nCharacterize Distribution       0.85      0.69      0.76       115\n           Find Anomalies       0.75      0.69      0.72       140\n                  Cluster       0.46      0.71      0.55        86\n                Correlate       0.70      0.65      0.67       192\n\n                micro avg       0.69      0.69      0.69      1379\n                macro avg       0.69      0.72      0.69      1379\n             weighted avg       0.72      0.69      0.69      1379\n\nConfusion Matrix...\n[[129   2  10  15   0   4   6   0   3   5]\n [  9 115   2  25  16  27   1  10   1   0]\n [  1  15  88  14  13   3   4   5   3  28]\n [  0   0   0  81   9   1   0   0   1   0]\n [  0   0   0   0  80   0   0   0   5   0]\n [  0   1   1   7   3  94   2   2   4   1]\n [  1   1   3   3   6   6  79   5   3   8]\n [  4  23   1   0   0   2   0  97   7   6]\n [  0   4   0   1   3  11   0   2  61   4]\n [  4   3   3   0   2   0   1   9  46 124]]\nTime usage: 0:00:00\nFold:  3\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.2, Train Acc:  21.88%, Time: 0:00:09 *\nIter:     60, Train Loss:    2.2, Train Acc:  28.12%, Time: 0:00:20 *\nIter:     90, Train Loss:    2.2, Train Acc:  12.50%, Time: 0:00:20 \nIter:    120, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:28 *\nIter:    150, Train Loss:    1.9, Train Acc:  25.00%, Time: 0:00:28 \nIter:    180, Train Loss:    1.6, Train Acc:  40.62%, Time: 0:00:35 *\nIter:    210, Train Loss:    1.5, Train Acc:  65.62%, Time: 0:00:45 *\nIter:    240, Train Loss:    1.4, Train Acc:  50.00%, Time: 0:00:45 \nIter:    270, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:00:53 *\nIter:    300, Train Loss:    1.3, Train Acc:  59.38%, Time: 0:00:53 \nIter:    330, Train Loss:   0.88, Train Acc:  78.12%, Time: 0:01:04 *\nIter:    360, Train Loss:    1.0, Train Acc:  75.00%, Time: 0:01:04 \nIter:    390, Train Loss:    1.2, Train Acc:  56.25%, Time: 0:01:04 \nEpoch: 2\nIter:    420, Train Loss:   0.94, Train Acc:  81.25%, Time: 0:01:13 *\nIter:    450, Train Loss:   0.83, Train Acc:  84.38%, Time: 0:01:22 *\nIter:    480, Train Loss:   0.89, Train Acc:  68.75%, Time: 0:01:23 \nIter:    510, Train Loss:   0.93, Train Acc:  75.00%, Time: 0:01:23 \nIter:    540, Train Loss:   0.64, Train Acc:  81.25%, Time: 0:01:23 \nIter:    570, Train Loss:   0.73, Train Acc:  81.25%, Time: 0:01:23 \nIter:    600, Train Loss:   0.51, Train Acc:  87.50%, Time: 0:01:31 *\nIter:    630, Train Loss:   0.47, Train Acc:  90.62%, Time: 0:01:38 *\nIter:    660, Train Loss:   0.68, Train Acc:  71.88%, Time: 0:01:38 \nIter:    690, Train Loss:   0.37, Train Acc:  96.88%, Time: 0:01:45 *\nIter:    720, Train Loss:   0.63, Train Acc:  84.38%, Time: 0:01:46 \nIter:    750, Train Loss:   0.71, Train Acc:  81.25%, Time: 0:01:46 \nIter:    780, Train Loss:   0.56, Train Acc:  84.38%, Time: 0:01:46 \nEpoch: 3\nIter:    810, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:01:47 \nIter:    840, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:47 \nIter:    870, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:47 \nIter:    900, Train Loss:    0.4, Train Acc:  90.62%, Time: 0:01:47 \nIter:    930, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:01:48 \nIter:    960, Train Loss:   0.38, Train Acc:  93.75%, Time: 0:01:48 \nIter:    990, Train Loss:   0.36, Train Acc:  84.38%, Time: 0:01:48 \nIter:   1020, Train Loss:   0.26, Train Acc: 100.00%, Time: 0:01:59 *\nIter:   1050, Train Loss:   0.42, Train Acc:  84.38%, Time: 0:01:59 \nIter:   1080, Train Loss:   0.38, Train Acc:  87.50%, Time: 0:01:59 \nIter:   1110, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:02:00 \nIter:   1140, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:02:00 \nIter:   1170, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:02:00 \nEpoch: 4\nIter:   1200, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:02:01 \nIter:   1230, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:02:01 \nIter:   1260, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:02:01 \nIter:   1290, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:02:01 \nIter:   1320, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:02:02 \nIter:   1350, Train Loss:   0.21, Train Acc:  90.62%, Time: 0:02:02 \nIter:   1380, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:02:02 \nIter:   1410, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:02:02 \nIter:   1440, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:02:03 \nIter:   1470, Train Loss:   0.17, Train Acc:  96.88%, Time: 0:02:03 \nIter:   1500, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:02:03 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/3/3\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/3/3\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.99, Test Acc:  69.04%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.67      0.70      0.69       127\n                   Filter       0.57      0.65      0.61       118\n    Compute Derived Value       0.39      0.44      0.41       152\n            Find Extremum       0.64      0.67      0.66       155\n                     Sort       0.86      0.67      0.75       123\n          Determine Range       0.78      0.63      0.70       114\nCharacterize Distribution       0.71      0.80      0.75       105\n           Find Anomalies       0.82      0.60      0.69       141\n                  Cluster       0.72      0.82      0.77       157\n                Correlate       0.82      0.83      0.83       239\n\n                micro avg       0.69      0.69      0.69      1431\n                macro avg       0.70      0.68      0.69      1431\n             weighted avg       0.70      0.69      0.69      1431\n\nConfusion Matrix...\n[[ 89   1  35   1   0   0   1   0   0   0]\n [ 13  77   2   4   0   3   0   5  14   0]\n [ 20  15  67  24   0   6   3   1   3  13]\n [  1   6  17 104  11   1   1   4   6   4]\n [  0   1   0  14  83   2   4   1  18   0]\n [  5  11   8   7   2  72   8   0   1   0]\n [  1   0  11   3   0   5  84   0   1   0]\n [  2  18  15   1   0   1   3  84   0  17]\n [  0   1   0   2   1   0  11   4 129   9]\n [  1   4  18   2   0   2   4   3   6 199]]\nTime usage: 0:00:00\nFold:  4\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.2, Train Acc:   9.38%, Time: 0:00:09 *\nIter:     60, Train Loss:    2.3, Train Acc:   9.38%, Time: 0:00:09 \nIter:     90, Train Loss:    2.1, Train Acc:  21.88%, Time: 0:00:17 *\nIter:    120, Train Loss:    1.8, Train Acc:  37.50%, Time: 0:00:24 *\nIter:    150, Train Loss:    1.9, Train Acc:  34.38%, Time: 0:00:24 \nIter:    180, Train Loss:    1.8, Train Acc:  40.62%, Time: 0:00:34 *\nIter:    210, Train Loss:    1.7, Train Acc:  50.00%, Time: 0:00:43 *\nIter:    240, Train Loss:    1.5, Train Acc:  56.25%, Time: 0:00:51 *\nIter:    270, Train Loss:    1.4, Train Acc:  65.62%, Time: 0:01:00 *\nIter:    300, Train Loss:    1.3, Train Acc:  59.38%, Time: 0:01:01 \nIter:    330, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:01:01 \nIter:    360, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:01:01 \nIter:    390, Train Loss:    1.2, Train Acc:  59.38%, Time: 0:01:01 \nEpoch: 2\nIter:    420, Train Loss:   0.98, Train Acc:  78.12%, Time: 0:01:10 *\nIter:    450, Train Loss:   0.61, Train Acc:  87.50%, Time: 0:01:20 *\nIter:    480, Train Loss:    0.8, Train Acc:  81.25%, Time: 0:01:20 \nIter:    510, Train Loss:   0.99, Train Acc:  75.00%, Time: 0:01:20 \nIter:    540, Train Loss:   0.55, Train Acc:  90.62%, Time: 0:01:28 *\nIter:    570, Train Loss:   0.52, Train Acc:  87.50%, Time: 0:01:28 \nIter:    600, Train Loss:   0.56, Train Acc:  87.50%, Time: 0:01:28 \nIter:    630, Train Loss:   0.62, Train Acc:  81.25%, Time: 0:01:29 \nIter:    660, Train Loss:   0.55, Train Acc:  90.62%, Time: 0:01:29 \nIter:    690, Train Loss:   0.52, Train Acc:  84.38%, Time: 0:01:29 \nIter:    720, Train Loss:   0.85, Train Acc:  68.75%, Time: 0:01:29 \nIter:    750, Train Loss:   0.38, Train Acc:  93.75%, Time: 0:01:38 *\nIter:    780, Train Loss:    0.6, Train Acc:  81.25%, Time: 0:01:38 \nEpoch: 3\nIter:    810, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:01:38 \nIter:    840, Train Loss:    0.5, Train Acc:  90.62%, Time: 0:01:38 \nIter:    870, Train Loss:   0.62, Train Acc:  71.88%, Time: 0:01:39 \nIter:    900, Train Loss:   0.25, Train Acc:  96.88%, Time: 0:01:49 *\nIter:    930, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:01:49 \nIter:    960, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:01:49 \nIter:    990, Train Loss:   0.44, Train Acc:  87.50%, Time: 0:01:50 \nIter:   1020, Train Loss:   0.27, Train Acc:  90.62%, Time: 0:01:50 \nIter:   1050, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:01:50 \nIter:   1080, Train Loss:   0.32, Train Acc:  90.62%, Time: 0:01:50 \nIter:   1110, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:01:51 \nIter:   1140, Train Loss:   0.29, Train Acc:  96.88%, Time: 0:01:51 \nIter:   1170, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:01:51 \nEpoch: 4\nIter:   1200, Train Loss:   0.11, Train Acc: 100.00%, Time: 0:01:59 *\nIter:   1230, Train Loss:   0.12, Train Acc: 100.00%, Time: 0:01:59 \nIter:   1260, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:59 \nIter:   1290, Train Loss:   0.38, Train Acc:  93.75%, Time: 0:02:00 \nIter:   1320, Train Loss:   0.47, Train Acc:  84.38%, Time: 0:02:00 \nIter:   1350, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:02:00 \nIter:   1380, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:02:00 \nIter:   1410, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:02:01 \nIter:   1440, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:02:01 \nIter:   1470, Train Loss:   0.23, Train Acc:  90.62%, Time: 0:02:01 \nIter:   1500, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:02:01 \nIter:   1530, Train Loss:   0.12, Train Acc: 100.00%, Time: 0:02:02 \nIter:   1560, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:02:02 \nEpoch: 5\nIter:   1590, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:02:02 \nIter:   1620, Train Loss:   0.13, Train Acc: 100.00%, Time: 0:02:03 \nIter:   1650, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:02:03 \nIter:   1680, Train Loss:   0.16, Train Acc:  93.75%, Time: 0:02:03 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/4/4\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/4/4\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  66.76%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.62      0.60      0.61       166\n                   Filter       0.52      0.58      0.55        92\n    Compute Derived Value       0.40      0.46      0.43        95\n            Find Extremum       0.74      0.90      0.81       226\n                     Sort       0.83      0.85      0.84        93\n          Determine Range       0.84      0.53      0.65       224\nCharacterize Distribution       0.79      0.75      0.77       120\n           Find Anomalies       0.68      0.62      0.65       202\n                  Cluster       0.53      0.63      0.57        92\n                Correlate       0.59      0.69      0.64        95\n\n                micro avg       0.67      0.67      0.67      1405\n                macro avg       0.65      0.66      0.65      1405\n             weighted avg       0.68      0.67      0.67      1405\n\nConfusion Matrix...\n[[100   8  19   6   2   6   0  14   0  11]\n [ 15  53   8   3   0  10   0   3   0   0]\n [ 13   0  44   9   0   0  17   8   0   4]\n [ 15   2   0 204   0   1   0   1   0   3]\n [  0   1   7   2  79   0   0   0   4   0]\n [  3   6  14  41  13 119   5   2  21   0]\n [  0   9   3   2   1   5  90   3   5   2]\n [  0  22  14   8   0   0   0 125  17  16]\n [  7   1   0   1   0   0   1  15  58   9]\n [  8   0   1   0   0   0   1  14   5  66]]\nTime usage: 0:00:00\nFold:  5\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:  12.50%, Time: 0:00:08 *\nIter:     60, Train Loss:    2.3, Train Acc:   6.25%, Time: 0:00:08 \nIter:     90, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:14 *\nIter:    120, Train Loss:    2.0, Train Acc:  31.25%, Time: 0:00:22 *\nIter:    150, Train Loss:    1.7, Train Acc:  50.00%, Time: 0:00:29 *\nIter:    180, Train Loss:    1.7, Train Acc:  56.25%, Time: 0:00:37 *\nIter:    210, Train Loss:    1.5, Train Acc:  56.25%, Time: 0:00:38 \nIter:    240, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:38 \nIter:    270, Train Loss:    1.2, Train Acc:  56.25%, Time: 0:00:38 \nIter:    300, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:00:45 *\nIter:    330, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:00:52 *\nIter:    360, Train Loss:   0.94, Train Acc:  78.12%, Time: 0:00:59 *\nIter:    390, Train Loss:    1.0, Train Acc:  81.25%, Time: 0:01:08 *\nEpoch: 2\nIter:    420, Train Loss:   0.95, Train Acc:  71.88%, Time: 0:01:08 \nIter:    450, Train Loss:   0.61, Train Acc:  81.25%, Time: 0:01:08 \nIter:    480, Train Loss:    0.5, Train Acc:  96.88%, Time: 0:01:16 *\nIter:    510, Train Loss:   0.67, Train Acc:  75.00%, Time: 0:01:16 \nIter:    540, Train Loss:   0.81, Train Acc:  84.38%, Time: 0:01:16 \nIter:    570, Train Loss:   0.74, Train Acc:  84.38%, Time: 0:01:17 \nIter:    600, Train Loss:   0.75, Train Acc:  75.00%, Time: 0:01:17 \nIter:    630, Train Loss:   0.77, Train Acc:  75.00%, Time: 0:01:17 \nIter:    660, Train Loss:   0.35, Train Acc:  93.75%, Time: 0:01:17 \nIter:    690, Train Loss:    0.4, Train Acc:  90.62%, Time: 0:01:18 \nIter:    720, Train Loss:   0.54, Train Acc:  90.62%, Time: 0:01:18 \nIter:    750, Train Loss:   0.58, Train Acc:  84.38%, Time: 0:01:18 \nIter:    780, Train Loss:   0.51, Train Acc:  81.25%, Time: 0:01:19 \nEpoch: 3\nIter:    810, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:01:19 \nIter:    840, Train Loss:   0.63, Train Acc:  81.25%, Time: 0:01:19 \nIter:    870, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:19 \nIter:    900, Train Loss:    0.4, Train Acc:  87.50%, Time: 0:01:20 \nIter:    930, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:01:20 \nIter:    960, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:01:20 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/5/5\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/5/5\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  63.65%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.63      0.70      0.66       141\n                   Filter       0.67      0.57      0.62       249\n    Compute Derived Value       0.59      0.56      0.57       125\n            Find Extremum       0.56      0.86      0.68       114\n                     Sort       0.72      0.90      0.80       108\n          Determine Range       0.43      0.51      0.47       131\nCharacterize Distribution       0.97      0.65      0.77       181\n           Find Anomalies       0.87      0.43      0.58       123\n                  Cluster       0.60      0.90      0.72        81\n                Correlate       0.51      0.52      0.51       139\n\n                micro avg       0.64      0.64      0.64      1392\n                macro avg       0.66      0.66      0.64      1392\n             weighted avg       0.67      0.64      0.64      1392\n\nConfusion Matrix...\n[[ 98   5   3  25   0   7   0   0   1   2]\n [ 13 141  23  17  11  17   1   3  16   7]\n [  7   7  70  17   7  11   1   0   5   0]\n [  0   0   6  98   0  10   0   0   0   0]\n [  1   1   0   5  97   3   0   0   1   0]\n [ 16  18   8   5  10  67   0   0   1   6]\n [ 12   1   4   3   1   7 117   1   1  34]\n [  0  16   1   3   2   6   1  53  21  20]\n [  0   0   1   0   2   3   1   1  73   0]\n [  8  20   3   1   4  25   0   3   3  72]]\nTime usage: 0:00:00\nFold:  6\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:   9.38%, Time: 0:00:07 *\nIter:     60, Train Loss:    2.2, Train Acc:  15.62%, Time: 0:00:14 *\nIter:     90, Train Loss:    2.0, Train Acc:  25.00%, Time: 0:00:20 *\nIter:    120, Train Loss:    2.0, Train Acc:  34.38%, Time: 0:00:29 *\nIter:    150, Train Loss:    1.8, Train Acc:  56.25%, Time: 0:00:37 *\nIter:    180, Train Loss:    1.8, Train Acc:  40.62%, Time: 0:00:37 \nIter:    210, Train Loss:    1.5, Train Acc:  65.62%, Time: 0:00:45 *\nIter:    240, Train Loss:    1.6, Train Acc:  65.62%, Time: 0:00:45 \nIter:    270, Train Loss:    1.4, Train Acc:  62.50%, Time: 0:00:45 \nIter:    300, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:00:57 *\nIter:    330, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:57 \nIter:    360, Train Loss:   0.91, Train Acc:  78.12%, Time: 0:01:06 *\nIter:    390, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:01:07 \nEpoch: 2\nIter:    420, Train Loss:   0.77, Train Acc:  84.38%, Time: 0:01:14 *\nIter:    450, Train Loss:   0.91, Train Acc:  78.12%, Time: 0:01:14 \nIter:    480, Train Loss:   0.65, Train Acc:  81.25%, Time: 0:01:15 \nIter:    510, Train Loss:   0.88, Train Acc:  75.00%, Time: 0:01:15 \nIter:    540, Train Loss:   0.81, Train Acc:  81.25%, Time: 0:01:15 \nIter:    570, Train Loss:   0.46, Train Acc:  90.62%, Time: 0:01:23 *\nIter:    600, Train Loss:   0.57, Train Acc:  81.25%, Time: 0:01:23 \nIter:    630, Train Loss:   0.31, Train Acc: 100.00%, Time: 0:01:30 *\nIter:    660, Train Loss:   0.67, Train Acc:  78.12%, Time: 0:01:31 \nIter:    690, Train Loss:   0.48, Train Acc:  81.25%, Time: 0:01:31 \nIter:    720, Train Loss:   0.43, Train Acc:  93.75%, Time: 0:01:31 \nIter:    750, Train Loss:   0.56, Train Acc:  81.25%, Time: 0:01:31 \nIter:    780, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:01:32 \nEpoch: 3\nIter:    810, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:01:32 \nIter:    840, Train Loss:   0.81, Train Acc:  75.00%, Time: 0:01:32 \nIter:    870, Train Loss:   0.44, Train Acc:  87.50%, Time: 0:01:32 \nIter:    900, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:33 \nIter:    930, Train Loss:   0.39, Train Acc:  93.75%, Time: 0:01:33 \nIter:    960, Train Loss:   0.37, Train Acc:  90.62%, Time: 0:01:33 \nIter:    990, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:01:33 \nIter:   1020, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:34 \nIter:   1050, Train Loss:    0.3, Train Acc:  90.62%, Time: 0:01:34 \nIter:   1080, Train Loss:   0.27, Train Acc:  96.88%, Time: 0:01:34 \nIter:   1110, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:35 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/6/6\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/6/6\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.97, Test Acc:  69.87%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.55      0.52      0.53       124\n                   Filter       0.57      0.55      0.56       150\n    Compute Derived Value       0.84      0.75      0.79       190\n            Find Extremum       0.70      0.82      0.75       191\n                     Sort       0.93      0.80      0.86       128\n          Determine Range       0.55      0.40      0.46       116\nCharacterize Distribution       0.54      0.76      0.63        94\n           Find Anomalies       0.74      0.78      0.76       143\n                  Cluster       0.73      0.70      0.71       138\n                Correlate       0.76      0.84      0.80       140\n\n                micro avg       0.70      0.70      0.70      1414\n                macro avg       0.69      0.69      0.69      1414\n             weighted avg       0.70      0.70      0.70      1414\n\nConfusion Matrix...\n[[ 64   9   7  23   4   3   1   0   1  12]\n [  6  82   9  22   0  12   0  17   0   2]\n [ 11   1 142   4   1   3  23   1   0   4]\n [ 14   4   0 156   2  11   4   0   0   0]\n [  5   0   2   4 103   2   2   0  10   0]\n [ 17  34   1   6   1  46   1   8   0   2]\n [  0   4   2   0   0   1  71   0  15   1]\n [  0   7   1   2   0   0   5 111   6  11]\n [  0   2   2   7   0   3  19   4  96   5]\n [  0   0   4   0   0   3   5   8   3 117]]\nTime usage: 0:00:00\nFold:  7\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  15.62%, Time: 0:00:09 *\nIter:     60, Train Loss:    2.2, Train Acc:  18.75%, Time: 0:00:16 *\nIter:     90, Train Loss:    2.2, Train Acc:  28.12%, Time: 0:00:25 *\nIter:    120, Train Loss:    2.0, Train Acc:  34.38%, Time: 0:00:32 *\nIter:    150, Train Loss:    1.8, Train Acc:  46.88%, Time: 0:00:39 *\nIter:    180, Train Loss:    1.5, Train Acc:  65.62%, Time: 0:00:47 *\nIter:    210, Train Loss:    1.6, Train Acc:  53.12%, Time: 0:00:47 \nIter:    240, Train Loss:    1.4, Train Acc:  59.38%, Time: 0:00:47 \nIter:    270, Train Loss:    1.1, Train Acc:  75.00%, Time: 0:01:01 *\nIter:    300, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:01:01 \nIter:    330, Train Loss:    1.4, Train Acc:  62.50%, Time: 0:01:01 \nIter:    360, Train Loss:   0.87, Train Acc:  81.25%, Time: 0:01:12 *\nIter:    390, Train Loss:   0.97, Train Acc:  71.88%, Time: 0:01:12 \nEpoch: 2\nIter:    420, Train Loss:   0.74, Train Acc:  90.62%, Time: 0:01:20 *\nIter:    450, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:01:20 \nIter:    480, Train Loss:   0.47, Train Acc:  90.62%, Time: 0:01:20 \nIter:    510, Train Loss:   0.88, Train Acc:  71.88%, Time: 0:01:20 \nIter:    540, Train Loss:   0.76, Train Acc:  75.00%, Time: 0:01:21 \nIter:    570, Train Loss:   0.66, Train Acc:  84.38%, Time: 0:01:21 \nIter:    600, Train Loss:   0.65, Train Acc:  87.50%, Time: 0:01:21 \nIter:    630, Train Loss:   0.49, Train Acc:  90.62%, Time: 0:01:21 \nIter:    660, Train Loss:   0.37, Train Acc:  93.75%, Time: 0:01:32 *\nIter:    690, Train Loss:   0.81, Train Acc:  71.88%, Time: 0:01:32 \nIter:    720, Train Loss:   0.39, Train Acc:  93.75%, Time: 0:01:32 \nIter:    750, Train Loss:   0.47, Train Acc:  81.25%, Time: 0:01:32 \nIter:    780, Train Loss:    0.5, Train Acc:  87.50%, Time: 0:01:33 \nEpoch: 3\nIter:    810, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:33 \nIter:    840, Train Loss:   0.19, Train Acc: 100.00%, Time: 0:01:41 *\nIter:    870, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:41 \nIter:    900, Train Loss:   0.39, Train Acc:  90.62%, Time: 0:01:42 \nIter:    930, Train Loss:   0.27, Train Acc:  96.88%, Time: 0:01:42 \nIter:    960, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:42 \nIter:    990, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:42 \nIter:   1020, Train Loss:   0.25, Train Acc:  96.88%, Time: 0:01:43 \nIter:   1050, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:43 \nIter:   1080, Train Loss:   0.43, Train Acc:  87.50%, Time: 0:01:43 \nIter:   1110, Train Loss:   0.56, Train Acc:  81.25%, Time: 0:01:43 \nIter:   1140, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:44 \nIter:   1170, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:01:44 \nEpoch: 4\nIter:   1200, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:01:44 \nIter:   1230, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:01:44 \nIter:   1260, Train Loss:   0.41, Train Acc:  87.50%, Time: 0:01:45 \nIter:   1290, Train Loss:   0.22, Train Acc:  96.88%, Time: 0:01:45 \nIter:   1320, Train Loss:   0.12, Train Acc:  96.88%, Time: 0:01:45 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/7/7\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/7/7\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.0, Test Acc:  70.32%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.83      0.60      0.70       131\n                   Filter       0.70      0.52      0.60       141\n    Compute Derived Value       0.42      0.85      0.56       112\n            Find Extremum       0.80      0.59      0.68       157\n                     Sort       0.89      0.68      0.77       136\n          Determine Range       0.69      0.69      0.69       191\nCharacterize Distribution       0.83      0.69      0.75       178\n           Find Anomalies       0.75      0.76      0.75       143\n                  Cluster       0.77      0.82      0.80       105\n                Correlate       0.65      0.93      0.76       121\n\n                micro avg       0.70      0.70      0.70      1415\n                macro avg       0.73      0.71      0.71      1415\n             weighted avg       0.74      0.70      0.71      1415\n\nConfusion Matrix...\n[[ 79   1  35   1   1   0   5   1   0   8]\n [  2  73  24   1   2  22   0  11   2   4]\n [ 12   0  95   0   0   0   0   0   1   4]\n [  0   6   8  93   2  24   2  18   2   2]\n [  0   1   8   4  93   5   4   0  12   9]\n [  2   0  30  13   1 132   5   1   1   6]\n [  0  19  12   0   0   4 122   1   3  17]\n [  0   1  12   2   0   2   9 109   2   6]\n [  0   2   0   2   6   1   0   2  86   6]\n [  0   1   2   0   0   0   0   3   2 113]]\nTime usage: 0:00:00\nFold:  8\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.2, Train Acc:  28.12%, Time: 0:00:10 *\nIter:     60, Train Loss:    2.2, Train Acc:  15.62%, Time: 0:00:10 \nIter:     90, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:11 \nIter:    120, Train Loss:    1.9, Train Acc:  40.62%, Time: 0:00:21 *\nIter:    150, Train Loss:    1.9, Train Acc:  31.25%, Time: 0:00:21 \nIter:    180, Train Loss:    2.0, Train Acc:  28.12%, Time: 0:00:22 \nIter:    210, Train Loss:    1.4, Train Acc:  65.62%, Time: 0:00:31 *\nIter:    240, Train Loss:    1.7, Train Acc:  40.62%, Time: 0:00:32 \nIter:    270, Train Loss:    1.4, Train Acc:  53.12%, Time: 0:00:32 \nIter:    300, Train Loss:    1.4, Train Acc:  46.88%, Time: 0:00:32 \nIter:    330, Train Loss:    1.0, Train Acc:  75.00%, Time: 0:00:42 *\nIter:    360, Train Loss:    1.3, Train Acc:  68.75%, Time: 0:00:42 \nIter:    390, Train Loss:   0.78, Train Acc:  81.25%, Time: 0:00:54 *\nEpoch: 2\nIter:    420, Train Loss:   0.95, Train Acc:  68.75%, Time: 0:00:54 \nIter:    450, Train Loss:   0.73, Train Acc:  84.38%, Time: 0:01:03 *\nIter:    480, Train Loss:   0.71, Train Acc:  75.00%, Time: 0:01:03 \nIter:    510, Train Loss:   0.57, Train Acc:  87.50%, Time: 0:01:14 *\nIter:    540, Train Loss:    0.7, Train Acc:  78.12%, Time: 0:01:14 \nIter:    570, Train Loss:   0.73, Train Acc:  81.25%, Time: 0:01:14 \nIter:    600, Train Loss:   0.59, Train Acc:  87.50%, Time: 0:01:14 \nIter:    630, Train Loss:    0.6, Train Acc:  81.25%, Time: 0:01:15 \nIter:    660, Train Loss:    0.7, Train Acc:  75.00%, Time: 0:01:15 \nIter:    690, Train Loss:   0.65, Train Acc:  87.50%, Time: 0:01:15 \nIter:    720, Train Loss:    0.6, Train Acc:  78.12%, Time: 0:01:15 \nIter:    750, Train Loss:   0.82, Train Acc:  75.00%, Time: 0:01:16 \nIter:    780, Train Loss:   0.36, Train Acc:  87.50%, Time: 0:01:16 \nEpoch: 3\nIter:    810, Train Loss:   0.36, Train Acc:  93.75%, Time: 0:01:27 *\nIter:    840, Train Loss:   0.56, Train Acc:  84.38%, Time: 0:01:28 \nIter:    870, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:01:28 \nIter:    900, Train Loss:   0.57, Train Acc:  84.38%, Time: 0:01:28 \nIter:    930, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:28 \nIter:    960, Train Loss:   0.46, Train Acc:  84.38%, Time: 0:01:29 \nIter:    990, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:01:39 *\nIter:   1020, Train Loss:   0.37, Train Acc:  96.88%, Time: 0:01:39 \nIter:   1050, Train Loss:   0.25, Train Acc: 100.00%, Time: 0:01:50 *\nIter:   1080, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:01:50 \nIter:   1110, Train Loss:   0.39, Train Acc:  90.62%, Time: 0:01:50 \nIter:   1140, Train Loss:   0.22, Train Acc:  96.88%, Time: 0:01:50 \nIter:   1170, Train Loss:   0.15, Train Acc: 100.00%, Time: 0:01:51 \nEpoch: 4\nIter:   1200, Train Loss:   0.21, Train Acc: 100.00%, Time: 0:01:51 \nIter:   1230, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:01:51 \nIter:   1260, Train Loss:   0.28, Train Acc:  96.88%, Time: 0:01:51 \nIter:   1290, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:52 \nIter:   1320, Train Loss:   0.18, Train Acc: 100.00%, Time: 0:01:52 \nIter:   1350, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:01:52 \nIter:   1380, Train Loss:   0.17, Train Acc:  90.62%, Time: 0:01:52 \nIter:   1410, Train Loss:  0.092, Train Acc: 100.00%, Time: 0:01:53 \nIter:   1440, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:53 \nIter:   1470, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:01:53 \nIter:   1500, Train Loss:   0.28, Train Acc:  96.88%, Time: 0:01:53 \nIter:   1530, Train Loss:   0.29, Train Acc:  96.88%, Time: 0:01:54 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/8/8\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/8/8\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.94, Test Acc:  70.20%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.65      0.56      0.60       144\n                   Filter       0.73      0.35      0.47       152\n    Compute Derived Value       0.64      0.85      0.73       136\n            Find Extremum       0.83      0.79      0.81       211\n                     Sort       0.91      0.89      0.90        87\n          Determine Range       0.35      0.62      0.44        91\nCharacterize Distribution       0.98      0.72      0.83       129\n           Find Anomalies       0.61      0.75      0.68       138\n                  Cluster       0.90      0.83      0.86       192\n                Correlate       0.57      0.65      0.61       106\n\n                micro avg       0.70      0.70      0.70      1386\n                macro avg       0.72      0.70      0.69      1386\n             weighted avg       0.74      0.70      0.70      1386\n\nConfusion Matrix...\n[[ 80   2  21   9   0  26   0   4   0   2]\n [ 20  53   9   7   0  49   0   5   3   6]\n [  0   0 115   1   1  16   1   1   0   1]\n [ 22   2   3 167   1   1   0  15   0   0]\n [  0   0   0   5  77   0   0   1   3   1]\n [  0   0  11  10   0  56   0   5   4   5]\n [  0   0   7   0   1   4  93   0   5  19]\n [  1  16   2   2   0   6   0 104   1   6]\n [  0   0   3   0   4   3   0  12 159  11]\n [  1   0   8   1   1   0   1  23   2  69]]\nTime usage: 0:00:00\nFold:  9\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:  12.50%, Time: 0:00:11 *\nIter:     60, Train Loss:    2.1, Train Acc:  18.75%, Time: 0:00:22 *\nIter:     90, Train Loss:    1.9, Train Acc:  37.50%, Time: 0:00:33 *\nIter:    120, Train Loss:    1.9, Train Acc:  34.38%, Time: 0:00:34 \nIter:    150, Train Loss:    1.9, Train Acc:  31.25%, Time: 0:00:34 \nIter:    180, Train Loss:    1.6, Train Acc:  53.12%, Time: 0:00:42 *\nIter:    210, Train Loss:    1.5, Train Acc:  59.38%, Time: 0:00:49 *\nIter:    240, Train Loss:    1.4, Train Acc:  56.25%, Time: 0:00:49 \nIter:    270, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:00:56 *\nIter:    300, Train Loss:    1.2, Train Acc:  75.00%, Time: 0:01:06 *\nIter:    330, Train Loss:    1.2, Train Acc:  59.38%, Time: 0:01:06 \nIter:    360, Train Loss:   0.94, Train Acc:  78.12%, Time: 0:01:13 *\nIter:    390, Train Loss:   0.81, Train Acc:  90.62%, Time: 0:01:21 *\nEpoch: 2\nIter:    420, Train Loss:    1.1, Train Acc:  62.50%, Time: 0:01:21 \nIter:    450, Train Loss:   0.83, Train Acc:  81.25%, Time: 0:01:21 \nIter:    480, Train Loss:   0.94, Train Acc:  78.12%, Time: 0:01:21 \nIter:    510, Train Loss:   0.74, Train Acc:  87.50%, Time: 0:01:22 \nIter:    540, Train Loss:   0.81, Train Acc:  84.38%, Time: 0:01:22 \nIter:    570, Train Loss:   0.86, Train Acc:  78.12%, Time: 0:01:22 \nIter:    600, Train Loss:   0.59, Train Acc:  84.38%, Time: 0:01:22 \nIter:    630, Train Loss:   0.74, Train Acc:  75.00%, Time: 0:01:23 \nIter:    660, Train Loss:    0.5, Train Acc:  87.50%, Time: 0:01:23 \nIter:    690, Train Loss:   0.39, Train Acc:  93.75%, Time: 0:01:32 *\nIter:    720, Train Loss:   0.42, Train Acc:  90.62%, Time: 0:01:33 \nIter:    750, Train Loss:   0.38, Train Acc:  93.75%, Time: 0:01:33 \nIter:    780, Train Loss:   0.48, Train Acc:  96.88%, Time: 0:01:42 *\nEpoch: 3\nIter:    810, Train Loss:   0.46, Train Acc:  90.62%, Time: 0:01:43 \nIter:    840, Train Loss:   0.44, Train Acc:  93.75%, Time: 0:01:43 \nIter:    870, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:01:43 \nIter:    900, Train Loss:   0.39, Train Acc:  90.62%, Time: 0:01:43 \nIter:    930, Train Loss:    0.5, Train Acc:  90.62%, Time: 0:01:44 \nIter:    960, Train Loss:   0.47, Train Acc:  87.50%, Time: 0:01:44 \nIter:    990, Train Loss:   0.34, Train Acc:  87.50%, Time: 0:01:44 \nIter:   1020, Train Loss:   0.42, Train Acc:  90.62%, Time: 0:01:45 \nIter:   1050, Train Loss:   0.68, Train Acc:  81.25%, Time: 0:01:45 \nIter:   1080, Train Loss:    0.2, Train Acc: 100.00%, Time: 0:01:52 *\nIter:   1110, Train Loss:   0.53, Train Acc:  87.50%, Time: 0:01:52 \nIter:   1140, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:52 \nIter:   1170, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:53 \nEpoch: 4\nIter:   1200, Train Loss:   0.23, Train Acc:  90.62%, Time: 0:01:53 \nIter:   1230, Train Loss:  0.082, Train Acc: 100.00%, Time: 0:01:53 \nIter:   1260, Train Loss:   0.29, Train Acc:  87.50%, Time: 0:01:53 \nIter:   1290, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:01:54 \nIter:   1320, Train Loss:  0.089, Train Acc: 100.00%, Time: 0:01:54 \nIter:   1350, Train Loss:  0.073, Train Acc: 100.00%, Time: 0:01:54 \nIter:   1380, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:01:54 \nIter:   1410, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:55 \nIter:   1440, Train Loss:   0.17, Train Acc: 100.00%, Time: 0:01:55 \nIter:   1470, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:01:55 \nIter:   1500, Train Loss:   0.19, Train Acc:  87.50%, Time: 0:01:55 \nIter:   1530, Train Loss:   0.11, Train Acc: 100.00%, Time: 0:01:56 \nIter:   1560, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:01:56 \nEpoch: 5\nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/9/9\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/9/9\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.2, Test Acc:  67.00%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.43      0.74      0.54        74\n                   Filter       0.58      0.62      0.60       144\n    Compute Derived Value       0.68      0.37      0.48       189\n            Find Extremum       0.67      0.83      0.74       166\n                     Sort       0.86      0.72      0.78       162\n          Determine Range       0.50      0.82      0.62        95\nCharacterize Distribution       0.85      0.81      0.83       159\n           Find Anomalies       0.69      0.51      0.59       139\n                  Cluster       0.89      0.64      0.75       128\n                Correlate       0.65      0.76      0.70       153\n\n                micro avg       0.67      0.67      0.67      1409\n                macro avg       0.68      0.68      0.66      1409\n             weighted avg       0.70      0.67      0.67      1409\n\nConfusion Matrix...\n[[ 55   0   0  16   0   2   1   0   0   0]\n [  1  89  19  11   1   6   1  13   1   2]\n [ 40  12  70   5   2  12  16   4   0  28]\n [  1   4   0 138   3  20   0   0   0   0]\n [  0   0   3  18 116  15   0   0   7   3]\n [  1  13   0   1   0  78   0   0   0   2]\n [  1   0   3  16   0   5 128   2   1   3]\n [  2  28   0   1   2  12   0  71   0  23]\n [ 20   3   0   0  11   0   4   5  82   3]\n [  7   5   8   1   0   6   0   8   1 117]]\nTime usage: 0:00:00\nFold:  10\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:  12.50%, Time: 0:00:10 *\nIter:     60, Train Loss:    2.2, Train Acc:  25.00%, Time: 0:00:21 *\nIter:     90, Train Loss:    2.0, Train Acc:  28.12%, Time: 0:00:31 *\nIter:    120, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:31 \nIter:    150, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:42 *\nIter:    180, Train Loss:    1.9, Train Acc:  46.88%, Time: 0:00:50 *\nIter:    210, Train Loss:    1.7, Train Acc:  59.38%, Time: 0:00:59 *\nIter:    240, Train Loss:    1.7, Train Acc:  53.12%, Time: 0:00:59 \nIter:    270, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:01:06 *\nIter:    300, Train Loss:    1.4, Train Acc:  56.25%, Time: 0:01:06 \nIter:    330, Train Loss:    1.1, Train Acc:  78.12%, Time: 0:01:13 *\nIter:    360, Train Loss:    1.2, Train Acc:  62.50%, Time: 0:01:13 \nIter:    390, Train Loss:   0.73, Train Acc:  87.50%, Time: 0:01:20 *\nEpoch: 2\nIter:    420, Train Loss:   0.84, Train Acc:  81.25%, Time: 0:01:20 \nIter:    450, Train Loss:   0.81, Train Acc:  87.50%, Time: 0:01:20 \nIter:    480, Train Loss:   0.81, Train Acc:  84.38%, Time: 0:01:20 \nIter:    510, Train Loss:   0.55, Train Acc:  93.75%, Time: 0:01:27 *\nIter:    540, Train Loss:    0.5, Train Acc:  90.62%, Time: 0:01:27 \nIter:    570, Train Loss:   0.68, Train Acc:  78.12%, Time: 0:01:27 \nIter:    600, Train Loss:   0.57, Train Acc:  84.38%, Time: 0:01:28 \nIter:    630, Train Loss:   0.48, Train Acc:  84.38%, Time: 0:01:28 \nIter:    660, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:01:28 \nIter:    690, Train Loss:   0.46, Train Acc:  90.62%, Time: 0:01:28 \nIter:    720, Train Loss:   0.92, Train Acc:  71.88%, Time: 0:01:29 \nIter:    750, Train Loss:   0.35, Train Acc:  96.88%, Time: 0:01:38 *\nIter:    780, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:01:38 \nEpoch: 3\nIter:    810, Train Loss:   0.47, Train Acc:  84.38%, Time: 0:01:38 \nIter:    840, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:39 \nIter:    870, Train Loss:    0.3, Train Acc:  90.62%, Time: 0:01:39 \nIter:    900, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:01:39 \nIter:    930, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:39 \nIter:    960, Train Loss:   0.39, Train Acc:  87.50%, Time: 0:01:40 \nIter:    990, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:01:40 \nIter:   1020, Train Loss:   0.35, Train Acc:  87.50%, Time: 0:01:40 \nIter:   1050, Train Loss:   0.56, Train Acc:  87.50%, Time: 0:01:40 \nIter:   1080, Train Loss:   0.47, Train Acc:  90.62%, Time: 0:01:41 \nIter:   1110, Train Loss:    0.3, Train Acc:  87.50%, Time: 0:01:41 \nIter:   1140, Train Loss:   0.39, Train Acc:  93.75%, Time: 0:01:41 \nIter:   1170, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:01:41 \nEpoch: 4\nIter:   1200, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:01:42 \nIter:   1230, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:01:42 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/10/10\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/bundle/10/10\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  68.29%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.80      0.72      0.76       126\n                   Filter       0.14      0.32      0.19        50\n    Compute Derived Value       0.67      0.53      0.59       206\n            Find Extremum       0.75      0.76      0.75       218\n                     Sort       0.86      0.75      0.80       136\n          Determine Range       0.53      0.77      0.63       113\nCharacterize Distribution       0.57      0.80      0.67        95\n           Find Anomalies       0.80      0.44      0.57        79\n                  Cluster       0.82      0.80      0.81       173\n                Correlate       0.87      0.67      0.75       204\n\n                micro avg       0.68      0.68      0.68      1400\n                macro avg       0.68      0.66      0.65      1400\n             weighted avg       0.73      0.68      0.70      1400\n\nConfusion Matrix...\n[[ 91  16   8   0   0   1   7   1   1   1]\n [  0  16  14   1   0  10   1   6   2   0]\n [ 17  11 110  31   0  22   6   0   7   2]\n [  1  17   5 165   9  15   2   0   1   3]\n [  2   7   1   6 102  10   3   0   5   0]\n [  0  14   1   0   0  87  10   0   0   1]\n [  0   1   3   0   0  11  76   0   4   0]\n [  0  10   4   0   0   3  20  35   2   5]\n [  3   2   0   1   7   6   7   0 138   9]\n [  0  22  19  16   0   0   1   2   8 136]]\nTime usage: 0:00:00\n[0.6823361819965548, 0.6874546773023931, 0.6904262753735881, 0.6676156585326822, 0.6364942528735632, 0.6987270154743923, 0.7031802120983811, 0.7020202019341925, 0.6699787083037615, 0.6828571425165448]\n0.6821090326406054, 0.01911251193154515, 0.02014635650360894, 0.00036528811233345565\ntable\n37 296 318 41\nFold:  1\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:   6.25%, Time: 0:00:12 *\nIter:     60, Train Loss:    2.2, Train Acc:  15.62%, Time: 0:00:23 *\nIter:     90, Train Loss:    2.2, Train Acc:  31.25%, Time: 0:00:33 *\nIter:    120, Train Loss:    2.1, Train Acc:  34.38%, Time: 0:00:39 *\nIter:    150, Train Loss:    1.9, Train Acc:  43.75%, Time: 0:00:46 *\nIter:    180, Train Loss:    1.8, Train Acc:  59.38%, Time: 0:00:54 *\nIter:    210, Train Loss:    1.5, Train Acc:  53.12%, Time: 0:00:54 \nIter:    240, Train Loss:    1.5, Train Acc:  62.50%, Time: 0:01:04 *\nIter:    270, Train Loss:    1.4, Train Acc:  53.12%, Time: 0:01:04 \nIter:    300, Train Loss:   0.97, Train Acc:  68.75%, Time: 0:01:14 *\nIter:    330, Train Loss:    1.1, Train Acc:  75.00%, Time: 0:01:21 *\nEpoch: 2\nIter:    360, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:01:22 \nIter:    390, Train Loss:   0.95, Train Acc:  75.00%, Time: 0:01:22 \nIter:    420, Train Loss:   0.92, Train Acc:  71.88%, Time: 0:01:22 \nIter:    450, Train Loss:   0.62, Train Acc:  87.50%, Time: 0:01:31 *\nIter:    480, Train Loss:   0.69, Train Acc:  87.50%, Time: 0:01:31 \nIter:    510, Train Loss:   0.53, Train Acc:  84.38%, Time: 0:01:32 \nIter:    540, Train Loss:   0.56, Train Acc:  87.50%, Time: 0:01:32 \nIter:    570, Train Loss:   0.77, Train Acc:  71.88%, Time: 0:01:32 \nIter:    600, Train Loss:   0.76, Train Acc:  81.25%, Time: 0:01:32 \nIter:    630, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:01:42 *\nIter:    660, Train Loss:    0.6, Train Acc:  84.38%, Time: 0:01:42 \nIter:    690, Train Loss:   0.97, Train Acc:  81.25%, Time: 0:01:42 \nEpoch: 3\nIter:    720, Train Loss:   0.57, Train Acc:  87.50%, Time: 0:01:42 \nIter:    750, Train Loss:   0.47, Train Acc:  84.38%, Time: 0:01:43 \nIter:    780, Train Loss:   0.35, Train Acc:  93.75%, Time: 0:01:54 *\nIter:    810, Train Loss:   0.59, Train Acc:  87.50%, Time: 0:01:54 \nIter:    840, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:54 \nIter:    870, Train Loss:   0.32, Train Acc:  96.88%, Time: 0:02:03 *\nIter:    900, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:02:04 \nIter:    930, Train Loss:   0.55, Train Acc:  84.38%, Time: 0:02:04 \nIter:    960, Train Loss:   0.68, Train Acc:  84.38%, Time: 0:02:04 \nIter:    990, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:02:04 \nIter:   1020, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:02:05 \nIter:   1050, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:02:05 \nEpoch: 4\nIter:   1080, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:02:05 \nIter:   1110, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:02:05 \nIter:   1140, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:02:06 \nIter:   1170, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:02:06 \nIter:   1200, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:02:06 \nIter:   1230, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:02:06 \nIter:   1260, Train Loss:   0.23, Train Acc:  90.62%, Time: 0:02:07 \nIter:   1290, Train Loss:    0.2, Train Acc: 100.00%, Time: 0:02:19 *\nIter:   1320, Train Loss:    0.1, Train Acc: 100.00%, Time: 0:02:19 \nIter:   1350, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:02:19 \nIter:   1380, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:02:19 \nIter:   1410, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:02:20 \nEpoch: 5\nIter:   1440, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:02:20 \nIter:   1470, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:02:20 \nIter:   1500, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:02:20 \nIter:   1530, Train Loss:  0.098, Train Acc: 100.00%, Time: 0:02:21 \nIter:   1560, Train Loss:  0.069, Train Acc: 100.00%, Time: 0:02:21 \nIter:   1590, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:02:21 \nIter:   1620, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:02:21 \nIter:   1650, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:02:22 \nIter:   1680, Train Loss:   0.24, Train Acc:  96.88%, Time: 0:02:22 \nIter:   1710, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:02:22 \nIter:   1740, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:02:23 \nIter:   1770, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:02:23 \nEpoch: 6\nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/1/1\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/1/1\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  67.30%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.61      0.50      0.55       226\n                   Filter       0.55      0.72      0.62       258\n    Compute Derived Value       0.82      0.40      0.54       309\n            Find Extremum       0.59      0.68      0.63       301\n                     Sort       0.78      0.92      0.85       248\n          Determine Range       0.56      0.60      0.58       234\nCharacterize Distribution       0.84      0.84      0.84       292\n           Find Anomalies       0.70      0.66      0.68       254\n                  Cluster       0.77      0.69      0.73       236\n                Correlate       0.61      0.73      0.66       263\n\n                micro avg       0.67      0.67      0.67      2621\n                macro avg       0.68      0.67      0.67      2621\n             weighted avg       0.69      0.67      0.67      2621\n\nConfusion Matrix...\n[[114  27   3  15   8   9   2  19   0  29]\n [ 11 186   8   8   9   7   2  19   3   5]\n [ 31  44 123  32   7  25  12   5   9  21]\n [ 19  12   0 204  18  27   3   7   6   5]\n [  0   1   0   8 229   5   0   0   5   0]\n [  3  35   0  33  10 141   7   0   4   1]\n [  0   2   4  14   3  12 245   3   2   7]\n [  1  17   0  14   0   4   4 168  17  29]\n [  6   0   1   0   2  15  14  11 163  24]\n [  2  17  11  16   6   9   2   7   2 191]]\nTime usage: 0:00:00\nFold:  2\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.2, Train Acc:  15.62%, Time: 0:00:11 *\nIter:     60, Train Loss:    2.4, Train Acc:   3.12%, Time: 0:00:12 \nIter:     90, Train Loss:    2.2, Train Acc:  21.88%, Time: 0:00:22 *\nIter:    120, Train Loss:    2.0, Train Acc:  34.38%, Time: 0:00:31 *\nIter:    150, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:44 *\nIter:    180, Train Loss:    1.8, Train Acc:  37.50%, Time: 0:00:44 \nIter:    210, Train Loss:    1.8, Train Acc:  40.62%, Time: 0:00:55 *\nIter:    240, Train Loss:    1.7, Train Acc:  56.25%, Time: 0:01:04 *\nIter:    270, Train Loss:    1.6, Train Acc:  59.38%, Time: 0:01:13 *\nIter:    300, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:01:24 *\nIter:    330, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:01:35 *\nIter:    360, Train Loss:    1.0, Train Acc:  68.75%, Time: 0:01:35 \nIter:    390, Train Loss:    1.1, Train Acc:  62.50%, Time: 0:01:35 \nEpoch: 2\nIter:    420, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:01:36 \nIter:    450, Train Loss:   0.61, Train Acc:  93.75%, Time: 0:01:45 *\nIter:    480, Train Loss:   0.82, Train Acc:  81.25%, Time: 0:01:45 \nIter:    510, Train Loss:    1.0, Train Acc:  68.75%, Time: 0:01:46 \nIter:    540, Train Loss:   0.57, Train Acc:  90.62%, Time: 0:01:46 \nIter:    570, Train Loss:   0.56, Train Acc:  87.50%, Time: 0:01:46 \nIter:    600, Train Loss:   0.99, Train Acc:  75.00%, Time: 0:01:46 \nIter:    630, Train Loss:   0.55, Train Acc:  87.50%, Time: 0:01:47 \nIter:    660, Train Loss:   0.72, Train Acc:  78.12%, Time: 0:01:47 \nIter:    690, Train Loss:   0.62, Train Acc:  84.38%, Time: 0:01:47 \nIter:    720, Train Loss:   0.55, Train Acc:  87.50%, Time: 0:01:47 \nIter:    750, Train Loss:   0.58, Train Acc:  84.38%, Time: 0:01:48 \nIter:    780, Train Loss:   0.45, Train Acc:  87.50%, Time: 0:01:48 \nEpoch: 3\nIter:    810, Train Loss:   0.43, Train Acc:  90.62%, Time: 0:01:48 \nIter:    840, Train Loss:   0.48, Train Acc:  90.62%, Time: 0:01:49 \nIter:    870, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:49 \nIter:    900, Train Loss:   0.29, Train Acc:  96.88%, Time: 0:01:58 *\nIter:    930, Train Loss:   0.36, Train Acc:  93.75%, Time: 0:01:58 \nIter:    960, Train Loss:   0.36, Train Acc:  87.50%, Time: 0:01:59 \nIter:    990, Train Loss:   0.45, Train Acc:  87.50%, Time: 0:01:59 \nIter:   1020, Train Loss:    0.4, Train Acc:  90.62%, Time: 0:01:59 \nIter:   1050, Train Loss:   0.34, Train Acc:  96.88%, Time: 0:01:59 \nIter:   1080, Train Loss:   0.46, Train Acc:  90.62%, Time: 0:02:00 \nIter:   1110, Train Loss:   0.49, Train Acc:  84.38%, Time: 0:02:00 \nIter:   1140, Train Loss:   0.24, Train Acc:  96.88%, Time: 0:02:00 \nIter:   1170, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:02:01 \nEpoch: 4\nIter:   1200, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:02:01 \nIter:   1230, Train Loss:   0.16, Train Acc:  96.88%, Time: 0:02:01 \nIter:   1260, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:02:01 \nIter:   1290, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:02:02 \nIter:   1320, Train Loss:   0.31, Train Acc:  87.50%, Time: 0:02:02 \nIter:   1350, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:02:02 \nIter:   1380, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:02:02 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/2/2\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/2/2\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.89, Test Acc:  71.45%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.70      0.64      0.67       220\n                   Filter       0.57      0.67      0.61       207\n    Compute Derived Value       0.46      0.43      0.44       143\n            Find Extremum       0.78      0.73      0.75       149\n                     Sort       0.85      0.77      0.81        92\n          Determine Range       0.55      0.83      0.66        88\nCharacterize Distribution       0.93      0.93      0.93       123\n           Find Anomalies       0.90      0.67      0.77       168\n                  Cluster       0.88      0.94      0.91        88\n                Correlate       0.76      0.77      0.77       179\n\n                micro avg       0.71      0.71      0.71      1457\n                macro avg       0.74      0.74      0.73      1457\n             weighted avg       0.73      0.71      0.72      1457\n\nConfusion Matrix...\n[[140  34  28   4   0   4   3   0   1   6]\n [ 13 139  13  14   2  12   2  10   0   2]\n [ 36  20  61   0   2  22   0   0   0   2]\n [  3   4  10 109   6   5   0   0   0  12]\n [  2   5   1   4  71   6   0   0   3   0]\n [  1   1   0   6   0  73   1   1   2   3]\n [  0   2   1   0   0   4 115   0   0   1]\n [  4  22   3   0   0   4   1 112   5  17]\n [  1   0   1   1   0   1   1   0  83   0]\n [  0  19  15   2   3   1   0   1   0 138]]\nTime usage: 0:00:00\nFold:  3\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.2, Train Acc:  21.88%, Time: 0:00:11 *\nIter:     60, Train Loss:    2.1, Train Acc:  21.88%, Time: 0:00:11 \nIter:     90, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:22 *\nIter:    120, Train Loss:    2.0, Train Acc:  28.12%, Time: 0:00:22 \nIter:    150, Train Loss:    1.8, Train Acc:  46.88%, Time: 0:00:32 *\nIter:    180, Train Loss:    1.8, Train Acc:  34.38%, Time: 0:00:33 \nIter:    210, Train Loss:    1.3, Train Acc:  59.38%, Time: 0:00:43 *\nIter:    240, Train Loss:    1.5, Train Acc:  56.25%, Time: 0:00:43 \nIter:    270, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:54 *\nIter:    300, Train Loss:    1.3, Train Acc:  59.38%, Time: 0:00:54 \nIter:    330, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:54 \nIter:    360, Train Loss:    1.1, Train Acc:  75.00%, Time: 0:01:04 *\nEpoch: 2\nIter:    390, Train Loss:   0.83, Train Acc:  78.12%, Time: 0:01:14 *\nIter:    420, Train Loss:   0.97, Train Acc:  68.75%, Time: 0:01:14 \nIter:    450, Train Loss:   0.74, Train Acc:  84.38%, Time: 0:01:24 *\nIter:    480, Train Loss:   0.63, Train Acc:  93.75%, Time: 0:01:34 *\nIter:    510, Train Loss:   0.86, Train Acc:  81.25%, Time: 0:01:34 \nIter:    540, Train Loss:   0.55, Train Acc:  87.50%, Time: 0:01:34 \nIter:    570, Train Loss:   0.62, Train Acc:  84.38%, Time: 0:01:34 \nIter:    600, Train Loss:   0.63, Train Acc:  84.38%, Time: 0:01:35 \nIter:    630, Train Loss:   0.49, Train Acc:  84.38%, Time: 0:01:35 \nIter:    660, Train Loss:   0.63, Train Acc:  84.38%, Time: 0:01:35 \nIter:    690, Train Loss:   0.57, Train Acc:  87.50%, Time: 0:01:35 \nIter:    720, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:01:36 \nEpoch: 3\nIter:    750, Train Loss:   0.44, Train Acc:  84.38%, Time: 0:01:36 \nIter:    780, Train Loss:   0.39, Train Acc:  87.50%, Time: 0:01:36 \nIter:    810, Train Loss:   0.56, Train Acc:  78.12%, Time: 0:01:36 \nIter:    840, Train Loss:   0.35, Train Acc:  93.75%, Time: 0:01:37 \nIter:    870, Train Loss:    0.4, Train Acc:  87.50%, Time: 0:01:37 \nIter:    900, Train Loss:   0.29, Train Acc:  96.88%, Time: 0:01:46 *\nIter:    930, Train Loss:   0.38, Train Acc:  93.75%, Time: 0:01:47 \nIter:    960, Train Loss:   0.65, Train Acc:  75.00%, Time: 0:01:47 \nIter:    990, Train Loss:   0.55, Train Acc:  84.38%, Time: 0:01:47 \nIter:   1020, Train Loss:   0.16, Train Acc:  93.75%, Time: 0:01:47 \nIter:   1050, Train Loss:   0.45, Train Acc:  87.50%, Time: 0:01:48 \nIter:   1080, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:01:48 \nIter:   1110, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:48 \nEpoch: 4\nIter:   1140, Train Loss:   0.21, Train Acc: 100.00%, Time: 0:01:58 *\nIter:   1170, Train Loss:   0.18, Train Acc: 100.00%, Time: 0:01:58 \nIter:   1200, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:01:58 \nIter:   1230, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:01:59 \nIter:   1260, Train Loss:   0.46, Train Acc:  90.62%, Time: 0:01:59 \nIter:   1290, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:01:59 \nIter:   1320, Train Loss:   0.11, Train Acc: 100.00%, Time: 0:01:59 \nIter:   1350, Train Loss:   0.21, Train Acc:  93.75%, Time: 0:02:00 \nIter:   1380, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:02:00 \nIter:   1410, Train Loss:  0.095, Train Acc: 100.00%, Time: 0:02:00 \nIter:   1440, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:02:00 \nIter:   1470, Train Loss:   0.17, Train Acc: 100.00%, Time: 0:02:01 \nEpoch: 5\nIter:   1500, Train Loss:    0.2, Train Acc:  87.50%, Time: 0:02:01 \nIter:   1530, Train Loss:  0.088, Train Acc: 100.00%, Time: 0:02:01 \nIter:   1560, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:02:01 \nIter:   1590, Train Loss:  0.097, Train Acc:  96.88%, Time: 0:02:02 \nIter:   1620, Train Loss:  0.064, Train Acc: 100.00%, Time: 0:02:02 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/3/3\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/3/3\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.0, Test Acc:  68.23%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.57      0.77      0.65       216\n                   Filter       0.67      0.38      0.48       242\n    Compute Derived Value       0.46      0.66      0.54       215\n            Find Extremum       0.77      0.65      0.71       225\n                     Sort       0.75      0.81      0.78       194\n          Determine Range       0.54      0.62      0.58       216\nCharacterize Distribution       0.78      0.68      0.73       189\n           Find Anomalies       0.94      0.62      0.75       216\n                  Cluster       0.77      0.80      0.79       217\n                Correlate       0.81      0.86      0.83       245\n\n                micro avg       0.68      0.68      0.68      2175\n                macro avg       0.71      0.68      0.68      2175\n             weighted avg       0.71      0.68      0.68      2175\n\nConfusion Matrix...\n[[166   7  13  15   0  10   1   0   1   3]\n [ 32  91  40  16  12  33   0   1  10   7]\n [ 40   5 141   1   1  14   8   1   2   2]\n [  8   1  35 147  11  18   0   1   0   4]\n [  8   0  10   2 158   6   1   1   6   2]\n [ 25  30   7  10   3 134   0   1   3   3]\n [ 11   1  11   1   2   4 129   0  13  17]\n [  1   1  26   0   1  16  20 133   9   9]\n [  0   0   4   0  22   9   2   2 174   4]\n [  1   0  19   0   0   2   4   1   7 211]]\nTime usage: 0:00:00\nFold:  4\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  21.88%, Time: 0:00:11 *\nIter:     60, Train Loss:    2.2, Train Acc:  18.75%, Time: 0:00:12 \nIter:     90, Train Loss:    2.3, Train Acc:   3.12%, Time: 0:00:12 \nIter:    120, Train Loss:    2.0, Train Acc:  25.00%, Time: 0:00:22 *\nIter:    150, Train Loss:    1.7, Train Acc:  53.12%, Time: 0:00:32 *\nIter:    180, Train Loss:    1.6, Train Acc:  53.12%, Time: 0:00:33 \nIter:    210, Train Loss:    1.3, Train Acc:  65.62%, Time: 0:00:43 *\nIter:    240, Train Loss:    1.6, Train Acc:  43.75%, Time: 0:00:43 \nIter:    270, Train Loss:    1.5, Train Acc:  50.00%, Time: 0:00:44 \nIter:    300, Train Loss:    1.3, Train Acc:  68.75%, Time: 0:00:53 *\nIter:    330, Train Loss:    1.0, Train Acc:  75.00%, Time: 0:00:59 *\nIter:    360, Train Loss:   0.96, Train Acc:  75.00%, Time: 0:01:00 \nIter:    390, Train Loss:    1.6, Train Acc:  46.88%, Time: 0:01:00 \nEpoch: 2\nIter:    420, Train Loss:    1.1, Train Acc:  75.00%, Time: 0:01:00 \nIter:    450, Train Loss:   0.84, Train Acc:  75.00%, Time: 0:01:00 \nIter:    480, Train Loss:   0.77, Train Acc:  78.12%, Time: 0:01:10 *\nIter:    510, Train Loss:    1.1, Train Acc:  78.12%, Time: 0:01:11 \nIter:    540, Train Loss:   0.78, Train Acc:  78.12%, Time: 0:01:11 \nIter:    570, Train Loss:   0.59, Train Acc:  78.12%, Time: 0:01:11 \nIter:    600, Train Loss:   0.87, Train Acc:  71.88%, Time: 0:01:11 \nIter:    630, Train Loss:   0.63, Train Acc:  78.12%, Time: 0:01:12 \nIter:    660, Train Loss:   0.58, Train Acc:  84.38%, Time: 0:01:21 *\nIter:    690, Train Loss:   0.62, Train Acc:  78.12%, Time: 0:01:22 \nIter:    720, Train Loss:    0.5, Train Acc:  87.50%, Time: 0:01:32 *\nIter:    750, Train Loss:   0.74, Train Acc:  84.38%, Time: 0:01:33 \nIter:    780, Train Loss:   0.66, Train Acc:  78.12%, Time: 0:01:33 \nEpoch: 3\nIter:    810, Train Loss:   0.18, Train Acc: 100.00%, Time: 0:01:44 *\nIter:    840, Train Loss:   0.32, Train Acc:  93.75%, Time: 0:01:44 \nIter:    870, Train Loss:   0.32, Train Acc:  90.62%, Time: 0:01:45 \nIter:    900, Train Loss:   0.49, Train Acc:  84.38%, Time: 0:01:45 \nIter:    930, Train Loss:   0.35, Train Acc:  93.75%, Time: 0:01:45 \nIter:    960, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:01:46 \nIter:    990, Train Loss:   0.37, Train Acc:  96.88%, Time: 0:01:46 \nIter:   1020, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:01:46 \nIter:   1050, Train Loss:   0.26, Train Acc: 100.00%, Time: 0:01:46 \nIter:   1080, Train Loss:    0.4, Train Acc:  87.50%, Time: 0:01:47 \nIter:   1110, Train Loss:   0.24, Train Acc:  96.88%, Time: 0:01:47 \nIter:   1140, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:47 \nIter:   1170, Train Loss:   0.42, Train Acc:  84.38%, Time: 0:01:47 \nIter:   1200, Train Loss:   0.29, Train Acc:  90.62%, Time: 0:01:48 \nEpoch: 4\nIter:   1230, Train Loss:   0.36, Train Acc:  93.75%, Time: 0:01:48 \nIter:   1260, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:01:48 \nIter:   1290, Train Loss:   0.18, Train Acc: 100.00%, Time: 0:01:48 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/4/4\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/4/4\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  66.50%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.41      0.45      0.43        84\n                   Filter       0.45      0.72      0.56        93\n    Compute Derived Value       0.77      0.42      0.54       178\n            Find Extremum       0.75      0.73      0.74       173\n                     Sort       0.65      0.99      0.78        92\n          Determine Range       0.61      0.56      0.58       110\nCharacterize Distribution       1.00      0.80      0.89       122\n           Find Anomalies       0.69      0.69      0.69       121\n                  Cluster       0.88      0.70      0.78       108\n                Correlate       0.56      0.70      0.62       116\n\n                micro avg       0.66      0.66      0.66      1197\n                macro avg       0.68      0.68      0.66      1197\n             weighted avg       0.70      0.66      0.67      1197\n\nConfusion Matrix...\n[[ 38  18   9   1   5   3   0   2   2   6]\n [  2  67   0   6   4  12   0   2   0   0]\n [ 20   0  74  30   1   1   0   6   3  43]\n [ 10   7   9 126  13   4   0   3   1   0]\n [  0   1   0   0  91   0   0   0   0   0]\n [ 15  16   2   0   3  62   0   0   0  12]\n [  4   6   0   2   5   4  97   2   1   1]\n [  1  21   0   3   2   9   0  84   0   1]\n [  1  12   1   1  12   2   0   3  76   0]\n [  1   0   1   0   5   5   0  20   3  81]]\nTime usage: 0:00:00\nFold:  5\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  12.50%, Time: 0:00:10 *\nIter:     60, Train Loss:    2.1, Train Acc:  37.50%, Time: 0:00:19 *\nIter:     90, Train Loss:    2.0, Train Acc:  25.00%, Time: 0:00:19 \nIter:    120, Train Loss:    2.0, Train Acc:  28.12%, Time: 0:00:19 \nIter:    150, Train Loss:    1.9, Train Acc:  43.75%, Time: 0:00:29 *\nIter:    180, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:29 \nIter:    210, Train Loss:    1.6, Train Acc:  56.25%, Time: 0:00:38 *\nIter:    240, Train Loss:    1.6, Train Acc:  59.38%, Time: 0:00:47 *\nIter:    270, Train Loss:    1.3, Train Acc:  71.88%, Time: 0:00:57 *\nIter:    300, Train Loss:    1.0, Train Acc:  75.00%, Time: 0:01:07 *\nIter:    330, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:01:07 \nIter:    360, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:01:08 \nIter:    390, Train Loss:   0.87, Train Acc:  78.12%, Time: 0:01:14 *\nEpoch: 2\nIter:    420, Train Loss:   0.76, Train Acc:  81.25%, Time: 0:01:20 *\nIter:    450, Train Loss:   0.78, Train Acc:  78.12%, Time: 0:01:20 \nIter:    480, Train Loss:   0.73, Train Acc:  84.38%, Time: 0:01:31 *\nIter:    510, Train Loss:   0.71, Train Acc:  78.12%, Time: 0:01:31 \nIter:    540, Train Loss:    1.0, Train Acc:  71.88%, Time: 0:01:31 \nIter:    570, Train Loss:   0.48, Train Acc:  90.62%, Time: 0:01:40 *\nIter:    600, Train Loss:   0.47, Train Acc:  90.62%, Time: 0:01:40 \nIter:    630, Train Loss:    0.6, Train Acc:  81.25%, Time: 0:01:41 \nIter:    660, Train Loss:   0.54, Train Acc:  87.50%, Time: 0:01:41 \nIter:    690, Train Loss:   0.69, Train Acc:  78.12%, Time: 0:01:41 \nIter:    720, Train Loss:   0.61, Train Acc:  84.38%, Time: 0:01:41 \nIter:    750, Train Loss:   0.44, Train Acc:  93.75%, Time: 0:01:51 *\nIter:    780, Train Loss:   0.52, Train Acc:  90.62%, Time: 0:01:51 \nIter:    810, Train Loss:   0.44, Train Acc:  90.62%, Time: 0:01:52 \nEpoch: 3\nIter:    840, Train Loss:   0.42, Train Acc:  90.62%, Time: 0:01:52 \nIter:    870, Train Loss:   0.38, Train Acc:  90.62%, Time: 0:01:52 \nIter:    900, Train Loss:   0.45, Train Acc:  90.62%, Time: 0:01:52 \nIter:    930, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:01:53 \nIter:    960, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:53 \nIter:    990, Train Loss:   0.18, Train Acc: 100.00%, Time: 0:02:03 *\nIter:   1020, Train Loss:   0.42, Train Acc:  87.50%, Time: 0:02:03 \nIter:   1050, Train Loss:    0.6, Train Acc:  84.38%, Time: 0:02:03 \nIter:   1080, Train Loss:   0.27, Train Acc:  90.62%, Time: 0:02:03 \nIter:   1110, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:02:04 \nIter:   1140, Train Loss:   0.21, Train Acc: 100.00%, Time: 0:02:04 \nIter:   1170, Train Loss:   0.32, Train Acc:  90.62%, Time: 0:02:04 \nIter:   1200, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:02:04 \nEpoch: 4\nIter:   1230, Train Loss:   0.24, Train Acc: 100.00%, Time: 0:02:05 \nIter:   1260, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:02:05 \nIter:   1290, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:02:05 \nIter:   1320, Train Loss:   0.33, Train Acc:  90.62%, Time: 0:02:05 \nIter:   1350, Train Loss:    0.4, Train Acc:  87.50%, Time: 0:02:06 \nIter:   1380, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:02:06 \nIter:   1410, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:02:06 \nIter:   1440, Train Loss:   0.19, Train Acc:  93.75%, Time: 0:02:07 \nIter:   1470, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:02:07 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/5/5\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/5/5\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:   0.91, Test Acc:  71.56%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.55      0.57      0.56       101\n                   Filter       0.64      0.80      0.71        95\n    Compute Derived Value       0.63      0.47      0.54        92\n            Find Extremum       0.87      0.88      0.88       140\n                     Sort       0.92      0.77      0.84       123\n          Determine Range       0.72      0.92      0.81        93\nCharacterize Distribution       0.75      0.75      0.75       110\n           Find Anomalies       0.66      0.58      0.62        91\n                  Cluster       0.70      0.71      0.70        90\n                Correlate       0.59      0.57      0.58        81\n\n                micro avg       0.72      0.72      0.72      1016\n                macro avg       0.70      0.70      0.70      1016\n             weighted avg       0.72      0.72      0.71      1016\n\nConfusion Matrix...\n[[ 58   0  18   0   1  12   7   0   1   4]\n [  1  76   4   1   2   0   1   6   2   2]\n [ 22   1  43   0   0   8  12   0   3   3]\n [  7   1   0 123   0   1   0   3   1   4]\n [  0   1   0  14  95   5   1   0   7   0]\n [  1   1   1   0   0  86   0   0   2   2]\n [  6  12   1   1   1   5  83   0   0   1]\n [  0  25   1   1   0   0   2  53   1   8]\n [  4   0   0   0   3   1   5   5  64   8]\n [  6   1   0   1   1   2   0  13  11  46]]\nTime usage: 0:00:00\nFold:  6\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.2, Train Acc:  21.88%, Time: 0:00:10 *\nIter:     60, Train Loss:    2.0, Train Acc:  28.12%, Time: 0:00:20 *\nIter:     90, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:21 \nIter:    120, Train Loss:    1.9, Train Acc:  46.88%, Time: 0:00:30 *\nIter:    150, Train Loss:    1.8, Train Acc:  43.75%, Time: 0:00:30 \nIter:    180, Train Loss:    1.6, Train Acc:  46.88%, Time: 0:00:30 \nIter:    210, Train Loss:    1.5, Train Acc:  62.50%, Time: 0:00:40 *\nIter:    240, Train Loss:    1.7, Train Acc:  53.12%, Time: 0:00:40 \nIter:    270, Train Loss:    1.3, Train Acc:  68.75%, Time: 0:00:50 *\nIter:    300, Train Loss:    1.0, Train Acc:  75.00%, Time: 0:00:57 *\nIter:    330, Train Loss:    1.3, Train Acc:  56.25%, Time: 0:00:57 \nIter:    360, Train Loss:    1.1, Train Acc:  78.12%, Time: 0:01:07 *\nEpoch: 2\nIter:    390, Train Loss:   0.82, Train Acc:  81.25%, Time: 0:01:16 *\nIter:    420, Train Loss:    1.1, Train Acc:  65.62%, Time: 0:01:16 \nIter:    450, Train Loss:   0.92, Train Acc:  75.00%, Time: 0:01:16 \nIter:    480, Train Loss:   0.87, Train Acc:  75.00%, Time: 0:01:17 \nIter:    510, Train Loss:   0.73, Train Acc:  78.12%, Time: 0:01:17 \nIter:    540, Train Loss:   0.55, Train Acc:  90.62%, Time: 0:01:24 *\nIter:    570, Train Loss:   0.85, Train Acc:  81.25%, Time: 0:01:24 \nIter:    600, Train Loss:    1.1, Train Acc:  62.50%, Time: 0:01:25 \nIter:    630, Train Loss:   0.63, Train Acc:  81.25%, Time: 0:01:25 \nIter:    660, Train Loss:   0.55, Train Acc:  81.25%, Time: 0:01:25 \nIter:    690, Train Loss:   0.65, Train Acc:  81.25%, Time: 0:01:25 \nIter:    720, Train Loss:   0.55, Train Acc:  81.25%, Time: 0:01:26 \nIter:    750, Train Loss:   0.54, Train Acc:  87.50%, Time: 0:01:26 \nEpoch: 3\nIter:    780, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:01:33 *\nIter:    810, Train Loss:   0.51, Train Acc:  90.62%, Time: 0:01:33 \nIter:    840, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:01:33 \nIter:    870, Train Loss:   0.39, Train Acc:  90.62%, Time: 0:01:34 \nIter:    900, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:43 *\nIter:    930, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:01:43 \nIter:    960, Train Loss:   0.32, Train Acc:  90.62%, Time: 0:01:43 \nIter:    990, Train Loss:   0.17, Train Acc: 100.00%, Time: 0:01:50 *\nIter:   1020, Train Loss:   0.31, Train Acc:  90.62%, Time: 0:01:50 \nIter:   1050, Train Loss:   0.27, Train Acc:  96.88%, Time: 0:01:51 \nIter:   1080, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:01:51 \nIter:   1110, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:01:51 \nIter:   1140, Train Loss:   0.41, Train Acc:  93.75%, Time: 0:01:51 \nEpoch: 4\nIter:   1170, Train Loss:   0.24, Train Acc:  96.88%, Time: 0:01:52 \nIter:   1200, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:01:52 \nIter:   1230, Train Loss:   0.37, Train Acc:  84.38%, Time: 0:01:52 \nIter:   1260, Train Loss:   0.28, Train Acc:  90.62%, Time: 0:01:52 \nIter:   1290, Train Loss:   0.22, Train Acc:  93.75%, Time: 0:01:53 \nIter:   1320, Train Loss:   0.46, Train Acc:  81.25%, Time: 0:01:53 \nIter:   1350, Train Loss:   0.31, Train Acc:  87.50%, Time: 0:01:53 \nIter:   1380, Train Loss:   0.26, Train Acc:  90.62%, Time: 0:01:53 \nIter:   1410, Train Loss:   0.24, Train Acc:  90.62%, Time: 0:01:54 \nIter:   1440, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:01:54 \nIter:   1470, Train Loss:  0.094, Train Acc: 100.00%, Time: 0:01:54 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/6/6\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/6/6\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  63.38%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.58      0.49      0.53       137\n                   Filter       0.37      0.53      0.43       144\n    Compute Derived Value       0.72      0.34      0.46       183\n            Find Extremum       0.82      0.76      0.79       211\n                     Sort       0.97      0.67      0.79       152\n          Determine Range       0.48      0.70      0.57       158\nCharacterize Distribution       0.73      0.67      0.70       171\n           Find Anomalies       0.60      0.72      0.65       155\n                  Cluster       0.89      0.74      0.81       161\n                Correlate       0.53      0.69      0.60       191\n\n                micro avg       0.63      0.63      0.63      1663\n                macro avg       0.67      0.63      0.63      1663\n             weighted avg       0.68      0.63      0.64      1663\n\nConfusion Matrix...\n[[ 67  37   9   0   0  12   6   5   0   1]\n [  2  76   1   6   2  23   1  17   0  16]\n [ 27  19  62  12   0  23  13   4   1  22]\n [  5  16  11 160   1  15   1   2   0   0]\n [  0   3   0  13 102  15   1   2   6  10]\n [  2  17   0   2   0 111   9   1   2  14]\n [  5   9   3   0   0  19 115   1   1  18]\n [  0  11   0   1   0   6   0 111   0  26]\n [  7   8   0   0   0   1   1  17 119   8]\n [  0  11   0   1   0   6  11  26   5 131]]\nTime usage: 0:00:00\nFold:  7\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.2, Train Acc:   9.38%, Time: 0:00:07 *\nIter:     60, Train Loss:    2.2, Train Acc:  12.50%, Time: 0:00:14 *\nIter:     90, Train Loss:    2.0, Train Acc:  34.38%, Time: 0:00:21 *\nIter:    120, Train Loss:    2.0, Train Acc:  34.38%, Time: 0:00:21 \nIter:    150, Train Loss:    1.9, Train Acc:  43.75%, Time: 0:00:28 *\nIter:    180, Train Loss:    1.6, Train Acc:  53.12%, Time: 0:00:35 *\nIter:    210, Train Loss:    1.4, Train Acc:  65.62%, Time: 0:00:42 *\nIter:    240, Train Loss:    1.1, Train Acc:  68.75%, Time: 0:00:52 *\nIter:    270, Train Loss:    1.2, Train Acc:  65.62%, Time: 0:00:52 \nIter:    300, Train Loss:    1.0, Train Acc:  75.00%, Time: 0:00:59 *\nIter:    330, Train Loss:   0.76, Train Acc:  78.12%, Time: 0:01:05 *\nIter:    360, Train Loss:   0.76, Train Acc:  78.12%, Time: 0:01:05 \nIter:    390, Train Loss:   0.65, Train Acc:  81.25%, Time: 0:01:12 *\nEpoch: 2\nIter:    420, Train Loss:   0.86, Train Acc:  59.38%, Time: 0:01:12 \nIter:    450, Train Loss:   0.88, Train Acc:  71.88%, Time: 0:01:12 \nIter:    480, Train Loss:   0.59, Train Acc:  90.62%, Time: 0:01:18 *\nIter:    510, Train Loss:   0.77, Train Acc:  75.00%, Time: 0:01:19 \nIter:    540, Train Loss:   0.86, Train Acc:  81.25%, Time: 0:01:19 \nIter:    570, Train Loss:   0.48, Train Acc:  87.50%, Time: 0:01:19 \nIter:    600, Train Loss:   0.46, Train Acc:  93.75%, Time: 0:01:25 *\nIter:    630, Train Loss:   0.74, Train Acc:  71.88%, Time: 0:01:26 \nIter:    660, Train Loss:   0.54, Train Acc:  90.62%, Time: 0:01:26 \nIter:    690, Train Loss:    0.6, Train Acc:  87.50%, Time: 0:01:26 \nIter:    720, Train Loss:    0.6, Train Acc:  90.62%, Time: 0:01:26 \nIter:    750, Train Loss:   0.69, Train Acc:  84.38%, Time: 0:01:27 \nIter:    780, Train Loss:    0.5, Train Acc:  90.62%, Time: 0:01:27 \nEpoch: 3\nIter:    810, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:01:27 \nIter:    840, Train Loss:   0.29, Train Acc: 100.00%, Time: 0:01:35 *\nIter:    870, Train Loss:   0.34, Train Acc:  96.88%, Time: 0:01:35 \nIter:    900, Train Loss:   0.48, Train Acc:  87.50%, Time: 0:01:35 \nIter:    930, Train Loss:   0.43, Train Acc:  87.50%, Time: 0:01:35 \nIter:    960, Train Loss:    0.3, Train Acc:  93.75%, Time: 0:01:36 \nIter:    990, Train Loss:   0.29, Train Acc:  90.62%, Time: 0:01:36 \nIter:   1020, Train Loss:   0.39, Train Acc:  87.50%, Time: 0:01:36 \nIter:   1050, Train Loss:   0.37, Train Acc:  84.38%, Time: 0:01:36 \nIter:   1080, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:01:37 \nIter:   1110, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:01:37 \nIter:   1140, Train Loss:   0.48, Train Acc:  93.75%, Time: 0:01:37 \nIter:   1170, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:01:37 \nEpoch: 4\nIter:   1200, Train Loss:   0.15, Train Acc:  96.88%, Time: 0:01:38 \nIter:   1230, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:01:38 \nIter:   1260, Train Loss:   0.25, Train Acc:  90.62%, Time: 0:01:38 \nIter:   1290, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:39 \nIter:   1320, Train Loss:   0.24, Train Acc:  93.75%, Time: 0:01:39 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/7/7\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/7/7\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.4, Test Acc:  59.72%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.90      0.24      0.38       146\n                   Filter       0.33      0.46      0.38       117\n    Compute Derived Value       0.60      0.47      0.53       152\n            Find Extremum       0.66      0.87      0.75       176\n                     Sort       0.73      0.89      0.80       123\n          Determine Range       0.82      0.61      0.70       184\nCharacterize Distribution       0.69      0.42      0.52       112\n           Find Anomalies       0.40      0.47      0.43       122\n                  Cluster       0.70      0.77      0.73       120\n                Correlate       0.47      0.74      0.57       121\n\n                micro avg       0.60      0.60      0.60      1373\n                macro avg       0.63      0.59      0.58      1373\n             weighted avg       0.64      0.60      0.59      1373\n\nConfusion Matrix...\n[[ 35  27  13  31  15   2   5   3   2  13]\n [  1  54   3  10   3   2   0  31   7   6]\n [  1  14  71  33   3  11   0  10   0   9]\n [  2   5   0 153   6   3   0   3   4   0]\n [  0   8   1   0 109   0   0   1   4   0]\n [  0  32   8   1  10 113  13   1   3   3]\n [  0   0  16   3   0   2  47   4  10  30]\n [  0  15   3   0   1   2   1  57   8  35]\n [  0   1   1   1   3   1   1  14  92   6]\n [  0   8   2   0   0   2   1  17   2  89]]\nTime usage: 0:00:00\nFold:  8\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  15.62%, Time: 0:00:10 *\nIter:     60, Train Loss:    2.0, Train Acc:  37.50%, Time: 0:00:17 *\nIter:     90, Train Loss:    2.2, Train Acc:  21.88%, Time: 0:00:17 \nIter:    120, Train Loss:    2.1, Train Acc:  34.38%, Time: 0:00:18 \nIter:    150, Train Loss:    1.9, Train Acc:  37.50%, Time: 0:00:18 \nIter:    180, Train Loss:    1.8, Train Acc:  43.75%, Time: 0:00:27 *\nIter:    210, Train Loss:    1.5, Train Acc:  56.25%, Time: 0:00:35 *\nIter:    240, Train Loss:    1.5, Train Acc:  43.75%, Time: 0:00:35 \nIter:    270, Train Loss:    1.4, Train Acc:  62.50%, Time: 0:00:44 *\nIter:    300, Train Loss:    1.3, Train Acc:  59.38%, Time: 0:00:44 \nIter:    330, Train Loss:   0.99, Train Acc:  71.88%, Time: 0:00:54 *\nIter:    360, Train Loss:   0.77, Train Acc:  84.38%, Time: 0:01:01 *\nIter:    390, Train Loss:   0.96, Train Acc:  75.00%, Time: 0:01:01 \nEpoch: 2\nIter:    420, Train Loss:   0.92, Train Acc:  71.88%, Time: 0:01:01 \nIter:    450, Train Loss:   0.68, Train Acc:  75.00%, Time: 0:01:02 \nIter:    480, Train Loss:    0.9, Train Acc:  71.88%, Time: 0:01:02 \nIter:    510, Train Loss:   0.79, Train Acc:  81.25%, Time: 0:01:02 \nIter:    540, Train Loss:   0.63, Train Acc:  93.75%, Time: 0:01:12 *\nIter:    570, Train Loss:   0.58, Train Acc:  81.25%, Time: 0:01:13 \nIter:    600, Train Loss:   0.41, Train Acc:  87.50%, Time: 0:01:13 \nIter:    630, Train Loss:   0.64, Train Acc:  71.88%, Time: 0:01:13 \nIter:    660, Train Loss:   0.54, Train Acc:  81.25%, Time: 0:01:14 \nIter:    690, Train Loss:   0.48, Train Acc:  90.62%, Time: 0:01:14 \nIter:    720, Train Loss:   0.59, Train Acc:  75.00%, Time: 0:01:14 \nIter:    750, Train Loss:   0.81, Train Acc:  78.12%, Time: 0:01:14 \nIter:    780, Train Loss:   0.58, Train Acc:  84.38%, Time: 0:01:15 \nIter:    810, Train Loss:   0.48, Train Acc:  75.00%, Time: 0:01:15 \nEpoch: 3\nIter:    840, Train Loss:   0.79, Train Acc:  78.12%, Time: 0:01:15 \nIter:    870, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:01:15 \nIter:    900, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:01:16 \nIter:    930, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:16 \nIter:    960, Train Loss:   0.29, Train Acc:  93.75%, Time: 0:01:16 \nIter:    990, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:01:16 \nIter:   1020, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:01:17 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/8/8\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/8/8\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  67.27%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.41      0.76      0.54       104\n                   Filter       0.63      0.63      0.63       110\n    Compute Derived Value       0.49      0.50      0.49        86\n            Find Extremum       0.74      0.63      0.68       133\n                     Sort       0.94      0.74      0.83        89\n          Determine Range       0.83      0.56      0.67        86\nCharacterize Distribution       0.76      0.67      0.71       116\n           Find Anomalies       0.78      0.60      0.68        89\n                  Cluster       0.77      0.82      0.79       120\n                Correlate       0.70      0.73      0.72       170\n\n                micro avg       0.67      0.67      0.67      1103\n                macro avg       0.71      0.66      0.67      1103\n             weighted avg       0.71      0.67      0.68      1103\n\nConfusion Matrix...\n[[ 79  10   7   2   0   0   2   0   0   4]\n [ 27  69   0   1   1   0   0   6   2   4]\n [ 26   4  43   0   0   0   1   1   2   9]\n [ 13   1  21  84   0   1   0   2   5   6]\n [  0   0   2  17  66   1   2   0   1   0]\n [ 22   0   0   6   0  48   1   1   1   7]\n [ 16   5   4   0   3   5  78   0   2   3]\n [  0  12   1   1   0   2   0  53   6  14]\n [  0   0   0   2   0   0  13   2  98   5]\n [  8   8  10   0   0   1   6   3  10 124]]\nTime usage: 0:00:00\nFold:  9\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.4, Train Acc:   6.25%, Time: 0:00:10 *\nIter:     60, Train Loss:    2.2, Train Acc:  18.75%, Time: 0:00:19 *\nIter:     90, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:28 *\nIter:    120, Train Loss:    2.1, Train Acc:  28.12%, Time: 0:00:35 *\nIter:    150, Train Loss:    1.9, Train Acc:  31.25%, Time: 0:00:42 *\nIter:    180, Train Loss:    1.9, Train Acc:  37.50%, Time: 0:00:49 *\nIter:    210, Train Loss:    1.6, Train Acc:  56.25%, Time: 0:01:00 *\nIter:    240, Train Loss:    1.6, Train Acc:  43.75%, Time: 0:01:00 \nIter:    270, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:01:10 *\nIter:    300, Train Loss:    1.3, Train Acc:  62.50%, Time: 0:01:10 \nIter:    330, Train Loss:    1.2, Train Acc:  71.88%, Time: 0:01:20 *\nIter:    360, Train Loss:    1.4, Train Acc:  59.38%, Time: 0:01:21 \nIter:    390, Train Loss:    1.0, Train Acc:  78.12%, Time: 0:01:31 *\nEpoch: 2\nIter:    420, Train Loss:   0.87, Train Acc:  81.25%, Time: 0:01:39 *\nIter:    450, Train Loss:    0.9, Train Acc:  75.00%, Time: 0:01:39 \nIter:    480, Train Loss:   0.89, Train Acc:  75.00%, Time: 0:01:39 \nIter:    510, Train Loss:   0.82, Train Acc:  81.25%, Time: 0:01:39 \nIter:    540, Train Loss:    1.0, Train Acc:  65.62%, Time: 0:01:40 \nIter:    570, Train Loss:   0.59, Train Acc:  81.25%, Time: 0:01:40 \nIter:    600, Train Loss:   0.63, Train Acc:  81.25%, Time: 0:01:40 \nIter:    630, Train Loss:    0.4, Train Acc:  93.75%, Time: 0:01:48 *\nIter:    660, Train Loss:   0.53, Train Acc:  81.25%, Time: 0:01:49 \nIter:    690, Train Loss:   0.54, Train Acc:  87.50%, Time: 0:01:49 \nIter:    720, Train Loss:   0.52, Train Acc:  90.62%, Time: 0:01:49 \nIter:    750, Train Loss:   0.57, Train Acc:  90.62%, Time: 0:01:49 \nIter:    780, Train Loss:   0.48, Train Acc:  81.25%, Time: 0:01:50 \nIter:    810, Train Loss:   0.39, Train Acc:  96.88%, Time: 0:01:59 *\nEpoch: 3\nIter:    840, Train Loss:   0.39, Train Acc:  87.50%, Time: 0:01:59 \nIter:    870, Train Loss:   0.35, Train Acc:  93.75%, Time: 0:02:00 \nIter:    900, Train Loss:   0.66, Train Acc:  75.00%, Time: 0:02:00 \nIter:    930, Train Loss:   0.43, Train Acc:  87.50%, Time: 0:02:00 \nIter:    960, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:02:00 \nIter:    990, Train Loss:   0.36, Train Acc:  90.62%, Time: 0:02:01 \nIter:   1020, Train Loss:   0.22, Train Acc: 100.00%, Time: 0:02:08 *\nIter:   1050, Train Loss:   0.25, Train Acc:  93.75%, Time: 0:02:08 \nIter:   1080, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:02:09 \nIter:   1110, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:02:09 \nIter:   1140, Train Loss:   0.34, Train Acc:  90.62%, Time: 0:02:09 \nIter:   1170, Train Loss:    0.2, Train Acc:  96.88%, Time: 0:02:09 \nIter:   1200, Train Loss:   0.13, Train Acc: 100.00%, Time: 0:02:10 \nIter:   1230, Train Loss:   0.35, Train Acc:  90.62%, Time: 0:02:10 \nEpoch: 4\nIter:   1260, Train Loss:   0.27, Train Acc:  93.75%, Time: 0:02:10 \nIter:   1290, Train Loss:   0.17, Train Acc:  93.75%, Time: 0:02:10 \nIter:   1320, Train Loss:   0.26, Train Acc:  93.75%, Time: 0:02:11 \nIter:   1350, Train Loss:   0.14, Train Acc:  96.88%, Time: 0:02:11 \nIter:   1380, Train Loss:   0.16, Train Acc:  93.75%, Time: 0:02:11 \nIter:   1410, Train Loss:   0.13, Train Acc: 100.00%, Time: 0:02:11 \nIter:   1440, Train Loss:    0.2, Train Acc:  93.75%, Time: 0:02:12 \nIter:   1470, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:02:12 \nIter:   1500, Train Loss:   0.18, Train Acc:  93.75%, Time: 0:02:12 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/9/9\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/9/9\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.2, Test Acc:  62.57%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.31      0.31      0.31        51\n                   Filter       0.70      0.17      0.27        95\n    Compute Derived Value       0.57      0.65      0.61        83\n            Find Extremum       0.41      0.97      0.58        68\n                     Sort       0.66      0.64      0.65        64\n          Determine Range       0.78      0.26      0.39        80\nCharacterize Distribution       0.79      0.88      0.83        68\n           Find Anomalies       0.79      0.81      0.80        80\n                  Cluster       0.68      0.88      0.77        76\n                Correlate       0.91      0.78      0.84        67\n\n                micro avg       0.63      0.63      0.63       732\n                macro avg       0.66      0.64      0.61       732\n             weighted avg       0.67      0.63      0.60       732\n\nConfusion Matrix...\n[[16  0  7 23  0  0  3  0  2  0]\n [26 16 22 16  6  6  1  1  1  0]\n [ 7  0 54  9  4  0  6  1  0  2]\n [ 1  0  0 66  0  0  0  1  0  0]\n [ 0  0  0  6 41  0  4  0 13  0]\n [ 1  7  4 35 10 21  1  1  0  0]\n [ 0  0  1  1  0  0 60  2  3  1]\n [ 0  0  6  4  0  0  0 65  3  2]\n [ 0  0  0  1  1  0  1  6 67  0]\n [ 0  0  0  0  0  0  0  5 10 52]]\nTime usage: 0:00:00\nFold:  10\nTraining and evaluating...\nEpoch: 1\nIter:     30, Train Loss:    2.3, Train Acc:  12.50%, Time: 0:00:10 *\nIter:     60, Train Loss:    2.4, Train Acc:   6.25%, Time: 0:00:10 \nIter:     90, Train Loss:    2.2, Train Acc:  21.88%, Time: 0:00:19 *\nIter:    120, Train Loss:    2.1, Train Acc:  25.00%, Time: 0:00:29 *\nIter:    150, Train Loss:    2.0, Train Acc:  40.62%, Time: 0:00:39 *\nIter:    180, Train Loss:    1.6, Train Acc:  50.00%, Time: 0:00:46 *\nIter:    210, Train Loss:    1.6, Train Acc:  56.25%, Time: 0:00:57 *\nIter:    240, Train Loss:    1.5, Train Acc:  59.38%, Time: 0:01:10 *\nIter:    270, Train Loss:    1.6, Train Acc:  40.62%, Time: 0:01:10 \nIter:    300, Train Loss:    1.3, Train Acc:  56.25%, Time: 0:01:11 \nIter:    330, Train Loss:    1.0, Train Acc:  71.88%, Time: 0:01:17 *\nIter:    360, Train Loss:   0.92, Train Acc:  78.12%, Time: 0:01:24 *\nIter:    390, Train Loss:    1.1, Train Acc:  59.38%, Time: 0:01:25 \nEpoch: 2\nIter:    420, Train Loss:   0.99, Train Acc:  75.00%, Time: 0:01:25 \nIter:    450, Train Loss:   0.88, Train Acc:  75.00%, Time: 0:01:25 \nIter:    480, Train Loss:   0.94, Train Acc:  81.25%, Time: 0:01:32 *\nIter:    510, Train Loss:   0.94, Train Acc:  71.88%, Time: 0:01:33 \nIter:    540, Train Loss:   0.64, Train Acc:  78.12%, Time: 0:01:33 \nIter:    570, Train Loss:   0.74, Train Acc:  71.88%, Time: 0:01:33 \nIter:    600, Train Loss:   0.89, Train Acc:  71.88%, Time: 0:01:33 \nIter:    630, Train Loss:   0.45, Train Acc:  93.75%, Time: 0:01:41 *\nIter:    660, Train Loss:   0.45, Train Acc:  90.62%, Time: 0:01:42 \nIter:    690, Train Loss:   0.77, Train Acc:  78.12%, Time: 0:01:42 \nIter:    720, Train Loss:   0.49, Train Acc:  87.50%, Time: 0:01:42 \nIter:    750, Train Loss:   0.47, Train Acc:  84.38%, Time: 0:01:42 \nIter:    780, Train Loss:   0.62, Train Acc:  81.25%, Time: 0:01:43 \nIter:    810, Train Loss:   0.37, Train Acc:  93.75%, Time: 0:01:43 \nEpoch: 3\nIter:    840, Train Loss:    0.4, Train Acc:  84.38%, Time: 0:01:43 \nIter:    870, Train Loss:   0.28, Train Acc:  93.75%, Time: 0:01:43 \nIter:    900, Train Loss:   0.41, Train Acc:  87.50%, Time: 0:01:44 \nIter:    930, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:01:51 *\nIter:    960, Train Loss:   0.39, Train Acc:  84.38%, Time: 0:01:51 \nIter:    990, Train Loss:    0.3, Train Acc:  90.62%, Time: 0:01:52 \nIter:   1020, Train Loss:   0.21, Train Acc: 100.00%, Time: 0:01:59 *\nIter:   1050, Train Loss:    0.3, Train Acc:  87.50%, Time: 0:01:59 \nIter:   1080, Train Loss:   0.41, Train Acc:  90.62%, Time: 0:01:59 \nIter:   1110, Train Loss:   0.19, Train Acc:  96.88%, Time: 0:01:59 \nIter:   1140, Train Loss:   0.18, Train Acc:  96.88%, Time: 0:02:00 \nIter:   1170, Train Loss:   0.31, Train Acc:  93.75%, Time: 0:02:00 \nIter:   1200, Train Loss:   0.35, Train Acc:  93.75%, Time: 0:02:00 \nIter:   1230, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:02:00 \nEpoch: 4\nIter:   1260, Train Loss:   0.27, Train Acc:  96.88%, Time: 0:02:01 \nIter:   1290, Train Loss:   0.11, Train Acc:  96.88%, Time: 0:02:01 \nIter:   1320, Train Loss:   0.23, Train Acc:  96.88%, Time: 0:02:01 \nIter:   1350, Train Loss:   0.14, Train Acc: 100.00%, Time: 0:02:01 \nIter:   1380, Train Loss:   0.13, Train Acc:  96.88%, Time: 0:02:02 \nIter:   1410, Train Loss:   0.21, Train Acc:  90.62%, Time: 0:02:02 \nIter:   1440, Train Loss:   0.21, Train Acc:  96.88%, Time: 0:02:02 \nIter:   1470, Train Loss:   0.33, Train Acc:  93.75%, Time: 0:02:02 \nIter:   1500, Train Loss:   0.23, Train Acc:  93.75%, Time: 0:02:03 \nNo optimization for a long time, auto-stopping...\nINFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/10/10\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from s3://corpus-2/model/ShinContextual/table/10/10\n", "name": "stderr"}, {"output_type": "stream", "text": "Testing...\nTest Loss:    1.1, Test Acc:  62.75%\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.50      0.56      0.53        79\n                   Filter       0.45      0.21      0.29        91\n    Compute Derived Value       0.67      0.40      0.50        94\n            Find Extremum       0.74      0.99      0.85        84\n                     Sort       0.41      0.97      0.58        29\n          Determine Range       0.53      0.51      0.52        73\nCharacterize Distribution       0.49      0.85      0.62        26\n           Find Anomalies       0.68      0.90      0.78        77\n                  Cluster       0.83      0.70      0.76        54\n                Correlate       0.87      0.66      0.75        91\n\n                micro avg       0.63      0.63      0.63       698\n                macro avg       0.62      0.67      0.62       698\n             weighted avg       0.64      0.63      0.61       698\n\nConfusion Matrix...\n[[44  4 13  3 12  2  0  0  0  1]\n [33 19  3  1  3 29  1  1  0  1]\n [ 2  6 38 14 10  0 16  8  0  0]\n [ 0  0  0 83  0  0  0  1  0  0]\n [ 0  0  0  1 28  0  0  0  0  0]\n [ 4  4  3  3  9 37  6  0  7  0]\n [ 1  0  0  0  2  1 22  0  0  0]\n [ 0  2  0  5  0  0  0 69  0  1]\n [ 0  0  0  1  0  1  0  8 38  6]\n [ 4  7  0  1  4  0  0 14  1 60]]\nTime usage: 0:00:00\n[0.6730255624894103, 0.7144818121878023, 0.6822988503006683, 0.6649958230897398, 0.7155511806330342, 0.6337943472420675, 0.5972323373383357, 0.6727107889740875, 0.6256830604349981, 0.6275071631529953]\n0.660728092584314, 0.03709754607573717, 0.039104247067456924, 0.0013762279248414422\n", "name": "stdout"}]}], "metadata": {"kernelspec": {"name": "tensorflow-1.8", "display_name": "TensorFlow-1.8", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}