{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "import numpy as np\nimport tensorflow as tf\nimport sys\nimport time\nfrom datetime import timedelta\nimport tensorflow.contrib.keras as kr\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\n\nimport moxing as mox\nmox.file.shift('os', 'mox')", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "INFO:root:Using MoXing-v1.14.1-ddfd6c9a\nINFO:root:Using OBS-Python-SDK-3.1.2\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "trainDataPath = \"s3://corpus-2/dataset/corpus_5_new.txt\"\nvocabPath = \"s3://corpus-text-classification1/data/glove.6B.100d.txt\"", "execution_count": 2, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "split_info = {\n    \"random\": False,\n    \"expert\": [20, 4],\n    \"bundle\": [920, 1],\n    \"table\": [37, 3]\n}\n\n\ndef dataset_split(info):\n    if info:\n        [num, pi] = info\n        train_data = [[] for i in range(num)]\n        with open(trainDataPath, \"r\", encoding='utf-8') as fp:\n            for line in fp.readlines():\n                word = line.split()\n                info = word[0].split(\":\")\n                index = int(info[pi]) - 1\n                label = int(info[0])\n                content = word[1:]\n                train_data[index].append([content,label])\n\n        for i in range(num):\n            np.random.shuffle(train_data[i])\n            train_data[i] = np.asarray(train_data[i])\n\n        np.random.shuffle(train_data)   \n        return train_data\n    \n    \n    train_data = []\n    with open(trainDataPath, 'r', encoding='utf-8') as f:\n        for line in f.readlines():\n            word = line.split()\n            label = int(word[0].split(\":\")[0])\n            content = word[1:]\n            train_data.append([content,label])\n    \n    np.random.shuffle(train_data)\n    return np.asarray(train_data)\n\n\ndef mergeData(data_x, data_y):\n    merge_x = data_x[0]\n    merge_y = data_y[0]\n    for i in range(1,len(data_x)):\n        merge_x = np.r_[merge_x,data_x[i]]\n        merge_y = np.r_[merge_y,data_y[i]]\n        \n    return merge_x, merge_y\n\n\ndef train_split_data(train_data, split_type):\n    \n    print(split_type)\n    \n    test_acc = []\n    fold_id = 0\n    \n    if split_type != \"random\":\n        tx = []\n        ty = []\n        for ti in train_data:\n            x_train, y_train = process_file(ti[:,0], ti[:,1], word_to_id, num_classes, seq_length)\n            tx.append(x_train)\n            ty.append(y_train)\n\n        tx = np.asarray(tx)\n        ty = np.asarray(ty)\n\n        print(len(tx),len(tx[0]),len(tx[1]),len(tx[0][0]))\n        \n        for train_i, test_i in kf.split(tx):\n            fold_id += 1\n            print(\"Fold: \", fold_id)\n            train_x, train_y = mergeData(tx[train_i],ty[train_i])\n            test_x, test_y = mergeData(tx[test_i],ty[test_i])\n            test_acc.append(classifier.train(\n                X_train=train_x,\n                y_train=train_y,\n                X_eval=test_x,\n                y_eval=test_y,\n                categories=categories,\n                epochs=50\n            ))\n        \n    else:\n        tx, ty = process_file(train_data[:,0], train_data[:,1], word_to_id, num_classes, seq_length)\n        print(len(tx),len(tx[0]),len(tx[1]))\n\n        for train_i, test_i in kf.split(tx):\n            fold_id += 1\n            print(\"Fold: \", fold_id)\n            test_acc.append(classifier.train(\n                X_train=tx[train_i],\n                y_train=ty[train_i],\n                X_eval=tx[test_i],\n                y_eval=ty[test_i],\n                categories=categories,\n                epochs=50\n            ))\n        \n    print(test_acc)\n    print(\"%s, %s, %s, %s\" % (np.mean(test_acc),np.std(test_acc),np.std(test_acc,ddof=1),np.var(test_acc)))\n    return test_acc", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "raw", "source": "def train_10_fold(train_data, categories):\n    \n    tx, ty = process_file(train_data[:,0], train_data[:,1], word_to_id, cat_to_id, num_classes, seq_length)\n    print(len(tx),len(tx[0]),len(tx[1]))\n    \n    fold_id = 0\n    test_acc = []\n    \n    kf = KFold(n_splits=10)\n    for train_i, test_i in kf.split(tx):\n        fold_id += 1\n        print(\"Fold: \", fold_id)\n        test_acc.append(classifier.train(\n            X_train=tx[train_i],\n            y_train=ty[train_i],\n            X_eval=tx[test_i],\n            y_eval=ty[test_i],\n            categories=categories,\n            epochs=30\n        ))\n    print(test_acc)\n    print(\"%s, %s, %s, %s\" % (np.mean(test_acc),np.std(test_acc),np.std(test_acc,ddof=1),np.var(test_acc)))\n    return test_acc"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def loadGloVe(filename):\n    vocab = []\n    embd = []\n    print('Loading GloVe!')\n    # vocab.append('unk') #\u88c5\u8f7d\u4e0d\u8ba4\u8bc6\u7684\u8bcd\n    # embd.append([0] * emb_size) #\u8fd9\u4e2aemb_size\u53ef\u80fd\u9700\u8981\u6307\u5b9a\n    file = open(filename,'r',encoding='utf-8')\n    for line in file.readlines():\n        row = line.strip().split(' ')\n        vocab.append(row[0])\n        embd.append([float(ei) for ei in row[1:]])\n    file.close()\n    print('Completed!')\n    return vocab,embd\n\n\ndef process_file(contents, labels, word_to_id, num_classes, pad_max_length):\n    \"\"\"\n    \u5c06\u6587\u4ef6\u8f6c\u6362\u4e3aid\u8868\u793a,\u5e76\u4e14\u5c06\u6bcf\u4e2a\u5355\u72ec\u7684\u6837\u672c\u957f\u5ea6\u56fa\u5b9a\u4e3apad_max_lengtn\n    \"\"\"\n    # contents, labels = readfile(filePath)\n    data_id, label_id = [], []\n    # \u5c06\u6587\u672c\u5185\u5bb9\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684id\u5f62\u5f0f\n    for i in range(len(contents)):\n        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])\n        label_id.append(labels[i] - 1)  # label_id.append(cat_to_id[labels[i]])\n    # \u4f7f\u7528keras\u63d0\u4f9b\u7684pad_sequences\u6765\u5c06\u6587\u672cpad\u4e3a\u56fa\u5b9a\u957f\u5ea6\n    x_pad = kr.preprocessing.sequence.pad_sequences(data_id, pad_max_length)\n    ''' https://blog.csdn.net/TH_NUM/article/details/80904900\n    pad_sequences(sequences, maxlen=None, dtype=\u2019int32\u2019, padding=\u2019pre\u2019, truncating=\u2019pre\u2019, value=0.) \n        sequences\uff1a\u6d6e\u70b9\u6570\u6216\u6574\u6570\u6784\u6210\u7684\u4e24\u5c42\u5d4c\u5957\u5217\u8868\n        maxlen\uff1aNone\u6216\u6574\u6570\uff0c\u4e3a\u5e8f\u5217\u7684\u6700\u5927\u957f\u5ea6\u3002\u5927\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u88ab\u622a\u77ed\uff0c\u5c0f\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u5728\u540e\u90e8\u586b0.\n        dtype\uff1a\u8fd4\u56de\u7684numpy array\u7684\u6570\u636e\u7c7b\u578b\n        padding\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u88650\u65f6\uff0c\u5728\u5e8f\u5217\u7684\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u8865\n        truncating\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u622a\u65ad\u5e8f\u5217\u65f6\uff0c\u4ece\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u622a\u65ad\n        value\uff1a\u6d6e\u70b9\u6570\uff0c\u6b64\u503c\u5c06\u5728\u586b\u5145\u65f6\u4ee3\u66ff\u9ed8\u8ba4\u7684\u586b\u5145\u503c0\n    '''\n    y_pad = kr.utils.to_categorical(label_id, num_classes=num_classes)  # \u5c06\u6807\u7b7e\u8f6c\u6362\u4e3aone-hot\u8868\u793a\n    ''' https://blog.csdn.net/nima1994/article/details/82468965\n    to_categorical(y, num_classes=None, dtype='float32')\n        \u5c06\u6574\u578b\u6807\u7b7e\u8f6c\u4e3aonehot\u3002y\u4e3aint\u6570\u7ec4\uff0cnum_classes\u4e3a\u6807\u7b7e\u7c7b\u522b\u603b\u6570\uff0c\u5927\u4e8emax(y)\uff08\u6807\u7b7e\u4ece0\u5f00\u59cb\u7684\uff09\u3002\n        \u8fd4\u56de\uff1a\u5982\u679cnum_classes=None\uff0c\u8fd4\u56delen(y) * [max(y)+1]\uff08\u7ef4\u5ea6\uff0cm*n\u8868\u793am\u884cn\u5217\u77e9\u9635\uff0c\u4e0b\u540c\uff09\uff0c\u5426\u5219\u4e3alen(y) * num_classes\u3002\n    '''\n    return x_pad, y_pad", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "categories = ['Retrieve Value', 'Filter', 'Compute Derived Value', 'Find Extremum', 'Sort', \n                  'Determine Range', 'Characterize Distribution', 'Find Anomalies', 'Cluster', 'Correlate']\nnum_classes = len(categories)\n\nvocab, embd = loadGloVe(vocabPath)\nvocab_size = len(vocab)\nembedding_dim = len(embd[0])\nembedding = np.asarray(embd)\nword_to_id = dict(zip(vocab, range(vocab_size)))\n\nprint(len(embedding),embedding_dim,vocab_size)\n \nseq_length = 41  # seq_length = 37  TREC", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Loading GloVe!\nCompleted!\n400000 100 400000\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "class Classifier:\n\n    def __init__(self, model, input_length, output_length):\n        self.model = model\n        self.input_length = input_length\n        self.output_length = output_length\n\n    def compile(self, batch_size=32):\n        self._ds_x = tf.placeholder(tf.float32, [None, self.input_length])\n        self._ds_y = tf.placeholder(tf.float32, [None, self.output_length])\n\n        ds = tf.data.Dataset.from_tensor_slices((self._ds_x, self._ds_y))\n        ds = ds.batch(batch_size)\n\n        self._ds_it = ds.make_initializable_iterator()\n        self._input, self._labels = self._ds_it.get_next()\n\n        self._features = self.model(self._input)\n        self._output = _create_dense_layer(self._features, self.output_length)\n\n        self._create_acc_computations()\n        self._create_backpropagation()\n\n    def _create_acc_computations(self):\n        self._predictions = tf.argmax(self._output, 1)\n        labels = tf.argmax(self._labels, 1)\n        self._accuracy = tf.reduce_mean(\n            tf.cast(tf.equal(self._predictions, labels), 'float32'))\n\n    def _create_backpropagation(self):\n        losses = tf.nn.softmax_cross_entropy_with_logits_v2(\n            logits=self._output,\n            labels=self._labels)\n        self._loss = tf.reduce_mean(losses)\n\n        optimizer = tf.train.AdamOptimizer(0.001)\n        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n        grads_and_vars = optimizer.compute_gradients(self._loss)\n\n        self._train_op = optimizer.apply_gradients(\n            grads_and_vars, global_step=global_step)\n\n    def summary(self):\n        print('input:', self._input.shape)\n        self.model.summary()\n        print('output:', self._output.shape)\n\n    def train(self, X_train, y_train, X_eval, y_eval, categories, epochs=20, require_improve=3):\n        \n        session = tf.Session()\n        session.run(tf.global_variables_initializer())\n        session.run(tf.local_variables_initializer())\n        \n        best_vac_acc = 0.0\n        last_improved = 0\n        \n        for e in range(epochs):\n            start_time = time.time()\n            loss, acc = self._train(X_train, y_train, session)\n            duration = time.time() - start_time\n\n            val_loss, val_acc = self._eval(X_eval, y_eval, session)\n            \n            if val_acc > best_vac_acc:\n                best_vac_acc = val_acc\n                last_improved = e\n                improved_str = '*'\n            else:\n                improved_str = ''\n            \n            output = 'Epoch: {:>1}, Train Loss: {:>6.4}, Train Acc: {:>6.2%}, Val Loss: {:>6.4}, Val Acc: {:>6.2%}, Time: {:.2f}s {}'\n            print(output.format(e + 1, loss, acc, val_loss, val_acc, duration, improved_str))\n            \n            if e - last_improved > require_improve:\n                print(\"No optimization for a long time, auto-stopping...\")\n                \n                y_test_cls = np.argmax(y_eval, 1)  # \u83b7\u5f97\u7c7b\u522b\n                y_test_pred_cls = np.argmax(self.predict(X_eval, session), 1)\n                accuracy_score = metrics.accuracy_score(y_test_cls, y_test_pred_cls)\n                \n                # evaluate\n                print(\"Precision, Recall and F1-Score...\")\n                print(metrics.classification_report(y_test_cls, y_test_pred_cls, target_names=categories))\n                '''\n                sklearn\u4e2d\u7684classification_report\u51fd\u6570\u7528\u4e8e\u663e\u793a\u4e3b\u8981\u5206\u7c7b\u6307\u6807\u7684\u6587\u672c\u62a5\u544a\uff0e\u5728\u62a5\u544a\u4e2d\u663e\u793a\u6bcf\u4e2a\u7c7b\u7684\u7cbe\u786e\u5ea6\uff0c\u53ec\u56de\u7387\uff0cF1\u503c\u7b49\u4fe1\u606f\u3002\n                    y_true\uff1a1\u7ef4\u6570\u7ec4\uff0c\u6216\u6807\u7b7e\u6307\u793a\u5668\u6570\u7ec4/\u7a00\u758f\u77e9\u9635\uff0c\u76ee\u6807\u503c\u3002 \n                    y_pred\uff1a1\u7ef4\u6570\u7ec4\uff0c\u6216\u6807\u7b7e\u6307\u793a\u5668\u6570\u7ec4/\u7a00\u758f\u77e9\u9635\uff0c\u5206\u7c7b\u5668\u8fd4\u56de\u7684\u4f30\u8ba1\u503c\u3002 \n                    labels\uff1aarray\uff0cshape = [n_labels]\uff0c\u62a5\u8868\u4e2d\u5305\u542b\u7684\u6807\u7b7e\u7d22\u5f15\u7684\u53ef\u9009\u5217\u8868\u3002 \n                    target_names\uff1a\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u4e0e\u6807\u7b7e\u5339\u914d\u7684\u53ef\u9009\u663e\u793a\u540d\u79f0\uff08\u76f8\u540c\u987a\u5e8f\uff09\u3002 \n                    \u539f\u6587\u94fe\u63a5\uff1ahttps://blog.csdn.net/akadiao/article/details/78788864\n                '''\n\n                print(\"Confusion Matrix...\")\n                print(metrics.confusion_matrix(y_test_cls, y_test_pred_cls))\n                '''\n                \u6df7\u6dc6\u77e9\u9635\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u603b\u7ed3\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u60c5\u5f62\u5206\u6790\u8868\uff0c\u4ee5\u77e9\u9635\u5f62\u5f0f\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u8bb0\u5f55\u6309\u7167\u771f\u5b9e\u7684\u7c7b\u522b\u4e0e\u5206\u7c7b\u6a21\u578b\u4f5c\u51fa\u7684\u5206\u7c7b\u5224\u65ad\u4e24\u4e2a\u6807\u51c6\u8fdb\u884c\u6c47\u603b\u3002\n                \u8fd9\u4e2a\u540d\u5b57\u6765\u6e90\u4e8e\u5b83\u53ef\u4ee5\u975e\u5e38\u5bb9\u6613\u7684\u8868\u660e\u591a\u4e2a\u7c7b\u522b\u662f\u5426\u6709\u6df7\u6dc6\uff08\u4e5f\u5c31\u662f\u4e00\u4e2aclass\u88ab\u9884\u6d4b\u6210\u53e6\u4e00\u4e2aclass\uff09\n                https://blog.csdn.net/u011734144/article/details/80277225\n                '''\n                break\n        # endfor\n        session.close()\n        return accuracy_score\n\n    def _train(self, X_train, y_train, session):\n        import numpy as np\n\n        session.run(\n            fetches=self._ds_it.initializer,\n            feed_dict={\n                self._ds_x: X_train,\n                self._ds_y: y_train\n            })\n        loss, acc, = [], []\n        while True:\n            try:\n                _, vloss, vacc = session.run(\n                    fetches=[self._train_op, self._loss, self._accuracy])\n\n                loss.append(vloss)\n                acc.append(vacc)\n            except tf.errors.OutOfRangeError:\n                break\n        # endwhile\n\n        loss, acc = np.mean(loss), np.mean(acc)\n        return loss, acc\n\n    def _eval(self, X_val, y_val, session):\n        session.run(\n            fetches=self._ds_it.initializer,\n            feed_dict={\n                self._ds_x: X_val,\n                self._ds_y: y_val\n            })\n\n        loss, acc, = 0, 0\n        while True:\n            try:\n                l, vloss, vacc = session.run(\n                    fetches=[self._labels, self._loss, self._accuracy])\n\n                loss += vloss * len(l)\n                acc += vacc * len(l)\n            except tf.errors.OutOfRangeError:\n                break\n\n        return loss / len(X_val), acc / len(X_val)\n\n    def predict(self, X, session):\n        session.run(self._ds_it.initializer,\n                         feed_dict={\n                             self._ds_x: X,\n                             self._ds_y: np.empty((len(X), self.output_length))\n                         }\n                         )\n\n        pred = list()\n        while True:\n            try:\n                ppred = session.run(tf.nn.softmax(self._output))\n\n                pred.extend(map(lambda l: l.tolist(), ppred))\n            except tf.errors.OutOfRangeError:\n                break\n\n        return pred\n\ndef _create_dense_layer(x, output_length):\n    '''Creates a dense layer\n    '''\n    input_size = x.shape[1].value\n    W = tf.Variable(\n        initial_value=tf.truncated_normal(\n            shape=[input_size, output_length],\n            stddev=0.1))\n    b = tf.Variable(\n        initial_value=tf.truncated_normal(\n            shape=[output_length]))\n\n    dense = tf.nn.xw_plus_b(x, W, b)\n\n    return dense", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "class ZhouCLSTMModel:\n    '''\n    Implementation proposal of: https://arxiv.org/pdf/1511.08630\n    '''\n    def __init__(self, embedding,\n        conv_size    = 3,\n        conv_filters = 300,\n        drop_rate    = 0.5,\n        lstm_units   = 150):\n        '''Constructor.\n        # Parameters:\n        conv_size: Size of the convolutions. Number of words that takes each\n            convolution step.\n        conv_filters: Number of convolution filters.\n        drop_rate: Drop rate for the final output of the LSTM layer.\n        lstm_units: Size of the states of the LSTM layer.\n        '''\n        self._embedding    = embedding\n        self._conv_size    = conv_size\n        self._conv_filters = conv_filters\n        self._drop_rate    = drop_rate\n        self._lstm_units   = lstm_units\n\n    def __call__(self, input):\n        self._embedding_tf = self._create_embedding_layer(\n            self._embedding, input)\n        \n        self._convolution_tf = self._create_convolutional_layers(\n            self._conv_size,\n            self._conv_filters,\n            self._drop_rate,\n            self._embedding_tf)\n        \n        self._lstm_tf = self._create_lstm_layer(\n            self._lstm_units,\n            self._convolution_tf)\n        \n        return self._lstm_tf\n\n    def summary(self):\n        print('embedding:', str(self._embedding_tf.shape))\n        print('conv:', str(self._convolution_tf.shape))\n        print('lstm:', str(self._lstm_tf.shape))\n\n    def _create_embedding_layer(self, embedding, input_x):\n        embedding = tf.Variable(initial_value=embedding)\n\n        embedded_chars = tf.nn.embedding_lookup(\n            embedding, tf.cast(input_x, 'int32'))\n\n        return embedded_chars\n\n    def _create_convolutional_layers(self,\n        conv_size, num_filters, drop_rate, embedding):\n        \n        filter_height = conv_size\n        filter_width = embedding.shape[2].value\n\n        filter_shape = [filter_height, filter_width, 1, num_filters]\n\n        W = tf.Variable(\n            initial_value=tf.truncated_normal(\n                shape=filter_shape,\n                stddev=0.1))\n        b = tf.Variable(\n            initial_value=tf.truncated_normal(\n                shape=[num_filters]))\n\n        embedding_expanded = tf.expand_dims(embedding, -1)\n        conv = tf.nn.conv2d(\n            input=embedding_expanded,\n            filter=W,\n            strides=[1,1,1,1],\n            padding='VALID')\n        conv_reduced = tf.reshape(\n            tensor=conv,\n            shape=[-1, conv.shape[1], conv.shape[3]])\n\n        bias = tf.nn.bias_add(conv_reduced, b)\n        c = tf.nn.relu(bias)\n\n        d = tf.nn.dropout(c, keep_prob=drop_rate)\n        return d\n\n    def _create_lstm_layer(self, lstm_units, conv_input):\n        lstm_cell = tf.nn.rnn_cell.LSTMCell(lstm_units)\n        sequence = tf.unstack(conv_input, axis=1)\n        (_, (h, _)) = tf.nn.static_rnn(lstm_cell, sequence, dtype=tf.float32)\n\n        return h", "execution_count": 7, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "word_vector = embedding.astype('float32')\nmodel = ZhouCLSTMModel(embedding=word_vector)\n\nclassifier = Classifier(\n    model=model,\n    input_length=seq_length,\n    output_length=num_classes)\n\nclassifier.compile(batch_size=32)\nclassifier.summary()", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "input: (?, 41)\nembedding: (?, 41, 100)\nconv: (?, 39, 300)\nlstm: (?, 150)\noutput: (?, 10)\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "split_info = {\n    # \"random\": False,\n    \"expert\": [20, 4],\n    \"bundle\": [920, 1],\n    \"table\": [37, 3]\n}\n\nkf = KFold(n_splits=10)\ntest_acc_split = []\nfor split_type,info in split_info.items():\n    train_data = dataset_split(info)\n    test_acc_split.append(train_split_data(train_data, split_type))", "execution_count": null, "outputs": [{"output_type": "stream", "text": "expert\n20 1103 636 41\nFold:  1\nEpoch: 1, Train Loss:   1.46, Train Acc: 50.63%, Val Loss:  1.548, Val Acc: 47.38%, Time: 10.06s *\nEpoch: 2, Train Loss: 0.6433, Train Acc: 79.59%, Val Loss:  1.607, Val Acc: 57.10%, Time: 7.33s *\nEpoch: 3, Train Loss: 0.3473, Train Acc: 89.43%, Val Loss:  1.596, Val Acc: 61.07%, Time: 7.24s *\nEpoch: 4, Train Loss: 0.2163, Train Acc: 93.25%, Val Loss:  1.492, Val Acc: 63.77%, Time: 7.20s *\nEpoch: 5, Train Loss: 0.1458, Train Acc: 95.45%, Val Loss:  2.043, Val Acc: 59.34%, Time: 7.37s \nEpoch: 6, Train Loss:  0.116, Train Acc: 96.40%, Val Loss:  1.892, Val Acc: 61.53%, Time: 7.16s \nEpoch: 7, Train Loss: 0.08493, Train Acc: 97.32%, Val Loss:  1.924, Val Acc: 65.50%, Time: 7.18s *\nEpoch: 8, Train Loss: 0.06725, Train Acc: 97.73%, Val Loss:   2.18, Val Acc: 62.97%, Time: 7.28s \nEpoch: 9, Train Loss: 0.05486, Train Acc: 98.15%, Val Loss:  2.461, Val Acc: 63.83%, Time: 7.15s \nEpoch: 10, Train Loss: 0.04314, Train Acc: 98.45%, Val Loss:  2.275, Val Acc: 64.23%, Time: 7.34s \nEpoch: 11, Train Loss: 0.03815, Train Acc: 98.81%, Val Loss:  2.333, Val Acc: 65.27%, Time: 7.23s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.66      0.43      0.52       171\n                   Filter       0.49      0.50      0.49       175\n    Compute Derived Value       0.67      0.48      0.56       249\n            Find Extremum       0.64      0.91      0.75       182\n                     Sort       0.50      0.84      0.62       116\n          Determine Range       0.62      0.70      0.66       211\nCharacterize Distribution       0.73      0.79      0.76       118\n           Find Anomalies       0.71      0.83      0.77       168\n                  Cluster       0.87      0.74      0.80       131\n                Correlate       0.86      0.56      0.67       218\n\n                micro avg       0.66      0.66      0.66      1739\n                macro avg       0.67      0.68      0.66      1739\n             weighted avg       0.68      0.66      0.65      1739\n\nConfusion Matrix...\n[[ 73  35  30   7  14   7   3   1   1   0]\n [ 16  88  13  15  13  20   0   9   1   0]\n [  7   8 120  40  12  31  11  14   3   3]\n [  0   0   3 166   2   2   0   0   0   9]\n [  0   3   0   7  97   6   0   3   0   0]\n [  0  16   2   9  29 147   3   4   0   1]\n [  1   7   3   2   3   8  93   0   0   1]\n [  0  10   1  10   0   1   2 140   2   2]\n [  0   4   0   2  14   1   2   7  97   4]\n [ 13  10   7   2  11  14  13  20   7 121]]\nFold:  2\nEpoch: 1, Train Loss:  1.399, Train Acc: 53.15%, Val Loss:   1.77, Val Acc: 48.26%, Time: 9.27s *\nEpoch: 2, Train Loss: 0.6055, Train Acc: 81.05%, Val Loss:  1.736, Val Acc: 53.88%, Time: 7.63s *\nEpoch: 3, Train Loss: 0.3396, Train Acc: 89.16%, Val Loss:   1.67, Val Acc: 58.15%, Time: 7.58s *\nEpoch: 4, Train Loss: 0.2084, Train Acc: 93.62%, Val Loss:   1.79, Val Acc: 61.47%, Time: 7.56s *\nEpoch: 5, Train Loss:  0.141, Train Acc: 95.47%, Val Loss:   2.04, Val Acc: 57.83%, Time: 7.56s \nEpoch: 6, Train Loss: 0.1006, Train Acc: 96.80%, Val Loss:  1.766, Val Acc: 65.35%, Time: 7.57s *\nEpoch: 7, Train Loss: 0.08261, Train Acc: 97.20%, Val Loss:  2.344, Val Acc: 58.94%, Time: 7.48s \nEpoch: 8, Train Loss: 0.06738, Train Acc: 97.73%, Val Loss:  1.991, Val Acc: 62.74%, Time: 7.66s \nEpoch: 9, Train Loss: 0.05263, Train Acc: 98.37%, Val Loss:  1.892, Val Acc: 65.82%, Time: 7.50s *\nEpoch: 10, Train Loss: 0.04974, Train Acc: 98.41%, Val Loss:   2.02, Val Acc: 66.69%, Time: 7.50s *\nEpoch: 11, Train Loss: 0.0335, Train Acc: 98.87%, Val Loss:  2.333, Val Acc: 64.87%, Time: 7.71s \nEpoch: 12, Train Loss: 0.03433, Train Acc: 98.94%, Val Loss:  2.165, Val Acc: 66.46%, Time: 7.58s \nEpoch: 13, Train Loss: 0.03894, Train Acc: 98.72%, Val Loss:  2.175, Val Acc: 65.66%, Time: 7.62s \nEpoch: 14, Train Loss: 0.02621, Train Acc: 99.09%, Val Loss:  2.515, Val Acc: 65.51%, Time: 7.53s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.47      0.27      0.34       134\n                   Filter       0.37      0.17      0.24       116\n    Compute Derived Value       0.47      0.68      0.56       130\n            Find Extremum       0.81      0.72      0.77       127\n                     Sort       0.87      0.84      0.85       125\n          Determine Range       0.64      0.55      0.59       122\nCharacterize Distribution       0.55      0.90      0.69       120\n           Find Anomalies       0.87      0.70      0.78       124\n                  Cluster       0.98      0.76      0.86       144\n                Correlate       0.54      0.89      0.67       122\n\n                micro avg       0.65      0.65      0.65      1264\n                macro avg       0.66      0.65      0.63      1264\n             weighted avg       0.66      0.65      0.64      1264\n\nConfusion Matrix...\n[[ 36   9  40   5   1   5   9   1   0  28]\n [ 22  20  17   4   2   6  17   2   0  26]\n [  0   0  88   1   0   6  25   0   0  10]\n [  0   0  11  92   2   3  16   0   0   3]\n [  0   3   4   2 105   1   1   1   1   7]\n [ 18   9  13   1   1  67  11   0   0   2]\n [  0   0   9   0   0   0 108   0   1   2]\n [  0  12   2   4   0  10   1  87   0   8]\n [  0   1   0   3  10   5   4   5 110   6]\n [  0   0   3   1   0   2   3   4   0 109]]\nFold:  3\nEpoch: 1, Train Loss:  1.431, Train Acc: 52.56%, Val Loss:  1.607, Val Acc: 51.72%, Time: 9.36s *\nEpoch: 2, Train Loss: 0.6359, Train Acc: 80.14%, Val Loss:  1.457, Val Acc: 60.38%, Time: 7.57s *\nEpoch: 3, Train Loss: 0.3413, Train Acc: 89.50%, Val Loss:  1.589, Val Acc: 62.55%, Time: 7.48s *\nEpoch: 4, Train Loss: 0.2105, Train Acc: 93.58%, Val Loss:  1.575, Val Acc: 64.96%, Time: 7.57s *\nEpoch: 5, Train Loss:  0.145, Train Acc: 95.51%, Val Loss:  1.741, Val Acc: 65.36%, Time: 7.54s *\nEpoch: 6, Train Loss: 0.1109, Train Acc: 96.40%, Val Loss:  1.984, Val Acc: 63.27%, Time: 7.54s \nEpoch: 7, Train Loss: 0.08718, Train Acc: 97.27%, Val Loss:  1.718, Val Acc: 66.72%, Time: 7.66s *\nEpoch: 8, Train Loss: 0.06659, Train Acc: 97.84%, Val Loss:  2.091, Val Acc: 66.80%, Time: 7.50s *\nEpoch: 9, Train Loss: 0.05395, Train Acc: 98.20%, Val Loss:  1.866, Val Acc: 66.80%, Time: 7.45s \nEpoch: 10, Train Loss: 0.04638, Train Acc: 98.59%, Val Loss:  1.937, Val Acc: 65.68%, Time: 7.62s \nEpoch: 11, Train Loss: 0.03442, Train Acc: 98.78%, Val Loss:  2.287, Val Acc: 64.39%, Time: 7.60s \nEpoch: 12, Train Loss: 0.03698, Train Acc: 98.82%, Val Loss:  2.053, Val Acc: 65.12%, Time: 7.50s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.62      0.31      0.41       128\n                   Filter       0.42      0.33      0.37       131\n    Compute Derived Value       0.38      0.58      0.46       125\n            Find Extremum       0.77      0.77      0.77       128\n                     Sort       0.83      0.88      0.85       112\n          Determine Range       0.56      0.44      0.49       121\nCharacterize Distribution       0.63      0.85      0.72       122\n           Find Anomalies       0.62      0.62      0.62       121\n                  Cluster       0.90      0.88      0.89       123\n                Correlate       0.79      0.84      0.81       136\n\n                micro avg       0.65      0.65      0.65      1247\n                macro avg       0.65      0.65      0.64      1247\n             weighted avg       0.65      0.65      0.64      1247\n\nConfusion Matrix...\n[[ 40   7  34  20   2  12   4   9   0   0]\n [  0  43  26   7   4  20   4  23   0   4]\n [  8   2  73   1   2   5  23   2   1   8]\n [  0   1  17  99   2   1   2   6   0   0]\n [  0   0   0   1  98   0   3   1   9   0]\n [  7  34   9   0   2  53  11   1   1   3]\n [  8   0   3   0   2   3 104   0   0   2]\n [  2  16  10   0   0   0  10  75   0   8]\n [  0   0   0   0   6   0   4   0 108   5]\n [  0   0  18   0   0   0   0   3   1 114]]\nFold:  4\nEpoch: 1, Train Loss:  1.475, Train Acc: 50.59%, Val Loss:  1.232, Val Acc: 62.76%, Time: 9.48s *\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 2, Train Loss: 0.6413, Train Acc: 79.74%, Val Loss:  1.047, Val Acc: 70.39%, Time: 7.48s *\nEpoch: 3, Train Loss: 0.3473, Train Acc: 88.89%, Val Loss:  1.128, Val Acc: 71.55%, Time: 7.39s *\nEpoch: 4, Train Loss: 0.2152, Train Acc: 93.38%, Val Loss:  1.121, Val Acc: 73.94%, Time: 7.52s *\nEpoch: 5, Train Loss: 0.1382, Train Acc: 95.73%, Val Loss:  1.158, Val Acc: 75.71%, Time: 7.51s *\nEpoch: 6, Train Loss: 0.1039, Train Acc: 96.76%, Val Loss:  1.183, Val Acc: 76.18%, Time: 7.60s *\nEpoch: 7, Train Loss: 0.08231, Train Acc: 97.48%, Val Loss:   1.31, Val Acc: 72.78%, Time: 7.51s \nEpoch: 8, Train Loss: 0.06468, Train Acc: 97.88%, Val Loss:  1.243, Val Acc: 76.48%, Time: 7.45s *\nEpoch: 9, Train Loss: 0.0546, Train Acc: 98.14%, Val Loss:  1.264, Val Acc: 75.40%, Time: 7.76s \nEpoch: 10, Train Loss: 0.04318, Train Acc: 98.46%, Val Loss:  1.431, Val Acc: 75.02%, Time: 7.51s \nEpoch: 11, Train Loss: 0.03944, Train Acc: 98.62%, Val Loss:  1.352, Val Acc: 76.10%, Time: 7.59s \nEpoch: 12, Train Loss: 0.03189, Train Acc: 98.90%, Val Loss:  1.576, Val Acc: 75.48%, Time: 7.56s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.94      0.50      0.65       122\n                   Filter       0.73      0.70      0.72       139\n    Compute Derived Value       0.53      0.85      0.65       124\n            Find Extremum       0.74      0.87      0.80       128\n                     Sort       0.78      0.77      0.78       117\n          Determine Range       0.67      0.61      0.64       119\nCharacterize Distribution       0.88      0.91      0.89       135\n           Find Anomalies       0.88      0.70      0.78       142\n                  Cluster       0.80      0.79      0.80       141\n                Correlate       0.78      0.82      0.80       130\n\n                micro avg       0.75      0.75      0.75      1297\n                macro avg       0.77      0.75      0.75      1297\n             weighted avg       0.78      0.75      0.75      1297\n\nConfusion Matrix...\n[[ 61   7  48   2   0   2   0   2   0   0]\n [  0  97  11   4   7  16   0   0   3   1]\n [  4   0 105   0   1   3   4   0   6   1]\n [  0   0  12 111   4   1   0   0   0   0]\n [  0   0   2  15  90   2   1   1   6   0]\n [  0   3   6  11  10  72   3   3   5   6]\n [  0   0   4   1   1   0 123   1   4   1]\n [  0  11  11   3   1   0   0  99   2  15]\n [  0   1   0   1   1   8   9   4 111   6]\n [  0  13   1   3   0   3   0   2   1 107]]\nFold:  5\nEpoch: 1, Train Loss:  1.379, Train Acc: 54.38%, Val Loss:  1.665, Val Acc: 51.93%, Time: 9.56s *\nEpoch: 2, Train Loss: 0.5822, Train Acc: 81.65%, Val Loss:  1.757, Val Acc: 56.70%, Time: 7.64s *\nEpoch: 3, Train Loss: 0.3265, Train Acc: 89.96%, Val Loss:  1.801, Val Acc: 60.28%, Time: 7.78s *\nEpoch: 4, Train Loss: 0.2154, Train Acc: 93.31%, Val Loss:  1.812, Val Acc: 60.18%, Time: 7.64s \nEpoch: 5, Train Loss: 0.1413, Train Acc: 95.66%, Val Loss:  1.907, Val Acc: 62.20%, Time: 7.60s *\nEpoch: 6, Train Loss: 0.1036, Train Acc: 96.65%, Val Loss:  2.092, Val Acc: 61.83%, Time: 7.78s \nEpoch: 7, Train Loss: 0.08737, Train Acc: 97.22%, Val Loss:  2.299, Val Acc: 61.65%, Time: 7.64s \nEpoch: 8, Train Loss: 0.0655, Train Acc: 97.85%, Val Loss:  2.736, Val Acc: 58.99%, Time: 7.60s \nEpoch: 9, Train Loss: 0.05701, Train Acc: 98.19%, Val Loss:  2.347, Val Acc: 58.81%, Time: 7.64s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.73      0.20      0.32       118\n                   Filter       0.60      0.43      0.50       129\n    Compute Derived Value       0.47      0.65      0.54       124\n            Find Extremum       0.47      0.82      0.60       114\n                     Sort       0.84      0.93      0.88       120\n          Determine Range       0.64      0.86      0.73       100\nCharacterize Distribution       0.68      0.47      0.55        90\n           Find Anomalies       0.57      0.58      0.57        93\n                  Cluster       0.58      0.54      0.56       100\n                Correlate       0.63      0.46      0.53       102\n\n                micro avg       0.59      0.59      0.59      1090\n                macro avg       0.62      0.59      0.58      1090\n             weighted avg       0.62      0.59      0.58      1090\n\nConfusion Matrix...\n[[ 24  14  44  12   3   1  10   7   0   3]\n [  4  55  13  20   0  19   0  11   7   0]\n [  0   4  80  29   1   3   0   7   0   0]\n [  0   0   1  94   7   3   1   6   2   0]\n [  0   1   0   0 112   1   0   0   6   0]\n [  0   0   8   2   1  86   2   0   1   0]\n [  0   0   7  15   1   5  42   0  13   7]\n [  3   4   2   4   2   8   6  54   8   2]\n [  2   9   4   2   2   8   0   3  54  16]\n [  0   5  12  22   5   1   1   7   2  47]]\nFold:  6\nEpoch: 1, Train Loss:  1.382, Train Acc: 53.65%, Val Loss:  1.677, Val Acc: 47.41%, Time: 9.28s *\nEpoch: 2, Train Loss: 0.5786, Train Acc: 82.33%, Val Loss:  1.757, Val Acc: 52.19%, Time: 7.45s *\nEpoch: 3, Train Loss:  0.316, Train Acc: 89.98%, Val Loss:  2.002, Val Acc: 52.43%, Time: 7.52s *\nEpoch: 4, Train Loss: 0.2064, Train Acc: 93.49%, Val Loss:  2.117, Val Acc: 55.47%, Time: 7.56s *\nEpoch: 5, Train Loss: 0.1387, Train Acc: 95.76%, Val Loss:  2.192, Val Acc: 57.86%, Time: 7.50s *\nEpoch: 6, Train Loss: 0.09606, Train Acc: 96.85%, Val Loss:  2.494, Val Acc: 55.39%, Time: 7.47s \nEpoch: 7, Train Loss: 0.08739, Train Acc: 97.29%, Val Loss:  2.633, Val Acc: 55.39%, Time: 7.52s \nEpoch: 8, Train Loss: 0.06141, Train Acc: 98.00%, Val Loss:  2.689, Val Acc: 55.95%, Time: 7.63s \nEpoch: 9, Train Loss: 0.05452, Train Acc: 98.22%, Val Loss:  3.148, Val Acc: 50.76%, Time: 7.53s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.50      0.16      0.24       126\n                   Filter       0.49      0.56      0.52       120\n    Compute Derived Value       0.33      0.58      0.42       134\n            Find Extremum       0.43      0.53      0.47       123\n                     Sort       0.86      0.68      0.76       126\n          Determine Range       0.55      0.60      0.58       126\nCharacterize Distribution       0.41      0.59      0.48       133\n           Find Anomalies       0.59      0.47      0.52       114\n                  Cluster       0.78      0.44      0.57       122\n                Correlate       0.61      0.47      0.53       129\n\n                micro avg       0.51      0.51      0.51      1253\n                macro avg       0.55      0.51      0.51      1253\n             weighted avg       0.55      0.51      0.51      1253\n\nConfusion Matrix...\n[[20 10 42 25  3 14  7  0  0  5]\n [ 0 67 14  6  0  1  1 22  5  4]\n [10  0 78 24  0  4 18  0  0  0]\n [ 7 12 14 65  5  5 10  3  1  1]\n [ 1  1  8  8 86 16  2  0  4  0]\n [ 0 16 15  2  1 76 15  1  0  0]\n [ 2  0 30  6  0  2 78  1  0 14]\n [ 0 17 16 11  0  1  0 54  2 13]\n [ 0  5  5  0  5  2 39 10 54  2]\n [ 0  9 13  4  0 17 22  1  3 60]]\nFold:  7\nEpoch: 1, Train Loss:  1.439, Train Acc: 51.83%, Val Loss:  1.378, Val Acc: 55.25%, Time: 9.46s *\nEpoch: 2, Train Loss: 0.6048, Train Acc: 80.98%, Val Loss:  1.351, Val Acc: 62.82%, Time: 7.53s *\nEpoch: 3, Train Loss:  0.329, Train Acc: 89.96%, Val Loss:  1.433, Val Acc: 64.20%, Time: 7.63s *\nEpoch: 4, Train Loss: 0.2129, Train Acc: 93.61%, Val Loss:  1.586, Val Acc: 65.99%, Time: 7.62s *\nEpoch: 5, Train Loss: 0.1415, Train Acc: 95.61%, Val Loss:  1.631, Val Acc: 66.64%, Time: 7.57s *\nEpoch: 6, Train Loss: 0.1062, Train Acc: 96.64%, Val Loss:  1.919, Val Acc: 66.88%, Time: 7.49s *\nEpoch: 7, Train Loss: 0.07996, Train Acc: 97.48%, Val Loss:  2.098, Val Acc: 66.80%, Time: 7.60s \nEpoch: 8, Train Loss: 0.06206, Train Acc: 98.04%, Val Loss:  2.193, Val Acc: 66.97%, Time: 7.62s *\nEpoch: 9, Train Loss: 0.05279, Train Acc: 98.29%, Val Loss:  2.257, Val Acc: 67.13%, Time: 7.57s *\nEpoch: 10, Train Loss: 0.04548, Train Acc: 98.53%, Val Loss:  2.418, Val Acc: 65.26%, Time: 7.73s \nEpoch: 11, Train Loss: 0.03652, Train Acc: 98.81%, Val Loss:  2.503, Val Acc: 65.09%, Time: 7.53s \n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 12, Train Loss: 0.03805, Train Acc: 98.72%, Val Loss:  2.402, Val Acc: 67.45%, Time: 7.80s *\nEpoch: 13, Train Loss: 0.0286, Train Acc: 99.15%, Val Loss:  3.026, Val Acc: 64.85%, Time: 7.62s \nEpoch: 14, Train Loss: 0.02584, Train Acc: 99.10%, Val Loss:  2.549, Val Acc: 64.36%, Time: 7.64s \nEpoch: 15, Train Loss: 0.02812, Train Acc: 99.13%, Val Loss:  2.488, Val Acc: 65.26%, Time: 7.56s \nEpoch: 16, Train Loss: 0.01973, Train Acc: 99.30%, Val Loss:  2.551, Val Acc: 67.05%, Time: 7.71s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.58      0.59      0.58       111\n                   Filter       0.57      0.42      0.48       133\n    Compute Derived Value       0.57      0.52      0.55       126\n            Find Extremum       0.63      0.80      0.71       123\n                     Sort       0.53      0.85      0.66       111\n          Determine Range       0.56      0.24      0.33       136\nCharacterize Distribution       0.74      0.58      0.65       120\n           Find Anomalies       0.76      0.91      0.83       127\n                  Cluster       0.84      0.91      0.87       118\n                Correlate       0.83      0.94      0.88       124\n\n                micro avg       0.67      0.67      0.67      1229\n                macro avg       0.66      0.67      0.65      1229\n             weighted avg       0.66      0.67      0.65      1229\n\nConfusion Matrix...\n[[ 65   0  13   9  19   5   0   0   0   0]\n [ 22  56   3   3  25  11   5   6   1   1]\n [ 24  21  66   1   0   0   6   0   0   8]\n [  1   0   3  99   0   3   0  11   4   2]\n [  0   0   2   9  94   3   1   0   0   2]\n [  0  10  20  30  25  32   8   4   3   4]\n [  0   8   5   4  11   1  70   9  11   1]\n [  0   3   4   1   0   1   2 115   0   1]\n [  0   0   0   0   2   0   2   2 107   5]\n [  1   0   0   1   0   1   0   4   1 116]]\nFold:  8\nEpoch: 1, Train Loss:  1.428, Train Acc: 53.10%, Val Loss:  1.555, Val Acc: 55.53%, Time: 9.27s *\nEpoch: 2, Train Loss: 0.6231, Train Acc: 80.12%, Val Loss:   1.74, Val Acc: 58.71%, Time: 7.51s *\nEpoch: 3, Train Loss: 0.3331, Train Acc: 89.75%, Val Loss:  1.711, Val Acc: 63.46%, Time: 7.39s *\nEpoch: 4, Train Loss: 0.2138, Train Acc: 93.62%, Val Loss:  1.681, Val Acc: 65.21%, Time: 7.29s *\nEpoch: 5, Train Loss: 0.1562, Train Acc: 95.14%, Val Loss:  1.897, Val Acc: 64.95%, Time: 7.34s \nEpoch: 6, Train Loss: 0.1144, Train Acc: 96.48%, Val Loss:  1.736, Val Acc: 67.30%, Time: 7.49s *\nEpoch: 7, Train Loss: 0.08342, Train Acc: 97.47%, Val Loss:  1.993, Val Acc: 65.34%, Time: 7.38s \nEpoch: 8, Train Loss: 0.06415, Train Acc: 97.93%, Val Loss:  1.974, Val Acc: 67.82%, Time: 7.45s *\nEpoch: 9, Train Loss: 0.05265, Train Acc: 98.35%, Val Loss:  2.158, Val Acc: 65.80%, Time: 7.33s \nEpoch: 10, Train Loss: 0.04319, Train Acc: 98.64%, Val Loss:  2.296, Val Acc: 66.32%, Time: 7.57s \nEpoch: 11, Train Loss: 0.0384, Train Acc: 98.84%, Val Loss:  2.425, Val Acc: 65.99%, Time: 7.33s \nEpoch: 12, Train Loss: 0.04165, Train Acc: 98.59%, Val Loss:  2.073, Val Acc: 68.14%, Time: 7.35s *\nEpoch: 13, Train Loss: 0.03587, Train Acc: 98.81%, Val Loss:   2.45, Val Acc: 67.23%, Time: 7.36s \nEpoch: 14, Train Loss: 0.02827, Train Acc: 99.10%, Val Loss:  2.355, Val Acc: 65.15%, Time: 7.31s \nEpoch: 15, Train Loss: 0.0271, Train Acc: 99.03%, Val Loss:  2.722, Val Acc: 65.21%, Time: 7.42s \nEpoch: 16, Train Loss: 0.02174, Train Acc: 99.25%, Val Loss:  2.803, Val Acc: 64.89%, Time: 7.37s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.66      0.68      0.67       113\n                   Filter       0.57      0.53      0.55       180\n    Compute Derived Value       0.45      0.75      0.56       153\n            Find Extremum       0.86      0.57      0.69       213\n                     Sort       0.70      0.79      0.74       136\n          Determine Range       0.70      0.55      0.62       134\nCharacterize Distribution       0.73      0.76      0.75       142\n           Find Anomalies       0.75      0.38      0.51       143\n                  Cluster       0.84      0.68      0.75       143\n                Correlate       0.51      0.73      0.60       181\n\n                micro avg       0.64      0.64      0.64      1538\n                macro avg       0.68      0.64      0.64      1538\n             weighted avg       0.68      0.64      0.64      1538\n\nConfusion Matrix...\n[[ 77   5   9   4   0   0   7   1   0  10]\n [  2  95  49   3   0  10   8   7   0   6]\n [  0   3 115   1   8   3   4   3   0  16]\n [ 11  23  18 122  15  15   4   0   0   5]\n [ 12   1   7   2 108   0   2   0   2   2]\n [ 14  11  12   3   0  74   6   3   0  11]\n [  0   1   9   0   0   1 108   1   2  20]\n [  1  26   9   3   7   2   0  55   4  36]\n [  0   0   1   2  15   0   4   1  97  23]\n [  0   2  26   2   2   1   4   2  10 132]]\nFold:  9\nEpoch: 1, Train Loss:  1.447, Train Acc: 51.71%, Val Loss:  1.172, Val Acc: 64.71%, Time: 9.34s *\nEpoch: 2, Train Loss: 0.6114, Train Acc: 80.67%, Val Loss: 0.9917, Val Acc: 70.27%, Time: 7.50s *\nEpoch: 3, Train Loss: 0.3458, Train Acc: 89.21%, Val Loss: 0.9899, Val Acc: 73.81%, Time: 7.57s *\nEpoch: 4, Train Loss: 0.2223, Train Acc: 92.94%, Val Loss: 0.8784, Val Acc: 77.76%, Time: 7.58s *\nEpoch: 5, Train Loss: 0.1465, Train Acc: 95.55%, Val Loss: 0.9312, Val Acc: 78.65%, Time: 7.62s *\nEpoch: 6, Train Loss: 0.1146, Train Acc: 96.36%, Val Loss: 0.9465, Val Acc: 77.84%, Time: 7.70s \nEpoch: 7, Train Loss: 0.08402, Train Acc: 97.34%, Val Loss:  1.348, Val Acc: 74.13%, Time: 7.69s \nEpoch: 8, Train Loss: 0.0711, Train Acc: 97.78%, Val Loss:  1.083, Val Acc: 79.61%, Time: 7.58s *\nEpoch: 9, Train Loss: 0.06836, Train Acc: 97.71%, Val Loss:  1.072, Val Acc: 78.73%, Time: 7.53s \nEpoch: 10, Train Loss: 0.05136, Train Acc: 98.30%, Val Loss:  1.222, Val Acc: 77.44%, Time: 7.60s \nEpoch: 11, Train Loss: 0.03661, Train Acc: 98.83%, Val Loss:  1.063, Val Acc: 80.82%, Time: 7.64s *\nEpoch: 12, Train Loss: 0.03996, Train Acc: 98.72%, Val Loss:  1.164, Val Acc: 77.52%, Time: 7.67s \nEpoch: 13, Train Loss: 0.03007, Train Acc: 98.94%, Val Loss:  1.153, Val Acc: 77.92%, Time: 7.51s \nEpoch: 14, Train Loss: 0.03612, Train Acc: 98.73%, Val Loss:  1.172, Val Acc: 78.40%, Time: 7.58s \nEpoch: 15, Train Loss: 0.02646, Train Acc: 99.12%, Val Loss:   1.23, Val Acc: 78.32%, Time: 7.69s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.82      0.53      0.65       122\n                   Filter       0.70      0.71      0.70       114\n    Compute Derived Value       0.68      0.74      0.71       114\n            Find Extremum       0.82      0.84      0.83       116\n                     Sort       0.88      0.96      0.92       117\n          Determine Range       0.75      0.68      0.71       128\nCharacterize Distribution       0.95      0.73      0.83       146\n           Find Anomalies       0.78      0.85      0.81       136\n                  Cluster       0.78      0.89      0.83       127\n                Correlate       0.74      0.94      0.83       121\n\n                micro avg       0.79      0.79      0.79      1241\n                macro avg       0.79      0.79      0.78      1241\n             weighted avg       0.79      0.79      0.78      1241\n\nConfusion Matrix...\n[[ 65   3  33   4   4   0   1   3   5   4]\n [  1  81   0   5   0   8   0   9   8   2]\n [  2   0  84   1   0   9   1   5   2  10]\n [  0   1   0  98   3   4   0   7   2   1]\n [  0   1   0   0 112   1   0   0   2   1]\n [  3  14   1   6   2  87   2   1   4   8]\n [  3  13   1   0   1   2 107   7   9   3]\n [  0   3   2   5   1   5   2 115   0   3]\n [  0   0   1   0   4   0   0   1 113   8]\n [  5   0   2   0   0   0   0   0   0 114]]\nFold:  10\nEpoch: 1, Train Loss:  1.528, Train Acc: 48.80%, Val Loss:  1.483, Val Acc: 52.83%, Time: 8.98s *\nEpoch: 2, Train Loss: 0.6436, Train Acc: 80.04%, Val Loss:  1.399, Val Acc: 60.88%, Time: 6.97s *\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 3, Train Loss: 0.3586, Train Acc: 88.87%, Val Loss:  1.522, Val Acc: 62.05%, Time: 7.06s *\nEpoch: 4, Train Loss: 0.2174, Train Acc: 93.10%, Val Loss:  1.705, Val Acc: 61.49%, Time: 7.06s \nEpoch: 5, Train Loss: 0.1497, Train Acc: 95.45%, Val Loss:  1.856, Val Acc: 61.58%, Time: 7.02s \nEpoch: 6, Train Loss: 0.1135, Train Acc: 96.46%, Val Loss:  1.974, Val Acc: 60.69%, Time: 7.12s \nEpoch: 7, Train Loss: 0.08107, Train Acc: 97.37%, Val Loss:  2.197, Val Acc: 59.85%, Time: 6.94s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.50      0.47      0.49       219\n                   Filter       0.53      0.49      0.51       215\n    Compute Derived Value       0.73      0.41      0.52       256\n            Find Extremum       0.76      0.80      0.78       406\n                     Sort       0.71      0.79      0.75       126\n          Determine Range       0.34      0.50      0.41       125\nCharacterize Distribution       0.58      0.66      0.62       203\n           Find Anomalies       0.42      0.33      0.37       205\n                  Cluster       0.36      0.77      0.49       121\n                Correlate       0.84      0.61      0.71       261\n\n                micro avg       0.59      0.59      0.59      2137\n                macro avg       0.58      0.58      0.56      2137\n             weighted avg       0.62      0.59      0.59      2137\n\nConfusion Matrix...\n[[103  12   8   5   1   0  21  63   6   0]\n [ 15 105   6  12   4  30   2  11  17  13]\n [ 33  10 104  13   3  40  14  13  18   8]\n [ 22   5   5 323  20  17   6   0   7   1]\n [  3   0   0  14 100   4   1   0   4   0]\n [  5  14   0  25   5  63   5   0   7   1]\n [  7   2   4   1   2   8 134   2  37   6]\n [  5  36   9  27   5  17   7  68  29   2]\n [  4   6   2   1   0   3  12   0  93   0]\n [  7   8   4   3   1   3  30   4  41 160]]\n[0.6566992524439333, 0.6503164556962026, 0.6471531676022454, 0.7525057825751735, 0.5944954128440367, 0.5091779728651237, 0.6672091131000814, 0.6391417425227568, 0.7864625302175665, 0.586335985025737]\n0.6489497414892856, 0.07519991783310556, 0.07926767340337582, 0.0056550276421058285\nbundle\n920 16 18 41\nFold:  1\nEpoch: 1, Train Loss:  2.254, Train Acc: 19.32%, Val Loss:  1.986, Val Acc: 29.26%, Time: 9.29s *\nEpoch: 2, Train Loss:  1.617, Train Acc: 45.27%, Val Loss:  1.402, Val Acc: 50.81%, Time: 7.35s *\nEpoch: 3, Train Loss:  1.045, Train Acc: 65.81%, Val Loss:  1.306, Val Acc: 57.39%, Time: 7.55s *\nEpoch: 4, Train Loss: 0.6777, Train Acc: 78.85%, Val Loss:  1.159, Val Acc: 64.45%, Time: 7.58s *\nEpoch: 5, Train Loss: 0.4552, Train Acc: 85.79%, Val Loss:  1.057, Val Acc: 69.47%, Time: 7.44s *\nEpoch: 6, Train Loss: 0.3107, Train Acc: 90.53%, Val Loss:  1.239, Val Acc: 68.06%, Time: 7.38s \nEpoch: 7, Train Loss:  0.228, Train Acc: 92.94%, Val Loss:  1.425, Val Acc: 68.27%, Time: 7.58s \nEpoch: 8, Train Loss: 0.1597, Train Acc: 94.98%, Val Loss:  1.417, Val Acc: 68.13%, Time: 7.46s \nEpoch: 9, Train Loss: 0.1416, Train Acc: 95.34%, Val Loss:  1.409, Val Acc: 68.41%, Time: 7.57s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.76      0.50      0.60       227\n                   Filter       0.75      0.57      0.65       174\n    Compute Derived Value       0.37      0.78      0.50       123\n            Find Extremum       0.54      0.70      0.61       116\n                     Sort       0.86      0.66      0.75        76\n          Determine Range       0.73      0.59      0.65       154\nCharacterize Distribution       0.69      0.73      0.71       115\n           Find Anomalies       0.86      0.74      0.80       149\n                  Cluster       0.96      0.79      0.87       112\n                Correlate       0.85      0.97      0.90       169\n\n                micro avg       0.69      0.69      0.69      1415\n                macro avg       0.74      0.70      0.70      1415\n             weighted avg       0.74      0.69      0.70      1415\n\nConfusion Matrix...\n[[113   7  94   7   0   1   4   1   0   0]\n [ 12 100  24  14   1  16   1   5   0   1]\n [  0   1  96   4   0   9   3   3   0   7]\n [  9   4  15  81   0   2   1   3   0   1]\n [  0   0   9  12  50   3   1   0   1   0]\n [  2  12  10  19   0  91  17   0   1   2]\n [  1   0  14   6   0   0  84   2   1   7]\n [ 11   3   0   4   1   3  10 111   1   5]\n [  1   5   0   1   6   0   1   2  89   7]\n [  0   1   1   1   0   0   0   2   0 164]]\nFold:  2\nEpoch: 1, Train Loss:  2.277, Train Acc: 19.86%, Val Loss:  1.994, Val Acc: 28.26%, Time: 9.56s *\nEpoch: 2, Train Loss:  1.596, Train Acc: 46.35%, Val Loss:  1.404, Val Acc: 52.31%, Time: 7.55s *\nEpoch: 3, Train Loss:  1.009, Train Acc: 68.17%, Val Loss:  1.268, Val Acc: 61.21%, Time: 7.49s *\nEpoch: 4, Train Loss: 0.6521, Train Acc: 79.42%, Val Loss:  1.234, Val Acc: 65.55%, Time: 7.51s *\nEpoch: 5, Train Loss: 0.4336, Train Acc: 86.90%, Val Loss:  1.352, Val Acc: 64.70%, Time: 7.68s \nEpoch: 6, Train Loss: 0.3033, Train Acc: 90.46%, Val Loss:  1.404, Val Acc: 66.33%, Time: 7.44s *\nEpoch: 7, Train Loss: 0.2215, Train Acc: 93.07%, Val Loss:  1.574, Val Acc: 64.06%, Time: 7.58s \nEpoch: 8, Train Loss:  0.164, Train Acc: 94.60%, Val Loss:  1.586, Val Acc: 65.77%, Time: 7.60s \nEpoch: 9, Train Loss: 0.1296, Train Acc: 95.87%, Val Loss:  1.716, Val Acc: 65.77%, Time: 7.47s \nEpoch: 10, Train Loss: 0.08765, Train Acc: 97.29%, Val Loss:  1.783, Val Acc: 65.98%, Time: 7.50s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.78      0.65      0.71       162\n                   Filter       0.63      0.41      0.49       190\n    Compute Derived Value       0.47      0.59      0.52       169\n            Find Extremum       0.65      0.84      0.73       174\n                     Sort       0.96      0.66      0.78       104\n          Determine Range       0.65      0.40      0.49       115\nCharacterize Distribution       0.54      0.91      0.68       143\n           Find Anomalies       0.71      0.75      0.73       111\n                  Cluster       0.96      0.75      0.84       119\n                Correlate       0.74      0.74      0.74       118\n\n                micro avg       0.66      0.66      0.66      1405\n                macro avg       0.71      0.67      0.67      1405\n             weighted avg       0.69      0.66      0.66      1405\n\nConfusion Matrix...\n[[105   4  34  16   0   0   0   3   0   0]\n [  8  77  34   9   0  17  22  21   1   1]\n [  0  21 100  22   1   0  19   3   0   3]\n [  1   1   6 146   0   1  17   0   0   2]\n [ 10   2  13   8  69   0   1   0   1   0]\n [  3  12  13   8   0  46  26   0   0   7]\n [  2   0   7   1   0   2 130   0   1   0]\n [  0   4   0  13   1   5   0  83   1   4]\n [  1   0   1   0   1   0  11   3  89  13]\n [  4   1   7   1   0   0  14   4   0  87]]\nFold:  3\nEpoch: 1, Train Loss:  2.298, Train Acc: 17.69%, Val Loss:  1.979, Val Acc: 32.85%, Time: 9.71s *\nEpoch: 2, Train Loss:  1.663, Train Acc: 43.38%, Val Loss:  1.398, Val Acc: 53.40%, Time: 7.63s *\nEpoch: 3, Train Loss:  1.101, Train Acc: 63.95%, Val Loss:  1.106, Val Acc: 65.62%, Time: 7.48s *\nEpoch: 4, Train Loss:  0.698, Train Acc: 78.10%, Val Loss:  1.027, Val Acc: 70.52%, Time: 7.63s *\nEpoch: 5, Train Loss: 0.4686, Train Acc: 85.57%, Val Loss:  1.028, Val Acc: 71.98%, Time: 7.49s *\nEpoch: 6, Train Loss: 0.3233, Train Acc: 89.90%, Val Loss:  1.099, Val Acc: 70.30%, Time: 7.51s \nEpoch: 7, Train Loss: 0.2313, Train Acc: 93.09%, Val Loss:  1.302, Val Acc: 67.30%, Time: 7.63s \nEpoch: 8, Train Loss:  0.158, Train Acc: 95.06%, Val Loss:  1.375, Val Acc: 67.96%, Time: 7.48s \nEpoch: 9, Train Loss: 0.1227, Train Acc: 96.10%, Val Loss:  1.449, Val Acc: 67.67%, Time: 7.70s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.90      0.48      0.63       154\n                   Filter       0.68      0.63      0.66       160\n    Compute Derived Value       0.35      0.59      0.44        82\n            Find Extremum       0.63      0.74      0.68       114\n                     Sort       0.84      0.84      0.84       172\n          Determine Range       0.55      0.51      0.53        80\nCharacterize Distribution       0.60      0.83      0.69       155\n           Find Anomalies       0.80      0.89      0.84       122\n                  Cluster       0.91      0.54      0.67       181\n                Correlate       0.73      0.81      0.77       147\n\n                micro avg       0.69      0.69      0.69      1367\n                macro avg       0.70      0.68      0.67      1367\n             weighted avg       0.73      0.69      0.69      1367\n\nConfusion Matrix...\n[[ 74  11  43   3   2  11  10   0   0   0]\n [  2 101  16  16   0   2   1  12   0  10]\n [  0   1  48  11   2   0   8   3   0   9]\n [  4  12   8  84   0   0   1   1   0   4]\n [  0   0   0   9 144  10   4   0   5   0]\n [  0   9   8   2   2  41  17   1   0   0]\n [  2   3   8   3   1   7 128   2   0   1]\n [  0   3   3   4   0   2   0 109   0   1]\n [  0   8   1   2  18   1  29   7  97  18]\n [  0   0   2   0   2   0  17   2   5 119]]\n", "name": "stdout"}, {"output_type": "stream", "text": "Fold:  4\nEpoch: 1, Train Loss:   2.24, Train Acc: 21.25%, Val Loss:  2.016, Val Acc: 29.46%, Time: 9.43s *\nEpoch: 2, Train Loss:  1.585, Train Acc: 45.70%, Val Loss:  1.461, Val Acc: 50.77%, Time: 7.48s *\nEpoch: 3, Train Loss: 0.9875, Train Acc: 67.07%, Val Loss:  1.365, Val Acc: 59.40%, Time: 7.41s *\nEpoch: 4, Train Loss:   0.63, Train Acc: 79.58%, Val Loss:  1.299, Val Acc: 63.72%, Time: 7.42s *\nEpoch: 5, Train Loss: 0.4241, Train Acc: 86.85%, Val Loss:  1.324, Val Acc: 65.32%, Time: 7.36s *\nEpoch: 6, Train Loss: 0.2928, Train Acc: 90.62%, Val Loss:  1.444, Val Acc: 64.90%, Time: 7.46s \nEpoch: 7, Train Loss: 0.2081, Train Acc: 93.38%, Val Loss:   1.75, Val Acc: 62.60%, Time: 7.45s \nEpoch: 8, Train Loss: 0.1563, Train Acc: 95.24%, Val Loss:  1.773, Val Acc: 63.65%, Time: 7.55s \nEpoch: 9, Train Loss: 0.1569, Train Acc: 95.18%, Val Loss:   1.78, Val Acc: 62.60%, Time: 7.35s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.55      0.62      0.59        90\n                   Filter       0.67      0.60      0.63       206\n    Compute Derived Value       0.38      0.47      0.42       167\n            Find Extremum       0.70      0.62      0.66       185\n                     Sort       0.80      0.53      0.64        78\n          Determine Range       0.74      0.50      0.60       183\nCharacterize Distribution       0.54      0.92      0.68       161\n           Find Anomalies       0.58      0.54      0.56        94\n                  Cluster       0.95      0.66      0.78        94\n                Correlate       0.70      0.69      0.69       178\n\n                micro avg       0.62      0.62      0.62      1436\n                macro avg       0.66      0.61      0.62      1436\n             weighted avg       0.65      0.62      0.62      1436\n\nConfusion Matrix...\n[[ 56   1  21   2   0   0   6   0   0   4]\n [  1 124  19  12   3   5  13  22   1   6]\n [ 32   3  78   6   0   5  38   2   0   3]\n [  4  15  22 114   0  18  10   1   0   1]\n [  0   4   2  26  41   3   2   0   0   0]\n [  8  21  28   3   2  92  22   3   2   2]\n [  0   1   8   0   0   1 148   1   0   2]\n [  0  17   2   0   0   1   0  51   0  23]\n [  0   0   0   0   5   0  12   3  62  12]\n [  0   0  28   0   0   0  22   5   0 123]]\nFold:  5\nEpoch: 1, Train Loss:  2.235, Train Acc: 21.32%, Val Loss:  1.811, Val Acc: 40.03%, Time: 9.38s *\nEpoch: 2, Train Loss:   1.54, Train Acc: 47.52%, Val Loss:  1.288, Val Acc: 57.72%, Time: 7.47s *\nEpoch: 3, Train Loss:  0.967, Train Acc: 68.33%, Val Loss:  1.157, Val Acc: 64.00%, Time: 7.46s *\nEpoch: 4, Train Loss: 0.6538, Train Acc: 78.94%, Val Loss: 0.9645, Val Acc: 71.45%, Time: 7.44s *\nEpoch: 5, Train Loss: 0.4459, Train Acc: 85.95%, Val Loss: 0.9563, Val Acc: 73.70%, Time: 7.56s *\nEpoch: 6, Train Loss:  0.316, Train Acc: 89.82%, Val Loss:  1.005, Val Acc: 71.79%, Time: 7.41s \nEpoch: 7, Train Loss: 0.2288, Train Acc: 92.67%, Val Loss:  1.124, Val Acc: 71.04%, Time: 7.37s \nEpoch: 8, Train Loss: 0.1701, Train Acc: 94.63%, Val Loss:  1.164, Val Acc: 72.61%, Time: 7.53s \nEpoch: 9, Train Loss: 0.1299, Train Acc: 95.83%, Val Loss:  1.165, Val Acc: 74.11%, Time: 7.29s *\nEpoch: 10, Train Loss: 0.1128, Train Acc: 96.39%, Val Loss:  1.258, Val Acc: 72.40%, Time: 7.50s \nEpoch: 11, Train Loss: 0.09082, Train Acc: 96.92%, Val Loss:   1.33, Val Acc: 71.65%, Time: 7.38s \nEpoch: 12, Train Loss: 0.08053, Train Acc: 97.27%, Val Loss:   1.39, Val Acc: 72.68%, Time: 7.40s \nEpoch: 13, Train Loss: 0.05802, Train Acc: 98.09%, Val Loss:  1.409, Val Acc: 72.88%, Time: 7.45s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.88      0.78      0.83       134\n                   Filter       0.54      0.86      0.66        98\n    Compute Derived Value       0.75      0.66      0.70       157\n            Find Extremum       0.65      0.90      0.75       156\n                     Sort       0.86      0.76      0.81       155\n          Determine Range       0.88      0.45      0.60       192\nCharacterize Distribution       0.55      0.88      0.68       148\n           Find Anomalies       0.64      0.88      0.74        82\n                  Cluster       0.77      0.35      0.49       116\n                Correlate       0.85      0.74      0.79       226\n\n                micro avg       0.72      0.72      0.72      1464\n                macro avg       0.74      0.73      0.70      1464\n             weighted avg       0.76      0.72      0.71      1464\n\nConfusion Matrix...\n[[104   6   6   6   4   2   2   4   0   0]\n [  0  84  12   0   0   1   1   0   0   0]\n [  6   1 103  14   1   2  16   0   1  13]\n [  0   7   1 141   0   0   2   5   0   0]\n [  0  16   2  15 118   2   1   0   1   0]\n [  0  28   7  12   2  87  44   9   0   3]\n [  0   0   2  14   0   1 130   1   0   0]\n [  0   4   1   2   0   0   2  72   0   1]\n [  7   8   1  11  10   0  19   7  41  12]\n [  1   1   3   3   3   4  18  15  10 168]]\nFold:  6\nEpoch: 1, Train Loss:  2.263, Train Acc: 18.84%, Val Loss:  2.015, Val Acc: 29.70%, Time: 9.38s *\nEpoch: 2, Train Loss:  1.582, Train Acc: 46.28%, Val Loss:  1.487, Val Acc: 49.49%, Time: 7.42s *\nEpoch: 3, Train Loss:  0.988, Train Acc: 68.29%, Val Loss:  1.372, Val Acc: 56.86%, Time: 7.68s *\nEpoch: 4, Train Loss: 0.6246, Train Acc: 80.62%, Val Loss:  1.423, Val Acc: 60.84%, Time: 7.49s *\nEpoch: 5, Train Loss:  0.429, Train Acc: 86.62%, Val Loss:  1.595, Val Acc: 58.53%, Time: 7.53s \nEpoch: 6, Train Loss: 0.3001, Train Acc: 90.70%, Val Loss:  1.788, Val Acc: 59.18%, Time: 7.65s \nEpoch: 7, Train Loss: 0.2296, Train Acc: 92.72%, Val Loss:  1.858, Val Acc: 59.10%, Time: 7.50s \nEpoch: 8, Train Loss: 0.1854, Train Acc: 94.13%, Val Loss:  2.109, Val Acc: 59.39%, Time: 7.39s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.61      0.33      0.42       141\n                   Filter       0.39      0.56      0.46        84\n    Compute Derived Value       0.42      0.61      0.50       171\n            Find Extremum       0.65      0.83      0.73       185\n                     Sort       0.79      0.75      0.77       138\n          Determine Range       0.59      0.32      0.41        73\nCharacterize Distribution       0.46      0.84      0.60        88\n           Find Anomalies       0.67      0.36      0.47       171\n                  Cluster       0.97      0.43      0.59       152\n                Correlate       0.67      0.77      0.72       181\n\n                micro avg       0.59      0.59      0.59      1384\n                macro avg       0.62      0.58      0.57      1384\n             weighted avg       0.64      0.59      0.58      1384\n\nConfusion Matrix...\n[[ 46   4  59   9   0   1  16   1   0   5]\n [  0  47  18   3   0   0   0  16   0   0]\n [ 30  18 105   6   1   2   2   0   0   7]\n [  0   9  11 154   0   8   1   1   1   0]\n [  0   6   1  26 103   0   0   0   0   2]\n [  0   0  21   4   0  23  23   0   0   2]\n [  0   0   8   1   1   0  74   0   0   4]\n [  0  27  15  16   1   0  24  61   1  26]\n [  0   1   7   1  24   3  18   9  65  24]\n [  0  10   7  16   1   2   2   3   0 140]]\nFold:  7\nEpoch: 1, Train Loss:  2.291, Train Acc: 18.66%, Val Loss:  1.944, Val Acc: 31.15%, Time: 9.41s *\nEpoch: 2, Train Loss:  1.703, Train Acc: 41.96%, Val Loss:  1.354, Val Acc: 53.27%, Time: 7.64s *\nEpoch: 3, Train Loss:  1.037, Train Acc: 66.14%, Val Loss:  1.176, Val Acc: 61.13%, Time: 7.69s *\nEpoch: 4, Train Loss: 0.6506, Train Acc: 79.47%, Val Loss:  1.171, Val Acc: 63.70%, Time: 7.42s *\nEpoch: 5, Train Loss: 0.4341, Train Acc: 86.11%, Val Loss:  1.262, Val Acc: 63.85%, Time: 7.57s *\nEpoch: 6, Train Loss: 0.3115, Train Acc: 90.01%, Val Loss:  1.464, Val Acc: 64.58%, Time: 7.43s *\nEpoch: 7, Train Loss: 0.2268, Train Acc: 92.74%, Val Loss:  1.512, Val Acc: 65.61%, Time: 7.40s *\nEpoch: 8, Train Loss: 0.1674, Train Acc: 94.64%, Val Loss:  1.715, Val Acc: 63.85%, Time: 7.57s \nEpoch: 9, Train Loss:  0.128, Train Acc: 96.06%, Val Loss:  1.781, Val Acc: 63.12%, Time: 7.52s \n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 10, Train Loss: 0.09477, Train Acc: 96.92%, Val Loss:  1.676, Val Acc: 67.45%, Time: 7.56s *\nEpoch: 11, Train Loss: 0.08485, Train Acc: 97.32%, Val Loss:  1.767, Val Acc: 65.25%, Time: 7.61s \nEpoch: 12, Train Loss: 0.07682, Train Acc: 97.39%, Val Loss:  1.859, Val Acc: 66.27%, Time: 7.42s \nEpoch: 13, Train Loss: 0.05012, Train Acc: 98.35%, Val Loss:  1.943, Val Acc: 66.42%, Time: 7.44s \nEpoch: 14, Train Loss: 0.04716, Train Acc: 98.47%, Val Loss:    1.9, Val Acc: 65.39%, Time: 7.54s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.56      0.57      0.57        96\n                   Filter       0.79      0.57      0.66       191\n    Compute Derived Value       0.61      0.80      0.69       173\n            Find Extremum       0.45      0.86      0.59       128\n                     Sort       0.93      0.61      0.74       140\n          Determine Range       0.73      0.52      0.61       147\nCharacterize Distribution       0.55      0.78      0.64        99\n           Find Anomalies       0.82      0.57      0.67       143\n                  Cluster       0.90      0.68      0.77       138\n                Correlate       0.65      0.71      0.68       106\n\n                micro avg       0.66      0.66      0.66      1361\n                macro avg       0.70      0.67      0.66      1361\n             weighted avg       0.71      0.66      0.67      1361\n\nConfusion Matrix...\n[[ 55   0  30   8   1   0   2   0   0   0]\n [ 23 108  17  24   2  11   2   4   0   0]\n [  9   3 138  13   0   3   6   1   0   0]\n [  2   2   8 110   0   0   0   0   0   6]\n [  0   3  10  37  85   3   1   0   1   0]\n [  8   8   6  37   0  77  10   1   0   0]\n [  0   0   2   2   0   0  77   0   1  17]\n [  1  12   6  13   1   5   7  81   6  11]\n [  0   0   1   0   2   7  21   7  94   6]\n [  0   1   7   0   0   0  15   5   3  75]]\nFold:  8\nEpoch: 1, Train Loss:  2.272, Train Acc: 20.49%, Val Loss:  2.003, Val Acc: 28.01%, Time: 9.22s *\nEpoch: 2, Train Loss:  1.617, Train Acc: 44.99%, Val Loss:  1.516, Val Acc: 49.05%, Time: 7.43s *\nEpoch: 3, Train Loss:  1.051, Train Acc: 65.18%, Val Loss:  1.243, Val Acc: 59.96%, Time: 7.55s *\nEpoch: 4, Train Loss: 0.6703, Train Acc: 78.49%, Val Loss:  1.157, Val Acc: 65.31%, Time: 7.35s *\nEpoch: 5, Train Loss: 0.4518, Train Acc: 85.55%, Val Loss:  1.133, Val Acc: 67.63%, Time: 7.48s *\nEpoch: 6, Train Loss: 0.3133, Train Acc: 90.21%, Val Loss:  1.223, Val Acc: 66.64%, Time: 7.44s \nEpoch: 7, Train Loss: 0.2402, Train Acc: 92.23%, Val Loss:  1.256, Val Acc: 67.21%, Time: 7.36s \nEpoch: 8, Train Loss: 0.1807, Train Acc: 94.11%, Val Loss:  1.451, Val Acc: 65.73%, Time: 7.43s \nEpoch: 9, Train Loss: 0.1254, Train Acc: 96.04%, Val Loss:  1.474, Val Acc: 66.50%, Time: 7.45s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.97      0.60      0.74       184\n                   Filter       0.40      0.64      0.49        91\n    Compute Derived Value       0.62      0.67      0.64       195\n            Find Extremum       0.77      0.78      0.77       184\n                     Sort       0.88      0.94      0.91        90\n          Determine Range       0.60      0.34      0.43       150\nCharacterize Distribution       0.35      0.62      0.44        78\n           Find Anomalies       0.91      0.71      0.80       188\n                  Cluster       0.97      0.60      0.74       141\n                Correlate       0.50      0.87      0.63       120\n\n                micro avg       0.67      0.67      0.67      1421\n                macro avg       0.70      0.68      0.66      1421\n             weighted avg       0.73      0.67      0.68      1421\n\nConfusion Matrix...\n[[111  18  36   4   0   0  11   4   0   0]\n [  0  58  16  12   0   2   1   0   0   2]\n [  1  34 130  16   0   8   0   2   0   4]\n [  2   1   3 144   8  16   4   3   1   2]\n [  0   1   0   1  85   0   0   1   2   0]\n [  0  26  12   5   2  51  51   1   0   2]\n [  0   0   5   0   0   4  48   0   0  21]\n [  0   1   0   3   0   1   7 134   0  42]\n [  0   2   2   2   2   2  14   0  84  33]\n [  0   3   6   1   0   1   3   2   0 104]]\nFold:  9\nEpoch: 1, Train Loss:  2.234, Train Acc: 21.50%, Val Loss:  1.946, Val Acc: 31.83%, Time: 9.38s *\nEpoch: 2, Train Loss:  1.497, Train Acc: 50.33%, Val Loss:   1.57, Val Acc: 49.02%, Time: 7.52s *\nEpoch: 3, Train Loss: 0.9174, Train Acc: 70.56%, Val Loss:  1.478, Val Acc: 59.54%, Time: 7.53s *\nEpoch: 4, Train Loss: 0.5869, Train Acc: 81.88%, Val Loss:  1.555, Val Acc: 61.93%, Time: 7.44s *\nEpoch: 5, Train Loss: 0.4113, Train Acc: 87.39%, Val Loss:  1.657, Val Acc: 62.44%, Time: 7.51s *\nEpoch: 6, Train Loss: 0.3049, Train Acc: 90.47%, Val Loss:  1.817, Val Acc: 63.52%, Time: 7.42s *\nEpoch: 7, Train Loss: 0.2112, Train Acc: 93.36%, Val Loss:  1.934, Val Acc: 64.10%, Time: 7.56s *\nEpoch: 8, Train Loss:  0.155, Train Acc: 95.23%, Val Loss:  2.222, Val Acc: 62.73%, Time: 7.45s \nEpoch: 9, Train Loss: 0.1081, Train Acc: 96.62%, Val Loss:  2.378, Val Acc: 62.15%, Time: 7.43s \nEpoch: 10, Train Loss: 0.08741, Train Acc: 97.29%, Val Loss:  2.423, Val Acc: 62.36%, Time: 7.51s \nEpoch: 11, Train Loss: 0.09402, Train Acc: 96.78%, Val Loss:  2.327, Val Acc: 64.10%, Time: 7.46s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.72      0.44      0.55       118\n                   Filter       0.54      0.36      0.43       143\n    Compute Derived Value       0.55      0.80      0.65       115\n            Find Extremum       0.68      0.80      0.74       194\n                     Sort       0.69      0.77      0.73       124\n          Determine Range       0.62      0.49      0.55       111\nCharacterize Distribution       0.61      0.67      0.64       168\n           Find Anomalies       0.62      0.54      0.58       149\n                  Cluster       0.67      0.67      0.67       122\n                Correlate       0.59      0.67      0.63       135\n\n                micro avg       0.63      0.63      0.63      1379\n                macro avg       0.63      0.62      0.62      1379\n             weighted avg       0.63      0.63      0.62      1379\n\nConfusion Matrix...\n[[ 52   2  22  21   0   0   6  12   0   3]\n [ 14  52  10  10   8  15   0  17   5  12]\n [  0   2  92  14   0   0   1   1   0   5]\n [  3   2   9 156  10   3   0   5   4   2]\n [  0   0   0   8  95   3   4   0  13   1]\n [  0  19   2  14   2  54  16   3   0   1]\n [  2   0  10   1   2   7 113   3  10  20]\n [  1  20  10   3   0   2  20  80   0  13]\n [  0   0   1   1  21   3   9   0  82   5]\n [  0   0  11   0   0   0  17   7   9  91]]\nFold:  10\nEpoch: 1, Train Loss:  2.293, Train Acc: 18.09%, Val Loss:  1.977, Val Acc: 30.01%, Time: 9.27s *\nEpoch: 2, Train Loss:  1.633, Train Acc: 45.17%, Val Loss:  1.507, Val Acc: 50.61%, Time: 7.69s *\nEpoch: 3, Train Loss:  1.006, Train Acc: 67.52%, Val Loss:  1.395, Val Acc: 57.52%, Time: 7.34s *\nEpoch: 4, Train Loss: 0.6328, Train Acc: 79.56%, Val Loss:  1.388, Val Acc: 61.94%, Time: 7.45s *\nEpoch: 5, Train Loss: 0.4242, Train Acc: 86.59%, Val Loss:  1.506, Val Acc: 62.58%, Time: 7.38s *\nEpoch: 6, Train Loss: 0.3223, Train Acc: 90.09%, Val Loss:  1.622, Val Acc: 64.22%, Time: 7.37s *\nEpoch: 7, Train Loss: 0.2345, Train Acc: 92.50%, Val Loss:  1.811, Val Acc: 62.65%, Time: 7.33s \nEpoch: 8, Train Loss: 0.1687, Train Acc: 94.69%, Val Loss:   1.75, Val Acc: 63.51%, Time: 7.35s \nEpoch: 9, Train Loss: 0.1269, Train Acc: 95.89%, Val Loss:  1.849, Val Acc: 61.23%, Time: 7.40s \nEpoch: 10, Train Loss: 0.1112, Train Acc: 96.40%, Val Loss:  1.827, Val Acc: 65.07%, Time: 7.47s *\nEpoch: 11, Train Loss: 0.09425, Train Acc: 96.86%, Val Loss:  1.828, Val Acc: 64.65%, Time: 7.38s \nEpoch: 12, Train Loss: 0.06269, Train Acc: 97.95%, Val Loss:  2.112, Val Acc: 64.79%, Time: 7.33s \nEpoch: 13, Train Loss: 0.05762, Train Acc: 98.12%, Val Loss:  2.109, Val Acc: 67.85%, Time: 7.42s *\nEpoch: 14, Train Loss: 0.04176, Train Acc: 98.53%, Val Loss:  2.151, Val Acc: 65.86%, Time: 7.41s \n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 15, Train Loss: 0.03294, Train Acc: 98.98%, Val Loss:  2.232, Val Acc: 65.79%, Time: 7.34s \nEpoch: 16, Train Loss: 0.03678, Train Acc: 98.81%, Val Loss:  2.492, Val Acc: 65.79%, Time: 7.46s \nEpoch: 17, Train Loss: 0.02774, Train Acc: 99.09%, Val Loss:  2.219, Val Acc: 66.93%, Time: 7.36s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.40      0.72      0.51        58\n                   Filter       0.40      0.55      0.46       115\n    Compute Derived Value       0.66      0.49      0.56       183\n            Find Extremum       0.83      0.68      0.75       224\n                     Sort       0.90      0.86      0.88       129\n          Determine Range       0.73      0.59      0.65       117\nCharacterize Distribution       0.82      0.71      0.76       174\n           Find Anomalies       0.61      0.84      0.71       164\n                  Cluster       0.81      0.87      0.84        95\n                Correlate       0.70      0.59      0.64       144\n\n                micro avg       0.68      0.68      0.68      1403\n                macro avg       0.68      0.69      0.68      1403\n             weighted avg       0.71      0.68      0.69      1403\n\nConfusion Matrix...\n[[ 42   0   8   1   0   0   0   5   0   2]\n [ 18  63   5   6   0   2   1   9   0  11]\n [ 22  22  89   3   0   8  17   9   1  12]\n [ 15  12   7 152   6   8   4  13   7   0]\n [  1   5   0   1 111   0   4   2   4   1]\n [  4   2  17  16   3  69   1   4   0   1]\n [  0  30   1   3   2   7 124   4   1   2]\n [  4  18   1   1   0   0   0 138   1   1]\n [  0   0   1   0   2   0   1   1  83   7]\n [  0   6   5   0   0   1   0  42   5  85]]\n[0.6918727915194346, 0.6633451957295373, 0.6912948061448427, 0.6190807799442897, 0.7158469945355191, 0.5910404624277457, 0.6612784717119765, 0.6678395496129487, 0.6287164612037709, 0.6813970064148254]\n0.661171251924489, 0.036112302137398994, 0.038065708768782555, 0.001304098365662792\ntable\n37 631 156 41\nFold:  1\nEpoch: 1, Train Loss:  1.584, Train Acc: 46.17%, Val Loss:  1.536, Val Acc: 50.41%, Time: 9.36s *\nEpoch: 2, Train Loss: 0.7494, Train Acc: 76.42%, Val Loss:  1.397, Val Acc: 60.67%, Time: 7.52s *\nEpoch: 3, Train Loss: 0.4061, Train Acc: 87.57%, Val Loss:  1.356, Val Acc: 64.36%, Time: 7.55s *\nEpoch: 4, Train Loss: 0.2387, Train Acc: 92.59%, Val Loss:  1.591, Val Acc: 62.38%, Time: 7.66s \nEpoch: 5, Train Loss: 0.1621, Train Acc: 95.23%, Val Loss:  1.618, Val Acc: 63.55%, Time: 7.58s \nEpoch: 6, Train Loss: 0.1204, Train Acc: 96.34%, Val Loss:  1.852, Val Acc: 63.10%, Time: 7.74s \nEpoch: 7, Train Loss: 0.09074, Train Acc: 97.01%, Val Loss:  1.894, Val Acc: 63.64%, Time: 7.56s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.50      0.70      0.58        94\n                   Filter       0.33      0.42      0.37       106\n    Compute Derived Value       0.51      0.26      0.35       174\n            Find Extremum       0.80      0.73      0.76       150\n                     Sort       0.95      0.90      0.93        62\n          Determine Range       0.58      0.63      0.61       126\nCharacterize Distribution       0.58      0.83      0.68        78\n           Find Anomalies       0.61      0.69      0.65       120\n                  Cluster       0.97      0.81      0.88        73\n                Correlate       0.79      0.67      0.73       128\n\n                micro avg       0.63      0.63      0.63      1111\n                macro avg       0.66      0.67      0.65      1111\n             weighted avg       0.64      0.63      0.62      1111\n\nConfusion Matrix...\n[[ 66  17   2   1   1   7   0   0   0   0]\n [ 15  44  14   1   1  29   0   1   0   1]\n [ 33   4  46  18   0   3  26  30   1  13]\n [  3  13  11 110   0   3   7   3   0   0]\n [  0   0   0   0  56   3   1   1   1   0]\n [ 12  16   7   4   0  80   7   0   0   0]\n [  0   0   7   0   1   4  65   0   0   1]\n [  0  25   1   2   0   3   1  83   0   5]\n [  0   1   0   1   0   3   3   3  59   3]\n [  4  12   3   1   0   3   3  16   0  86]]\nFold:  2\nEpoch: 1, Train Loss:  1.647, Train Acc: 44.31%, Val Loss:  1.752, Val Acc: 41.18%, Time: 8.77s *\nEpoch: 2, Train Loss: 0.8125, Train Acc: 74.19%, Val Loss:  1.358, Val Acc: 61.22%, Time: 7.00s *\nEpoch: 3, Train Loss: 0.4392, Train Acc: 86.32%, Val Loss:  1.326, Val Acc: 65.11%, Time: 7.05s *\nEpoch: 4, Train Loss: 0.2664, Train Acc: 91.96%, Val Loss:  1.369, Val Acc: 66.50%, Time: 6.99s *\nEpoch: 5, Train Loss: 0.1797, Train Acc: 94.65%, Val Loss:  1.671, Val Acc: 65.02%, Time: 6.96s \nEpoch: 6, Train Loss: 0.1272, Train Acc: 96.04%, Val Loss:  1.758, Val Acc: 65.85%, Time: 6.94s \nEpoch: 7, Train Loss: 0.09995, Train Acc: 96.66%, Val Loss:  1.989, Val Acc: 65.62%, Time: 6.95s \nEpoch: 8, Train Loss: 0.07069, Train Acc: 97.72%, Val Loss:  1.922, Val Acc: 67.28%, Time: 6.88s *\nEpoch: 9, Train Loss: 0.05534, Train Acc: 98.22%, Val Loss:  2.239, Val Acc: 65.11%, Time: 6.89s \nEpoch: 10, Train Loss: 0.05192, Train Acc: 98.35%, Val Loss:  2.086, Val Acc: 66.27%, Time: 6.87s \nEpoch: 11, Train Loss: 0.03964, Train Acc: 98.66%, Val Loss:  2.164, Val Acc: 67.05%, Time: 6.91s \nEpoch: 12, Train Loss: 0.03261, Train Acc: 98.91%, Val Loss:  2.256, Val Acc: 66.91%, Time: 6.95s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.45      0.64      0.53       185\n                   Filter       0.72      0.54      0.62       248\n    Compute Derived Value       0.51      0.61      0.56       215\n            Find Extremum       0.73      0.70      0.71       236\n                     Sort       0.83      0.64      0.73       211\n          Determine Range       0.65      0.60      0.62       217\nCharacterize Distribution       0.84      0.73      0.78       193\n           Find Anomalies       0.73      0.81      0.77       213\n                  Cluster       0.93      0.75      0.83       224\n                Correlate       0.67      0.83      0.74       219\n\n                micro avg       0.69      0.69      0.69      2161\n                macro avg       0.70      0.69      0.69      2161\n             weighted avg       0.71      0.69      0.69      2161\n\nConfusion Matrix...\n[[119  18  28   2   1   3   7   4   1   2]\n [ 31 135  29   2   1  29   4  10   0   7]\n [ 54   8 132   1   0   7   3   3   0   7]\n [ 30   1   7 165  10   3   2   9   3   6]\n [ 13   4  16  18 136  11   2   2   3   6]\n [ 10   3   8  34   7 130   3  10   2  10]\n [  4   3   7   2   2   7 141   5   4  18]\n [  0   9  13   1   0   0   1 173   0  16]\n [  3   3   6   1   6   3   2  12 169  19]\n [  0   4  13   1   0   8   3   9   0 181]]\nFold:  3\nEpoch: 1, Train Loss:  1.627, Train Acc: 45.35%, Val Loss:  1.333, Val Acc: 55.92%, Time: 9.47s *\nEpoch: 2, Train Loss: 0.7579, Train Acc: 76.36%, Val Loss:  1.351, Val Acc: 66.78%, Time: 7.74s *\nEpoch: 3, Train Loss: 0.4215, Train Acc: 87.07%, Val Loss:  1.331, Val Acc: 68.19%, Time: 7.67s *\nEpoch: 4, Train Loss: 0.2564, Train Acc: 92.00%, Val Loss:  1.463, Val Acc: 69.49%, Time: 7.74s *\nEpoch: 5, Train Loss: 0.1672, Train Acc: 94.74%, Val Loss:  1.537, Val Acc: 70.14%, Time: 7.64s *\nEpoch: 6, Train Loss: 0.1207, Train Acc: 96.30%, Val Loss:  1.869, Val Acc: 64.93%, Time: 7.81s \nEpoch: 7, Train Loss: 0.09169, Train Acc: 97.20%, Val Loss:  1.893, Val Acc: 66.78%, Time: 7.65s \nEpoch: 8, Train Loss: 0.07466, Train Acc: 97.57%, Val Loss:  1.951, Val Acc: 66.23%, Time: 7.71s \nEpoch: 9, Train Loss: 0.05242, Train Acc: 98.26%, Val Loss:  2.075, Val Acc: 65.91%, Time: 7.72s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.47      0.29      0.36        80\n                   Filter       0.71      0.56      0.62       106\n    Compute Derived Value       0.37      0.51      0.43        86\n            Find Extremum       0.90      0.71      0.79        97\n                     Sort       0.73      0.88      0.80        88\n          Determine Range       0.46      0.83      0.59        92\nCharacterize Distribution       0.64      0.69      0.67       108\n           Find Anomalies       0.85      0.71      0.77        87\n                  Cluster       0.89      0.66      0.75        96\n                Correlate       0.92      0.68      0.78        81\n\n                micro avg       0.65      0.65      0.65       921\n                macro avg       0.69      0.65      0.66       921\n             weighted avg       0.70      0.65      0.66       921\n\nConfusion Matrix...\n[[23  0 20  1  2 28  6  0  0  0]\n [ 3 59 22  4  4 10  4  0  0  0]\n [ 1  0 44  0  0 29 11  1  0  0]\n [ 3  0 15 69  5  5  0  0  0  0]\n [ 0  0  0  2 77  3  2  0  4  0]\n [ 2  0  2  1  3 76  7  0  0  1]\n [12 14  2  0  0  3 75  1  1  0]\n [ 0 10  1  0  0  7  4 62  1  2]\n [ 0  0  0  0 14  5  8  4 63  2]\n [ 5  0 14  0  0  0  0  5  2 55]]\nFold:  4\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.595, Train Acc: 46.29%, Val Loss:  1.623, Val Acc: 48.77%, Time: 9.25s *\nEpoch: 2, Train Loss: 0.7374, Train Acc: 77.10%, Val Loss:   1.36, Val Acc: 59.93%, Time: 7.60s *\nEpoch: 3, Train Loss: 0.4053, Train Acc: 87.33%, Val Loss:  1.448, Val Acc: 61.58%, Time: 7.43s *\nEpoch: 4, Train Loss: 0.2366, Train Acc: 92.64%, Val Loss:   1.76, Val Acc: 60.34%, Time: 7.65s \nEpoch: 5, Train Loss: 0.1569, Train Acc: 95.25%, Val Loss:  2.081, Val Acc: 59.69%, Time: 7.39s \nEpoch: 6, Train Loss: 0.1176, Train Acc: 96.38%, Val Loss:  2.009, Val Acc: 58.95%, Time: 7.39s \nEpoch: 7, Train Loss: 0.09358, Train Acc: 97.09%, Val Loss:  2.367, Val Acc: 56.81%, Time: 7.57s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.60      0.64      0.62        97\n                   Filter       0.39      0.48      0.43       162\n    Compute Derived Value       0.90      0.35      0.50       159\n            Find Extremum       0.44      0.80      0.57       162\n                     Sort       0.91      0.68      0.78       111\n          Determine Range       0.41      0.88      0.56        86\nCharacterize Distribution       0.85      0.61      0.71       132\n           Find Anomalies       0.64      0.59      0.61        90\n                  Cluster       0.82      0.33      0.47        98\n                Correlate       0.63      0.41      0.50       121\n\n                micro avg       0.57      0.57      0.57      1218\n                macro avg       0.66      0.58      0.57      1218\n             weighted avg       0.66      0.57      0.57      1218\n\nConfusion Matrix...\n[[ 62  13   0  10   0   8   0   2   0   2]\n [ 13  77   0  46   0  14   4   7   0   1]\n [ 10  17  55  38   0  25   6   8   0   0]\n [  5  15   0 129   2  10   0   1   0   0]\n [  1   9   0  17  75   8   0   0   1   0]\n [  0   5   0   2   0  76   2   1   0   0]\n [  2   1   3  17   1  19  80   4   3   2]\n [  0  31   0   2   0   1   0  53   3   0]\n [  9  15   0   0   0  14   2   2  32  24]\n [  2  16   3  29   4  12   0   5   0  50]]\nFold:  5\nEpoch: 1, Train Loss:    1.6, Train Acc: 45.73%, Val Loss:  1.456, Val Acc: 53.23%, Time: 9.47s *\nEpoch: 2, Train Loss: 0.7358, Train Acc: 76.88%, Val Loss:  1.198, Val Acc: 63.53%, Time: 7.76s *\nEpoch: 3, Train Loss: 0.4076, Train Acc: 87.54%, Val Loss:   1.11, Val Acc: 69.62%, Time: 7.62s *\nEpoch: 4, Train Loss: 0.2472, Train Acc: 92.42%, Val Loss:  1.128, Val Acc: 73.12%, Time: 7.51s *\nEpoch: 5, Train Loss: 0.1791, Train Acc: 94.48%, Val Loss:   1.25, Val Acc: 70.07%, Time: 7.56s \nEpoch: 6, Train Loss: 0.1242, Train Acc: 96.25%, Val Loss:  1.356, Val Acc: 71.06%, Time: 7.62s \nEpoch: 7, Train Loss: 0.0968, Train Acc: 96.91%, Val Loss:  1.668, Val Acc: 68.10%, Time: 7.57s \nEpoch: 8, Train Loss: 0.0708, Train Acc: 97.72%, Val Loss:  1.597, Val Acc: 70.34%, Time: 7.70s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.55      0.47      0.51        93\n                   Filter       0.64      0.47      0.54       106\n    Compute Derived Value       0.70      0.66      0.68       134\n            Find Extremum       0.71      0.80      0.76       127\n                     Sort       0.83      0.80      0.81        95\n          Determine Range       0.63      0.79      0.70        96\nCharacterize Distribution       0.81      0.74      0.78       112\n           Find Anomalies       0.67      0.65      0.66       112\n                  Cluster       0.73      0.89      0.80       129\n                Correlate       0.84      0.80      0.82       112\n\n                micro avg       0.72      0.72      0.72      1116\n                macro avg       0.71      0.71      0.71      1116\n             weighted avg       0.71      0.72      0.71      1116\n\nConfusion Matrix...\n[[ 44   4  25   0   0   2   3  13   0   2]\n [ 24  50   5   8   6   3   0   3   7   0]\n [  9   1  89   1   1  17   8   0   2   6]\n [  1   0   2 102   1   5   0  13   2   1]\n [  1   0   0  10  76   3   0   2   3   0]\n [  1   3   0  13   1  76   2   0   0   0]\n [  0   0   1   0   3   0  83   2  15   8]\n [  0  15   5   5   0  13   0  73   1   0]\n [  0   3   0   4   4   0   2   1 115   0]\n [  0   2   0   0   0   1   4   2  13  90]]\nFold:  6\nEpoch: 1, Train Loss:  1.611, Train Acc: 45.41%, Val Loss:  1.383, Val Acc: 57.54%, Time: 9.24s *\nEpoch: 2, Train Loss: 0.7831, Train Acc: 75.74%, Val Loss:   1.22, Val Acc: 65.73%, Time: 7.18s *\nEpoch: 3, Train Loss:  0.441, Train Acc: 86.34%, Val Loss:   1.22, Val Acc: 66.71%, Time: 7.18s *\nEpoch: 4, Train Loss: 0.2786, Train Acc: 91.55%, Val Loss:  1.201, Val Acc: 68.17%, Time: 7.26s *\nEpoch: 5, Train Loss: 0.1757, Train Acc: 94.54%, Val Loss:  1.301, Val Acc: 69.64%, Time: 7.18s *\nEpoch: 6, Train Loss: 0.1228, Train Acc: 96.01%, Val Loss:  1.432, Val Acc: 66.83%, Time: 7.17s \nEpoch: 7, Train Loss: 0.08528, Train Acc: 97.25%, Val Loss:  1.571, Val Acc: 70.07%, Time: 7.22s *\nEpoch: 8, Train Loss: 0.06884, Train Acc: 97.79%, Val Loss:  1.588, Val Acc: 69.58%, Time: 7.33s \nEpoch: 9, Train Loss: 0.05568, Train Acc: 98.15%, Val Loss:  1.512, Val Acc: 69.46%, Time: 7.26s \nEpoch: 10, Train Loss: 0.04235, Train Acc: 98.56%, Val Loss:  2.213, Val Acc: 64.20%, Time: 7.21s \nEpoch: 11, Train Loss: 0.04168, Train Acc: 98.59%, Val Loss:  1.753, Val Acc: 71.41%, Time: 7.21s *\nEpoch: 12, Train Loss: 0.04097, Train Acc: 98.64%, Val Loss:  1.902, Val Acc: 68.17%, Time: 7.24s \nEpoch: 13, Train Loss: 0.0316, Train Acc: 98.94%, Val Loss:  1.978, Val Acc: 68.05%, Time: 7.23s \nEpoch: 14, Train Loss: 0.02984, Train Acc: 98.92%, Val Loss:  1.982, Val Acc: 68.54%, Time: 7.22s \nEpoch: 15, Train Loss: 0.03111, Train Acc: 98.95%, Val Loss:  1.946, Val Acc: 68.30%, Time: 7.23s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.60      0.66      0.63       237\n                   Filter       0.57      0.68      0.62       196\n    Compute Derived Value       0.58      0.44      0.50       149\n            Find Extremum       0.84      0.85      0.84       192\n                     Sort       0.81      0.61      0.70        96\n          Determine Range       0.63      0.80      0.70        89\nCharacterize Distribution       0.70      0.84      0.77       144\n           Find Anomalies       0.74      0.52      0.61       172\n                  Cluster       0.72      0.81      0.76       107\n                Correlate       0.86      0.80      0.83       255\n\n                micro avg       0.70      0.70      0.70      1637\n                macro avg       0.71      0.70      0.70      1637\n             weighted avg       0.71      0.70      0.70      1637\n\nConfusion Matrix...\n[[156  11  31   8   0   2  15   7   3   4]\n [ 25 133   4  12   0  10   0  11   1   0]\n [ 51  14  66   0   0   0   6   7   2   3]\n [  4   5   1 163  13   2   2   1   0   1]\n [  0   4   1   7  59  19   0   0   6   0]\n [  3  11   1   0   0  71   1   1   0   1]\n [ 10   0   6   1   0   3 121   1   0   2]\n [  6  36   1   1   1   5   1  90  14  17]\n [  1   2   0   1   0   0  10   2  87   4]\n [  4  16   3   1   0   1  16   1   8 205]]\nFold:  7\nEpoch: 1, Train Loss:  1.792, Train Acc: 39.86%, Val Loss:  1.482, Val Acc: 51.21%, Time: 8.58s *\nEpoch: 2, Train Loss: 0.8498, Train Acc: 73.33%, Val Loss:   1.43, Val Acc: 61.72%, Time: 6.56s *\nEpoch: 3, Train Loss: 0.4705, Train Acc: 85.22%, Val Loss:  1.305, Val Acc: 66.98%, Time: 6.60s *\nEpoch: 4, Train Loss: 0.2862, Train Acc: 91.05%, Val Loss:  1.382, Val Acc: 67.90%, Time: 6.57s *\nEpoch: 5, Train Loss: 0.1953, Train Acc: 93.98%, Val Loss:  1.609, Val Acc: 64.86%, Time: 6.55s \nEpoch: 6, Train Loss: 0.1407, Train Acc: 95.59%, Val Loss:  1.781, Val Acc: 64.17%, Time: 6.65s \nEpoch: 7, Train Loss: 0.08923, Train Acc: 97.21%, Val Loss:   1.87, Val Acc: 66.36%, Time: 6.68s \nEpoch: 8, Train Loss:   0.08, Train Acc: 97.33%, Val Loss:  1.714, Val Acc: 67.24%, Time: 6.56s \nNo optimization for a long time, auto-stopping...\n", "name": "stdout"}, {"output_type": "stream", "text": "Precision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.55      0.48      0.51       244\n                   Filter       0.56      0.78      0.66       246\n    Compute Derived Value       0.53      0.44      0.48       277\n            Find Extremum       0.68      0.69      0.69       275\n                     Sort       0.95      0.77      0.85       257\n          Determine Range       0.61      0.45      0.52       271\nCharacterize Distribution       0.73      0.86      0.79       283\n           Find Anomalies       0.56      0.69      0.62       300\n                  Cluster       0.83      0.77      0.80       271\n                Correlate       0.75      0.74      0.75       314\n\n                micro avg       0.67      0.67      0.67      2738\n                macro avg       0.68      0.67      0.67      2738\n             weighted avg       0.68      0.67      0.67      2738\n\nConfusion Matrix...\n[[118  10  53   6   0  15  12  22   1   7]\n [  2 193   2   8   0   5   1  21   0  14]\n [ 45  19 121  10   0   8  11  42   2  19]\n [ 15  17  15 191   0  29   0   6   1   1]\n [  0  12   3  22 197   7   3   2   8   3]\n [ 30  47  17  20   4 123  13   9   3   5]\n [  3   5   1   0   1   6 244  17   3   3]\n [  2  37   4  22   0   3   4 206   5  17]\n [  1   0   3   0   4   5  22  17 210   9]\n [  0   3  10   1   1   2  22  23  19 233]]\nFold:  8\nEpoch: 1, Train Loss:   1.61, Train Acc: 46.39%, Val Loss:  1.922, Val Acc: 38.55%, Time: 8.91s *\nEpoch: 2, Train Loss: 0.7588, Train Acc: 76.15%, Val Loss:  1.862, Val Acc: 49.86%, Time: 7.06s *\nEpoch: 3, Train Loss: 0.4002, Train Acc: 87.69%, Val Loss:  1.732, Val Acc: 56.61%, Time: 7.06s *\nEpoch: 4, Train Loss:  0.248, Train Acc: 92.32%, Val Loss:  2.154, Val Acc: 54.98%, Time: 7.34s \nEpoch: 5, Train Loss: 0.1634, Train Acc: 95.10%, Val Loss:  2.224, Val Acc: 56.23%, Time: 7.12s \nEpoch: 6, Train Loss: 0.1183, Train Acc: 96.27%, Val Loss:  2.348, Val Acc: 56.66%, Time: 7.12s *\nEpoch: 7, Train Loss: 0.0804, Train Acc: 97.38%, Val Loss:  2.153, Val Acc: 61.50%, Time: 7.14s *\nEpoch: 8, Train Loss: 0.06234, Train Acc: 98.03%, Val Loss:  2.403, Val Acc: 59.11%, Time: 7.08s \nEpoch: 9, Train Loss: 0.05834, Train Acc: 98.10%, Val Loss:    2.6, Val Acc: 58.78%, Time: 7.27s \nEpoch: 10, Train Loss: 0.04819, Train Acc: 98.38%, Val Loss:  2.691, Val Acc: 59.92%, Time: 7.14s \nEpoch: 11, Train Loss: 0.04373, Train Acc: 98.57%, Val Loss:  2.815, Val Acc: 59.54%, Time: 7.22s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.67      0.42      0.52       210\n                   Filter       0.40      0.25      0.30       187\n    Compute Derived Value       0.65      0.44      0.53       201\n            Find Extremum       0.51      0.82      0.63       164\n                     Sort       0.67      0.87      0.76       174\n          Determine Range       0.50      0.65      0.56       213\nCharacterize Distribution       0.66      0.49      0.56       169\n           Find Anomalies       0.44      0.58      0.50       162\n                  Cluster       0.86      0.79      0.82       178\n                Correlate       0.74      0.77      0.75       181\n\n                micro avg       0.60      0.60      0.60      1839\n                macro avg       0.61      0.61      0.59      1839\n             weighted avg       0.61      0.60      0.59      1839\n\nConfusion Matrix...\n[[ 89   9   7  56  13  11   9   7   0   9]\n [  9  46  10  24   8  31   0  47   9   3]\n [ 23  15  89  29   5  28   2  10   0   0]\n [  3   0   1 135  13   5   1   6   0   0]\n [  0   3   0   4 151  13   1   1   1   0]\n [  7  30  13   3  15 138   0   6   1   0]\n [  1   1   6   7   3  29  83   9  10  20]\n [  1   5   9   3   3   6  25  94   1  15]\n [  0   3   0   0  10   5   3  14 140   3]\n [  0   4   1   2   3  12   1  18   1 139]]\nFold:  9\nEpoch: 1, Train Loss:  1.554, Train Acc: 48.28%, Val Loss:  1.611, Val Acc: 48.90%, Time: 9.66s *\nEpoch: 2, Train Loss: 0.7424, Train Acc: 76.49%, Val Loss:  1.199, Val Acc: 62.87%, Time: 7.91s *\nEpoch: 3, Train Loss: 0.4272, Train Acc: 86.79%, Val Loss:  1.045, Val Acc: 70.59%, Time: 7.82s *\nEpoch: 4, Train Loss: 0.2617, Train Acc: 92.08%, Val Loss:  1.294, Val Acc: 66.73%, Time: 7.85s \nEpoch: 5, Train Loss:  0.173, Train Acc: 94.60%, Val Loss:  1.131, Val Acc: 73.71%, Time: 7.82s *\nEpoch: 6, Train Loss:   0.12, Train Acc: 96.33%, Val Loss:  1.289, Val Acc: 69.67%, Time: 8.05s \nEpoch: 7, Train Loss: 0.1013, Train Acc: 96.76%, Val Loss:  1.209, Val Acc: 72.06%, Time: 7.86s \nEpoch: 8, Train Loss: 0.07034, Train Acc: 97.59%, Val Loss:  1.763, Val Acc: 65.81%, Time: 7.80s \nEpoch: 9, Train Loss: 0.05369, Train Acc: 98.24%, Val Loss:  1.885, Val Acc: 64.52%, Time: 7.91s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.77      0.64      0.70        67\n                   Filter       0.30      0.48      0.37        27\n    Compute Derived Value       0.58      0.53      0.55        64\n            Find Extremum       1.00      0.59      0.74       120\n                     Sort       0.89      0.70      0.79        60\n          Determine Range       0.32      0.91      0.47        32\nCharacterize Distribution       0.81      0.55      0.66        47\n           Find Anomalies       0.81      0.64      0.72        45\n                  Cluster       0.55      0.68      0.61        34\n                Correlate       0.74      1.00      0.85        48\n\n                micro avg       0.66      0.66      0.66       544\n                macro avg       0.68      0.67      0.64       544\n             weighted avg       0.75      0.66      0.68       544\n\nConfusion Matrix...\n[[43  1 16  0  1  6  0  0  0  0]\n [ 1 13  0  0  0 13  0  0  0  0]\n [ 1  6 34  0  0 17  0  0  0  6]\n [ 9 15  4 71  0  7  0  7  2  5]\n [ 0  0  0  0 42  9  0  0  9  0]\n [ 0  0  2  0  0 29  1  0  0  0]\n [ 1  3  1  0  1  4 26  0  8  3]\n [ 1  1  2  0  0  7  5 29  0  0]\n [ 0  5  0  0  3  0  0  0 23  3]\n [ 0  0  0  0  0  0  0  0  0 48]]\nFold:  10\nEpoch: 1, Train Loss:  1.587, Train Acc: 46.69%, Val Loss:  1.746, Val Acc: 52.53%, Time: 9.52s *\nEpoch: 2, Train Loss: 0.7495, Train Acc: 76.08%, Val Loss:  1.286, Val Acc: 64.27%, Time: 7.65s *\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "kf = KFold(n_splits=10)\ntest_acc_split = []\nfor split_type,info in split_info.items():\n    train_data = dataset_split(info)\n    test_acc_split.append(train_split_data(train_data, split_type))", "execution_count": null, "outputs": [{"output_type": "stream", "text": "random\n14035 41 41\nFold:  1\nEpoch: 1, Train Loss:  1.344, Train Acc: 54.23%, Val Loss: 0.6779, Val Acc: 78.13%, Time: 43.17s *\nEpoch: 2, Train Loss: 0.4508, Train Acc: 86.06%, Val Loss: 0.4143, Val Acc: 87.11%, Time: 42.28s *\nEpoch: 3, Train Loss: 0.2389, Train Acc: 92.39%, Val Loss: 0.3458, Val Acc: 89.67%, Time: 43.00s *\nEpoch: 4, Train Loss: 0.1614, Train Acc: 94.75%, Val Loss: 0.2616, Val Acc: 93.23%, Time: 42.45s *\nEpoch: 5, Train Loss: 0.1088, Train Acc: 96.51%, Val Loss:  0.295, Val Acc: 91.81%, Time: 42.22s \nEpoch: 6, Train Loss: 0.08015, Train Acc: 97.20%, Val Loss: 0.3082, Val Acc: 92.95%, Time: 42.55s \nEpoch: 7, Train Loss: 0.06802, Train Acc: 97.65%, Val Loss:  0.318, Val Acc: 92.38%, Time: 42.61s \nEpoch: 8, Train Loss: 0.05446, Train Acc: 98.24%, Val Loss:  0.289, Val Acc: 93.09%, Time: 42.85s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.87      0.99      0.93       109\n                   Filter       0.92      0.95      0.93       134\n    Compute Derived Value       0.95      0.92      0.93       151\n            Find Extremum       0.95      0.95      0.95       163\n                     Sort       0.98      0.89      0.93       144\n          Determine Range       0.92      0.94      0.93       146\nCharacterize Distribution       0.95      0.96      0.96       130\n           Find Anomalies       0.94      0.90      0.92       150\n                  Cluster       0.88      0.96      0.92       111\n                Correlate       0.97      0.90      0.93       166\n\n                micro avg       0.93      0.93      0.93      1404\n                macro avg       0.93      0.94      0.93      1404\n             weighted avg       0.94      0.93      0.93      1404\n\nConfusion Matrix...\n[[108   0   1   0   0   0   0   0   0   0]\n [  2 127   0   2   0   2   0   1   0   0]\n [  3   3 139   0   1   3   0   0   1   1]\n [  1   1   0 155   1   1   1   0   1   2]\n [  2   1   0   3 128   4   0   0   6   0]\n [  2   2   1   1   0 137   1   1   1   0]\n [  1   0   0   0   0   2 125   1   1   0]\n [  2   4   4   0   1   0   1 135   2   1]\n [  1   0   0   0   0   0   1   1 107   1]\n [  2   0   2   3   0   0   2   5   2 150]]\nFold:  2\nEpoch: 1, Train Loss:  1.368, Train Acc: 53.12%, Val Loss: 0.6642, Val Acc: 77.85%, Time: 43.52s *\nEpoch: 2, Train Loss: 0.4628, Train Acc: 85.19%, Val Loss: 0.3953, Val Acc: 88.18%, Time: 42.62s *\nEpoch: 3, Train Loss: 0.2434, Train Acc: 92.43%, Val Loss: 0.3039, Val Acc: 91.81%, Time: 44.54s *\nEpoch: 4, Train Loss: 0.1532, Train Acc: 95.21%, Val Loss: 0.2481, Val Acc: 92.88%, Time: 69.29s *\nEpoch: 5, Train Loss: 0.1025, Train Acc: 96.74%, Val Loss: 0.2454, Val Acc: 93.38%, Time: 72.56s *\nEpoch: 6, Train Loss: 0.07901, Train Acc: 97.43%, Val Loss: 0.2767, Val Acc: 93.09%, Time: 72.92s \nEpoch: 7, Train Loss: 0.05913, Train Acc: 97.99%, Val Loss: 0.2528, Val Acc: 93.45%, Time: 72.72s *\nEpoch: 8, Train Loss: 0.05374, Train Acc: 98.30%, Val Loss: 0.2243, Val Acc: 95.16%, Time: 73.87s *\nEpoch: 9, Train Loss: 0.04252, Train Acc: 98.56%, Val Loss: 0.2221, Val Acc: 94.87%, Time: 72.67s \nEpoch: 10, Train Loss: 0.0384, Train Acc: 98.79%, Val Loss: 0.2827, Val Acc: 94.52%, Time: 74.15s \nEpoch: 11, Train Loss: 0.03514, Train Acc: 98.87%, Val Loss: 0.2952, Val Acc: 93.73%, Time: 74.60s \nEpoch: 12, Train Loss: 0.03429, Train Acc: 98.88%, Val Loss: 0.2742, Val Acc: 94.02%, Time: 74.75s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.99      0.95      0.97       149\n                   Filter       0.91      0.96      0.94       144\n    Compute Derived Value       0.95      0.89      0.92       157\n            Find Extremum       0.93      0.96      0.95       164\n                     Sort       0.96      0.99      0.97       130\n          Determine Range       0.91      0.91      0.91       139\nCharacterize Distribution       0.86      0.95      0.90       108\n           Find Anomalies       0.95      0.90      0.92       147\n                  Cluster       0.93      0.96      0.94       141\n                Correlate       0.97      0.92      0.95       125\n\n                micro avg       0.94      0.94      0.94      1404\n                macro avg       0.94      0.94      0.94      1404\n             weighted avg       0.94      0.94      0.94      1404\n\nConfusion Matrix...\n[[141   1   2   1   1   3   0   0   0   0]\n [  0 138   2   0   0   1   0   1   2   0]\n [  1   4 140   3   1   4   2   1   1   0]\n [  0   3   0 157   1   0   1   1   1   0]\n [  0   0   0   1 129   0   0   0   0   0]\n [  0   2   0   2   2 126   5   0   1   1]\n [  0   0   1   0   1   2 103   0   1   0]\n [  0   3   1   1   0   3   3 132   2   2]\n [  0   0   0   2   0   0   2   2 135   0]\n [  0   0   1   1   0   0   4   2   2 115]]\nFold:  3\nEpoch: 1, Train Loss:  1.326, Train Acc: 54.96%, Val Loss: 0.6536, Val Acc: 78.28%, Time: 77.48s *\nEpoch: 2, Train Loss: 0.4438, Train Acc: 86.22%, Val Loss:  0.402, Val Acc: 87.18%, Time: 74.87s *\nEpoch: 3, Train Loss: 0.2383, Train Acc: 92.53%, Val Loss: 0.3186, Val Acc: 90.60%, Time: 74.33s *\nEpoch: 4, Train Loss: 0.1576, Train Acc: 95.19%, Val Loss: 0.2886, Val Acc: 91.24%, Time: 74.41s *\nEpoch: 5, Train Loss: 0.1113, Train Acc: 96.59%, Val Loss: 0.2516, Val Acc: 93.52%, Time: 73.20s *\nEpoch: 6, Train Loss: 0.08363, Train Acc: 97.21%, Val Loss:  0.254, Val Acc: 92.95%, Time: 74.00s \nEpoch: 7, Train Loss: 0.05477, Train Acc: 98.17%, Val Loss: 0.2393, Val Acc: 94.02%, Time: 71.82s *\nEpoch: 8, Train Loss: 0.06217, Train Acc: 97.99%, Val Loss: 0.2808, Val Acc: 92.38%, Time: 74.27s \nEpoch: 9, Train Loss: 0.04238, Train Acc: 98.60%, Val Loss: 0.2509, Val Acc: 94.37%, Time: 74.32s *\nEpoch: 10, Train Loss: 0.04455, Train Acc: 98.49%, Val Loss: 0.2327, Val Acc: 94.73%, Time: 73.76s *\nEpoch: 11, Train Loss: 0.03722, Train Acc: 98.60%, Val Loss: 0.2772, Val Acc: 94.37%, Time: 75.41s \nEpoch: 12, Train Loss: 0.03098, Train Acc: 98.89%, Val Loss: 0.3031, Val Acc: 93.66%, Time: 74.09s \nEpoch: 13, Train Loss: 0.02954, Train Acc: 99.00%, Val Loss: 0.2295, Val Acc: 94.73%, Time: 74.06s \nEpoch: 14, Train Loss: 0.02337, Train Acc: 99.21%, Val Loss:  0.231, Val Acc: 95.01%, Time: 74.20s *\nEpoch: 15, Train Loss: 0.0244, Train Acc: 99.11%, Val Loss: 0.2708, Val Acc: 94.59%, Time: 74.49s \nEpoch: 16, Train Loss:   0.02, Train Acc: 99.34%, Val Loss:  0.332, Val Acc: 93.52%, Time: 73.97s \nEpoch: 17, Train Loss: 0.02462, Train Acc: 99.12%, Val Loss: 0.3972, Val Acc: 93.02%, Time: 74.44s \nEpoch: 18, Train Loss: 0.02482, Train Acc: 99.15%, Val Loss: 0.2987, Val Acc: 94.02%, Time: 72.29s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.97      0.94      0.95       141\n                   Filter       0.91      0.94      0.92       153\n    Compute Derived Value       0.97      0.89      0.93       161\n            Find Extremum       0.86      0.97      0.91       163\n                     Sort       0.94      0.98      0.96       116\n          Determine Range       0.91      0.89      0.90       127\nCharacterize Distribution       0.94      0.92      0.93       142\n           Find Anomalies       0.98      0.92      0.95       138\n                  Cluster       0.97      0.97      0.97       122\n                Correlate       0.95      0.97      0.96       141\n\n                micro avg       0.94      0.94      0.94      1404\n                macro avg       0.94      0.94      0.94      1404\n             weighted avg       0.94      0.94      0.94      1404\n\nConfusion Matrix...\n[[132   2   0   2   1   1   1   1   0   1]\n [  1 144   2   1   0   3   1   0   1   0]\n [  2   2 143  10   0   1   1   0   1   1]\n [  0   2   0 158   3   0   0   0   0   0]\n [  0   0   0   1 114   1   0   0   0   0]\n [  1   3   0   4   1 113   2   0   2   1]\n [  0   1   2   3   0   2 131   1   0   2]\n [  0   5   0   2   0   2   0 127   0   2]\n [  0   0   0   0   2   1   1   0 118   0]\n [  0   0   0   2   0   0   2   0   0 137]]\nFold:  4\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.403, Train Acc: 52.39%, Val Loss: 0.6452, Val Acc: 79.63%, Time: 76.34s *\nEpoch: 2, Train Loss: 0.4633, Train Acc: 85.09%, Val Loss: 0.4032, Val Acc: 88.39%, Time: 75.24s *\nEpoch: 3, Train Loss: 0.2433, Train Acc: 92.53%, Val Loss: 0.3031, Val Acc: 92.02%, Time: 74.13s *\nEpoch: 4, Train Loss: 0.1496, Train Acc: 95.45%, Val Loss: 0.2439, Val Acc: 93.38%, Time: 75.06s *\nEpoch: 5, Train Loss: 0.1096, Train Acc: 96.53%, Val Loss:  0.224, Val Acc: 93.66%, Time: 74.34s *\nEpoch: 6, Train Loss: 0.08114, Train Acc: 97.41%, Val Loss: 0.2375, Val Acc: 93.66%, Time: 74.67s \nEpoch: 7, Train Loss: 0.07542, Train Acc: 97.46%, Val Loss: 0.2378, Val Acc: 93.95%, Time: 74.57s *\nEpoch: 8, Train Loss: 0.05095, Train Acc: 98.28%, Val Loss: 0.1923, Val Acc: 95.09%, Time: 74.45s *\nEpoch: 9, Train Loss: 0.0484, Train Acc: 98.36%, Val Loss: 0.2425, Val Acc: 93.95%, Time: 74.78s \nEpoch: 10, Train Loss: 0.03569, Train Acc: 98.78%, Val Loss: 0.2126, Val Acc: 95.01%, Time: 73.20s \nEpoch: 11, Train Loss: 0.03543, Train Acc: 98.76%, Val Loss: 0.2348, Val Acc: 94.73%, Time: 75.45s \nEpoch: 12, Train Loss: 0.03401, Train Acc: 98.94%, Val Loss: 0.2521, Val Acc: 94.52%, Time: 75.31s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       1.00      0.86      0.92       113\n                   Filter       0.94      0.92      0.93       141\n    Compute Derived Value       0.95      0.96      0.96       176\n            Find Extremum       0.96      0.95      0.95       164\n                     Sort       0.93      0.97      0.95       118\n          Determine Range       0.95      0.96      0.96       133\nCharacterize Distribution       0.95      0.90      0.93       132\n           Find Anomalies       0.94      0.96      0.95       159\n                  Cluster       0.89      1.00      0.94       118\n                Correlate       0.97      0.97      0.97       150\n\n                micro avg       0.95      0.95      0.95      1404\n                macro avg       0.95      0.95      0.95      1404\n             weighted avg       0.95      0.95      0.95      1404\n\nConfusion Matrix...\n[[ 97   2   6   2   0   0   4   0   1   1]\n [  0 130   0   3   1   1   1   3   0   2]\n [  0   1 169   0   1   4   1   0   0   0]\n [  0   1   0 156   4   0   0   3   0   0]\n [  0   0   1   1 114   1   0   0   1   0]\n [  0   0   0   1   1 128   0   0   3   0]\n [  0   1   1   0   1   1 119   2   5   2]\n [  0   3   0   0   0   0   0 153   3   0]\n [  0   0   0   0   0   0   0   0 118   0]\n [  0   1   0   0   0   0   0   1   2 146]]\nFold:  5\nEpoch: 1, Train Loss:  1.385, Train Acc: 52.96%, Val Loss: 0.6864, Val Acc: 78.35%, Time: 76.91s *\nEpoch: 2, Train Loss: 0.4524, Train Acc: 85.73%, Val Loss: 0.3923, Val Acc: 87.96%, Time: 74.54s *\nEpoch: 3, Train Loss: 0.2543, Train Acc: 92.01%, Val Loss: 0.2848, Val Acc: 91.74%, Time: 75.06s *\nEpoch: 4, Train Loss: 0.1553, Train Acc: 94.95%, Val Loss: 0.2272, Val Acc: 92.81%, Time: 73.39s *\nEpoch: 5, Train Loss: 0.1169, Train Acc: 96.43%, Val Loss: 0.2045, Val Acc: 94.30%, Time: 75.65s *\nEpoch: 6, Train Loss: 0.08379, Train Acc: 97.30%, Val Loss: 0.1694, Val Acc: 95.30%, Time: 75.02s *\nEpoch: 7, Train Loss: 0.06199, Train Acc: 98.07%, Val Loss: 0.2286, Val Acc: 93.30%, Time: 75.11s \nEpoch: 8, Train Loss: 0.05096, Train Acc: 98.31%, Val Loss: 0.1545, Val Acc: 95.80%, Time: 74.53s *\nEpoch: 9, Train Loss: 0.04755, Train Acc: 98.39%, Val Loss: 0.2013, Val Acc: 94.87%, Time: 72.84s \nEpoch: 10, Train Loss: 0.0405, Train Acc: 98.70%, Val Loss: 0.1456, Val Acc: 95.66%, Time: 74.99s \nEpoch: 11, Train Loss: 0.03812, Train Acc: 98.73%, Val Loss: 0.1854, Val Acc: 95.09%, Time: 74.03s \nEpoch: 12, Train Loss: 0.03514, Train Acc: 98.77%, Val Loss:   0.16, Val Acc: 95.58%, Time: 74.95s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.99      0.98      0.99       147\n                   Filter       0.96      0.94      0.95       148\n    Compute Derived Value       0.95      0.95      0.95       135\n            Find Extremum       0.99      0.93      0.96       169\n                     Sort       0.94      0.97      0.95       119\n          Determine Range       0.91      0.93      0.92       127\nCharacterize Distribution       0.95      0.95      0.95       146\n           Find Anomalies       0.99      0.92      0.96       119\n                  Cluster       0.89      1.00      0.94       114\n                Correlate       0.94      0.95      0.95       180\n\n                micro avg       0.95      0.95      0.95      1404\n                macro avg       0.95      0.95      0.95      1404\n             weighted avg       0.95      0.95      0.95      1404\n\nConfusion Matrix...\n[[144   0   0   0   0   0   1   0   1   1]\n [  0 139   0   0   0   6   1   0   1   1]\n [  0   2 128   0   0   1   0   0   2   2]\n [  0   0   0 158   5   4   0   1   1   0]\n [  0   0   0   0 116   1   0   0   2   0]\n [  0   2   3   0   1 118   2   0   0   1]\n [  0   1   2   0   0   0 139   0   2   2]\n [  1   1   1   1   0   0   1 110   1   3]\n [  0   0   0   0   0   0   0   0 114   0]\n [  0   0   1   0   2   0   2   0   4 171]]\nFold:  6\nEpoch: 1, Train Loss:  1.339, Train Acc: 54.50%, Val Loss: 0.6866, Val Acc: 77.90%, Time: 76.65s *\nEpoch: 2, Train Loss: 0.4489, Train Acc: 85.51%, Val Loss: 0.4464, Val Acc: 85.74%, Time: 73.77s *\nEpoch: 3, Train Loss: 0.2411, Train Acc: 92.57%, Val Loss: 0.3371, Val Acc: 89.52%, Time: 74.26s *\nEpoch: 4, Train Loss: 0.1428, Train Acc: 95.58%, Val Loss:  0.234, Val Acc: 92.59%, Time: 74.84s *\nEpoch: 5, Train Loss: 0.1099, Train Acc: 96.65%, Val Loss: 0.2349, Val Acc: 92.94%, Time: 74.29s *\nEpoch: 6, Train Loss: 0.0773, Train Acc: 97.61%, Val Loss: 0.2081, Val Acc: 93.44%, Time: 74.77s *\nEpoch: 7, Train Loss: 0.06829, Train Acc: 97.68%, Val Loss: 0.2243, Val Acc: 93.73%, Time: 72.63s *\nEpoch: 8, Train Loss: 0.06191, Train Acc: 97.93%, Val Loss: 0.2205, Val Acc: 93.66%, Time: 74.88s \nEpoch: 9, Train Loss: 0.04519, Train Acc: 98.58%, Val Loss:  0.208, Val Acc: 93.59%, Time: 73.95s \nEpoch: 10, Train Loss: 0.03793, Train Acc: 98.81%, Val Loss:  0.216, Val Acc: 94.08%, Time: 74.73s *\nEpoch: 11, Train Loss: 0.03801, Train Acc: 98.77%, Val Loss: 0.2236, Val Acc: 94.30%, Time: 74.88s *\nEpoch: 12, Train Loss: 0.03196, Train Acc: 98.87%, Val Loss: 0.2274, Val Acc: 94.73%, Time: 74.62s *\nEpoch: 13, Train Loss: 0.03094, Train Acc: 98.93%, Val Loss:  0.308, Val Acc: 93.16%, Time: 74.38s \nEpoch: 14, Train Loss: 0.02679, Train Acc: 99.19%, Val Loss: 0.2144, Val Acc: 95.30%, Time: 73.33s *\nEpoch: 15, Train Loss: 0.02897, Train Acc: 99.15%, Val Loss: 0.2354, Val Acc: 93.94%, Time: 74.35s \nEpoch: 16, Train Loss: 0.0233, Train Acc: 99.34%, Val Loss: 0.2086, Val Acc: 95.87%, Time: 75.61s *\nEpoch: 17, Train Loss: 0.01865, Train Acc: 99.37%, Val Loss: 0.2798, Val Acc: 94.65%, Time: 75.68s \nEpoch: 18, Train Loss: 0.01706, Train Acc: 99.53%, Val Loss: 0.2246, Val Acc: 94.73%, Time: 84.92s \nEpoch: 19, Train Loss: 0.02187, Train Acc: 99.27%, Val Loss: 0.2457, Val Acc: 94.73%, Time: 78.20s \nEpoch: 20, Train Loss: 0.02038, Train Acc: 99.25%, Val Loss: 0.2363, Val Acc: 95.22%, Time: 74.24s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.94      0.98      0.96       136\n                   Filter       0.91      0.97      0.94       154\n    Compute Derived Value       0.99      0.90      0.94       177\n            Find Extremum       0.96      0.96      0.96       162\n                     Sort       0.93      0.99      0.96       138\n          Determine Range       0.93      0.91      0.92       127\nCharacterize Distribution       0.90      0.91      0.90       117\n           Find Anomalies       0.96      0.94      0.95       124\n                  Cluster       0.97      0.95      0.96       121\n                Correlate       0.95      0.94      0.95       147\n\n                micro avg       0.94      0.94      0.94      1403\n                macro avg       0.94      0.94      0.94      1403\n             weighted avg       0.95      0.94      0.94      1403\n\nConfusion Matrix...\n[[133   0   0   0   1   0   2   0   0   0]\n [  1 150   0   1   0   2   0   0   0   0]\n [  5   5 159   3   1   2   1   0   0   1]\n [  1   1   0 156   1   0   2   0   0   1]\n [  0   1   0   0 136   1   0   0   0   0]\n [  0   2   0   1   5 115   4   0   0   0]\n [  0   0   1   1   1   2 106   1   1   4]\n [  1   4   0   0   0   0   1 117   0   1]\n [  0   0   0   1   0   2   2   1 115   0]\n [  0   1   1   0   1   0   0   3   3 138]]\nFold:  7\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.383, Train Acc: 53.02%, Val Loss: 0.6527, Val Acc: 79.83%, Time: 75.17s *\nEpoch: 2, Train Loss: 0.4634, Train Acc: 85.58%, Val Loss: 0.4269, Val Acc: 86.81%, Time: 74.77s *\nEpoch: 3, Train Loss: 0.2504, Train Acc: 92.12%, Val Loss:  0.355, Val Acc: 89.45%, Time: 75.19s *\nEpoch: 4, Train Loss: 0.1598, Train Acc: 95.01%, Val Loss: 0.2847, Val Acc: 91.73%, Time: 74.35s *\nEpoch: 5, Train Loss: 0.1146, Train Acc: 96.30%, Val Loss: 0.2375, Val Acc: 92.80%, Time: 74.81s *\nEpoch: 6, Train Loss: 0.08076, Train Acc: 97.33%, Val Loss: 0.2167, Val Acc: 93.23%, Time: 75.04s *\nEpoch: 7, Train Loss: 0.06253, Train Acc: 97.94%, Val Loss: 0.2338, Val Acc: 94.01%, Time: 74.98s *\nEpoch: 8, Train Loss: 0.05976, Train Acc: 98.05%, Val Loss: 0.2495, Val Acc: 93.51%, Time: 74.71s \nEpoch: 9, Train Loss: 0.05753, Train Acc: 98.05%, Val Loss: 0.2706, Val Acc: 92.94%, Time: 74.50s \nEpoch: 10, Train Loss: 0.03126, Train Acc: 98.95%, Val Loss: 0.2304, Val Acc: 94.37%, Time: 74.65s *\nEpoch: 11, Train Loss: 0.04038, Train Acc: 98.66%, Val Loss:  0.258, Val Acc: 94.08%, Time: 72.90s \nEpoch: 12, Train Loss: 0.02559, Train Acc: 99.09%, Val Loss: 0.2738, Val Acc: 94.01%, Time: 75.27s \nEpoch: 13, Train Loss: 0.02586, Train Acc: 99.17%, Val Loss: 0.3007, Val Acc: 93.94%, Time: 75.68s \nEpoch: 14, Train Loss: 0.0256, Train Acc: 98.98%, Val Loss:   0.29, Val Acc: 93.59%, Time: 75.47s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.93      0.97      0.95       147\n                   Filter       0.96      0.88      0.92       145\n    Compute Derived Value       0.90      0.92      0.91       130\n            Find Extremum       0.95      0.98      0.96       167\n                     Sort       0.99      0.94      0.96       124\n          Determine Range       0.88      0.97      0.92       137\nCharacterize Distribution       0.87      0.94      0.91       139\n           Find Anomalies       0.95      0.89      0.92       128\n                  Cluster       0.98      0.90      0.94       147\n                Correlate       0.96      0.96      0.96       139\n\n                micro avg       0.94      0.94      0.94      1403\n                macro avg       0.94      0.93      0.94      1403\n             weighted avg       0.94      0.94      0.94      1403\n\nConfusion Matrix...\n[[142   2   2   0   0   0   1   0   0   0]\n [  1 128   3   1   0   6   3   3   0   0]\n [  4   2 119   1   0   3   1   0   0   0]\n [  0   0   1 163   0   2   0   1   0   0]\n [  2   0   0   0 116   2   3   0   1   0]\n [  0   0   2   1   0 133   1   0   0   0]\n [  1   0   0   0   0   4 131   1   1   1]\n [  1   0   4   5   0   0   1 114   1   2]\n [  1   2   0   0   1   1   7   0 133   2]\n [  1   0   1   0   0   0   2   1   0 134]]\nFold:  8\nEpoch: 1, Train Loss:  1.405, Train Acc: 51.85%, Val Loss: 0.6753, Val Acc: 78.90%, Time: 77.07s *\nEpoch: 2, Train Loss: 0.4644, Train Acc: 85.39%, Val Loss: 0.4574, Val Acc: 86.67%, Time: 75.10s *\nEpoch: 3, Train Loss: 0.2442, Train Acc: 92.19%, Val Loss: 0.3339, Val Acc: 90.66%, Time: 74.07s *\nEpoch: 4, Train Loss: 0.1559, Train Acc: 94.87%, Val Loss: 0.2949, Val Acc: 93.30%, Time: 75.48s *\nEpoch: 5, Train Loss: 0.1055, Train Acc: 96.67%, Val Loss:  0.268, Val Acc: 94.23%, Time: 75.15s *\nEpoch: 6, Train Loss: 0.08074, Train Acc: 97.38%, Val Loss: 0.3245, Val Acc: 92.16%, Time: 76.56s \nEpoch: 7, Train Loss: 0.06422, Train Acc: 98.03%, Val Loss: 0.2759, Val Acc: 94.01%, Time: 74.91s \nEpoch: 8, Train Loss: 0.05277, Train Acc: 98.19%, Val Loss: 0.2684, Val Acc: 93.51%, Time: 75.25s \nEpoch: 9, Train Loss: 0.04433, Train Acc: 98.54%, Val Loss: 0.2812, Val Acc: 94.23%, Time: 74.76s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       1.00      0.96      0.98       139\n                   Filter       0.86      0.96      0.91       155\n    Compute Derived Value       0.96      0.85      0.90       129\n            Find Extremum       0.97      0.93      0.95       181\n                     Sort       0.93      0.95      0.94       112\n          Determine Range       0.90      0.93      0.91       136\nCharacterize Distribution       0.97      0.87      0.92       137\n           Find Anomalies       0.93      0.94      0.94       135\n                  Cluster       0.89      0.98      0.93       127\n                Correlate       0.95      0.97      0.96       152\n\n                micro avg       0.93      0.93      0.93      1403\n                macro avg       0.94      0.93      0.93      1403\n             weighted avg       0.94      0.93      0.93      1403\n\nConfusion Matrix...\n[[134   0   0   2   1   1   0   1   0   0]\n [  0 149   0   1   0   0   0   4   1   0]\n [  0  11 110   0   1   4   2   0   0   1]\n [  0   0   1 168   3   5   0   3   0   1]\n [  0   0   0   1 106   0   0   0   5   0]\n [  0   5   3   0   0 126   0   0   0   2]\n [  0   3   1   0   2   3 119   0   7   2]\n [  0   2   0   1   0   1   2 127   1   1]\n [  0   1   0   0   1   0   0   0 124   1]\n [  0   2   0   0   0   0   0   1   2 147]]\nFold:  9\nEpoch: 1, Train Loss:  1.357, Train Acc: 53.42%, Val Loss: 0.6213, Val Acc: 80.83%, Time: 76.75s *\nEpoch: 2, Train Loss: 0.4524, Train Acc: 85.70%, Val Loss: 0.3863, Val Acc: 88.03%, Time: 74.86s *\nEpoch: 3, Train Loss: 0.2408, Train Acc: 92.57%, Val Loss: 0.2321, Val Acc: 93.30%, Time: 74.40s *\nEpoch: 4, Train Loss: 0.1544, Train Acc: 95.15%, Val Loss: 0.2075, Val Acc: 93.73%, Time: 73.57s *\nEpoch: 5, Train Loss: 0.1043, Train Acc: 96.70%, Val Loss: 0.2375, Val Acc: 93.16%, Time: 75.88s \nEpoch: 6, Train Loss: 0.08207, Train Acc: 97.32%, Val Loss: 0.2012, Val Acc: 94.08%, Time: 74.39s *\nEpoch: 7, Train Loss: 0.06824, Train Acc: 97.71%, Val Loss: 0.2335, Val Acc: 93.94%, Time: 74.39s \nEpoch: 8, Train Loss: 0.0497, Train Acc: 98.29%, Val Loss: 0.1854, Val Acc: 95.37%, Time: 74.79s *\nEpoch: 9, Train Loss: 0.04732, Train Acc: 98.54%, Val Loss: 0.2197, Val Acc: 94.23%, Time: 75.42s \nEpoch: 10, Train Loss: 0.03324, Train Acc: 98.83%, Val Loss: 0.2127, Val Acc: 94.94%, Time: 74.86s \nEpoch: 11, Train Loss: 0.03435, Train Acc: 98.88%, Val Loss:  0.214, Val Acc: 95.44%, Time: 73.84s *\nEpoch: 12, Train Loss:  0.029, Train Acc: 99.06%, Val Loss: 0.2086, Val Acc: 95.37%, Time: 76.42s \nEpoch: 13, Train Loss: 0.02617, Train Acc: 99.13%, Val Loss: 0.2124, Val Acc: 95.87%, Time: 75.18s *\nEpoch: 14, Train Loss: 0.03739, Train Acc: 98.80%, Val Loss:  0.228, Val Acc: 95.22%, Time: 74.92s \nEpoch: 15, Train Loss: 0.02459, Train Acc: 99.22%, Val Loss: 0.2588, Val Acc: 94.87%, Time: 75.28s \nEpoch: 16, Train Loss: 0.01941, Train Acc: 99.26%, Val Loss: 0.2198, Val Acc: 96.08%, Time: 74.79s *\nEpoch: 17, Train Loss: 0.03054, Train Acc: 99.01%, Val Loss: 0.2361, Val Acc: 95.22%, Time: 75.11s \nEpoch: 18, Train Loss: 0.02435, Train Acc: 99.23%, Val Loss: 0.2509, Val Acc: 95.79%, Time: 74.01s \nEpoch: 19, Train Loss: 0.01823, Train Acc: 99.40%, Val Loss: 0.2252, Val Acc: 95.15%, Time: 74.46s \nEpoch: 20, Train Loss: 0.0159, Train Acc: 99.44%, Val Loss: 0.2364, Val Acc: 95.72%, Time: 75.17s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.97      0.99      0.98       145\n                   Filter       0.93      0.98      0.95       146\n    Compute Derived Value       0.98      0.96      0.97       159\n            Find Extremum       0.97      0.95      0.96       164\n                     Sort       0.88      0.99      0.93       101\n          Determine Range       0.96      0.94      0.95       126\nCharacterize Distribution       0.97      0.92      0.95       140\n           Find Anomalies       0.97      0.95      0.96       131\n                  Cluster       0.96      0.93      0.95       132\n                Correlate       0.98      0.98      0.98       159\n\n                micro avg       0.96      0.96      0.96      1403\n                macro avg       0.96      0.96      0.96      1403\n             weighted avg       0.96      0.96      0.96      1403\n\nConfusion Matrix...\n[[144   1   0   0   0   0   0   0   0   0]\n [  0 143   0   0   0   1   1   1   0   0]\n [  2   2 152   2   0   0   0   1   0   0]\n [  0   2   0 155   5   1   1   0   0   0]\n [  0   0   0   0 100   0   0   0   1   0]\n [  1   1   1   0   1 119   1   0   1   1]\n [  0   1   1   2   2   2 129   0   1   2]\n [  0   3   1   1   0   0   0 124   2   0]\n [  0   1   0   0   5   1   1   1 123   0]\n [  2   0   0   0   0   0   0   1   0 156]]\nFold:  10\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.359, Train Acc: 53.77%, Val Loss: 0.6785, Val Acc: 77.12%, Time: 76.89s *\nEpoch: 2, Train Loss: 0.4668, Train Acc: 85.06%, Val Loss: 0.3305, Val Acc: 88.88%, Time: 73.94s *\nEpoch: 3, Train Loss: 0.2429, Train Acc: 92.49%, Val Loss: 0.3025, Val Acc: 90.73%, Time: 74.31s *\nEpoch: 4, Train Loss: 0.1571, Train Acc: 95.14%, Val Loss: 0.2228, Val Acc: 93.51%, Time: 74.83s *\nEpoch: 5, Train Loss: 0.1034, Train Acc: 96.63%, Val Loss: 0.2158, Val Acc: 94.51%, Time: 75.09s *\nEpoch: 6, Train Loss: 0.08234, Train Acc: 97.31%, Val Loss: 0.1872, Val Acc: 94.30%, Time: 74.66s \nEpoch: 7, Train Loss: 0.06591, Train Acc: 97.87%, Val Loss: 0.2464, Val Acc: 93.01%, Time: 74.44s \nEpoch: 8, Train Loss: 0.05658, Train Acc: 98.00%, Val Loss: 0.2755, Val Acc: 92.94%, Time: 73.95s \nEpoch: 9, Train Loss: 0.03826, Train Acc: 98.70%, Val Loss:  0.172, Val Acc: 96.08%, Time: 74.51s *\nEpoch: 10, Train Loss: 0.03906, Train Acc: 98.54%, Val Loss:  0.188, Val Acc: 95.58%, Time: 74.61s \nEpoch: 11, Train Loss: 0.03306, Train Acc: 98.91%, Val Loss: 0.2144, Val Acc: 94.87%, Time: 75.50s \nEpoch: 12, Train Loss: 0.03308, Train Acc: 98.89%, Val Loss: 0.1835, Val Acc: 95.94%, Time: 75.29s \nEpoch: 13, Train Loss: 0.02926, Train Acc: 98.94%, Val Loss:  0.195, Val Acc: 95.51%, Time: 74.89s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.97      0.99      0.98       138\n                   Filter       0.93      0.92      0.93       132\n    Compute Derived Value       0.97      0.94      0.96       160\n            Find Extremum       0.97      0.94      0.96       163\n                     Sort       0.97      0.98      0.98       104\n          Determine Range       0.90      0.97      0.93       124\nCharacterize Distribution       0.90      0.96      0.93       138\n           Find Anomalies       0.92      0.94      0.93       142\n                  Cluster       0.97      0.97      0.97       137\n                Correlate       0.99      0.91      0.95       165\n\n                micro avg       0.95      0.95      0.95      1403\n                macro avg       0.95      0.95      0.95      1403\n             weighted avg       0.95      0.95      0.95      1403\n\nConfusion Matrix...\n[[136   0   2   0   0   0   0   0   0   0]\n [  0 122   1   1   0   3   1   4   0   0]\n [  0   1 150   0   0   4   3   2   0   0]\n [  2   0   0 154   2   2   1   2   0   0]\n [  0   0   0   1 102   1   0   0   0   0]\n [  1   0   0   1   1 120   0   0   1   0]\n [  1   3   0   0   0   2 132   0   0   0]\n [  0   3   1   1   0   1   0 134   2   0]\n [  0   0   0   0   0   0   2   1 133   1]\n [  0   2   0   1   0   0   8   3   1 150]]\n[0.9337606837606838, 0.9373219373219374, 0.938034188034188, 0.9472934472934473, 0.9522792022792023, 0.9444048467569494, 0.9358517462580185, 0.9337134711332858, 0.9586600142551674, 0.9501069137562367]\n0.9431426450849116, 0.008256230805861613, 0.008702831411523384, 6.81653471196583e-05\nexpert\n20 629 983 41\nFold:  1\nEpoch: 1, Train Loss:  1.493, Train Acc: 50.13%, Val Loss:  1.601, Val Acc: 57.38%, Time: 76.56s *\nEpoch: 2, Train Loss: 0.6063, Train Acc: 81.18%, Val Loss:  1.725, Val Acc: 64.08%, Time: 74.22s *\nEpoch: 3, Train Loss: 0.3311, Train Acc: 89.79%, Val Loss:  2.023, Val Acc: 63.46%, Time: 75.23s \nEpoch: 4, Train Loss: 0.2098, Train Acc: 93.14%, Val Loss:  2.156, Val Acc: 63.52%, Time: 71.90s \nEpoch: 5, Train Loss: 0.1466, Train Acc: 95.19%, Val Loss:  2.253, Val Acc: 64.83%, Time: 73.41s *\nEpoch: 6, Train Loss: 0.1106, Train Acc: 96.60%, Val Loss:   2.22, Val Acc: 66.63%, Time: 75.68s *\nEpoch: 7, Train Loss: 0.08145, Train Acc: 97.49%, Val Loss:  2.254, Val Acc: 65.32%, Time: 75.60s \nEpoch: 8, Train Loss: 0.06328, Train Acc: 97.94%, Val Loss:  2.252, Val Acc: 65.38%, Time: 74.98s \nEpoch: 9, Train Loss: 0.05239, Train Acc: 98.24%, Val Loss:   2.66, Val Acc: 62.72%, Time: 74.82s \nEpoch: 10, Train Loss: 0.04099, Train Acc: 98.65%, Val Loss:  2.569, Val Acc: 61.29%, Time: 74.23s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.38      0.60      0.47       101\n                   Filter       0.59      0.36      0.45       134\n    Compute Derived Value       0.85      0.49      0.62       203\n            Find Extremum       0.74      0.70      0.72       326\n                     Sort       0.62      0.85      0.72       115\n          Determine Range       0.38      0.26      0.31       135\nCharacterize Distribution       0.77      0.50      0.61       171\n           Find Anomalies       0.69      0.65      0.67       127\n                  Cluster       0.50      0.93      0.65       120\n                Correlate       0.64      0.86      0.73       180\n\n                micro avg       0.62      0.62      0.62      1612\n                macro avg       0.62      0.62      0.59      1612\n             weighted avg       0.65      0.62      0.61      1612\n\nConfusion Matrix...\n[[ 61   1   4   0   7   0   1  13   5   9]\n [ 33  48   2   3  12  11   0   6   5  14]\n [ 23  10  99  14   2  10   7   9   8  21]\n [ 23   1   1 229  13  26   3   3  15  12]\n [  0   0   0  13  98   1   0   0   3   0]\n [  2  12   6  30  24  35   5   5   6  10]\n [ 13   9   2   0   2   8  86   0  37  14]\n [  0   0   0  20   0   0   2  82  16   7]\n [  0   0   0   0   0   1   6   0 112   1]\n [  5   0   3   0   0   0   2   0  16 154]]\nFold:  2\nEpoch: 1, Train Loss:  1.421, Train Acc: 52.21%, Val Loss:  1.477, Val Acc: 58.00%, Time: 77.16s *\nEpoch: 2, Train Loss: 0.6162, Train Acc: 80.80%, Val Loss:   1.38, Val Acc: 66.51%, Time: 72.65s *\nEpoch: 3, Train Loss: 0.3423, Train Acc: 89.35%, Val Loss:  1.435, Val Acc: 66.91%, Time: 75.01s *\nEpoch: 4, Train Loss: 0.2277, Train Acc: 92.82%, Val Loss:  1.519, Val Acc: 68.08%, Time: 75.39s *\nEpoch: 5, Train Loss: 0.1569, Train Acc: 95.12%, Val Loss:  1.422, Val Acc: 69.96%, Time: 76.08s *\nEpoch: 6, Train Loss: 0.1135, Train Acc: 96.40%, Val Loss:  1.545, Val Acc: 69.18%, Time: 74.47s \nEpoch: 7, Train Loss: 0.07771, Train Acc: 97.45%, Val Loss:  1.788, Val Acc: 69.90%, Time: 74.53s \nEpoch: 8, Train Loss: 0.06067, Train Acc: 97.90%, Val Loss:  1.869, Val Acc: 69.77%, Time: 74.99s \nEpoch: 9, Train Loss: 0.05428, Train Acc: 98.20%, Val Loss:  2.001, Val Acc: 69.96%, Time: 75.32s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.88      0.84      0.86       113\n                   Filter       0.64      0.64      0.64       180\n    Compute Derived Value       0.59      0.69      0.64       153\n            Find Extremum       0.89      0.74      0.81       213\n                     Sort       0.77      0.89      0.83       136\n          Determine Range       0.60      0.63      0.62       134\nCharacterize Distribution       0.98      0.65      0.78       142\n           Find Anomalies       0.82      0.29      0.43       143\n                  Cluster       0.72      0.79      0.75       143\n                Correlate       0.49      0.79      0.60       181\n\n                micro avg       0.70      0.70      0.70      1538\n                macro avg       0.74      0.70      0.70      1538\n             weighted avg       0.73      0.70      0.69      1538\n\nConfusion Matrix...\n[[ 95   1   4   5   0   0   0   0   1   7]\n [  1 115  28   1   2  14   0   2   1  16]\n [  1   1 106   2   1  11   0   3   8  20]\n [  2  18   2 158  14  10   1   1   2   5]\n [  2   0   1   5 121   3   0   0   2   2]\n [  6  10   8   3   1  85   1   1   3  16]\n [  0   1   8   1   0  12  92   1   9  18]\n [  1  32   6   0   1   1   0  42   6  54]\n [  0   1   1   1  16   0   0   0 113  11]\n [  0   2  16   1   1   5   0   1  12 143]]\nFold:  3\nEpoch: 1, Train Loss:  1.418, Train Acc: 53.12%, Val Loss:  1.584, Val Acc: 56.12%, Time: 78.77s *\nEpoch: 2, Train Loss: 0.6058, Train Acc: 80.98%, Val Loss:  1.528, Val Acc: 64.47%, Time: 75.06s *\nEpoch: 3, Train Loss: 0.3332, Train Acc: 89.53%, Val Loss:  1.939, Val Acc: 62.32%, Time: 76.53s \n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 4, Train Loss: 0.2107, Train Acc: 93.30%, Val Loss:  1.974, Val Acc: 62.96%, Time: 76.07s \nEpoch: 5, Train Loss: 0.1411, Train Acc: 95.64%, Val Loss:  2.219, Val Acc: 65.02%, Time: 76.50s *\nEpoch: 6, Train Loss: 0.1092, Train Acc: 96.74%, Val Loss:  2.291, Val Acc: 63.91%, Time: 76.63s \nEpoch: 7, Train Loss: 0.08563, Train Acc: 97.15%, Val Loss:  2.225, Val Acc: 63.12%, Time: 76.31s \nEpoch: 8, Train Loss: 0.05958, Train Acc: 98.03%, Val Loss:  2.276, Val Acc: 63.99%, Time: 73.76s \nEpoch: 9, Train Loss: 0.04931, Train Acc: 98.40%, Val Loss:  2.738, Val Acc: 60.25%, Time: 77.56s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.73      0.63      0.68       124\n                   Filter       0.63      0.51      0.56       130\n    Compute Derived Value       0.80      0.17      0.28       116\n            Find Extremum       0.47      0.88      0.61       120\n                     Sort       0.53      0.99      0.69       122\n          Determine Range       0.60      0.60      0.60       131\nCharacterize Distribution       0.53      0.53      0.53       141\n           Find Anomalies       0.67      0.59      0.63       134\n                  Cluster       0.64      0.55      0.59       125\n                Correlate       0.85      0.50      0.63       115\n\n                micro avg       0.60      0.60      0.60      1258\n                macro avg       0.65      0.60      0.58      1258\n             weighted avg       0.64      0.60      0.58      1258\n\nConfusion Matrix...\n[[ 78   4   1   8  12   0  20   1   0   0]\n [  2  66   4  18   5  18   5  11   1   0]\n [ 15   2  20  40   9  15  11   4   0   0]\n [  0   1   0 106   3   0   0   9   0   1]\n [  0   1   0   0 121   0   0   0   0   0]\n [  2   7   0   2  28  79   5   1   7   0]\n [  2   9   0  16   9   8  75   8  14   0]\n [  0   1   0  17   3   2  19  79  12   1]\n [  7  10   0   0  18  10   0   3  69   8]\n [  1   3   0  18  21   0   7   2   5  58]]\nFold:  4\nEpoch: 1, Train Loss:  1.442, Train Acc: 52.08%, Val Loss:  1.252, Val Acc: 61.37%, Time: 75.88s *\nEpoch: 2, Train Loss: 0.6179, Train Acc: 81.00%, Val Loss:  1.304, Val Acc: 64.98%, Time: 73.55s *\nEpoch: 3, Train Loss: 0.3488, Train Acc: 89.34%, Val Loss:  1.431, Val Acc: 66.10%, Time: 72.87s *\nEpoch: 4, Train Loss: 0.2156, Train Acc: 93.25%, Val Loss:  1.605, Val Acc: 63.23%, Time: 72.60s \nEpoch: 5, Train Loss: 0.1556, Train Acc: 95.21%, Val Loss:   1.58, Val Acc: 64.92%, Time: 72.94s \nEpoch: 6, Train Loss: 0.1107, Train Acc: 96.51%, Val Loss:  1.612, Val Acc: 67.68%, Time: 72.30s *\nEpoch: 7, Train Loss: 0.07673, Train Acc: 97.60%, Val Loss:  1.692, Val Acc: 67.17%, Time: 70.68s \nEpoch: 8, Train Loss: 0.06798, Train Acc: 97.72%, Val Loss:  1.709, Val Acc: 66.22%, Time: 72.59s \nEpoch: 9, Train Loss: 0.05235, Train Acc: 98.26%, Val Loss:  1.836, Val Acc: 68.64%, Time: 73.33s *\nEpoch: 10, Train Loss: 0.03857, Train Acc: 98.67%, Val Loss:   2.29, Val Acc: 65.60%, Time: 73.40s \nEpoch: 11, Train Loss: 0.03473, Train Acc: 98.83%, Val Loss:  2.196, Val Acc: 66.10%, Time: 73.00s \nEpoch: 12, Train Loss: 0.03599, Train Acc: 98.80%, Val Loss:  2.436, Val Acc: 64.81%, Time: 72.28s \nEpoch: 13, Train Loss: 0.03138, Train Acc: 98.96%, Val Loss:  2.365, Val Acc: 64.08%, Time: 72.68s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.65      0.60      0.62       234\n                   Filter       0.53      0.53      0.53       221\n    Compute Derived Value       0.52      0.34      0.41       174\n            Find Extremum       0.88      0.69      0.78       207\n                     Sort       0.74      0.84      0.79       123\n          Determine Range       0.45      0.81      0.57       126\nCharacterize Distribution       0.81      0.74      0.77       152\n           Find Anomalies       0.68      0.38      0.48       200\n                  Cluster       0.54      0.80      0.64       126\n                Correlate       0.73      0.87      0.80       213\n\n                micro avg       0.64      0.64      0.64      1776\n                macro avg       0.65      0.66      0.64      1776\n             weighted avg       0.66      0.64      0.64      1776\n\nConfusion Matrix...\n[[141  19  14   3   1  25   5  12   5   9]\n [ 22 118  11   9   5  31   2   6  12   5]\n [ 24  21  59   2   3  31  16  11   4   3]\n [  4  10  15 143  19  12   0   2   1   1]\n [  4   0   0   0 103   3   0   0  13   0]\n [  0   4   1   1   3 102   1   1   5   8]\n [  8   1   0   0   1  16 112   1  10   3]\n [  7  34   0   3   1   7   2  75  35  36]\n [  8   6   0   1   3   2   0   2 101   3]\n [  0  11  14   0   0   0   0   0   2 186]]\nFold:  5\nEpoch: 1, Train Loss:  1.364, Train Acc: 54.87%, Val Loss:  1.757, Val Acc: 50.64%, Time: 78.93s *\nEpoch: 2, Train Loss: 0.5881, Train Acc: 82.04%, Val Loss:  1.697, Val Acc: 58.15%, Time: 77.44s *\nEpoch: 3, Train Loss: 0.3163, Train Acc: 90.52%, Val Loss:  1.862, Val Acc: 60.62%, Time: 77.52s *\nEpoch: 4, Train Loss: 0.2038, Train Acc: 93.66%, Val Loss:  2.257, Val Acc: 56.23%, Time: 75.01s \nEpoch: 5, Train Loss: 0.1351, Train Acc: 95.76%, Val Loss:  2.125, Val Acc: 61.17%, Time: 77.66s *\nEpoch: 6, Train Loss: 0.1031, Train Acc: 96.75%, Val Loss:  2.445, Val Acc: 60.99%, Time: 76.89s \nEpoch: 7, Train Loss: 0.07585, Train Acc: 97.55%, Val Loss:  2.551, Val Acc: 60.35%, Time: 77.14s \nEpoch: 8, Train Loss: 0.06502, Train Acc: 97.82%, Val Loss:  2.494, Val Acc: 62.55%, Time: 77.40s *\nEpoch: 9, Train Loss: 0.05029, Train Acc: 98.39%, Val Loss:  2.731, Val Acc: 61.45%, Time: 77.94s \nEpoch: 10, Train Loss: 0.04345, Train Acc: 98.67%, Val Loss:  2.847, Val Acc: 61.08%, Time: 77.12s \nEpoch: 11, Train Loss: 0.03686, Train Acc: 98.73%, Val Loss:  3.242, Val Acc: 56.59%, Time: 75.73s \nEpoch: 12, Train Loss: 0.03176, Train Acc: 98.87%, Val Loss:  3.213, Val Acc: 60.07%, Time: 77.95s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.47      0.48      0.48       118\n                   Filter       0.46      0.43      0.45       115\n    Compute Derived Value       0.76      0.29      0.42       127\n            Find Extremum       0.60      0.60      0.60       112\n                     Sort       0.73      0.88      0.80       122\n          Determine Range       0.74      0.60      0.66        94\nCharacterize Distribution       0.98      0.42      0.59        97\n           Find Anomalies       0.44      0.44      0.44        94\n                  Cluster       0.55      0.89      0.68        98\n                Correlate       0.53      0.88      0.66       115\n\n                micro avg       0.59      0.59      0.59      1092\n                macro avg       0.63      0.59      0.58      1092\n             weighted avg       0.63      0.59      0.58      1092\n\nConfusion Matrix...\n[[ 57   5  10  14  11   1   1   2   0  17]\n [ 21  50   1   3   0   5   0  18  11   6]\n [ 23  13  37  22   6   2   0  14   4   6]\n [  4  14   0  67  10   0   0   7   5   5]\n [  0   0   0   0 107   5   0   0  10   0]\n [  9  13   0   0   3  56   0   5   8   0]\n [  5   0   1   3   2   6  41   6   6  27]\n [  1  12   0   0   1   1   0  41  16  22]\n [  0   0   0   0   5   0   0   1  87   5]\n [  0   1   0   2   1   0   0   0  10 101]]\nFold:  6\nEpoch: 1, Train Loss:  1.418, Train Acc: 52.34%, Val Loss:  1.417, Val Acc: 58.61%, Time: 79.25s *\nEpoch: 2, Train Loss: 0.5922, Train Acc: 81.58%, Val Loss:  1.595, Val Acc: 61.31%, Time: 76.83s *\nEpoch: 3, Train Loss: 0.3315, Train Acc: 89.77%, Val Loss:  1.655, Val Acc: 62.69%, Time: 76.09s *\nEpoch: 4, Train Loss: 0.2021, Train Acc: 93.70%, Val Loss:  1.474, Val Acc: 65.88%, Time: 76.53s *\nEpoch: 5, Train Loss: 0.1481, Train Acc: 95.43%, Val Loss:  1.594, Val Acc: 66.04%, Time: 76.77s *\nEpoch: 6, Train Loss: 0.1035, Train Acc: 96.66%, Val Loss:  1.898, Val Acc: 64.49%, Time: 76.56s \nEpoch: 7, Train Loss: 0.08321, Train Acc: 97.30%, Val Loss:  1.822, Val Acc: 64.82%, Time: 76.57s \n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 8, Train Loss: 0.06316, Train Acc: 98.08%, Val Loss:  1.965, Val Acc: 65.39%, Time: 77.27s \nEpoch: 9, Train Loss: 0.0469, Train Acc: 98.43%, Val Loss:  2.025, Val Acc: 66.86%, Time: 75.77s *\nEpoch: 10, Train Loss: 0.0407, Train Acc: 98.68%, Val Loss:  2.509, Val Acc: 61.96%, Time: 75.90s \nEpoch: 11, Train Loss: 0.03326, Train Acc: 98.88%, Val Loss:  2.204, Val Acc: 64.24%, Time: 76.41s \nEpoch: 12, Train Loss:  0.036, Train Acc: 98.81%, Val Loss:  2.545, Val Acc: 62.69%, Time: 73.39s \nEpoch: 13, Train Loss: 0.03214, Train Acc: 98.85%, Val Loss:  2.392, Val Acc: 64.33%, Time: 76.36s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.50      0.67      0.58       123\n                   Filter       0.46      0.53      0.50       124\n    Compute Derived Value       0.63      0.31      0.41       130\n            Find Extremum       0.70      0.89      0.78       124\n                     Sort       0.72      0.70      0.71       111\n          Determine Range       0.34      0.30      0.32       121\nCharacterize Distribution       0.84      0.72      0.78       122\n           Find Anomalies       0.88      0.51      0.64       126\n                  Cluster       0.81      0.87      0.84       116\n                Correlate       0.67      0.95      0.79       128\n\n                micro avg       0.64      0.64      0.64      1225\n                macro avg       0.66      0.64      0.63      1225\n             weighted avg       0.66      0.64      0.63      1225\n\nConfusion Matrix...\n[[ 83   3   1  16   2  14   1   0   0   3]\n [  0  66   1   5   3  35   0   8   5   1]\n [ 40  25  40   4   0   5   6   0   0  10]\n [  0   6   1 110   3   1   0   0   0   3]\n [  0   6   0  11  78   8   1   0   7   0]\n [ 10  36  12   5  10  36   1   0   1  10]\n [  5   0   3   6   2   7  88   0   8   3]\n [ 20   0   5   1   2   1   6  64   2  25]\n [  0   0   0   0   8   0   2   1 101   4]\n [  7   0   0   0   0   0   0   0   0 121]]\nFold:  7\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "raw", "source": "train_10_fold(trainData, categories)"}, {"metadata": {}, "cell_type": "raw", "source": "classifier.train(\n    X_train=X_train,\n    y_train=y_train,\n    X_eval=X_eval,\n    y_eval=y_eval,\n    epochs=30\n)"}], "metadata": {"kernelspec": {"name": "tensorflow-1.8", "display_name": "TensorFlow-1.8", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}