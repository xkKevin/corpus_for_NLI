{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "import numpy as np\nimport tensorflow as tf\nimport sys\nimport time\nfrom datetime import timedelta\nimport tensorflow.contrib.keras as kr\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\n\nimport moxing as mox\nmox.file.shift('os', 'mox')", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "INFO:root:Using MoXing-v1.14.1-ddfd6c9a\nINFO:root:Using OBS-Python-SDK-3.1.2\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "trainDataPath = \"s3://corpus-2/dataset/corpus_5_new.txt\"\nvocabPath = \"s3://corpus-text-classification1/data/glove.6B.100d.txt\"", "execution_count": 2, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "split_info = {\n    \"random\": False,\n    \"expert\": [20, 4],\n    \"bundle\": [920, 1],\n    \"table\": [37, 3]\n}\n\n\ndef dataset_split(info):\n    if info:\n        [num, pi] = info\n        train_data = [[] for i in range(num)]\n        with open(trainDataPath, \"r\", encoding='utf-8') as fp:\n            for line in fp.readlines():\n                word = line.split()\n                info = word[0].split(\":\")\n                index = int(info[pi]) - 1\n                label = int(info[0])\n                content = word[1:]\n                train_data[index].append([content,label])\n\n        for i in range(num):\n            np.random.shuffle(train_data[i])\n            train_data[i] = np.asarray(train_data[i])\n\n        np.random.shuffle(train_data)   \n        return train_data\n    \n    \n    train_data = []\n    with open(trainDataPath, 'r', encoding='utf-8') as f:\n        for line in f.readlines():\n            word = line.split()\n            label = int(word[0].split(\":\")[0])\n            content = word[1:]\n            train_data.append([content,label])\n    \n    np.random.shuffle(train_data)\n    return np.asarray(train_data)\n\n\ndef mergeData(data_x, data_y):\n    merge_x = data_x[0]\n    merge_y = data_y[0]\n    for i in range(1,len(data_x)):\n        merge_x = np.r_[merge_x,data_x[i]]\n        merge_y = np.r_[merge_y,data_y[i]]\n        \n    return merge_x, merge_y\n\n\ndef train_split_data(train_data, split_type):\n    \n    print(split_type)\n    \n    test_acc = []\n    fold_id = 0\n    \n    if split_type != \"random\":\n        tx = []\n        ty = []\n        for ti in train_data:\n            x_train, y_train = process_file(ti[:,0], ti[:,1], word_to_id, num_classes, seq_length)\n            tx.append(x_train)\n            ty.append(y_train)\n\n        tx = np.asarray(tx)\n        ty = np.asarray(ty)\n\n        print(len(tx),len(tx[0]),len(tx[1]),len(tx[0][0]))\n        \n        for train_i, test_i in kf.split(tx):\n            fold_id += 1\n            print(\"Fold: \", fold_id)\n            train_x, train_y = mergeData(tx[train_i],ty[train_i])\n            test_x, test_y = mergeData(tx[test_i],ty[test_i])\n            test_acc.append(classifier.train(\n                X_train=train_x,\n                y_train=train_y,\n                X_eval=test_x,\n                y_eval=test_y,\n                categories=categories,\n                epochs=50\n            ))\n        \n    else:\n        tx, ty = process_file(train_data[:,0], train_data[:,1], word_to_id, num_classes, seq_length)\n        print(len(tx),len(tx[0]),len(tx[1]))\n\n        for train_i, test_i in kf.split(tx):\n            fold_id += 1\n            print(\"Fold: \", fold_id)\n            test_acc.append(classifier.train(\n                X_train=tx[train_i],\n                y_train=ty[train_i],\n                X_eval=tx[test_i],\n                y_eval=ty[test_i],\n                categories=categories,\n                epochs=50\n            ))\n        \n    print(test_acc)\n    print(\"%s, %s, %s, %s\" % (np.mean(test_acc),np.std(test_acc),np.std(test_acc,ddof=1),np.var(test_acc)))\n    return test_acc", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "raw", "source": "def train_10_fold(train_data, categories):\n    \n    tx, ty = process_file(train_data[:,0], train_data[:,1], word_to_id, cat_to_id, num_classes, seq_length)\n    print(len(tx),len(tx[0]),len(tx[1]))\n    \n    fold_id = 0\n    test_acc = []\n    \n    kf = KFold(n_splits=10)\n    for train_i, test_i in kf.split(tx):\n        fold_id += 1\n        print(\"Fold: \", fold_id)\n        test_acc.append(classifier.train(\n            X_train=tx[train_i],\n            y_train=ty[train_i],\n            X_eval=tx[test_i],\n            y_eval=ty[test_i],\n            categories=categories,\n            epochs=30\n        ))\n    print(test_acc)\n    print(\"%s, %s, %s, %s\" % (np.mean(test_acc),np.std(test_acc),np.std(test_acc,ddof=1),np.var(test_acc)))\n    return test_acc"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def loadGloVe(filename):\n    vocab = []\n    embd = []\n    print('Loading GloVe!')\n    # vocab.append('unk') #\u88c5\u8f7d\u4e0d\u8ba4\u8bc6\u7684\u8bcd\n    # embd.append([0] * emb_size) #\u8fd9\u4e2aemb_size\u53ef\u80fd\u9700\u8981\u6307\u5b9a\n    file = open(filename,'r',encoding='utf-8')\n    for line in file.readlines():\n        row = line.strip().split(' ')\n        vocab.append(row[0])\n        embd.append([float(ei) for ei in row[1:]])\n    file.close()\n    print('Completed!')\n    return vocab,embd\n\n\ndef process_file(contents, labels, word_to_id, num_classes, pad_max_length):\n    \"\"\"\n    \u5c06\u6587\u4ef6\u8f6c\u6362\u4e3aid\u8868\u793a,\u5e76\u4e14\u5c06\u6bcf\u4e2a\u5355\u72ec\u7684\u6837\u672c\u957f\u5ea6\u56fa\u5b9a\u4e3apad_max_lengtn\n    \"\"\"\n    # contents, labels = readfile(filePath)\n    data_id, label_id = [], []\n    # \u5c06\u6587\u672c\u5185\u5bb9\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684id\u5f62\u5f0f\n    for i in range(len(contents)):\n        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])\n        label_id.append(labels[i] - 1)  # label_id.append(cat_to_id[labels[i]])\n    # \u4f7f\u7528keras\u63d0\u4f9b\u7684pad_sequences\u6765\u5c06\u6587\u672cpad\u4e3a\u56fa\u5b9a\u957f\u5ea6\n    x_pad = kr.preprocessing.sequence.pad_sequences(data_id, pad_max_length)\n    ''' https://blog.csdn.net/TH_NUM/article/details/80904900\n    pad_sequences(sequences, maxlen=None, dtype=\u2019int32\u2019, padding=\u2019pre\u2019, truncating=\u2019pre\u2019, value=0.) \n        sequences\uff1a\u6d6e\u70b9\u6570\u6216\u6574\u6570\u6784\u6210\u7684\u4e24\u5c42\u5d4c\u5957\u5217\u8868\n        maxlen\uff1aNone\u6216\u6574\u6570\uff0c\u4e3a\u5e8f\u5217\u7684\u6700\u5927\u957f\u5ea6\u3002\u5927\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u88ab\u622a\u77ed\uff0c\u5c0f\u4e8e\u6b64\u957f\u5ea6\u7684\u5e8f\u5217\u5c06\u5728\u540e\u90e8\u586b0.\n        dtype\uff1a\u8fd4\u56de\u7684numpy array\u7684\u6570\u636e\u7c7b\u578b\n        padding\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u88650\u65f6\uff0c\u5728\u5e8f\u5217\u7684\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u8865\n        truncating\uff1a\u2018pre\u2019\u6216\u2018post\u2019\uff0c\u786e\u5b9a\u5f53\u9700\u8981\u622a\u65ad\u5e8f\u5217\u65f6\uff0c\u4ece\u8d77\u59cb\u8fd8\u662f\u7ed3\u5c3e\u622a\u65ad\n        value\uff1a\u6d6e\u70b9\u6570\uff0c\u6b64\u503c\u5c06\u5728\u586b\u5145\u65f6\u4ee3\u66ff\u9ed8\u8ba4\u7684\u586b\u5145\u503c0\n    '''\n    y_pad = kr.utils.to_categorical(label_id, num_classes=num_classes)  # \u5c06\u6807\u7b7e\u8f6c\u6362\u4e3aone-hot\u8868\u793a\n    ''' https://blog.csdn.net/nima1994/article/details/82468965\n    to_categorical(y, num_classes=None, dtype='float32')\n        \u5c06\u6574\u578b\u6807\u7b7e\u8f6c\u4e3aonehot\u3002y\u4e3aint\u6570\u7ec4\uff0cnum_classes\u4e3a\u6807\u7b7e\u7c7b\u522b\u603b\u6570\uff0c\u5927\u4e8emax(y)\uff08\u6807\u7b7e\u4ece0\u5f00\u59cb\u7684\uff09\u3002\n        \u8fd4\u56de\uff1a\u5982\u679cnum_classes=None\uff0c\u8fd4\u56delen(y) * [max(y)+1]\uff08\u7ef4\u5ea6\uff0cm*n\u8868\u793am\u884cn\u5217\u77e9\u9635\uff0c\u4e0b\u540c\uff09\uff0c\u5426\u5219\u4e3alen(y) * num_classes\u3002\n    '''\n    return x_pad, y_pad", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "categories = ['Retrieve Value', 'Filter', 'Compute Derived Value', 'Find Extremum', 'Sort', \n                  'Determine Range', 'Characterize Distribution', 'Find Anomalies', 'Cluster', 'Correlate']\nnum_classes = len(categories)\n\nvocab, embd = loadGloVe(vocabPath)\nvocab_size = len(vocab)\nembedding_dim = len(embd[0])\nembedding = np.asarray(embd)\nword_to_id = dict(zip(vocab, range(vocab_size)))\n\nprint(len(embedding),embedding_dim,vocab_size)\n \nseq_length = 41  # seq_length = 37  TREC", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Loading GloVe!\nCompleted!\n400000 100 400000\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "class Classifier:\n\n    def __init__(self, model, input_length, output_length):\n        self.model = model\n        self.input_length = input_length\n        self.output_length = output_length\n\n    def compile(self, batch_size=32):\n        self._ds_x = tf.placeholder(tf.float32, [None, self.input_length])\n        self._ds_y = tf.placeholder(tf.float32, [None, self.output_length])\n\n        ds = tf.data.Dataset.from_tensor_slices((self._ds_x, self._ds_y))\n        ds = ds.batch(batch_size)\n\n        self._ds_it = ds.make_initializable_iterator()\n        self._input, self._labels = self._ds_it.get_next()\n\n        self._features = self.model(self._input)\n        self._output = _create_dense_layer(self._features, self.output_length)\n\n        self._create_acc_computations()\n        self._create_backpropagation()\n\n    def _create_acc_computations(self):\n        self._predictions = tf.argmax(self._output, 1)\n        labels = tf.argmax(self._labels, 1)\n        self._accuracy = tf.reduce_mean(\n            tf.cast(tf.equal(self._predictions, labels), 'float32'))\n\n    def _create_backpropagation(self):\n        losses = tf.nn.softmax_cross_entropy_with_logits_v2(\n            logits=self._output,\n            labels=self._labels)\n        self._loss = tf.reduce_mean(losses)\n\n        optimizer = tf.train.AdamOptimizer(0.001)\n        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n        grads_and_vars = optimizer.compute_gradients(self._loss)\n\n        self._train_op = optimizer.apply_gradients(\n            grads_and_vars, global_step=global_step)\n\n    def summary(self):\n        print('input:', self._input.shape)\n        self.model.summary()\n        print('output:', self._output.shape)\n\n    def train(self, X_train, y_train, X_eval, y_eval, categories, epochs=20, require_improve=3):\n        \n        session = tf.Session()\n        session.run(tf.global_variables_initializer())\n        session.run(tf.local_variables_initializer())\n        \n        best_vac_acc = 0.0\n        last_improved = 0\n        \n        for e in range(epochs):\n            start_time = time.time()\n            loss, acc = self._train(X_train, y_train, session)\n            duration = time.time() - start_time\n\n            val_loss, val_acc = self._eval(X_eval, y_eval, session)\n            \n            if val_acc > best_vac_acc:\n                best_vac_acc = val_acc\n                last_improved = e\n                improved_str = '*'\n            else:\n                improved_str = ''\n            \n            output = 'Epoch: {:>1}, Train Loss: {:>6.4}, Train Acc: {:>6.2%}, Val Loss: {:>6.4}, Val Acc: {:>6.2%}, Time: {:.2f}s {}'\n            print(output.format(e + 1, loss, acc, val_loss, val_acc, duration, improved_str))\n            \n            if e - last_improved > require_improve:\n                print(\"No optimization for a long time, auto-stopping...\")\n                \n                y_test_cls = np.argmax(y_eval, 1)  # \u83b7\u5f97\u7c7b\u522b\n                y_test_pred_cls = np.argmax(self.predict(X_eval, session), 1)\n                accuracy_score = metrics.accuracy_score(y_test_cls, y_test_pred_cls)\n                \n                # evaluate\n                print(\"Precision, Recall and F1-Score...\")\n                print(metrics.classification_report(y_test_cls, y_test_pred_cls, target_names=categories))\n                '''\n                sklearn\u4e2d\u7684classification_report\u51fd\u6570\u7528\u4e8e\u663e\u793a\u4e3b\u8981\u5206\u7c7b\u6307\u6807\u7684\u6587\u672c\u62a5\u544a\uff0e\u5728\u62a5\u544a\u4e2d\u663e\u793a\u6bcf\u4e2a\u7c7b\u7684\u7cbe\u786e\u5ea6\uff0c\u53ec\u56de\u7387\uff0cF1\u503c\u7b49\u4fe1\u606f\u3002\n                    y_true\uff1a1\u7ef4\u6570\u7ec4\uff0c\u6216\u6807\u7b7e\u6307\u793a\u5668\u6570\u7ec4/\u7a00\u758f\u77e9\u9635\uff0c\u76ee\u6807\u503c\u3002 \n                    y_pred\uff1a1\u7ef4\u6570\u7ec4\uff0c\u6216\u6807\u7b7e\u6307\u793a\u5668\u6570\u7ec4/\u7a00\u758f\u77e9\u9635\uff0c\u5206\u7c7b\u5668\u8fd4\u56de\u7684\u4f30\u8ba1\u503c\u3002 \n                    labels\uff1aarray\uff0cshape = [n_labels]\uff0c\u62a5\u8868\u4e2d\u5305\u542b\u7684\u6807\u7b7e\u7d22\u5f15\u7684\u53ef\u9009\u5217\u8868\u3002 \n                    target_names\uff1a\u5b57\u7b26\u4e32\u5217\u8868\uff0c\u4e0e\u6807\u7b7e\u5339\u914d\u7684\u53ef\u9009\u663e\u793a\u540d\u79f0\uff08\u76f8\u540c\u987a\u5e8f\uff09\u3002 \n                    \u539f\u6587\u94fe\u63a5\uff1ahttps://blog.csdn.net/akadiao/article/details/78788864\n                '''\n\n                print(\"Confusion Matrix...\")\n                print(metrics.confusion_matrix(y_test_cls, y_test_pred_cls))\n                '''\n                \u6df7\u6dc6\u77e9\u9635\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u603b\u7ed3\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u7684\u60c5\u5f62\u5206\u6790\u8868\uff0c\u4ee5\u77e9\u9635\u5f62\u5f0f\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u8bb0\u5f55\u6309\u7167\u771f\u5b9e\u7684\u7c7b\u522b\u4e0e\u5206\u7c7b\u6a21\u578b\u4f5c\u51fa\u7684\u5206\u7c7b\u5224\u65ad\u4e24\u4e2a\u6807\u51c6\u8fdb\u884c\u6c47\u603b\u3002\n                \u8fd9\u4e2a\u540d\u5b57\u6765\u6e90\u4e8e\u5b83\u53ef\u4ee5\u975e\u5e38\u5bb9\u6613\u7684\u8868\u660e\u591a\u4e2a\u7c7b\u522b\u662f\u5426\u6709\u6df7\u6dc6\uff08\u4e5f\u5c31\u662f\u4e00\u4e2aclass\u88ab\u9884\u6d4b\u6210\u53e6\u4e00\u4e2aclass\uff09\n                https://blog.csdn.net/u011734144/article/details/80277225\n                '''\n                break\n        # endfor\n        session.close()\n        return accuracy_score\n\n    def _train(self, X_train, y_train, session):\n        import numpy as np\n\n        session.run(\n            fetches=self._ds_it.initializer,\n            feed_dict={\n                self._ds_x: X_train,\n                self._ds_y: y_train\n            })\n        loss, acc, = [], []\n        while True:\n            try:\n                _, vloss, vacc = session.run(\n                    fetches=[self._train_op, self._loss, self._accuracy])\n\n                loss.append(vloss)\n                acc.append(vacc)\n            except tf.errors.OutOfRangeError:\n                break\n        # endwhile\n\n        loss, acc = np.mean(loss), np.mean(acc)\n        return loss, acc\n\n    def _eval(self, X_val, y_val, session):\n        session.run(\n            fetches=self._ds_it.initializer,\n            feed_dict={\n                self._ds_x: X_val,\n                self._ds_y: y_val\n            })\n\n        loss, acc, = 0, 0\n        while True:\n            try:\n                l, vloss, vacc = session.run(\n                    fetches=[self._labels, self._loss, self._accuracy])\n\n                loss += vloss * len(l)\n                acc += vacc * len(l)\n            except tf.errors.OutOfRangeError:\n                break\n\n        return loss / len(X_val), acc / len(X_val)\n\n    def predict(self, X, session):\n        session.run(self._ds_it.initializer,\n                         feed_dict={\n                             self._ds_x: X,\n                             self._ds_y: np.empty((len(X), self.output_length))\n                         }\n                         )\n\n        pred = list()\n        while True:\n            try:\n                ppred = session.run(tf.nn.softmax(self._output))\n\n                pred.extend(map(lambda l: l.tolist(), ppred))\n            except tf.errors.OutOfRangeError:\n                break\n\n        return pred\n\ndef _create_dense_layer(x, output_length):\n    '''Creates a dense layer\n    '''\n    input_size = x.shape[1].value\n    W = tf.Variable(\n        initial_value=tf.truncated_normal(\n            shape=[input_size, output_length],\n            stddev=0.1))\n    b = tf.Variable(\n        initial_value=tf.truncated_normal(\n            shape=[output_length]))\n\n    dense = tf.nn.xw_plus_b(x, W, b)\n\n    return dense", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "class KimConvolutionalModel:\n    '''\n    Implementation proposal of: https://arxiv.org/pdf/1408.5882.pdf\n    '''\n    def __init__(self,\n        embeddings_configuration,\n        conv_configurations = [(3, 100), (4, 100), (5, 100)],\n        drop_rate           = 0.5):\n        '''Constructor.\n        # Parameters:\n        embeddings: List of embeddings configuration. Each configuration is a\n            pair of the form (embedding, trainable). `embedding` is a numpy\n            array and `trainable` is a boolean that indicates whether that\n            embedding is trainable or not.\n        conv_configurations: List of pairs. Each pair represents a\n            convolution configuration. Each configuration determines the\n            size and number of each filter.\n        '''\n\n        self._embeddings_configuration = embeddings_configuration\n        self._conv_configurations = conv_configurations\n        self._drop_rate = drop_rate\n\n    def __call__(self, input):\n        self._embeddings_tf = tf.stack(\n            values = [\n                self._create_embedding_layer(e, input)\n                for e in self._embeddings_configuration],\n            axis = 1\n        )\n\n        self._convolutions_tf = self._create_convolutional_layers(\n            self._conv_configurations, self._embeddings_tf)\n        \n        self._add_tf = self._create_add_layers(self._convolutions_tf)\n\n        self._poolings_tf = self._create_maxpooling_layer(\n            self._add_tf)\n\n        self._reshape_tf = self._create_reshape_layer(self._poolings_tf)\n        self._dropout_tf = tf.nn.dropout(\n            self._reshape_tf,\n            keep_prob = self._drop_rate)\n\n        return self._dropout_tf\n\n    def summary(self):\n        print('embedding:', str(self._embeddings_tf.shape))\n        for c in self._convolutions_tf:\n            print('conv:', str(c.shape))\n        for a in self._add_tf:\n            print('add:', str(a.shape))\n        for p in self._poolings_tf:\n            print('pool:', str(p.shape))\n        print('reshape:', str(self._reshape_tf.shape))\n\n    def _create_embedding_layer(self, embedding_configuration, input_x):\n        return tf.nn.embedding_lookup(\n            params = tf.Variable(\n                initial_value = embedding_configuration[0],\n                trainable     = embedding_configuration[1]),\n            ids = tf.cast(input_x, 'int32')\n        )\n\n    def _create_convolutional_layers(self, configuration, input_embedding):\n        '''Creates the convolutional layers.\n        # Parameters:\n        configuration: A list. It must be of the form\n            [(filter_size, num_filters), ...]\n        # Returns:\n        A list of tensorflow nodes. Each node 'i' computes the configuration 'i'.\n        '''\n        convolutions = []\n        for filter_height, num_filters in configuration:\n            filter_width = input_embedding.shape[3].value\n            filter_shape = [1, filter_height, filter_width, num_filters]\n\n            # Create weights and bias\n            W = tf.Variable(\n                initial_value=tf.truncated_normal(\n                    shape=filter_shape,\n                    stddev=0.1))\n            b = tf.Variable(\n                initial_value=tf.truncated_normal(\n                    shape=[num_filters]))\n\n            conv = tf.nn.conv2d(\n                input=input_embedding,\n                filter=W,\n                strides=[1, 1, 1, 1],\n                padding=\"VALID\")\n            bias = tf.nn.bias_add(conv, b)\n            h = tf.nn.relu(bias)\n            convolutions.append(h)\n\n        return convolutions\n\n    def _create_add_layers(self, convolutions):\n        return [\n            tf.reduce_sum(\n                input_tensor = c,\n                axis=1,\n                keepdims=True)\n            for c in convolutions\n        ]\n\n    def _create_maxpooling_layer(self, tensors):\n        '''Creates the maxpooling layer. Computes maxpooling on each node\n        # Parameters:\n        input_convolutions: List of tensorflow nodes.\n        # Returns:\n        A list of tensorflow nodes. Each node 'i' computes the maxpooling of node 'i'\n        '''\n        return [\n            tf.reshape(\n                tensor = tf.nn.max_pool(\n                    value=t,\n                    ksize=[1, 1, t.shape[2], 1],\n                    strides=[1, 1, 1, 1],\n                    padding='VALID'),\n                shape = [-1, t.shape[3]]\n            )\n            for t in tensors\n        ]\n\n    def _create_reshape_layer(self, tensors):\n        '''Creates a flatten layer\n        '''\n        return tf.concat(tensors, axis=1)", "execution_count": 7, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "word_vector = embedding.astype('float32')\nmodel = KimConvolutionalModel(\n        embeddings_configuration=[\n            (word_vector, True)\n        ]\n    )\n\nclassifier = Classifier(\n    model=model,\n    input_length=seq_length,\n    output_length=num_classes)\n\nclassifier.compile(batch_size=32)\nclassifier.summary()", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "input: (?, 41)\nembedding: (?, 1, 41, 100)\nconv: (?, 1, 39, 100)\nconv: (?, 1, 38, 100)\nconv: (?, 1, 37, 100)\nadd: (?, 1, 39, 100)\nadd: (?, 1, 38, 100)\nadd: (?, 1, 37, 100)\npool: (?, 100)\npool: (?, 100)\npool: (?, 100)\nreshape: (?, 300)\noutput: (?, 10)\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "split_info = {\n    # \"random\": False,\n    \"expert\": [20, 4],\n    \"bundle\": [920, 1],\n    \"table\": [37, 3]\n}\n\nkf = KFold(n_splits=10)\ntest_acc_split = []\nfor split_type,info in split_info.items():\n    train_data = dataset_split(info)\n    test_acc_split.append(train_split_data(train_data, split_type))", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "expert\n20 935 475 41\nFold:  1\nEpoch: 1, Train Loss:  1.779, Train Acc: 45.09%, Val Loss:  1.428, Val Acc: 54.26%, Time: 8.13s *\nEpoch: 2, Train Loss: 0.7172, Train Acc: 78.52%, Val Loss:  1.232, Val Acc: 62.13%, Time: 3.48s *\nEpoch: 3, Train Loss:  0.444, Train Acc: 86.71%, Val Loss:  1.154, Val Acc: 66.45%, Time: 3.48s *\nEpoch: 4, Train Loss:   0.29, Train Acc: 91.63%, Val Loss:   1.15, Val Acc: 67.16%, Time: 3.46s *\nEpoch: 5, Train Loss: 0.2078, Train Acc: 94.00%, Val Loss:   1.14, Val Acc: 68.94%, Time: 3.46s *\nEpoch: 6, Train Loss: 0.1498, Train Acc: 95.63%, Val Loss:  1.208, Val Acc: 68.01%, Time: 3.46s \nEpoch: 7, Train Loss:  0.108, Train Acc: 96.96%, Val Loss:  1.216, Val Acc: 69.72%, Time: 3.46s *\nEpoch: 8, Train Loss: 0.09492, Train Acc: 97.21%, Val Loss:  1.183, Val Acc: 70.07%, Time: 3.45s *\nEpoch: 9, Train Loss: 0.07364, Train Acc: 97.95%, Val Loss:  1.283, Val Acc: 69.29%, Time: 3.48s \nEpoch: 10, Train Loss: 0.06433, Train Acc: 98.09%, Val Loss:  1.413, Val Acc: 67.94%, Time: 3.45s \nEpoch: 11, Train Loss: 0.05594, Train Acc: 98.39%, Val Loss:   1.46, Val Acc: 69.15%, Time: 3.44s \nEpoch: 12, Train Loss: 0.04708, Train Acc: 98.60%, Val Loss:  1.471, Val Acc: 69.15%, Time: 3.46s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.68      0.59      0.63       117\n                   Filter       0.61      0.58      0.59       180\n    Compute Derived Value       0.55      0.73      0.63       157\n            Find Extremum       0.95      0.60      0.74       207\n                     Sort       0.79      0.84      0.82       137\n          Determine Range       0.47      0.71      0.57       105\nCharacterize Distribution       0.71      0.72      0.72       111\n           Find Anomalies       0.66      0.73      0.69       108\n                  Cluster       0.86      0.82      0.84       122\n                Correlate       0.81      0.71      0.76       166\n\n                micro avg       0.70      0.70      0.70      1410\n                macro avg       0.71      0.70      0.70      1410\n             weighted avg       0.72      0.70      0.70      1410\n\nConfusion Matrix...\n[[ 69   7  16   3   3  10   7   2   0   0]\n [ 15 105  25   2   3  12   5   3   2   8]\n [  4  13 114   0   1   9   4  10   2   0]\n [  5  20   5 125  14  22   1  11   2   2]\n [  3   8   4   0 115   1   2   0   4   0]\n [  2   1  11   0   0  75   5   7   3   1]\n [  0   0   8   0   1   8  80   3   2   9]\n [  1   9   6   2   0   3   4  79   1   3]\n [  1   0   1   0   7   4   0   4 100   5]\n [  2  10  16   0   1  14   4   1   0 118]]\nFold:  2\nEpoch: 1, Train Loss:  1.738, Train Acc: 46.78%, Val Loss:  1.773, Val Acc: 45.81%, Time: 3.65s *\nEpoch: 2, Train Loss: 0.6989, Train Acc: 78.29%, Val Loss:  1.792, Val Acc: 50.41%, Time: 3.38s *\nEpoch: 3, Train Loss: 0.4234, Train Acc: 87.46%, Val Loss:  1.706, Val Acc: 54.02%, Time: 3.37s *\nEpoch: 4, Train Loss: 0.2859, Train Acc: 91.73%, Val Loss:  1.849, Val Acc: 55.06%, Time: 3.37s *\nEpoch: 5, Train Loss: 0.2002, Train Acc: 94.19%, Val Loss:  1.819, Val Acc: 56.11%, Time: 3.36s *\nEpoch: 6, Train Loss: 0.1493, Train Acc: 95.75%, Val Loss:  1.879, Val Acc: 56.64%, Time: 3.38s *\nEpoch: 7, Train Loss: 0.1065, Train Acc: 97.14%, Val Loss:  2.105, Val Acc: 54.48%, Time: 3.35s \nEpoch: 8, Train Loss: 0.08326, Train Acc: 97.69%, Val Loss:  2.102, Val Acc: 55.06%, Time: 3.37s \nEpoch: 9, Train Loss: 0.07435, Train Acc: 97.91%, Val Loss:  2.086, Val Acc: 57.28%, Time: 3.37s *\nEpoch: 10, Train Loss: 0.05828, Train Acc: 98.40%, Val Loss:  2.216, Val Acc: 56.52%, Time: 3.37s \nEpoch: 11, Train Loss: 0.05141, Train Acc: 98.56%, Val Loss:  2.383, Val Acc: 55.41%, Time: 3.35s \nEpoch: 12, Train Loss: 0.04821, Train Acc: 98.59%, Val Loss:  2.135, Val Acc: 57.86%, Time: 3.37s *\nEpoch: 13, Train Loss: 0.04064, Train Acc: 98.84%, Val Loss:  2.489, Val Acc: 54.77%, Time: 3.37s \nEpoch: 14, Train Loss: 0.03284, Train Acc: 99.00%, Val Loss:  2.652, Val Acc: 55.59%, Time: 3.39s \nEpoch: 15, Train Loss: 0.02817, Train Acc: 99.30%, Val Loss:  2.562, Val Acc: 55.82%, Time: 3.40s \nEpoch: 16, Train Loss: 0.02853, Train Acc: 99.15%, Val Loss:  2.649, Val Acc: 55.36%, Time: 3.38s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.57      0.53      0.55       179\n                   Filter       0.35      0.14      0.20       182\n    Compute Derived Value       0.53      0.38      0.44       246\n            Find Extremum       0.56      0.87      0.68       181\n                     Sort       0.61      0.82      0.70       122\n          Determine Range       0.55      0.73      0.63       214\nCharacterize Distribution       0.50      0.67      0.58       116\n           Find Anomalies       0.55      0.78      0.64       167\n                  Cluster       0.78      0.55      0.64       133\n                Correlate       0.90      0.43      0.58       178\n\n                micro avg       0.57      0.57      0.57      1718\n                macro avg       0.59      0.59      0.56      1718\n             weighted avg       0.58      0.57      0.55      1718\n\nConfusion Matrix...\n[[ 94   8  18   3   8  28  15   4   1   0]\n [ 23  25  26  20  16  41   0  29   2   0]\n [ 15   5  93  43   8  26  31  23   1   1]\n [  5   4   2 158   5   1   0   6   0   0]\n [  1   1   4  10 100   0   0   5   1   0]\n [  2   7  12   6  14 157   8   3   3   2]\n [  2   0   5  14   6   5  78   1   4   1]\n [  2   2   2   7   1   6  13 130   2   2]\n [ 11   9   3   4   4  14   1  12  73   2]\n [ 10  10  12  19   1  10   9  24   7  76]]\nFold:  3\nEpoch: 1, Train Loss:  1.832, Train Acc: 44.53%, Val Loss:  1.163, Val Acc: 64.14%, Time: 3.69s *\nEpoch: 2, Train Loss: 0.7691, Train Acc: 76.25%, Val Loss:  0.957, Val Acc: 71.15%, Time: 3.62s *\nEpoch: 3, Train Loss:  0.467, Train Acc: 85.93%, Val Loss:  0.918, Val Acc: 73.57%, Time: 3.54s *\nEpoch: 4, Train Loss: 0.3097, Train Acc: 91.02%, Val Loss: 0.8395, Val Acc: 75.99%, Time: 3.51s *\nEpoch: 5, Train Loss: 0.2216, Train Acc: 93.60%, Val Loss: 0.9243, Val Acc: 75.34%, Time: 3.50s \nEpoch: 6, Train Loss: 0.1637, Train Acc: 94.99%, Val Loss: 0.8406, Val Acc: 77.68%, Time: 3.53s *\nEpoch: 7, Train Loss: 0.1302, Train Acc: 96.26%, Val Loss:  0.919, Val Acc: 75.99%, Time: 3.51s \nEpoch: 8, Train Loss: 0.09896, Train Acc: 97.20%, Val Loss: 0.9639, Val Acc: 74.86%, Time: 3.52s \nEpoch: 9, Train Loss: 0.08302, Train Acc: 97.52%, Val Loss: 0.9334, Val Acc: 76.79%, Time: 3.51s \nEpoch: 10, Train Loss: 0.06941, Train Acc: 97.88%, Val Loss: 0.9664, Val Acc: 77.92%, Time: 3.49s *\nEpoch: 11, Train Loss: 0.05797, Train Acc: 98.26%, Val Loss:  1.066, Val Acc: 75.18%, Time: 3.53s \nEpoch: 12, Train Loss: 0.04688, Train Acc: 98.59%, Val Loss:  1.055, Val Acc: 77.52%, Time: 3.51s \nEpoch: 13, Train Loss: 0.04295, Train Acc: 98.75%, Val Loss:  1.099, Val Acc: 77.92%, Time: 3.51s *\nEpoch: 14, Train Loss: 0.04111, Train Acc: 98.74%, Val Loss:   1.17, Val Acc: 75.91%, Time: 3.52s \nEpoch: 15, Train Loss: 0.03826, Train Acc: 98.80%, Val Loss:  1.177, Val Acc: 77.60%, Time: 3.50s \nEpoch: 16, Train Loss: 0.03225, Train Acc: 99.02%, Val Loss:  1.162, Val Acc: 77.52%, Time: 3.49s \nEpoch: 17, Train Loss: 0.03091, Train Acc: 99.10%, Val Loss:  1.259, Val Acc: 75.83%, Time: 3.51s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.73      0.48      0.58       122\n                   Filter       0.75      0.62      0.68       114\n    Compute Derived Value       0.58      0.74      0.65       114\n            Find Extremum       0.76      0.59      0.66       116\n                     Sort       0.81      0.92      0.86       117\n          Determine Range       0.75      0.73      0.74       128\nCharacterize Distribution       0.81      0.70      0.75       146\n           Find Anomalies       0.61      0.87      0.72       136\n                  Cluster       0.86      0.85      0.86       127\n                Correlate       0.85      0.92      0.88       121\n\n                micro avg       0.74      0.74      0.74      1241\n                macro avg       0.75      0.74      0.74      1241\n             weighted avg       0.75      0.74      0.74      1241\n\nConfusion Matrix...\n[[ 59   3  35   7   4   1   6   3   1   3]\n [  6  71   1   8   0   4   5  16   3   0]\n [  3   0  84   1   1  12   5   6   0   2]\n [  2   2   5  68   7   8   1  22   0   1]\n [  0   1   1   0 108   0   1   4   2   0]\n [  2   5   7   2   5  93   4   3   3   4]\n [  4   8   4   1   1   3 102  15   8   0]\n [  1   0   4   2   0   2   2 118   0   7]\n [  0   5   1   0   6   1   0   4 108   2]\n [  4   0   3   0   1   0   0   2   0 111]]\nFold:  4\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.723, Train Acc: 46.39%, Val Loss:  1.368, Val Acc: 58.27%, Time: 3.78s *\nEpoch: 2, Train Loss: 0.7225, Train Acc: 77.62%, Val Loss:  1.343, Val Acc: 61.66%, Time: 3.52s *\nEpoch: 3, Train Loss: 0.4337, Train Acc: 87.29%, Val Loss:  1.485, Val Acc: 62.87%, Time: 3.51s *\nEpoch: 4, Train Loss: 0.2838, Train Acc: 91.55%, Val Loss:   1.39, Val Acc: 65.05%, Time: 3.51s *\nEpoch: 5, Train Loss: 0.2015, Train Acc: 94.08%, Val Loss:  1.367, Val Acc: 65.94%, Time: 3.52s *\nEpoch: 6, Train Loss: 0.1553, Train Acc: 95.48%, Val Loss:  1.374, Val Acc: 66.18%, Time: 3.51s *\nEpoch: 7, Train Loss: 0.1095, Train Acc: 96.84%, Val Loss:  1.428, Val Acc: 67.39%, Time: 3.52s *\nEpoch: 8, Train Loss: 0.09259, Train Acc: 97.30%, Val Loss:  1.433, Val Acc: 69.73%, Time: 3.52s *\nEpoch: 9, Train Loss: 0.0749, Train Acc: 97.80%, Val Loss:   1.57, Val Acc: 68.28%, Time: 3.53s \nEpoch: 10, Train Loss: 0.06158, Train Acc: 98.34%, Val Loss:  1.754, Val Acc: 65.62%, Time: 3.52s \nEpoch: 11, Train Loss: 0.04972, Train Acc: 98.42%, Val Loss:  1.699, Val Acc: 66.83%, Time: 3.51s \nEpoch: 12, Train Loss: 0.04812, Train Acc: 98.62%, Val Loss:  1.643, Val Acc: 68.60%, Time: 3.51s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.76      0.59      0.66       134\n                   Filter       0.48      0.71      0.57       117\n    Compute Derived Value       0.62      0.39      0.48       129\n            Find Extremum       0.91      0.72      0.80       120\n                     Sort       0.59      0.93      0.72       115\n          Determine Range       0.57      0.69      0.62       118\nCharacterize Distribution       0.87      0.90      0.89       115\n           Find Anomalies       0.73      0.51      0.60       130\n                  Cluster       0.82      0.71      0.76       136\n                Correlate       0.68      0.73      0.71       125\n\n                micro avg       0.68      0.68      0.68      1239\n                macro avg       0.70      0.69      0.68      1239\n             weighted avg       0.70      0.68      0.68      1239\n\nConfusion Matrix...\n[[ 79  13  16   2   3   9   7   3   2   0]\n [ 13  83   1   0   8   7   0   0   0   5]\n [  7  18  50   0  16  19   1   6   0  12]\n [  0  12   4  86  15   2   0   0   0   1]\n [  0   2   0   0 107   3   0   0   2   1]\n [  5   7   7   1   9  81   2   1   1   4]\n [  0   0   2   0   2   2 104   1   2   2]\n [  0  28   1   2   3  13   0  66   5  12]\n [  0   8   0   3  13   4   1   5  97   5]\n [  0   1   0   0   6   3   5   9  10  91]]\nFold:  5\nEpoch: 1, Train Loss:  1.767, Train Acc: 45.15%, Val Loss:  1.455, Val Acc: 56.93%, Time: 3.52s *\nEpoch: 2, Train Loss: 0.7487, Train Acc: 77.26%, Val Loss:  1.435, Val Acc: 60.40%, Time: 3.37s *\nEpoch: 3, Train Loss: 0.4514, Train Acc: 86.54%, Val Loss:  1.449, Val Acc: 62.31%, Time: 3.37s *\nEpoch: 4, Train Loss: 0.2923, Train Acc: 91.43%, Val Loss:  1.454, Val Acc: 64.27%, Time: 3.35s *\nEpoch: 5, Train Loss: 0.2115, Train Acc: 93.76%, Val Loss:  1.557, Val Acc: 61.92%, Time: 3.49s \nEpoch: 6, Train Loss: 0.1528, Train Acc: 95.68%, Val Loss:  1.561, Val Acc: 64.55%, Time: 3.36s *\nEpoch: 7, Train Loss: 0.1119, Train Acc: 96.88%, Val Loss:  1.735, Val Acc: 64.67%, Time: 3.35s *\nEpoch: 8, Train Loss: 0.09516, Train Acc: 97.15%, Val Loss:  1.778, Val Acc: 62.54%, Time: 3.36s \nEpoch: 9, Train Loss: 0.0778, Train Acc: 97.81%, Val Loss:  1.771, Val Acc: 64.83%, Time: 3.35s *\nEpoch: 10, Train Loss: 0.05799, Train Acc: 98.34%, Val Loss:  2.006, Val Acc: 62.82%, Time: 3.35s \nEpoch: 11, Train Loss: 0.05443, Train Acc: 98.38%, Val Loss:  2.135, Val Acc: 61.92%, Time: 3.35s \nEpoch: 12, Train Loss: 0.04444, Train Acc: 98.78%, Val Loss:  2.107, Val Acc: 62.70%, Time: 3.36s \nEpoch: 13, Train Loss: 0.03939, Train Acc: 98.85%, Val Loss:  2.114, Val Acc: 63.66%, Time: 3.35s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.52      0.71      0.60       222\n                   Filter       0.46      0.40      0.43       239\n    Compute Derived Value       0.51      0.56      0.53       171\n            Find Extremum       0.86      0.63      0.73       204\n                     Sort       0.64      0.87      0.74       123\n          Determine Range       0.74      0.46      0.57       140\nCharacterize Distribution       0.88      0.76      0.81       150\n           Find Anomalies       0.55      0.56      0.55       206\n                  Cluster       0.66      0.66      0.66       119\n                Correlate       0.80      0.85      0.82       209\n\n                micro avg       0.64      0.64      0.64      1783\n                macro avg       0.66      0.65      0.65      1783\n             weighted avg       0.65      0.64      0.64      1783\n\nConfusion Matrix...\n[[158   1   3   2   0   1   1  54   1   1]\n [ 59  95  31  12  13   7   1  15   5   1]\n [ 38  20  96   0   1   1   2   9   1   3]\n [ 12   8  14 129  27   0   0   4   6   4]\n [  4   2   3   0 107   4   0   0   3   0]\n [ 11   5  27   4   9  65   5   3   2   9]\n [  3   7   3   0   6   8 114   1   8   0]\n [  5  45   4   2   1   0   3 115  12  19]\n [ 11  13   0   0   1   1   4   2  79   8]\n [  0  12   7   1   2   1   0   6   2 178]]\nFold:  6\nEpoch: 1, Train Loss:  1.732, Train Acc: 47.32%, Val Loss:  1.536, Val Acc: 52.12%, Time: 3.74s *\nEpoch: 2, Train Loss: 0.7115, Train Acc: 78.32%, Val Loss:   1.36, Val Acc: 59.43%, Time: 3.50s *\nEpoch: 3, Train Loss: 0.4368, Train Acc: 86.97%, Val Loss:  1.323, Val Acc: 61.08%, Time: 3.51s *\nEpoch: 4, Train Loss: 0.2877, Train Acc: 91.64%, Val Loss:  1.301, Val Acc: 62.19%, Time: 3.50s *\nEpoch: 5, Train Loss: 0.1989, Train Acc: 94.12%, Val Loss:   1.38, Val Acc: 63.52%, Time: 3.51s *\nEpoch: 6, Train Loss: 0.1525, Train Acc: 95.63%, Val Loss:  1.378, Val Acc: 62.97%, Time: 3.51s \nEpoch: 7, Train Loss: 0.1188, Train Acc: 96.44%, Val Loss:  1.451, Val Acc: 62.26%, Time: 3.50s \nEpoch: 8, Train Loss: 0.08854, Train Acc: 97.45%, Val Loss:  1.606, Val Acc: 63.21%, Time: 3.61s \nEpoch: 9, Train Loss: 0.07549, Train Acc: 97.87%, Val Loss:  1.665, Val Acc: 62.19%, Time: 3.51s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.75      0.64      0.69       118\n                   Filter       0.61      0.54      0.57       127\n    Compute Derived Value       0.58      0.54      0.56       134\n            Find Extremum       0.83      0.60      0.70       126\n                     Sort       0.58      0.82      0.68       118\n          Determine Range       0.55      0.80      0.65       129\nCharacterize Distribution       0.70      0.80      0.75       128\n           Find Anomalies       0.67      0.65      0.66       114\n                  Cluster       0.60      0.66      0.63       122\n                Correlate       0.70      0.45      0.55       156\n\n                micro avg       0.64      0.64      0.64      1272\n                macro avg       0.66      0.65      0.64      1272\n             weighted avg       0.66      0.64      0.64      1272\n\nConfusion Matrix...\n[[ 76   9  10   0   8   5   5   0   5   0]\n [  0  68   2   2  16  16   2  18   0   3]\n [ 20   0  72   8   8  19   3   1   2   1]\n [  2   7  13  76  12  10   2   2   1   1]\n [  0   0   9   3  97   5   1   0   3   0]\n [  0   1   2   0  13 103   4   1   4   1]\n [  1   6   6   1   3   5 103   0   2   1]\n [  0  17   2   1   0   5   1  74   7   7]\n [  1   0   1   0   8   3   7   6  80  16]\n [  1   4   7   1   2  15  19   8  29  70]]\nFold:  7\nEpoch: 1, Train Loss:  1.707, Train Acc: 47.71%, Val Loss:  1.683, Val Acc: 51.30%, Time: 3.70s *\nEpoch: 2, Train Loss: 0.7112, Train Acc: 78.44%, Val Loss:  1.595, Val Acc: 56.43%, Time: 3.51s *\nEpoch: 3, Train Loss: 0.4377, Train Acc: 87.01%, Val Loss:  1.599, Val Acc: 60.59%, Time: 3.55s *\nEpoch: 4, Train Loss: 0.2826, Train Acc: 92.00%, Val Loss:  1.637, Val Acc: 60.10%, Time: 3.55s \nEpoch: 5, Train Loss: 0.1995, Train Acc: 94.33%, Val Loss:  1.762, Val Acc: 59.61%, Time: 3.55s \n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 6, Train Loss: 0.1431, Train Acc: 95.97%, Val Loss:  1.822, Val Acc: 61.64%, Time: 3.52s *\nEpoch: 7, Train Loss: 0.1154, Train Acc: 96.77%, Val Loss:  1.678, Val Acc: 63.52%, Time: 3.51s *\nEpoch: 8, Train Loss: 0.08839, Train Acc: 97.56%, Val Loss:  1.784, Val Acc: 63.93%, Time: 3.53s *\nEpoch: 9, Train Loss: 0.06989, Train Acc: 97.93%, Val Loss:  1.941, Val Acc: 61.48%, Time: 3.55s \nEpoch: 10, Train Loss: 0.05882, Train Acc: 98.34%, Val Loss:  2.092, Val Acc: 62.38%, Time: 3.54s \nEpoch: 11, Train Loss: 0.05453, Train Acc: 98.38%, Val Loss:  2.093, Val Acc: 62.13%, Time: 3.52s \nEpoch: 12, Train Loss: 0.04706, Train Acc: 98.61%, Val Loss:  2.208, Val Acc: 62.79%, Time: 3.52s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.39      0.52      0.45       115\n                   Filter       0.41      0.53      0.46       110\n    Compute Derived Value       0.39      0.45      0.42       128\n            Find Extremum       0.80      0.68      0.74       127\n                     Sort       0.73      0.95      0.83       123\n          Determine Range       0.49      0.29      0.37       126\nCharacterize Distribution       0.66      0.61      0.63       127\n           Find Anomalies       0.79      0.56      0.65       125\n                  Cluster       0.89      0.85      0.87       127\n                Correlate       0.87      0.86      0.87       120\n\n                micro avg       0.63      0.63      0.63      1228\n                macro avg       0.64      0.63      0.63      1228\n             weighted avg       0.65      0.63      0.63      1228\n\nConfusion Matrix...\n[[ 60  25  15   2   3   6   1   1   0   2]\n [ 16  58   6   4  10   8   4   2   1   1]\n [ 35  15  57   0   0   3  12   1   1   4]\n [  2   7  17  86   7   2   2   0   1   3]\n [  1   2   0   3 117   0   0   0   0   0]\n [ 27  10  15   7  15  37   8   1   6   0]\n [  8   1  21   1   3  10  77   2   4   0]\n [  1  22  11   3   1   4   9  70   1   3]\n [  1   2   2   1   4   3   2   2 108   2]\n [  1   0   1   0   0   3   2  10   0 103]]\nFold:  8\nEpoch: 1, Train Loss:  1.729, Train Acc: 46.74%, Val Loss:  1.415, Val Acc: 55.99%, Time: 3.68s *\nEpoch: 2, Train Loss: 0.7146, Train Acc: 77.98%, Val Loss:  1.412, Val Acc: 61.52%, Time: 3.64s *\nEpoch: 3, Train Loss: 0.4328, Train Acc: 86.94%, Val Loss:  1.327, Val Acc: 65.28%, Time: 3.50s *\nEpoch: 4, Train Loss:  0.287, Train Acc: 91.64%, Val Loss:  1.302, Val Acc: 66.44%, Time: 3.51s *\nEpoch: 5, Train Loss: 0.2006, Train Acc: 94.39%, Val Loss:  1.343, Val Acc: 65.67%, Time: 3.50s \nEpoch: 6, Train Loss: 0.1431, Train Acc: 96.03%, Val Loss:  1.441, Val Acc: 66.36%, Time: 3.49s \nEpoch: 7, Train Loss: 0.1146, Train Acc: 96.85%, Val Loss:  1.392, Val Acc: 67.74%, Time: 3.50s *\nEpoch: 8, Train Loss: 0.09021, Train Acc: 97.53%, Val Loss:  1.612, Val Acc: 66.44%, Time: 3.51s \nEpoch: 9, Train Loss: 0.06962, Train Acc: 98.08%, Val Loss:  1.704, Val Acc: 64.98%, Time: 3.51s \nEpoch: 10, Train Loss: 0.05685, Train Acc: 98.45%, Val Loss:   1.73, Val Acc: 66.97%, Time: 3.49s \nEpoch: 11, Train Loss: 0.05353, Train Acc: 98.41%, Val Loss:  1.699, Val Acc: 67.13%, Time: 3.54s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.92      0.51      0.66       127\n                   Filter       0.65      0.54      0.59       133\n    Compute Derived Value       0.36      0.55      0.44       126\n            Find Extremum       0.84      0.78      0.81       130\n                     Sort       0.74      0.92      0.82       117\n          Determine Range       0.62      0.70      0.66       119\nCharacterize Distribution       0.65      0.78      0.71       129\n           Find Anomalies       0.69      0.63      0.66       140\n                  Cluster       0.86      0.68      0.76       146\n                Correlate       0.76      0.73      0.75       135\n\n                micro avg       0.68      0.68      0.68      1302\n                macro avg       0.71      0.68      0.68      1302\n             weighted avg       0.71      0.68      0.69      1302\n\nConfusion Matrix...\n[[ 65  15  33   2   4   4   2   2   0   0]\n [  1  72  35   2   2  12   3   4   1   1]\n [  0   4  69   0   7  18  24   1   0   3]\n [  2   0  19 101   7   1   0   0   0   0]\n [  1   0   0   1 108   0   2   0   5   0]\n [  0   1   5  10   9  83   4   2   3   2]\n [  1   1   2   0   2   6 101  13   2   1]\n [  0  14   9   3   1   3   2  88   2  18]\n [  0   2   2   1   5   6  18   6 100   6]\n [  1   2  17   0   1   0   0  12   3  99]]\nFold:  9\nEpoch: 1, Train Loss:    1.8, Train Acc: 45.01%, Val Loss:  1.755, Val Acc: 47.12%, Time: 3.59s *\nEpoch: 2, Train Loss: 0.7027, Train Acc: 78.31%, Val Loss:  1.704, Val Acc: 53.50%, Time: 3.43s *\nEpoch: 3, Train Loss:  0.422, Train Acc: 87.85%, Val Loss:  1.758, Val Acc: 57.69%, Time: 3.39s *\nEpoch: 4, Train Loss: 0.2734, Train Acc: 92.14%, Val Loss:  1.823, Val Acc: 57.25%, Time: 3.40s \nEpoch: 5, Train Loss: 0.1931, Train Acc: 94.51%, Val Loss:  1.915, Val Acc: 57.25%, Time: 3.39s \nEpoch: 6, Train Loss: 0.1345, Train Acc: 96.19%, Val Loss:  2.028, Val Acc: 59.00%, Time: 3.41s *\nEpoch: 7, Train Loss: 0.1084, Train Acc: 96.84%, Val Loss:  2.073, Val Acc: 59.31%, Time: 3.47s *\nEpoch: 8, Train Loss: 0.08466, Train Acc: 97.68%, Val Loss:  2.167, Val Acc: 59.25%, Time: 3.42s \nEpoch: 9, Train Loss: 0.06767, Train Acc: 97.98%, Val Loss:    2.3, Val Acc: 58.63%, Time: 3.41s \nEpoch: 10, Train Loss: 0.05761, Train Acc: 98.37%, Val Loss:  2.296, Val Acc: 59.56%, Time: 3.41s *\nEpoch: 11, Train Loss: 0.05088, Train Acc: 98.51%, Val Loss:  2.394, Val Acc: 59.94%, Time: 3.40s *\nEpoch: 12, Train Loss: 0.04339, Train Acc: 98.78%, Val Loss:  2.566, Val Acc: 59.13%, Time: 3.41s \nEpoch: 13, Train Loss: 0.03978, Train Acc: 98.82%, Val Loss:  2.447, Val Acc: 60.38%, Time: 3.41s *\nEpoch: 14, Train Loss: 0.03429, Train Acc: 99.09%, Val Loss:  2.945, Val Acc: 57.12%, Time: 3.42s \nEpoch: 15, Train Loss: 0.02858, Train Acc: 99.17%, Val Loss:  2.827, Val Acc: 60.00%, Time: 3.40s \nEpoch: 16, Train Loss: 0.02882, Train Acc: 99.10%, Val Loss:  2.969, Val Acc: 60.06%, Time: 3.40s \nEpoch: 17, Train Loss: 0.0249, Train Acc: 99.28%, Val Loss:  2.859, Val Acc: 61.06%, Time: 3.39s *\nEpoch: 18, Train Loss: 0.02605, Train Acc: 99.30%, Val Loss:  3.132, Val Acc: 59.94%, Time: 3.42s \nEpoch: 19, Train Loss: 0.02355, Train Acc: 99.20%, Val Loss:  3.229, Val Acc: 60.19%, Time: 3.40s \nEpoch: 20, Train Loss: 0.01987, Train Acc: 99.33%, Val Loss:  3.108, Val Acc: 59.62%, Time: 3.40s \nEpoch: 21, Train Loss: 0.02211, Train Acc: 99.25%, Val Loss:  3.194, Val Acc: 60.12%, Time: 3.40s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.45      0.46      0.45       107\n                   Filter       0.36      0.42      0.39       113\n    Compute Derived Value       0.76      0.55      0.64       207\n            Find Extremum       0.70      0.65      0.68       323\n                     Sort       0.69      0.80      0.74       122\n          Determine Range       0.58      0.45      0.51       122\nCharacterize Distribution       0.68      0.47      0.56       179\n           Find Anomalies       0.46      0.66      0.54       124\n                  Cluster       0.55      0.76      0.64       120\n                Correlate       0.66      0.73      0.69       183\n\n                micro avg       0.60      0.60      0.60      1600\n                macro avg       0.59      0.60      0.58      1600\n             weighted avg       0.62      0.60      0.60      1600\n\nConfusion Matrix...\n[[ 49   6   4  12   5   2   6  15   3   5]\n [  2  48   1   0   0   2   1  34  12  13]\n [ 14  11 113  36   0   5   6   5   6  11]\n [ 20  18   3 211  22  15   4  16  14   0]\n [  0   1   0   6  98   8   1   0   8   0]\n [  4  34   1  14  10  55   3   1   0   0]\n [ 13   4  14   4   1   0  85  14  12  32]\n [  2   8   0  18   2   0   0  82   5   7]\n [  0   1   1   0   4   7  12   3  91   1]\n [  5   1  11   1   0   1   7   9  15 133]]\nFold:  10\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.755, Train Acc: 46.04%, Val Loss:  1.339, Val Acc: 58.78%, Time: 3.70s *\nEpoch: 2, Train Loss: 0.7373, Train Acc: 77.12%, Val Loss:  1.177, Val Acc: 65.30%, Time: 3.50s *\nEpoch: 3, Train Loss: 0.4505, Train Acc: 86.54%, Val Loss:    1.1, Val Acc: 67.71%, Time: 3.59s *\nEpoch: 4, Train Loss: 0.2929, Train Acc: 91.35%, Val Loss:  1.102, Val Acc: 69.16%, Time: 3.51s *\nEpoch: 5, Train Loss: 0.2164, Train Acc: 93.89%, Val Loss:   1.09, Val Acc: 70.21%, Time: 3.53s *\nEpoch: 6, Train Loss: 0.1533, Train Acc: 95.85%, Val Loss:  1.156, Val Acc: 70.37%, Time: 3.51s *\nEpoch: 7, Train Loss: 0.1252, Train Acc: 96.38%, Val Loss:  1.302, Val Acc: 68.68%, Time: 3.51s \nEpoch: 8, Train Loss: 0.09313, Train Acc: 97.40%, Val Loss:  1.318, Val Acc: 69.00%, Time: 3.54s \nEpoch: 9, Train Loss: 0.07708, Train Acc: 97.66%, Val Loss:  1.234, Val Acc: 71.42%, Time: 3.52s *\nEpoch: 10, Train Loss: 0.05927, Train Acc: 98.30%, Val Loss:  1.286, Val Acc: 70.77%, Time: 3.51s \nEpoch: 11, Train Loss: 0.05922, Train Acc: 98.24%, Val Loss:   1.33, Val Acc: 70.21%, Time: 3.51s \nEpoch: 12, Train Loss: 0.04804, Train Acc: 98.47%, Val Loss:  1.325, Val Acc: 72.54%, Time: 3.51s *\nEpoch: 13, Train Loss: 0.04269, Train Acc: 98.76%, Val Loss:  1.339, Val Acc: 72.22%, Time: 3.51s \nEpoch: 14, Train Loss: 0.03796, Train Acc: 98.87%, Val Loss:  1.342, Val Acc: 73.67%, Time: 3.50s *\nEpoch: 15, Train Loss: 0.03363, Train Acc: 98.90%, Val Loss:   1.44, Val Acc: 71.26%, Time: 3.52s \nEpoch: 16, Train Loss: 0.03233, Train Acc: 98.87%, Val Loss:  1.495, Val Acc: 72.87%, Time: 3.51s \nEpoch: 17, Train Loss: 0.03153, Train Acc: 99.06%, Val Loss:  1.495, Val Acc: 71.82%, Time: 3.51s \nEpoch: 18, Train Loss: 0.03118, Train Acc: 99.14%, Val Loss:  1.562, Val Acc: 71.82%, Time: 3.50s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.70      0.68      0.69       123\n                   Filter       0.58      0.60      0.59       137\n    Compute Derived Value       0.59      0.64      0.61       123\n            Find Extremum       0.84      0.78      0.81       126\n                     Sort       0.80      0.67      0.73       112\n          Determine Range       0.60      0.40      0.49       121\nCharacterize Distribution       0.70      0.91      0.79       128\n           Find Anomalies       0.65      0.74      0.69       123\n                  Cluster       0.92      0.92      0.92       118\n                Correlate       0.92      0.92      0.92       131\n\n                micro avg       0.73      0.73      0.73      1242\n                macro avg       0.73      0.73      0.72      1242\n             weighted avg       0.73      0.73      0.72      1242\n\nConfusion Matrix...\n[[ 84   8  16   7   1   1   0   1   0   5]\n [  1  82   0   1   7  22   5  15   2   2]\n [ 12   4  79   1   0   4  16   4   2   1]\n [  1   9   6  98   1   0   3   8   0   0]\n [  2   4   4  10  75   2   2  10   3   0]\n [ 11  28  11   0   3  49  11   7   0   1]\n [  1   0   2   0   1   3 116   2   1   2]\n [  8   1  13   0   0   0   9  91   1   0]\n [  0   0   1   0   6   0   2   1 108   0]\n [  0   5   2   0   0   0   1   2   1 120]]\n[0.6950354609929078, 0.5727590221187427, 0.7429492344883158, 0.6811945117029863, 0.6371284352215367, 0.6438679245283019, 0.6294788273615635, 0.6804915514592934, 0.603125, 0.7262479871175523]\n0.66122779549912, 0.050903378253622934, 0.053656871959510896, 0.002591153917631412\nbundle\n920 16 16 41\nFold:  1\nEpoch: 1, Train Loss:  2.602, Train Acc: 29.29%, Val Loss:   1.61, Val Acc: 47.84%, Time: 3.73s *\nEpoch: 2, Train Loss:  1.177, Train Acc: 62.91%, Val Loss:  1.286, Val Acc: 59.97%, Time: 3.45s *\nEpoch: 3, Train Loss: 0.7921, Train Acc: 75.60%, Val Loss:  1.135, Val Acc: 65.51%, Time: 3.48s *\nEpoch: 4, Train Loss: 0.5717, Train Acc: 82.96%, Val Loss:  1.106, Val Acc: 66.64%, Time: 3.45s *\nEpoch: 5, Train Loss: 0.4194, Train Acc: 87.34%, Val Loss:  1.088, Val Acc: 68.42%, Time: 3.47s *\nEpoch: 6, Train Loss: 0.3084, Train Acc: 91.10%, Val Loss:  1.113, Val Acc: 68.99%, Time: 3.46s *\nEpoch: 7, Train Loss: 0.2314, Train Acc: 93.48%, Val Loss:  1.165, Val Acc: 69.98%, Time: 3.47s *\nEpoch: 8, Train Loss: 0.1769, Train Acc: 95.31%, Val Loss:  1.115, Val Acc: 71.19%, Time: 3.47s *\nEpoch: 9, Train Loss: 0.1318, Train Acc: 96.23%, Val Loss:  1.156, Val Acc: 70.55%, Time: 3.47s \nEpoch: 10, Train Loss: 0.1149, Train Acc: 96.98%, Val Loss:  1.269, Val Acc: 71.26%, Time: 3.45s *\nEpoch: 11, Train Loss: 0.08783, Train Acc: 97.61%, Val Loss:  1.291, Val Acc: 71.82%, Time: 3.47s *\nEpoch: 12, Train Loss: 0.07653, Train Acc: 97.89%, Val Loss:  1.371, Val Acc: 71.19%, Time: 3.47s \nEpoch: 13, Train Loss: 0.06055, Train Acc: 98.53%, Val Loss:   1.42, Val Acc: 71.61%, Time: 3.47s \nEpoch: 14, Train Loss: 0.04814, Train Acc: 98.66%, Val Loss:  1.415, Val Acc: 71.26%, Time: 3.46s \nEpoch: 15, Train Loss: 0.04912, Train Acc: 98.67%, Val Loss:   1.51, Val Acc: 71.04%, Time: 3.45s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.71      0.60      0.65       146\n                   Filter       0.43      0.65      0.52       122\n    Compute Derived Value       0.51      0.28      0.36       102\n            Find Extremum       0.67      0.88      0.76       112\n                     Sort       0.92      0.86      0.89       232\n          Determine Range       0.87      0.55      0.68        83\nCharacterize Distribution       0.70      0.84      0.76       164\n           Find Anomalies       0.77      0.76      0.76       132\n                  Cluster       0.96      0.82      0.89       194\n                Correlate       0.73      0.80      0.77       122\n\n                micro avg       0.73      0.73      0.73      1409\n                macro avg       0.73      0.71      0.70      1409\n             weighted avg       0.75      0.73      0.73      1409\n\nConfusion Matrix...\n[[ 88  25   4   3   4   0  18   0   0   4]\n [  0  79  14   3   1   2   2  11   1   9]\n [ 15  20  29  22   1   1   5   2   0   7]\n [  6   2   0  99   0   0   0   5   0   0]\n [  0   7   1  12 199   2   4   3   3   1]\n [  3   6   8   6   2  46  10   1   0   1]\n [  1  12   1   1   1   1 137   0   2   8]\n [  2  26   0   1   0   0   0 100   1   2]\n [  9   1   0   0   8   1   4   7 160   4]\n [  0   5   0   1   1   0  16   1   0  98]]\nFold:  2\nEpoch: 1, Train Loss:  2.542, Train Acc: 29.81%, Val Loss:  1.766, Val Acc: 42.78%, Time: 3.65s *\nEpoch: 2, Train Loss:  1.127, Train Acc: 64.35%, Val Loss:  1.494, Val Acc: 54.69%, Time: 3.53s *\nEpoch: 3, Train Loss: 0.7597, Train Acc: 77.19%, Val Loss:  1.424, Val Acc: 58.56%, Time: 3.48s *\nEpoch: 4, Train Loss: 0.5517, Train Acc: 83.29%, Val Loss:   1.35, Val Acc: 60.75%, Time: 3.47s *\nEpoch: 5, Train Loss: 0.3984, Train Acc: 88.37%, Val Loss:  1.406, Val Acc: 62.79%, Time: 3.46s *\nEpoch: 6, Train Loss: 0.2976, Train Acc: 91.44%, Val Loss:    1.4, Val Acc: 64.27%, Time: 3.45s *\nEpoch: 7, Train Loss: 0.2256, Train Acc: 93.69%, Val Loss:  1.503, Val Acc: 63.14%, Time: 3.47s \nEpoch: 8, Train Loss: 0.1768, Train Acc: 94.88%, Val Loss:  1.607, Val Acc: 62.44%, Time: 3.48s \nEpoch: 9, Train Loss: 0.1321, Train Acc: 96.25%, Val Loss:  1.615, Val Acc: 63.71%, Time: 3.46s \nEpoch: 10, Train Loss: 0.1062, Train Acc: 97.17%, Val Loss:  1.799, Val Acc: 61.45%, Time: 3.45s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.66      0.48      0.56       127\n                   Filter       0.34      0.80      0.48       128\n    Compute Derived Value       0.64      0.50      0.56       157\n            Find Extremum       0.81      0.66      0.73       184\n                     Sort       0.66      0.93      0.77        88\n          Determine Range       0.71      0.51      0.60       168\nCharacterize Distribution       0.60      0.74      0.66       105\n           Find Anomalies       0.61      0.51      0.55       192\n                  Cluster       0.84      0.69      0.76       145\n                Correlate       0.69      0.58      0.63       125\n\n                micro avg       0.62      0.62      0.62      1419\n                macro avg       0.66      0.64      0.63      1419\n             weighted avg       0.66      0.62      0.62      1419\n\nConfusion Matrix...\n[[ 61  36   6   0   0   1   5  14   0   4]\n [  1 102  20   0   1   0   0   1   1   2]\n [ 21  27  78   5   0   4  10   8   0   4]\n [  2  18   2 122  11  21   0   3   1   4]\n [  0   3   0   0  82   0   1   0   2   0]\n [  6  30   3   8  13  86   9   8   0   5]\n [  0  20   2   0   1   1  78   1   1   1]\n [  1  52   3  15   1   3   9  97   4   7]\n [  0   6   0   0  12   0  14   7 100   6]\n [  0   2   7   0   3   5   5  21  10  72]]\nFold:  3\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  2.486, Train Acc: 30.51%, Val Loss:  1.632, Val Acc: 49.42%, Time: 3.65s *\nEpoch: 2, Train Loss:  1.146, Train Acc: 63.44%, Val Loss:  1.392, Val Acc: 57.84%, Time: 3.47s *\nEpoch: 3, Train Loss: 0.7613, Train Acc: 76.65%, Val Loss:  1.345, Val Acc: 62.73%, Time: 3.46s *\nEpoch: 4, Train Loss: 0.5483, Train Acc: 83.78%, Val Loss:  1.313, Val Acc: 63.96%, Time: 3.47s *\nEpoch: 5, Train Loss: 0.3928, Train Acc: 88.66%, Val Loss:  1.273, Val Acc: 66.19%, Time: 3.46s *\nEpoch: 6, Train Loss: 0.2988, Train Acc: 90.99%, Val Loss:  1.293, Val Acc: 66.98%, Time: 3.48s *\nEpoch: 7, Train Loss:  0.216, Train Acc: 93.81%, Val Loss:  1.414, Val Acc: 66.33%, Time: 3.48s \nEpoch: 8, Train Loss: 0.1604, Train Acc: 95.57%, Val Loss:  1.351, Val Acc: 68.13%, Time: 3.56s *\nEpoch: 9, Train Loss:   0.13, Train Acc: 96.52%, Val Loss:  1.464, Val Acc: 67.91%, Time: 3.50s \nEpoch: 10, Train Loss: 0.1031, Train Acc: 97.21%, Val Loss:  1.577, Val Acc: 68.20%, Time: 3.48s *\nEpoch: 11, Train Loss: 0.09152, Train Acc: 97.42%, Val Loss:  1.531, Val Acc: 68.92%, Time: 3.48s *\nEpoch: 12, Train Loss: 0.07306, Train Acc: 98.00%, Val Loss:  1.711, Val Acc: 67.77%, Time: 3.49s \nEpoch: 13, Train Loss: 0.06214, Train Acc: 98.17%, Val Loss:   1.81, Val Acc: 67.77%, Time: 3.46s \nEpoch: 14, Train Loss: 0.05535, Train Acc: 98.38%, Val Loss:  1.888, Val Acc: 66.55%, Time: 3.49s \nEpoch: 15, Train Loss: 0.04251, Train Acc: 98.77%, Val Loss:  1.895, Val Acc: 67.91%, Time: 3.48s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.47      0.39      0.43        69\n                   Filter       0.55      0.74      0.63       168\n    Compute Derived Value       0.74      0.44      0.55       208\n            Find Extremum       0.65      0.84      0.73       136\n                     Sort       0.73      0.91      0.81       128\n          Determine Range       0.71      0.43      0.53       152\nCharacterize Distribution       0.87      0.81      0.84       159\n           Find Anomalies       0.62      0.80      0.70       104\n                  Cluster       0.59      0.93      0.72       103\n                Correlate       0.75      0.50      0.60       163\n\n                micro avg       0.67      0.67      0.67      1390\n                macro avg       0.67      0.68      0.65      1390\n             weighted avg       0.69      0.67      0.66      1390\n\nConfusion Matrix...\n[[ 27   5   9  14   5   0   0   1   1   7]\n [  5 125   3   4   7   1   0  13   6   4]\n [ 22  39  92   6  10  16   3   8   3   9]\n [  0   8   1 114   8   1   3   0   0   1]\n [  0   3   0   0 116   3   0   1   5   0]\n [  4  23   7  19   8  65  10   1  12   3]\n [  0   4   9   1   1   4 129   2   8   1]\n [  0  11   1   4   0   0   1  83   1   3]\n [  0   1   1   0   3   1   0   1  96   0]\n [  0   7   2  14   0   1   2  23  32  82]]\nFold:  4\nEpoch: 1, Train Loss:  2.522, Train Acc: 28.92%, Val Loss:  1.628, Val Acc: 49.93%, Time: 3.68s *\nEpoch: 2, Train Loss:  1.141, Train Acc: 63.39%, Val Loss:  1.342, Val Acc: 57.81%, Time: 3.47s *\nEpoch: 3, Train Loss: 0.7673, Train Acc: 75.93%, Val Loss:  1.236, Val Acc: 63.97%, Time: 3.48s *\nEpoch: 4, Train Loss: 0.5549, Train Acc: 82.98%, Val Loss:  1.228, Val Acc: 64.83%, Time: 3.47s *\nEpoch: 5, Train Loss: 0.3922, Train Acc: 88.47%, Val Loss:  1.197, Val Acc: 67.15%, Time: 3.47s *\nEpoch: 6, Train Loss: 0.2955, Train Acc: 91.56%, Val Loss:  1.274, Val Acc: 66.06%, Time: 3.46s \nEpoch: 7, Train Loss: 0.2258, Train Acc: 93.41%, Val Loss:  1.329, Val Acc: 67.51%, Time: 3.46s *\nEpoch: 8, Train Loss: 0.1602, Train Acc: 95.53%, Val Loss:  1.403, Val Acc: 68.89%, Time: 3.45s *\nEpoch: 9, Train Loss: 0.1325, Train Acc: 96.13%, Val Loss:  1.463, Val Acc: 67.58%, Time: 3.58s \nEpoch: 10, Train Loss: 0.1027, Train Acc: 97.17%, Val Loss:  1.507, Val Acc: 68.45%, Time: 3.46s \nEpoch: 11, Train Loss: 0.08357, Train Acc: 97.61%, Val Loss:  1.582, Val Acc: 67.66%, Time: 3.47s \nEpoch: 12, Train Loss: 0.0717, Train Acc: 98.08%, Val Loss:   1.64, Val Acc: 68.31%, Time: 3.45s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.71      0.58      0.64       141\n                   Filter       0.44      0.60      0.50       139\n    Compute Derived Value       0.83      0.73      0.78       154\n            Find Extremum       0.76      0.75      0.75       144\n                     Sort       0.80      0.71      0.75        90\n          Determine Range       0.71      0.60      0.65       159\nCharacterize Distribution       0.55      0.85      0.67       120\n           Find Anomalies       0.78      0.60      0.68       115\n                  Cluster       0.60      0.91      0.72        86\n                Correlate       0.88      0.66      0.75       234\n\n                micro avg       0.69      0.69      0.69      1382\n                macro avg       0.70      0.70      0.69      1382\n             weighted avg       0.72      0.69      0.69      1382\n\nConfusion Matrix...\n[[ 82  12   5  12   3   5  17   4   0   1]\n [  4  83   1   1   7  22   3   9   8   1]\n [  3  25 113   6   0   0   4   1   0   2]\n [ 10  14   1 108   2   7   2   0   0   0]\n [  0   1   0  11  64   2   1   0  11   0]\n [  1  39   4   2   2  96   9   1   2   3]\n [  9   0   3   0   1   2 102   1   2   0]\n [  1   5   0   2   0   1  21  69   2  14]\n [  1   3   0   0   0   0   2   1  78   1]\n [  4   8   9   1   1   1  25   3  28 154]]\nFold:  5\nEpoch: 1, Train Loss:  2.427, Train Acc: 30.48%, Val Loss:  1.511, Val Acc: 52.16%, Time: 3.66s *\nEpoch: 2, Train Loss:  1.119, Train Acc: 65.15%, Val Loss:  1.218, Val Acc: 64.36%, Time: 3.48s *\nEpoch: 3, Train Loss: 0.7517, Train Acc: 77.22%, Val Loss:   1.17, Val Acc: 65.66%, Time: 3.48s *\nEpoch: 4, Train Loss: 0.5572, Train Acc: 83.27%, Val Loss:  1.159, Val Acc: 66.45%, Time: 3.45s *\nEpoch: 5, Train Loss: 0.3996, Train Acc: 88.31%, Val Loss:  1.148, Val Acc: 66.96%, Time: 3.47s *\nEpoch: 6, Train Loss: 0.3039, Train Acc: 90.88%, Val Loss:  1.212, Val Acc: 67.60%, Time: 3.47s *\nEpoch: 7, Train Loss: 0.2344, Train Acc: 93.27%, Val Loss:  1.256, Val Acc: 69.12%, Time: 3.46s *\nEpoch: 8, Train Loss: 0.1711, Train Acc: 95.27%, Val Loss:  1.258, Val Acc: 67.24%, Time: 3.48s \nEpoch: 9, Train Loss: 0.1388, Train Acc: 96.17%, Val Loss:  1.339, Val Acc: 68.61%, Time: 3.47s \nEpoch: 10, Train Loss: 0.1129, Train Acc: 96.76%, Val Loss:  1.369, Val Acc: 67.53%, Time: 3.46s \nEpoch: 11, Train Loss: 0.09639, Train Acc: 97.32%, Val Loss:  1.434, Val Acc: 67.89%, Time: 3.47s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.74      0.56      0.64       112\n                   Filter       0.44      0.92      0.60       143\n    Compute Derived Value       0.70      0.55      0.61       143\n            Find Extremum       0.81      0.58      0.67       243\n                     Sort       0.74      0.71      0.72       153\n          Determine Range       0.60      0.46      0.52       108\nCharacterize Distribution       0.66      0.94      0.77        71\n           Find Anomalies       0.79      0.75      0.77       126\n                  Cluster       0.71      0.63      0.67       123\n                Correlate       0.79      0.74      0.76       164\n\n                micro avg       0.67      0.67      0.67      1386\n                macro avg       0.70      0.68      0.67      1386\n             weighted avg       0.71      0.67      0.67      1386\n\nConfusion Matrix...\n[[ 63  21  14   1   0   0   8   2   1   2]\n [  1 132   2   3   1   2   0   2   0   0]\n [  0  10  78  10   3  11   8   3   6  14]\n [  8  55   7 140  15   8   2   3   3   2]\n [  4  21   0   7 109   1   1   0  10   0]\n [  3  29   8  11   5  50   2   0   0   0]\n [  0   0   0   0   0   0  67   0   3   1]\n [  2  14   1   1   1   0   1  94   3   9]\n [  0   3   1   0  12  11   8   6  78   4]\n [  4  15   1   0   2   1   5   9   6 121]]\nFold:  6\nEpoch: 1, Train Loss:  2.532, Train Acc: 29.89%, Val Loss:  1.836, Val Acc: 44.15%, Time: 3.74s *\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 2, Train Loss:  1.134, Train Acc: 63.45%, Val Loss:  1.615, Val Acc: 52.51%, Time: 3.45s *\nEpoch: 3, Train Loss: 0.7512, Train Acc: 76.74%, Val Loss:  1.558, Val Acc: 58.04%, Time: 3.45s *\nEpoch: 4, Train Loss:  0.535, Train Acc: 84.10%, Val Loss:  1.518, Val Acc: 60.07%, Time: 3.47s *\nEpoch: 5, Train Loss: 0.3858, Train Acc: 88.63%, Val Loss:  1.638, Val Acc: 59.05%, Time: 3.44s \nEpoch: 6, Train Loss: 0.2788, Train Acc: 92.34%, Val Loss:   1.64, Val Acc: 60.95%, Time: 3.47s *\nEpoch: 7, Train Loss: 0.2096, Train Acc: 94.46%, Val Loss:  1.719, Val Acc: 61.45%, Time: 3.46s *\nEpoch: 8, Train Loss: 0.1614, Train Acc: 95.58%, Val Loss:  1.816, Val Acc: 60.65%, Time: 3.46s \nEpoch: 9, Train Loss: 0.1311, Train Acc: 96.28%, Val Loss:  1.842, Val Acc: 60.80%, Time: 3.47s \nEpoch: 10, Train Loss: 0.1037, Train Acc: 97.26%, Val Loss:  1.896, Val Acc: 62.04%, Time: 3.45s *\nEpoch: 11, Train Loss: 0.08411, Train Acc: 97.65%, Val Loss:  2.025, Val Acc: 61.75%, Time: 3.47s \nEpoch: 12, Train Loss: 0.07104, Train Acc: 98.16%, Val Loss:  2.184, Val Acc: 58.91%, Time: 3.44s \nEpoch: 13, Train Loss: 0.0567, Train Acc: 98.42%, Val Loss:   2.33, Val Acc: 62.69%, Time: 3.47s *\nEpoch: 14, Train Loss: 0.05577, Train Acc: 98.45%, Val Loss:  2.431, Val Acc: 60.44%, Time: 3.49s \nEpoch: 15, Train Loss: 0.04218, Train Acc: 98.93%, Val Loss:  2.373, Val Acc: 63.20%, Time: 3.45s *\nEpoch: 16, Train Loss: 0.03892, Train Acc: 98.88%, Val Loss:  2.533, Val Acc: 59.71%, Time: 3.46s \nEpoch: 17, Train Loss: 0.05104, Train Acc: 98.48%, Val Loss:  2.696, Val Acc: 60.29%, Time: 3.46s \nEpoch: 18, Train Loss: 0.0351, Train Acc: 99.00%, Val Loss:  2.904, Val Acc: 58.98%, Time: 3.64s \nEpoch: 19, Train Loss: 0.02501, Train Acc: 99.32%, Val Loss:  3.092, Val Acc: 59.93%, Time: 3.48s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.69      0.72      0.71       162\n                   Filter       0.47      0.65      0.55       111\n    Compute Derived Value       0.47      0.34      0.39       172\n            Find Extremum       0.81      0.63      0.71       212\n                     Sort       0.58      0.63      0.61        63\n          Determine Range       0.62      0.47      0.53       134\nCharacterize Distribution       0.61      0.58      0.60       186\n           Find Anomalies       0.55      0.74      0.63       166\n                  Cluster       0.80      0.67      0.73       112\n                Correlate       0.25      0.44      0.31        57\n\n                micro avg       0.59      0.59      0.59      1375\n                macro avg       0.59      0.59      0.58      1375\n             weighted avg       0.61      0.59      0.59      1375\n\nConfusion Matrix...\n[[116   6  30   3   1   1   2   0   1   2]\n [  3  72   6   1   0   9   0  18   0   2]\n [ 34  16  58   1   7  15  21   8   2  10]\n [ 12   6  14 134   6   4   6  23   3   4]\n [  0   7   1  11  40   2   1   0   1   0]\n [  0  34   1   1   8  63  21   2   2   2]\n [  0   0   2  14   4   3 108  27   8  20]\n [  0   7  10   1   1   3   5 123   1  15]\n [  2   2   0   0   1   2   2   6  75  22]\n [  0   2   1   0   1   0  10  17   1  25]]\nFold:  7\nEpoch: 1, Train Loss:  2.523, Train Acc: 30.55%, Val Loss:  1.537, Val Acc: 46.79%, Time: 3.64s *\nEpoch: 2, Train Loss:  1.164, Train Acc: 62.29%, Val Loss:  1.105, Val Acc: 65.05%, Time: 3.46s *\nEpoch: 3, Train Loss: 0.7825, Train Acc: 75.83%, Val Loss:   1.04, Val Acc: 67.30%, Time: 3.47s *\nEpoch: 4, Train Loss: 0.5878, Train Acc: 82.03%, Val Loss: 0.9781, Val Acc: 68.22%, Time: 3.47s *\nEpoch: 5, Train Loss: 0.4181, Train Acc: 87.72%, Val Loss: 0.9948, Val Acc: 69.70%, Time: 3.46s *\nEpoch: 6, Train Loss: 0.3115, Train Acc: 90.77%, Val Loss: 0.9472, Val Acc: 70.26%, Time: 3.45s *\nEpoch: 7, Train Loss: 0.2405, Train Acc: 92.93%, Val Loss:  0.941, Val Acc: 72.45%, Time: 3.46s *\nEpoch: 8, Train Loss: 0.1825, Train Acc: 94.84%, Val Loss:  1.002, Val Acc: 72.80%, Time: 3.45s *\nEpoch: 9, Train Loss: 0.1368, Train Acc: 96.21%, Val Loss:  1.032, Val Acc: 72.30%, Time: 3.47s \nEpoch: 10, Train Loss: 0.1132, Train Acc: 96.77%, Val Loss:  1.008, Val Acc: 73.78%, Time: 3.46s *\nEpoch: 11, Train Loss:  0.093, Train Acc: 97.47%, Val Loss:  1.113, Val Acc: 72.23%, Time: 3.48s \nEpoch: 12, Train Loss: 0.0745, Train Acc: 98.12%, Val Loss:  1.188, Val Acc: 70.61%, Time: 3.47s \nEpoch: 13, Train Loss: 0.06993, Train Acc: 98.01%, Val Loss:  1.256, Val Acc: 71.46%, Time: 3.45s \nEpoch: 14, Train Loss: 0.06267, Train Acc: 98.05%, Val Loss:  1.216, Val Acc: 72.37%, Time: 3.45s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.79      0.77      0.78       125\n                   Filter       0.59      0.62      0.60       172\n    Compute Derived Value       0.79      0.75      0.77       131\n            Find Extremum       0.86      0.62      0.72       215\n                     Sort       0.71      0.90      0.80       139\n          Determine Range       0.71      0.53      0.61       132\nCharacterize Distribution       0.55      0.92      0.69        66\n           Find Anomalies       0.76      0.71      0.74       150\n                  Cluster       0.72      0.82      0.77       125\n                Correlate       0.82      0.85      0.84       164\n\n                micro avg       0.73      0.73      0.73      1419\n                macro avg       0.73      0.75      0.73      1419\n             weighted avg       0.75      0.73      0.73      1419\n\nConfusion Matrix...\n[[ 96   7  10   4   0   0   7   0   1   0]\n [ 10 106   4  10  13   1   2  15   5   6]\n [  8  10  98   0   0   3   5   1   1   5]\n [  2  20   4 134  23  17   6   4   3   2]\n [  2   2   0   1 125   0   0   0   7   2]\n [  4  18   5   3  10  70  13   2   6   1]\n [  0   0   1   0   0   1  61   0   1   2]\n [  0  16   2   3   2   6   2 107   5   7]\n [  0   0   0   0   2   1   7   7 103   5]\n [  0   1   0   0   0   0   8   4  11 140]]\nFold:  8\nEpoch: 1, Train Loss:  2.568, Train Acc: 29.22%, Val Loss:  1.588, Val Acc: 48.33%, Time: 3.64s *\nEpoch: 2, Train Loss:  1.168, Train Acc: 61.73%, Val Loss:  1.176, Val Acc: 63.73%, Time: 3.48s *\nEpoch: 3, Train Loss: 0.8004, Train Acc: 74.46%, Val Loss:  1.057, Val Acc: 67.99%, Time: 3.47s *\nEpoch: 4, Train Loss: 0.5681, Train Acc: 82.51%, Val Loss: 0.9485, Val Acc: 70.48%, Time: 3.48s *\nEpoch: 5, Train Loss: 0.4204, Train Acc: 87.64%, Val Loss: 0.9659, Val Acc: 70.62%, Time: 3.45s *\nEpoch: 6, Train Loss: 0.3121, Train Acc: 90.67%, Val Loss: 0.9848, Val Acc: 71.61%, Time: 3.47s *\nEpoch: 7, Train Loss: 0.2346, Train Acc: 93.28%, Val Loss: 0.9012, Val Acc: 73.88%, Time: 3.47s *\nEpoch: 8, Train Loss: 0.1755, Train Acc: 94.85%, Val Loss: 0.9873, Val Acc: 72.68%, Time: 3.45s \nEpoch: 9, Train Loss: 0.1358, Train Acc: 96.09%, Val Loss:  1.115, Val Acc: 72.60%, Time: 3.46s \nEpoch: 10, Train Loss: 0.1085, Train Acc: 96.99%, Val Loss:  1.152, Val Acc: 73.88%, Time: 3.45s \nEpoch: 11, Train Loss: 0.09083, Train Acc: 97.39%, Val Loss:  1.122, Val Acc: 73.17%, Time: 3.47s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.83      0.83      0.83       161\n                   Filter       0.41      0.65      0.50       102\n    Compute Derived Value       0.83      0.52      0.64       201\n            Find Extremum       0.75      0.72      0.73       156\n                     Sort       0.69      0.73      0.71        73\n          Determine Range       0.81      0.72      0.76       148\nCharacterize Distribution       0.66      0.79      0.72       123\n           Find Anomalies       0.72      0.62      0.67       186\n                  Cluster       0.71      0.89      0.79        81\n                Correlate       0.75      0.81      0.78       178\n\n                micro avg       0.71      0.71      0.71      1409\n                macro avg       0.72      0.73      0.71      1409\n             weighted avg       0.73      0.71      0.71      1409\n\nConfusion Matrix...\n[[134  14   4   1   0   1   0   3   0   4]\n [  2  66   6  13   3   2   1   5   0   4]\n [  9  23 104  11   1   4  16   9   3  21]\n [  8  14   0 112  16   3   0   3   0   0]\n [  0   9   1   3  53   2   1   0   4   0]\n [  2   4   3   3   2 107  16  11   0   0]\n [  2   5   3   0   1   8  97   0   6   1]\n [  2  22   2   1   0   5  10 116  11  17]\n [  0   0   0   5   1   0   1   1  72   1]\n [  3   5   2   1   0   0   4  13   6 144]]\nFold:  9\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  2.533, Train Acc: 28.40%, Val Loss:  1.623, Val Acc: 45.00%, Time: 3.64s *\nEpoch: 2, Train Loss:  1.173, Train Acc: 62.88%, Val Loss:  1.327, Val Acc: 58.86%, Time: 3.47s *\nEpoch: 3, Train Loss:  0.789, Train Acc: 75.69%, Val Loss:  1.253, Val Acc: 62.36%, Time: 3.47s *\nEpoch: 4, Train Loss: 0.5733, Train Acc: 83.03%, Val Loss:    1.2, Val Acc: 63.79%, Time: 3.47s *\nEpoch: 5, Train Loss: 0.4173, Train Acc: 87.93%, Val Loss:  1.248, Val Acc: 65.14%, Time: 3.55s *\nEpoch: 6, Train Loss: 0.3047, Train Acc: 91.09%, Val Loss:  1.311, Val Acc: 66.21%, Time: 3.49s *\nEpoch: 7, Train Loss: 0.2368, Train Acc: 93.32%, Val Loss:   1.33, Val Acc: 65.71%, Time: 3.47s \nEpoch: 8, Train Loss: 0.1692, Train Acc: 95.36%, Val Loss:  1.355, Val Acc: 66.07%, Time: 3.45s \nEpoch: 9, Train Loss: 0.1367, Train Acc: 96.31%, Val Loss:  1.429, Val Acc: 66.93%, Time: 3.48s *\nEpoch: 10, Train Loss: 0.1088, Train Acc: 96.95%, Val Loss:  1.533, Val Acc: 66.93%, Time: 3.45s \nEpoch: 11, Train Loss: 0.09706, Train Acc: 97.33%, Val Loss:  1.688, Val Acc: 64.64%, Time: 3.47s \nEpoch: 12, Train Loss: 0.07624, Train Acc: 97.91%, Val Loss:  1.674, Val Acc: 65.86%, Time: 3.45s \nEpoch: 13, Train Loss: 0.05878, Train Acc: 98.38%, Val Loss:  1.766, Val Acc: 66.36%, Time: 3.50s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.81      0.59      0.68       201\n                   Filter       0.46      0.70      0.56       149\n    Compute Derived Value       0.70      0.59      0.64       170\n            Find Extremum       0.63      0.76      0.69       117\n                     Sort       0.66      0.76      0.71        88\n          Determine Range       0.73      0.45      0.55       114\nCharacterize Distribution       0.60      0.47      0.52       126\n           Find Anomalies       0.63      0.67      0.65       119\n                  Cluster       0.78      0.84      0.81       174\n                Correlate       0.66      0.73      0.69       142\n\n                micro avg       0.66      0.66      0.66      1400\n                macro avg       0.67      0.66      0.65      1400\n             weighted avg       0.68      0.66      0.66      1400\n\nConfusion Matrix...\n[[118  30   8  22   6   3   3   9   1   1]\n [  6 105   1  12   0   2   1  17   3   2]\n [  9  28 101   2   1   5   7   4   5   8]\n [  2   5   0  89   9   0   7   4   0   1]\n [  0   1   0   9  67   2   1   0   8   0]\n [  5  21  17   3   2  51   7   1   7   0]\n [  1  14   7   0   2   4  59   1   6  32]\n [  2  15   1   1   1   0   2  80   8   9]\n [  0   1   0   2  13   0   7   3 147   1]\n [  2   7  10   1   0   3   5   8   3 103]]\nFold:  10\nEpoch: 1, Train Loss:  2.462, Train Acc: 30.50%, Val Loss:  1.737, Val Acc: 43.36%, Time: 3.63s *\nEpoch: 2, Train Loss:   1.13, Train Acc: 64.32%, Val Loss:  1.446, Val Acc: 55.39%, Time: 3.47s *\nEpoch: 3, Train Loss: 0.7697, Train Acc: 76.56%, Val Loss:  1.394, Val Acc: 57.12%, Time: 3.46s *\nEpoch: 4, Train Loss: 0.5531, Train Acc: 83.91%, Val Loss:  1.322, Val Acc: 60.65%, Time: 3.45s *\nEpoch: 5, Train Loss: 0.4077, Train Acc: 88.07%, Val Loss:  1.452, Val Acc: 60.44%, Time: 3.46s \nEpoch: 6, Train Loss: 0.3068, Train Acc: 91.01%, Val Loss:  1.398, Val Acc: 62.03%, Time: 3.47s *\nEpoch: 7, Train Loss: 0.2249, Train Acc: 93.41%, Val Loss:  1.425, Val Acc: 62.52%, Time: 3.52s *\nEpoch: 8, Train Loss: 0.1657, Train Acc: 95.14%, Val Loss:  1.414, Val Acc: 64.18%, Time: 3.48s *\nEpoch: 9, Train Loss: 0.1271, Train Acc: 96.61%, Val Loss:  1.491, Val Acc: 64.25%, Time: 3.44s *\nEpoch: 10, Train Loss: 0.1068, Train Acc: 97.06%, Val Loss:  1.554, Val Acc: 63.00%, Time: 3.47s \nEpoch: 11, Train Loss: 0.08817, Train Acc: 97.43%, Val Loss:  1.543, Val Acc: 64.94%, Time: 3.44s *\nEpoch: 12, Train Loss: 0.08188, Train Acc: 97.69%, Val Loss:  1.702, Val Acc: 62.86%, Time: 3.47s \nEpoch: 13, Train Loss: 0.06669, Train Acc: 98.30%, Val Loss:  1.718, Val Acc: 65.28%, Time: 3.44s *\nEpoch: 14, Train Loss: 0.05031, Train Acc: 98.72%, Val Loss:  1.907, Val Acc: 63.42%, Time: 3.44s \nEpoch: 15, Train Loss: 0.04142, Train Acc: 98.87%, Val Loss:  1.847, Val Acc: 64.11%, Time: 3.46s \nEpoch: 16, Train Loss: 0.0416, Train Acc: 98.78%, Val Loss:  2.112, Val Acc: 61.83%, Time: 3.46s \nEpoch: 17, Train Loss: 0.04146, Train Acc: 98.75%, Val Loss:  1.966, Val Acc: 63.83%, Time: 3.43s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.61      0.86      0.72       120\n                   Filter       0.59      0.35      0.44       218\n    Compute Derived Value       0.34      0.53      0.42        97\n            Find Extremum       0.65      0.68      0.67       141\n                     Sort       0.90      0.80      0.85       152\n          Determine Range       0.48      0.66      0.56       124\nCharacterize Distribution       0.69      0.78      0.73       209\n           Find Anomalies       0.54      0.45      0.49        83\n                  Cluster       0.74      0.59      0.66       127\n                Correlate       0.80      0.66      0.72       175\n\n                micro avg       0.64      0.64      0.64      1446\n                macro avg       0.64      0.63      0.62      1446\n             weighted avg       0.66      0.64      0.63      1446\n\nConfusion Matrix...\n[[103   0  12   1   0   1   1   0   0   2]\n [ 43  77  30   8   2  24  15  14   5   0]\n [  3   1  51  16   0  18   5   1   2   0]\n [  8   4  10  96   1  11   7   2   0   2]\n [  0   0   1   9 121  11   3   1   6   0]\n [  5  12   4  13   1  82   3   1   0   3]\n [  4   1  11   3   2   9 162   3   8   6]\n [  0  18   4   1   0   6  11  37   1   5]\n [  2  11   2   0   1   6  13   7  75  10]\n [  0   7  23   0   6   3  14   3   4 115]]\n[0.7345635202271115, 0.6187455954897816, 0.6683453237410072, 0.6866859623733719, 0.6724386724386724, 0.592, 0.7329105003523608, 0.7132718239886444, 0.6571428571428571, 0.6355463347164592]\n0.6711650590470267, 0.045094941952398396, 0.047534242507553094, 0.002033553789690181\ntable\n37 358 1205 41\nFold:  1\nEpoch: 1, Train Loss:  1.912, Train Acc: 41.80%, Val Loss:  1.532, Val Acc: 51.00%, Time: 3.34s *\nEpoch: 2, Train Loss: 0.8405, Train Acc: 74.04%, Val Loss:  1.268, Val Acc: 60.57%, Time: 3.18s *\nEpoch: 3, Train Loss: 0.5255, Train Acc: 84.08%, Val Loss:  1.126, Val Acc: 65.68%, Time: 3.16s *\nEpoch: 4, Train Loss:  0.363, Train Acc: 89.27%, Val Loss:  1.119, Val Acc: 67.36%, Time: 3.14s *\nEpoch: 5, Train Loss: 0.2528, Train Acc: 92.51%, Val Loss:  1.184, Val Acc: 66.76%, Time: 3.17s \nEpoch: 6, Train Loss: 0.1853, Train Acc: 94.65%, Val Loss:  1.228, Val Acc: 66.84%, Time: 3.17s \nEpoch: 7, Train Loss: 0.1442, Train Acc: 95.84%, Val Loss:  1.218, Val Acc: 67.32%, Time: 3.23s \nEpoch: 8, Train Loss: 0.1094, Train Acc: 97.02%, Val Loss:  1.233, Val Acc: 68.24%, Time: 3.15s *\nEpoch: 9, Train Loss: 0.08741, Train Acc: 97.58%, Val Loss:   1.42, Val Acc: 67.40%, Time: 3.18s \nEpoch: 10, Train Loss: 0.07222, Train Acc: 97.91%, Val Loss:  1.343, Val Acc: 68.32%, Time: 3.15s *\nEpoch: 11, Train Loss: 0.05869, Train Acc: 98.23%, Val Loss:  1.413, Val Acc: 68.75%, Time: 3.17s *\nEpoch: 12, Train Loss: 0.05081, Train Acc: 98.41%, Val Loss:  1.552, Val Acc: 67.36%, Time: 3.18s \nEpoch: 13, Train Loss: 0.04498, Train Acc: 98.77%, Val Loss:  1.425, Val Acc: 69.15%, Time: 3.18s *\nEpoch: 14, Train Loss: 0.04382, Train Acc: 98.75%, Val Loss:   1.79, Val Acc: 65.68%, Time: 3.18s \nEpoch: 15, Train Loss: 0.04072, Train Acc: 98.75%, Val Loss:  1.515, Val Acc: 69.15%, Time: 3.16s \nEpoch: 16, Train Loss: 0.03681, Train Acc: 98.86%, Val Loss:  1.474, Val Acc: 68.99%, Time: 3.16s \nEpoch: 17, Train Loss: 0.03103, Train Acc: 99.06%, Val Loss:  1.627, Val Acc: 67.68%, Time: 3.16s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.59      0.50      0.54       243\n                   Filter       0.56      0.60      0.58       208\n    Compute Derived Value       0.64      0.58      0.61       257\n            Find Extremum       0.60      0.89      0.72       244\n                     Sort       0.86      0.82      0.84       224\n          Determine Range       0.74      0.50      0.60       242\nCharacterize Distribution       0.84      0.78      0.81       245\n           Find Anomalies       0.61      0.75      0.67       276\n                  Cluster       0.81      0.71      0.75       265\n                Correlate       0.73      0.73      0.73       302\n\n                micro avg       0.69      0.69      0.69      2506\n                macro avg       0.70      0.69      0.69      2506\n             weighted avg       0.70      0.69      0.69      2506\n\nConfusion Matrix...\n[[122   4  32  41   3   7   5   2   3  24]\n [ 31 124   3  11   1   7   0  27   2   2]\n [ 25  28 150  18   5   9   2  15   4   1]\n [  7   8   6 218   1   0   0   1   0   3]\n [  0   2   0  23 184   4   2   2   4   3]\n [ 21  20  17  19   5 121  11  18   4   6]\n [  0  10   2   0   3   4 192  12  15   7]\n [  0  10   6  15   1   7   2 208   4  23]\n [  0  12   4   9  10   3   1  28 187  11]\n [  2   4  13  11   0   2  13  28   9 220]]\nFold:  2\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.879, Train Acc: 43.26%, Val Loss:   1.76, Val Acc: 45.56%, Time: 3.35s *\nEpoch: 2, Train Loss: 0.7737, Train Acc: 76.36%, Val Loss:  1.536, Val Acc: 54.93%, Time: 3.20s *\nEpoch: 3, Train Loss: 0.4666, Train Acc: 85.83%, Val Loss:  1.549, Val Acc: 56.01%, Time: 3.18s *\nEpoch: 4, Train Loss: 0.2993, Train Acc: 91.29%, Val Loss:   1.63, Val Acc: 56.63%, Time: 3.21s *\nEpoch: 5, Train Loss: 0.2111, Train Acc: 94.19%, Val Loss:  1.657, Val Acc: 58.50%, Time: 3.22s *\nEpoch: 6, Train Loss: 0.1523, Train Acc: 95.63%, Val Loss:  1.697, Val Acc: 59.41%, Time: 3.30s *\nEpoch: 7, Train Loss: 0.1128, Train Acc: 96.75%, Val Loss:  1.866, Val Acc: 57.50%, Time: 3.21s \nEpoch: 8, Train Loss: 0.09509, Train Acc: 97.36%, Val Loss:  2.015, Val Acc: 56.97%, Time: 3.17s \nEpoch: 9, Train Loss: 0.07375, Train Acc: 98.01%, Val Loss:  1.984, Val Acc: 58.29%, Time: 3.19s \nEpoch: 10, Train Loss: 0.0612, Train Acc: 98.34%, Val Loss:  2.045, Val Acc: 59.29%, Time: 3.19s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.42      0.30      0.35       210\n                   Filter       0.51      0.44      0.47       285\n    Compute Derived Value       0.44      0.62      0.52       277\n            Find Extremum       0.52      0.81      0.63       278\n                     Sort       0.83      0.78      0.81       227\n          Determine Range       0.49      0.46      0.48       203\nCharacterize Distribution       0.65      0.70      0.68       259\n           Find Anomalies       0.70      0.61      0.65       226\n                  Cluster       0.87      0.69      0.77       223\n                Correlate       0.78      0.52      0.62       224\n\n                micro avg       0.60      0.60      0.60      2412\n                macro avg       0.62      0.59      0.60      2412\n             weighted avg       0.62      0.60      0.60      2412\n\nConfusion Matrix...\n[[ 63  30  48  54   3   4   8   0   0   0]\n [  7 124  49  27   5  30  12  23   1   7]\n [ 32   9 172  36   5   2  19   1   0   1]\n [ 20  10   3 224   1  17   1   2   0   0]\n [  0   3   4  15 178  13   7   0   7   0]\n [ 13  34  23  19  10  93   7   3   0   1]\n [  8   8  25  20   3   7 182   1   3   2]\n [  1  11  34  13   0   1  12 137   6  11]\n [  4   1   7   1   5  14  18   9 153  11]\n [  1  13  25  19   4   7  13  20   6 116]]\nFold:  3\nEpoch: 1, Train Loss:  1.731, Train Acc: 46.79%, Val Loss:  1.609, Val Acc: 48.68%, Time: 3.89s *\nEpoch: 2, Train Loss: 0.7412, Train Acc: 77.39%, Val Loss:  1.387, Val Acc: 58.25%, Time: 3.67s *\nEpoch: 3, Train Loss: 0.4513, Train Acc: 86.44%, Val Loss:  1.327, Val Acc: 59.74%, Time: 3.68s *\nEpoch: 4, Train Loss: 0.3129, Train Acc: 90.86%, Val Loss:  1.351, Val Acc: 63.70%, Time: 3.68s *\nEpoch: 5, Train Loss:   0.21, Train Acc: 93.75%, Val Loss:  1.343, Val Acc: 62.05%, Time: 3.68s \nEpoch: 6, Train Loss: 0.1629, Train Acc: 95.24%, Val Loss:  1.376, Val Acc: 63.86%, Time: 3.67s *\nEpoch: 7, Train Loss: 0.1155, Train Acc: 96.76%, Val Loss:  1.534, Val Acc: 58.91%, Time: 3.68s \nEpoch: 8, Train Loss: 0.1005, Train Acc: 97.01%, Val Loss:   1.75, Val Acc: 59.90%, Time: 3.69s \nEpoch: 9, Train Loss: 0.07663, Train Acc: 97.81%, Val Loss:  1.694, Val Acc: 62.21%, Time: 3.67s \nEpoch: 10, Train Loss: 0.06095, Train Acc: 98.23%, Val Loss:  1.668, Val Acc: 61.22%, Time: 3.68s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.40      0.33      0.36        64\n                   Filter       0.80      0.61      0.69        46\n    Compute Derived Value       0.23      0.54      0.33        35\n            Find Extremum       0.74      0.96      0.84       115\n                     Sort       0.95      0.62      0.75        65\n          Determine Range       0.79      0.67      0.72        33\nCharacterize Distribution       0.47      0.59      0.52        54\n           Find Anomalies       0.45      0.52      0.48        29\n                  Cluster       0.69      0.53      0.60        55\n                Correlate       0.78      0.55      0.64       110\n\n                micro avg       0.62      0.62      0.62       606\n                macro avg       0.63      0.59      0.59       606\n             weighted avg       0.67      0.62      0.63       606\n\nConfusion Matrix...\n[[ 21   1  34   2   0   1   4   0   1   0]\n [  0  28   5   6   0   0   1   5   0   1]\n [ 14   0  19   1   0   1   0   0   0   0]\n [  1   0   1 110   0   1   0   0   0   2]\n [  0   1   1  15  40   0   1   2   4   1]\n [  0   0   3   3   0  22   3   1   1   0]\n [  8   0   6   6   0   1  32   1   0   0]\n [  3   5   3   1   0   0   1  15   0   1]\n [  0   0   3   1   0   0   7   3  29  12]\n [  5   0   6   3   2   2  19   6   7  60]]\nFold:  4\nEpoch: 1, Train Loss:  1.784, Train Acc: 45.33%, Val Loss:  1.808, Val Acc: 46.48%, Time: 3.78s *\nEpoch: 2, Train Loss: 0.7565, Train Acc: 76.58%, Val Loss:  1.696, Val Acc: 53.76%, Time: 3.48s *\nEpoch: 3, Train Loss:  0.459, Train Acc: 86.25%, Val Loss:  1.599, Val Acc: 59.86%, Time: 3.49s *\nEpoch: 4, Train Loss: 0.3054, Train Acc: 91.15%, Val Loss:  1.683, Val Acc: 57.04%, Time: 3.56s \nEpoch: 5, Train Loss:  0.215, Train Acc: 93.62%, Val Loss:  1.727, Val Acc: 59.78%, Time: 3.55s \nEpoch: 6, Train Loss: 0.1579, Train Acc: 95.38%, Val Loss:  1.955, Val Acc: 58.06%, Time: 3.51s \nEpoch: 7, Train Loss: 0.1228, Train Acc: 96.55%, Val Loss:  2.033, Val Acc: 58.69%, Time: 3.53s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.36      0.36      0.36       111\n                   Filter       0.50      0.57      0.53       121\n    Compute Derived Value       0.28      0.42      0.34       119\n            Find Extremum       0.51      0.75      0.61       121\n                     Sort       0.91      0.92      0.91       123\n          Determine Range       0.85      0.18      0.30       159\nCharacterize Distribution       0.70      0.86      0.77       132\n           Find Anomalies       0.61      0.54      0.57       143\n                  Cluster       0.84      0.69      0.76       123\n                Correlate       0.71      0.69      0.70       126\n\n                micro avg       0.59      0.59      0.59      1278\n                macro avg       0.63      0.60      0.59      1278\n             weighted avg       0.64      0.59      0.58      1278\n\nConfusion Matrix...\n[[ 40  17  22  10   0   1   6  13   0   2]\n [  4  69  11  10   0   1   1  21   0   4]\n [ 26   2  50   4   2   0   4   4   2  25]\n [  2   0  27  91   0   0   1   0   0   0]\n [  0   0   2   6 113   0   1   1   0   0]\n [ 26  33  30  26   1  29   7   1   4   2]\n [  5   0  11   0   0   0 114   0   2   0]\n [  8  18   6  24   2   3   2  77   2   1]\n [  1   0   5   5   5   0  19   1  85   2]\n [  0   0  12   3   1   0   9   8   6  87]]\nFold:  5\nEpoch: 1, Train Loss:   1.82, Train Acc: 44.58%, Val Loss:  1.607, Val Acc: 49.26%, Time: 3.81s *\nEpoch: 2, Train Loss: 0.7519, Train Acc: 76.91%, Val Loss:   1.27, Val Acc: 61.86%, Time: 3.52s *\nEpoch: 3, Train Loss: 0.4638, Train Acc: 86.39%, Val Loss:  1.314, Val Acc: 62.96%, Time: 3.56s *\nEpoch: 4, Train Loss: 0.3052, Train Acc: 91.16%, Val Loss:  1.316, Val Acc: 62.67%, Time: 3.54s \nEpoch: 5, Train Loss: 0.2136, Train Acc: 93.92%, Val Loss:  1.407, Val Acc: 64.29%, Time: 3.50s *\nEpoch: 6, Train Loss: 0.1601, Train Acc: 95.31%, Val Loss:  1.395, Val Acc: 65.76%, Time: 3.47s *\nEpoch: 7, Train Loss: 0.1223, Train Acc: 96.58%, Val Loss:  1.496, Val Acc: 65.46%, Time: 3.49s \nEpoch: 8, Train Loss: 0.09829, Train Acc: 97.36%, Val Loss:  1.686, Val Acc: 63.48%, Time: 3.46s \nEpoch: 9, Train Loss: 0.07537, Train Acc: 97.86%, Val Loss:  1.665, Val Acc: 65.76%, Time: 3.52s \nEpoch: 10, Train Loss: 0.06421, Train Acc: 98.16%, Val Loss:  1.708, Val Acc: 65.68%, Time: 3.50s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.70      0.31      0.43       103\n                   Filter       0.63      0.51      0.56       128\n    Compute Derived Value       0.34      0.60      0.44       162\n            Find Extremum       0.61      0.60      0.61       158\n                     Sort       0.73      0.80      0.76       114\n          Determine Range       0.79      0.72      0.75       149\nCharacterize Distribution       0.77      0.84      0.80       161\n           Find Anomalies       0.82      0.75      0.78       127\n                  Cluster       0.85      0.79      0.82       126\n                Correlate       0.87      0.65      0.75       130\n\n                micro avg       0.66      0.66      0.66      1358\n                macro avg       0.71      0.66      0.67      1358\n             weighted avg       0.70      0.66      0.67      1358\n\nConfusion Matrix...\n[[ 32   2  54   1   0   5   9   0   0   0]\n [  0  65  32   9  12   2   1   4   1   2]\n [  4   2  98  35   1  11   6   4   0   1]\n [  2   9  38  95   0   4   4   3   0   3]\n [  0   3   9   4  91   0   4   0   3   0]\n [  1   2  15   2  14 107   7   1   0   0]\n [  3  11   6   1   1   2 135   2   0   0]\n [  0   6   8   6   0   0   1  95   6   5]\n [  0   1   4   1   6   5   2   6  99   2]\n [  4   2  23   1   0   0   7   1   7  85]]\nFold:  6\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.831, Train Acc: 44.35%, Val Loss:  1.573, Val Acc: 48.13%, Time: 3.59s *\nEpoch: 2, Train Loss: 0.7872, Train Acc: 75.86%, Val Loss:  1.307, Val Acc: 58.13%, Time: 3.43s *\nEpoch: 3, Train Loss: 0.4837, Train Acc: 85.79%, Val Loss:  1.249, Val Acc: 63.17%, Time: 3.42s *\nEpoch: 4, Train Loss: 0.3291, Train Acc: 90.36%, Val Loss:  1.303, Val Acc: 62.43%, Time: 3.43s \nEpoch: 5, Train Loss: 0.2299, Train Acc: 93.42%, Val Loss:  1.421, Val Acc: 61.20%, Time: 3.41s \nEpoch: 6, Train Loss: 0.1651, Train Acc: 95.28%, Val Loss:  1.467, Val Acc: 62.12%, Time: 3.41s \nEpoch: 7, Train Loss: 0.1223, Train Acc: 96.57%, Val Loss:  1.505, Val Acc: 62.00%, Time: 3.41s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.72      0.42      0.53       168\n                   Filter       0.46      0.56      0.50       201\n    Compute Derived Value       0.50      0.45      0.47       180\n            Find Extremum       0.61      0.86      0.71       184\n                     Sort       0.77      0.63      0.69       119\n          Determine Range       0.46      0.62      0.53       159\nCharacterize Distribution       0.75      0.75      0.75       118\n           Find Anomalies       0.68      0.76      0.72       169\n                  Cluster       0.82      0.64      0.72       150\n                Correlate       0.84      0.59      0.69       181\n\n                micro avg       0.62      0.62      0.62      1629\n                macro avg       0.66      0.63      0.63      1629\n             weighted avg       0.65      0.62      0.62      1629\n\nConfusion Matrix...\n[[ 71  17  35  15   4  18   4   2   1   1]\n [ 10 113  15   6   4  40   0  11   1   1]\n [  8  10  81  35   4  24   8   5   1   4]\n [  3   6   4 158   0   1   1   6   4   1]\n [  0   4   2  31  75   5   0   1   0   1]\n [  1  13  12   7   5  98   5   6   8   4]\n [  0   5   0   3   2  15  88   2   3   0]\n [  1  31   0   4   0   0   1 128   0   4]\n [  1  17   1   0   2   5   6  17  96   5]\n [  3  31  12   2   1   6   5  11   3 107]]\nFold:  7\nEpoch: 1, Train Loss:  1.861, Train Acc: 42.82%, Val Loss:   1.74, Val Acc: 48.24%, Time: 3.64s *\nEpoch: 2, Train Loss: 0.7716, Train Acc: 76.03%, Val Loss:  1.474, Val Acc: 58.24%, Time: 3.46s *\nEpoch: 3, Train Loss:  0.461, Train Acc: 86.12%, Val Loss:  1.472, Val Acc: 60.35%, Time: 3.49s *\nEpoch: 4, Train Loss: 0.3027, Train Acc: 91.14%, Val Loss:  1.601, Val Acc: 60.63%, Time: 3.47s *\nEpoch: 5, Train Loss: 0.2224, Train Acc: 93.77%, Val Loss:  1.733, Val Acc: 60.14%, Time: 3.49s \nEpoch: 6, Train Loss: 0.1625, Train Acc: 95.22%, Val Loss:  1.883, Val Acc: 63.10%, Time: 3.50s *\nEpoch: 7, Train Loss: 0.1143, Train Acc: 96.59%, Val Loss:   1.89, Val Acc: 62.39%, Time: 3.55s \nEpoch: 8, Train Loss: 0.09256, Train Acc: 97.39%, Val Loss:  2.005, Val Acc: 62.89%, Time: 3.44s \nEpoch: 9, Train Loss: 0.07313, Train Acc: 97.78%, Val Loss:  2.065, Val Acc: 61.97%, Time: 3.45s \nEpoch: 10, Train Loss: 0.05994, Train Acc: 98.29%, Val Loss:  2.049, Val Acc: 61.90%, Time: 3.49s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.53      0.05      0.10       168\n                   Filter       0.54      0.50      0.52       159\n    Compute Derived Value       0.49      0.76      0.60       127\n            Find Extremum       0.46      0.76      0.57       114\n                     Sort       0.80      0.80      0.80       152\n          Determine Range       0.82      0.71      0.76       140\nCharacterize Distribution       0.76      0.59      0.67       143\n           Find Anomalies       0.56      0.63      0.59       137\n                  Cluster       0.91      0.79      0.84       146\n                Correlate       0.62      0.94      0.75       134\n\n                micro avg       0.64      0.64      0.64      1420\n                macro avg       0.65      0.65      0.62      1420\n             weighted avg       0.65      0.64      0.61      1420\n\nConfusion Matrix...\n[[  9  23  65  46   7   2   5   1   0  10]\n [  6  79   5  24   1   1   4  23   5  11]\n [  1   3  97   8   1   3   6   8   0   0]\n [  0   2   3  87   9   0   1  12   0   0]\n [  0   4   3   4 122   8   3   3   5   0]\n [  0  21   2   6   1  99   3   3   1   4]\n [  0   4  13   6   0   4  85  12   0  19]\n [  1   3   7   7   2   3   1  86   1  26]\n [  0   7   0   1   9   0   3   5 115   6]\n [  0   1   3   2   0   0   1   1   0 126]]\nFold:  8\nEpoch: 1, Train Loss:   1.79, Train Acc: 44.40%, Val Loss:  1.637, Val Acc: 51.07%, Time: 3.72s *\nEpoch: 2, Train Loss: 0.7599, Train Acc: 76.37%, Val Loss:  1.398, Val Acc: 61.20%, Time: 3.52s *\nEpoch: 3, Train Loss: 0.4679, Train Acc: 86.11%, Val Loss:  1.348, Val Acc: 64.89%, Time: 3.53s *\nEpoch: 4, Train Loss: 0.3105, Train Acc: 91.09%, Val Loss:   1.45, Val Acc: 65.84%, Time: 3.55s *\nEpoch: 5, Train Loss: 0.2186, Train Acc: 93.64%, Val Loss:  1.519, Val Acc: 65.58%, Time: 3.51s \nEpoch: 6, Train Loss: 0.1641, Train Acc: 95.20%, Val Loss:  1.402, Val Acc: 67.38%, Time: 3.54s *\nEpoch: 7, Train Loss: 0.1263, Train Acc: 96.51%, Val Loss:  1.606, Val Acc: 65.49%, Time: 3.52s \nEpoch: 8, Train Loss: 0.09561, Train Acc: 97.22%, Val Loss:  1.576, Val Acc: 69.70%, Time: 3.53s *\nEpoch: 9, Train Loss: 0.07569, Train Acc: 97.96%, Val Loss:   1.66, Val Acc: 68.58%, Time: 3.52s \nEpoch: 10, Train Loss: 0.06319, Train Acc: 98.22%, Val Loss:  1.638, Val Acc: 68.07%, Time: 3.51s \nEpoch: 11, Train Loss: 0.05194, Train Acc: 98.54%, Val Loss:  1.721, Val Acc: 68.58%, Time: 3.53s \nEpoch: 12, Train Loss: 0.04733, Train Acc: 98.66%, Val Loss:   1.74, Val Acc: 68.93%, Time: 3.51s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.76      0.75      0.76       102\n                   Filter       0.56      0.52      0.54       109\n    Compute Derived Value       0.51      0.54      0.53       167\n            Find Extremum       0.74      0.88      0.80       194\n                     Sort       0.67      0.74      0.70        94\n          Determine Range       0.69      0.73      0.71       128\nCharacterize Distribution       0.71      0.63      0.67        65\n           Find Anomalies       0.71      0.79      0.74        89\n                  Cluster       0.88      0.63      0.73        97\n                Correlate       0.70      0.53      0.61       120\n\n                micro avg       0.68      0.68      0.68      1165\n                macro avg       0.69      0.67      0.68      1165\n             weighted avg       0.69      0.68      0.68      1165\n\nConfusion Matrix...\n[[ 77  10  10   3   0   1   1   0   0   0]\n [  0  57  26   9   1   1   0   7   0   8]\n [  2   8  91  31   3  19   2   6   1   4]\n [  3   6   2 170   9   1   0   3   0   0]\n [  6  10   3   4  70   1   0   0   0   0]\n [  5   5   9   7   4  93   3   1   1   0]\n [  1   0   9   0   1   2  41   0   1  10]\n [  1   2  10   0   0   1   2  70   3   0]\n [  1   0   3   2  17   2   4   2  61   5]\n [  5   3  14   4   0  13   5  10   2  64]]\nFold:  9\nEpoch: 1, Train Loss:  1.782, Train Acc: 45.47%, Val Loss:  1.359, Val Acc: 59.33%, Time: 3.90s *\nEpoch: 2, Train Loss: 0.7682, Train Acc: 76.38%, Val Loss:  1.198, Val Acc: 61.48%, Time: 3.73s *\nEpoch: 3, Train Loss: 0.4682, Train Acc: 85.88%, Val Loss:  1.255, Val Acc: 59.33%, Time: 3.70s \nEpoch: 4, Train Loss: 0.3137, Train Acc: 90.72%, Val Loss:  1.257, Val Acc: 63.16%, Time: 3.73s *\nEpoch: 5, Train Loss: 0.2234, Train Acc: 93.40%, Val Loss:  1.469, Val Acc: 59.33%, Time: 3.75s \nEpoch: 6, Train Loss: 0.1642, Train Acc: 95.22%, Val Loss:  1.328, Val Acc: 63.16%, Time: 3.75s \nEpoch: 7, Train Loss: 0.1234, Train Acc: 96.43%, Val Loss:  1.304, Val Acc: 64.59%, Time: 3.72s *\nEpoch: 8, Train Loss: 0.09735, Train Acc: 97.24%, Val Loss:  1.529, Val Acc: 59.81%, Time: 3.72s \nEpoch: 9, Train Loss: 0.07994, Train Acc: 97.78%, Val Loss:  1.488, Val Acc: 62.68%, Time: 3.71s \nEpoch: 10, Train Loss: 0.06585, Train Acc: 98.03%, Val Loss:   1.62, Val Acc: 61.00%, Time: 3.72s \n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 11, Train Loss: 0.05274, Train Acc: 98.50%, Val Loss:  1.703, Val Acc: 61.00%, Time: 3.76s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.36      0.12      0.18        34\n                   Filter       0.39      0.41      0.40        32\n    Compute Derived Value       0.64      0.67      0.65        63\n            Find Extremum       1.00      0.82      0.90        77\n                     Sort       0.67      0.62      0.64        26\n          Determine Range       0.30      0.72      0.42        29\nCharacterize Distribution       0.37      0.36      0.36        45\n           Find Anomalies       0.73      0.33      0.46        33\n                  Cluster       0.72      0.60      0.65        30\n                Correlate       0.66      0.90      0.76        49\n\n                micro avg       0.59      0.59      0.59       418\n                macro avg       0.58      0.55      0.54       418\n             weighted avg       0.63      0.59      0.59       418\n\nConfusion Matrix...\n[[ 4  6 10  0  1 11  0  0  0  2]\n [ 0 13  6  0  2 10  1  0  0  0]\n [ 0  0 42  0  0 12  6  0  0  3]\n [ 0  1  2 63  3  8  0  0  0  0]\n [ 0  0  0  0 16  0  5  0  5  0]\n [ 0  0  3  0  1 21  4  0  0  0]\n [ 7  0  2  0  0  3 16  0  1 16]\n [ 0 13  0  0  0  4  4 11  1  0]\n [ 0  0  0  0  1  2  6  1 18  2]\n [ 0  0  1  0  0  0  1  3  0 44]]\nFold:  10\nEpoch: 1, Train Loss:  1.793, Train Acc: 44.70%, Val Loss:   1.36, Val Acc: 58.97%, Time: 3.70s *\nEpoch: 2, Train Loss: 0.7596, Train Acc: 76.82%, Val Loss:  1.142, Val Acc: 64.04%, Time: 3.48s *\nEpoch: 3, Train Loss: 0.4692, Train Acc: 85.82%, Val Loss:  1.182, Val Acc: 66.05%, Time: 3.51s *\nEpoch: 4, Train Loss: 0.3067, Train Acc: 91.19%, Val Loss:  1.159, Val Acc: 66.45%, Time: 3.66s *\nEpoch: 5, Train Loss: 0.2247, Train Acc: 93.46%, Val Loss:  1.233, Val Acc: 66.29%, Time: 3.52s \nEpoch: 6, Train Loss: 0.1618, Train Acc: 95.45%, Val Loss:  1.336, Val Acc: 65.97%, Time: 3.49s \nEpoch: 7, Train Loss:  0.128, Train Acc: 96.22%, Val Loss:  1.429, Val Acc: 66.29%, Time: 3.52s \nEpoch: 8, Train Loss: 0.09352, Train Acc: 97.32%, Val Loss:  1.748, Val Acc: 63.64%, Time: 3.50s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.56      0.71      0.63       161\n                   Filter       0.49      0.50      0.49       163\n    Compute Derived Value       0.91      0.43      0.58       148\n            Find Extremum       0.54      0.88      0.67       175\n                     Sort       0.76      0.82      0.79        62\n          Determine Range       0.64      0.17      0.27        80\nCharacterize Distribution       0.92      0.77      0.84       107\n           Find Anomalies       0.69      0.55      0.61       144\n                  Cluster       0.62      0.85      0.72        55\n                Correlate       0.86      0.86      0.86       148\n\n                micro avg       0.65      0.65      0.65      1243\n                macro avg       0.70      0.65      0.65      1243\n             weighted avg       0.69      0.65      0.64      1243\n\nConfusion Matrix...\n[[115   7   0  19   0   0   0  18   2   0]\n [ 42  81   0  30   2   1   0   5   0   2]\n [ 37  22  63  12   0   1   0   7   2   4]\n [  2   4   2 154   9   0   0   2   1   1]\n [  1   0   0   8  51   0   0   0   2   0]\n [  1   8   2  46   3  14   5   0   1   0]\n [  3   3   2   2   0   2  82   1   8   4]\n [  4  30   0   6   1   3   1  79  13   7]\n [  1   1   0   2   1   1   0   0  47   2]\n [  1  11   0   6   0   0   1   2   0 127]]\n[0.6887470071827614, 0.5978441127694859, 0.6204620462046204, 0.5907668231611893, 0.6642120765832106, 0.6230816451810927, 0.6373239436619719, 0.6815450643776824, 0.5933014354066986, 0.6540627514078842]\n0.6351346905936597, 0.034214675897310844, 0.03606543507998919, 0.0011706440467580234\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "kf = KFold(n_splits=10)\ntest_acc_split = []\nfor split_type,info in split_info.items():\n    train_data = dataset_split(info)\n    test_acc_split.append(train_split_data(train_data, split_type))", "execution_count": null, "outputs": [{"output_type": "stream", "text": "random\n14035 41 41\nFold:  1\nEpoch: 1, Train Loss:  1.721, Train Acc: 48.15%, Val Loss: 0.9305, Val Acc: 71.30%, Time: 54.91s *\nEpoch: 2, Train Loss:  0.659, Train Acc: 79.91%, Val Loss: 0.5716, Val Acc: 82.69%, Time: 54.80s *\nEpoch: 3, Train Loss: 0.3863, Train Acc: 88.56%, Val Loss: 0.4205, Val Acc: 87.32%, Time: 54.21s *\nEpoch: 4, Train Loss: 0.2544, Train Acc: 92.69%, Val Loss: 0.3696, Val Acc: 89.46%, Time: 54.69s *\nEpoch: 5, Train Loss: 0.1841, Train Acc: 94.77%, Val Loss:  0.306, Val Acc: 90.60%, Time: 55.56s *\nEpoch: 6, Train Loss: 0.1327, Train Acc: 96.26%, Val Loss: 0.3011, Val Acc: 90.81%, Time: 54.52s *\nEpoch: 7, Train Loss: 0.1044, Train Acc: 97.15%, Val Loss: 0.2641, Val Acc: 92.17%, Time: 54.46s *\nEpoch: 8, Train Loss: 0.08492, Train Acc: 97.56%, Val Loss: 0.2606, Val Acc: 91.95%, Time: 54.39s \nEpoch: 9, Train Loss: 0.06751, Train Acc: 98.17%, Val Loss: 0.2519, Val Acc: 93.23%, Time: 54.23s *\nEpoch: 10, Train Loss: 0.05726, Train Acc: 98.41%, Val Loss: 0.2443, Val Acc: 93.02%, Time: 53.40s \nEpoch: 11, Train Loss: 0.05206, Train Acc: 98.45%, Val Loss: 0.2371, Val Acc: 93.09%, Time: 53.89s \nEpoch: 12, Train Loss: 0.04364, Train Acc: 98.73%, Val Loss: 0.2555, Val Acc: 93.16%, Time: 54.16s \nEpoch: 13, Train Loss: 0.03432, Train Acc: 99.03%, Val Loss: 0.2344, Val Acc: 93.87%, Time: 49.26s *\nEpoch: 14, Train Loss: 0.03275, Train Acc: 99.01%, Val Loss:  0.228, Val Acc: 93.45%, Time: 54.16s \nEpoch: 15, Train Loss: 0.03216, Train Acc: 98.94%, Val Loss:  0.243, Val Acc: 93.95%, Time: 53.60s *\nEpoch: 16, Train Loss: 0.0315, Train Acc: 99.00%, Val Loss:  0.226, Val Acc: 94.09%, Time: 54.42s *\nEpoch: 17, Train Loss: 0.03003, Train Acc: 99.11%, Val Loss: 0.2254, Val Acc: 93.38%, Time: 54.34s \nEpoch: 18, Train Loss: 0.02694, Train Acc: 99.07%, Val Loss: 0.2318, Val Acc: 94.30%, Time: 53.71s *\nEpoch: 19, Train Loss: 0.02554, Train Acc: 99.14%, Val Loss: 0.2681, Val Acc: 93.59%, Time: 53.99s \nEpoch: 20, Train Loss: 0.0201, Train Acc: 99.41%, Val Loss:  0.259, Val Acc: 93.95%, Time: 53.50s \nEpoch: 21, Train Loss: 0.02204, Train Acc: 99.37%, Val Loss:  0.278, Val Acc: 94.09%, Time: 54.13s \nEpoch: 22, Train Loss: 0.01815, Train Acc: 99.39%, Val Loss: 0.3247, Val Acc: 93.38%, Time: 54.06s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.98      0.95      0.97       147\n                   Filter       0.83      0.94      0.89       144\n    Compute Derived Value       0.98      0.94      0.96       162\n            Find Extremum       0.95      0.92      0.93       142\n                     Sort       0.94      0.97      0.96       119\n          Determine Range       0.86      0.93      0.89       113\nCharacterize Distribution       0.99      0.84      0.91       130\n           Find Anomalies       0.94      0.96      0.95       146\n                  Cluster       0.90      0.96      0.93       130\n                Correlate       0.96      0.92      0.94       171\n\n                micro avg       0.93      0.93      0.93      1404\n                macro avg       0.93      0.93      0.93      1404\n             weighted avg       0.94      0.93      0.93      1404\n\nConfusion Matrix...\n[[140   5   0   1   0   0   0   0   1   0]\n [  0 136   0   1   0   3   0   1   3   0]\n [  2   4 152   1   0   2   0   0   0   1]\n [  0   3   1 130   4   4   0   0   0   0]\n [  0   1   0   0 116   0   0   0   2   0]\n [  0   4   1   0   1 105   0   1   1   0]\n [  0   5   1   1   1   4 109   2   3   4]\n [  1   3   0   1   0   0   0 140   0   1]\n [  0   0   0   2   1   1   0   1 125   0]\n [  0   2   0   0   0   3   1   4   4 157]]\nFold:  2\nEpoch: 1, Train Loss:  1.695, Train Acc: 49.86%, Val Loss: 0.9545, Val Acc: 69.66%, Time: 54.16s *\nEpoch: 2, Train Loss: 0.6565, Train Acc: 80.32%, Val Loss: 0.5896, Val Acc: 82.41%, Time: 53.77s *\nEpoch: 3, Train Loss: 0.3863, Train Acc: 88.71%, Val Loss: 0.4317, Val Acc: 87.75%, Time: 53.93s *\nEpoch: 4, Train Loss:  0.261, Train Acc: 92.47%, Val Loss: 0.3623, Val Acc: 88.39%, Time: 54.20s *\nEpoch: 5, Train Loss: 0.1782, Train Acc: 94.95%, Val Loss: 0.2831, Val Acc: 91.81%, Time: 53.82s *\nEpoch: 6, Train Loss: 0.1347, Train Acc: 96.24%, Val Loss: 0.2891, Val Acc: 91.67%, Time: 53.59s \nEpoch: 7, Train Loss: 0.1027, Train Acc: 97.19%, Val Loss: 0.2666, Val Acc: 92.09%, Time: 53.77s *\nEpoch: 8, Train Loss: 0.08205, Train Acc: 97.54%, Val Loss: 0.2716, Val Acc: 92.02%, Time: 54.37s \nEpoch: 9, Train Loss: 0.06962, Train Acc: 97.94%, Val Loss: 0.2457, Val Acc: 92.66%, Time: 53.79s *\nEpoch: 10, Train Loss: 0.0556, Train Acc: 98.47%, Val Loss: 0.2582, Val Acc: 92.24%, Time: 53.68s \nEpoch: 11, Train Loss: 0.04913, Train Acc: 98.68%, Val Loss: 0.1878, Val Acc: 95.01%, Time: 54.51s *\nEpoch: 12, Train Loss: 0.04046, Train Acc: 98.85%, Val Loss:  0.249, Val Acc: 93.52%, Time: 54.18s \nEpoch: 13, Train Loss: 0.04304, Train Acc: 98.67%, Val Loss: 0.2145, Val Acc: 93.80%, Time: 53.61s \nEpoch: 14, Train Loss: 0.03186, Train Acc: 99.09%, Val Loss: 0.2366, Val Acc: 93.59%, Time: 54.35s \nEpoch: 15, Train Loss: 0.03085, Train Acc: 99.03%, Val Loss: 0.2303, Val Acc: 93.87%, Time: 53.95s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.98      0.96      0.97       120\n                   Filter       0.93      0.90      0.92       142\n    Compute Derived Value       0.88      0.94      0.91       156\n            Find Extremum       0.99      0.92      0.95       171\n                     Sort       0.94      0.96      0.95       117\n          Determine Range       0.90      0.96      0.93       139\nCharacterize Distribution       0.99      0.94      0.97       139\n           Find Anomalies       0.91      0.94      0.92       152\n                  Cluster       0.96      0.94      0.95       141\n                Correlate       0.92      0.94      0.93       127\n\n                micro avg       0.94      0.94      0.94      1404\n                macro avg       0.94      0.94      0.94      1404\n             weighted avg       0.94      0.94      0.94      1404\n\nConfusion Matrix...\n[[115   0   3   0   0   0   0   2   0   0]\n [  0 128   3   0   1   5   0   4   0   1]\n [  1   3 146   0   1   2   0   1   1   1]\n [  0   1   3 158   4   2   0   2   0   1]\n [  1   0   0   1 112   1   0   0   2   0]\n [  0   0   2   0   0 134   1   1   0   1]\n [  0   1   4   0   0   0 131   2   1   0]\n [  0   2   0   1   0   3   0 143   1   2]\n [  0   0   2   0   0   1   0   2 132   4]\n [  0   2   2   0   1   1   0   1   0 120]]\nFold:  3\nEpoch: 1, Train Loss:  1.696, Train Acc: 49.28%, Val Loss: 0.8944, Val Acc: 72.79%, Time: 49.09s *\nEpoch: 2, Train Loss: 0.6571, Train Acc: 80.17%, Val Loss: 0.5579, Val Acc: 84.19%, Time: 54.48s *\nEpoch: 3, Train Loss: 0.3871, Train Acc: 88.63%, Val Loss: 0.3979, Val Acc: 87.96%, Time: 53.62s *\nEpoch: 4, Train Loss: 0.2596, Train Acc: 92.56%, Val Loss: 0.3318, Val Acc: 90.38%, Time: 53.55s *\nEpoch: 5, Train Loss: 0.1865, Train Acc: 94.67%, Val Loss: 0.2961, Val Acc: 91.31%, Time: 54.25s *\nEpoch: 6, Train Loss: 0.1412, Train Acc: 95.97%, Val Loss: 0.2773, Val Acc: 91.88%, Time: 53.92s *\nEpoch: 7, Train Loss: 0.1078, Train Acc: 97.04%, Val Loss:  0.238, Val Acc: 93.52%, Time: 53.91s *\nEpoch: 8, Train Loss: 0.08039, Train Acc: 97.80%, Val Loss: 0.2283, Val Acc: 93.87%, Time: 54.07s *\nEpoch: 9, Train Loss: 0.07435, Train Acc: 98.04%, Val Loss:  0.215, Val Acc: 93.80%, Time: 53.95s \nEpoch: 10, Train Loss: 0.0593, Train Acc: 98.25%, Val Loss: 0.2261, Val Acc: 94.73%, Time: 53.25s *\nEpoch: 11, Train Loss: 0.04871, Train Acc: 98.71%, Val Loss: 0.2353, Val Acc: 94.09%, Time: 53.84s \nEpoch: 12, Train Loss: 0.04487, Train Acc: 98.57%, Val Loss: 0.2539, Val Acc: 93.30%, Time: 54.23s \nEpoch: 13, Train Loss: 0.04302, Train Acc: 98.81%, Val Loss: 0.2337, Val Acc: 94.52%, Time: 54.09s \nEpoch: 14, Train Loss: 0.03602, Train Acc: 98.88%, Val Loss: 0.2434, Val Acc: 94.66%, Time: 53.22s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.94      0.99      0.97       130\n                   Filter       0.89      0.95      0.92       144\n    Compute Derived Value       0.93      0.92      0.93       139\n            Find Extremum       0.98      0.93      0.95       168\n                     Sort       0.90      0.97      0.94       114\n          Determine Range       0.91      0.95      0.93       147\nCharacterize Distribution       0.95      0.94      0.95       149\n           Find Anomalies       0.97      0.93      0.95       123\n                  Cluster       0.98      0.93      0.96       133\n                Correlate       0.98      0.92      0.95       157\n\n                micro avg       0.94      0.94      0.94      1404\n                macro avg       0.94      0.94      0.94      1404\n             weighted avg       0.95      0.94      0.94      1404\n\nConfusion Matrix...\n[[129   0   0   1   0   0   0   0   0   0]\n [  0 137   1   0   1   2   0   2   1   0]\n [  1   5 128   0   2   3   0   0   0   0]\n [  1   2   2 157   3   3   0   0   0   0]\n [  0   1   1   1 111   0   0   0   0   0]\n [  0   0   2   1   1 140   3   0   0   0]\n [  1   3   1   0   1   2 140   0   0   1]\n [  1   4   1   0   0   0   1 114   0   2]\n [  1   1   0   1   2   3   1   0 124   0]\n [  3   1   1   0   2   1   2   1   1 145]]\nFold:  4\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.709, Train Acc: 48.65%, Val Loss: 0.8859, Val Acc: 72.15%, Time: 53.89s *\nEpoch: 2, Train Loss: 0.6522, Train Acc: 80.17%, Val Loss: 0.5756, Val Acc: 83.05%, Time: 53.17s *\nEpoch: 3, Train Loss: 0.3933, Train Acc: 88.60%, Val Loss: 0.4061, Val Acc: 87.39%, Time: 54.41s *\nEpoch: 4, Train Loss: 0.2686, Train Acc: 92.38%, Val Loss: 0.3286, Val Acc: 90.03%, Time: 49.41s *\nEpoch: 5, Train Loss: 0.1823, Train Acc: 94.98%, Val Loss: 0.3236, Val Acc: 90.31%, Time: 54.95s *\nEpoch: 6, Train Loss: 0.1359, Train Acc: 96.19%, Val Loss: 0.2738, Val Acc: 91.67%, Time: 53.75s *\nEpoch: 7, Train Loss: 0.1077, Train Acc: 96.96%, Val Loss: 0.2733, Val Acc: 91.81%, Time: 54.28s *\nEpoch: 8, Train Loss: 0.08884, Train Acc: 97.48%, Val Loss: 0.2216, Val Acc: 94.23%, Time: 53.74s *\nEpoch: 9, Train Loss: 0.07443, Train Acc: 97.81%, Val Loss: 0.2339, Val Acc: 92.74%, Time: 54.85s \nEpoch: 10, Train Loss: 0.05679, Train Acc: 98.38%, Val Loss: 0.2421, Val Acc: 93.87%, Time: 54.81s \nEpoch: 11, Train Loss: 0.05119, Train Acc: 98.42%, Val Loss:  0.194, Val Acc: 94.73%, Time: 54.06s *\nEpoch: 12, Train Loss: 0.04185, Train Acc: 98.96%, Val Loss: 0.1935, Val Acc: 93.73%, Time: 54.06s \nEpoch: 13, Train Loss: 0.03312, Train Acc: 99.06%, Val Loss: 0.2259, Val Acc: 94.09%, Time: 53.56s \nEpoch: 14, Train Loss: 0.03439, Train Acc: 99.01%, Val Loss:  0.218, Val Acc: 94.52%, Time: 53.74s \nEpoch: 15, Train Loss: 0.03437, Train Acc: 98.88%, Val Loss: 0.2044, Val Acc: 94.59%, Time: 54.34s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.96      0.94      0.95       145\n                   Filter       0.95      0.87      0.90       163\n    Compute Derived Value       0.94      0.97      0.96       146\n            Find Extremum       0.97      0.96      0.97       173\n                     Sort       0.93      0.94      0.93       120\n          Determine Range       0.94      0.93      0.93       109\nCharacterize Distribution       0.92      0.93      0.92       122\n           Find Anomalies       0.90      0.94      0.92       142\n                  Cluster       0.89      0.93      0.91       128\n                Correlate       0.97      0.97      0.97       156\n\n                micro avg       0.94      0.94      0.94      1404\n                macro avg       0.94      0.94      0.94      1404\n             weighted avg       0.94      0.94      0.94      1404\n\nConfusion Matrix...\n[[136   2   4   0   0   1   1   0   1   0]\n [  2 141   3   1   2   3   1   9   1   0]\n [  2   0 142   1   0   0   0   0   0   1]\n [  0   0   1 166   2   0   1   2   1   0]\n [  0   1   1   0 113   0   0   0   4   1]\n [  2   0   0   0   1 101   2   0   2   1]\n [  0   1   0   2   2   1 113   0   1   2]\n [  0   2   0   0   1   2   1 134   2   0]\n [  0   2   0   0   1   0   3   3 119   0]\n [  0   0   0   1   0   0   1   1   2 151]]\nFold:  5\nEpoch: 1, Train Loss:  1.675, Train Acc: 49.47%, Val Loss: 0.9131, Val Acc: 72.58%, Time: 54.47s *\nEpoch: 2, Train Loss: 0.6499, Train Acc: 79.95%, Val Loss:  0.571, Val Acc: 83.40%, Time: 54.00s *\nEpoch: 3, Train Loss: 0.3836, Train Acc: 88.72%, Val Loss: 0.4336, Val Acc: 87.25%, Time: 53.86s *\nEpoch: 4, Train Loss: 0.2482, Train Acc: 92.68%, Val Loss: 0.3688, Val Acc: 89.17%, Time: 54.21s *\nEpoch: 5, Train Loss: 0.1838, Train Acc: 94.53%, Val Loss: 0.3118, Val Acc: 90.60%, Time: 53.71s *\nEpoch: 6, Train Loss: 0.1384, Train Acc: 95.99%, Val Loss: 0.2835, Val Acc: 91.67%, Time: 48.72s *\nEpoch: 7, Train Loss: 0.09982, Train Acc: 97.06%, Val Loss: 0.2676, Val Acc: 91.74%, Time: 54.24s *\nEpoch: 8, Train Loss: 0.08213, Train Acc: 97.77%, Val Loss: 0.2377, Val Acc: 93.02%, Time: 53.44s *\nEpoch: 9, Train Loss: 0.06642, Train Acc: 98.18%, Val Loss: 0.2562, Val Acc: 92.24%, Time: 53.99s \nEpoch: 10, Train Loss: 0.05266, Train Acc: 98.47%, Val Loss: 0.2348, Val Acc: 93.45%, Time: 53.94s *\nEpoch: 11, Train Loss: 0.04495, Train Acc: 98.61%, Val Loss: 0.2201, Val Acc: 94.16%, Time: 54.33s *\nEpoch: 12, Train Loss: 0.04451, Train Acc: 98.68%, Val Loss: 0.2907, Val Acc: 92.81%, Time: 53.89s \nEpoch: 13, Train Loss: 0.03613, Train Acc: 98.86%, Val Loss: 0.2501, Val Acc: 93.30%, Time: 53.65s \nEpoch: 14, Train Loss: 0.03468, Train Acc: 98.88%, Val Loss: 0.2449, Val Acc: 93.73%, Time: 53.99s \nEpoch: 15, Train Loss: 0.03708, Train Acc: 98.90%, Val Loss: 0.2583, Val Acc: 93.02%, Time: 54.53s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.99      0.96      0.98       134\n                   Filter       0.88      0.94      0.91       139\n    Compute Derived Value       0.97      0.97      0.97       160\n            Find Extremum       0.97      0.94      0.95       153\n                     Sort       0.97      0.95      0.96       133\n          Determine Range       0.95      0.88      0.91       126\nCharacterize Distribution       0.86      0.91      0.89       128\n           Find Anomalies       0.93      0.93      0.93       139\n                  Cluster       0.93      0.97      0.95       130\n                Correlate       0.95      0.93      0.94       162\n\n                micro avg       0.94      0.94      0.94      1404\n                macro avg       0.94      0.94      0.94      1404\n             weighted avg       0.94      0.94      0.94      1404\n\nConfusion Matrix...\n[[129   2   1   1   0   0   0   0   1   0]\n [  0 131   1   1   0   1   1   4   0   0]\n [  0   1 155   1   0   0   2   0   1   0]\n [  0   2   0 144   2   1   0   2   1   1]\n [  0   1   1   1 126   0   1   0   3   0]\n [  1   4   0   1   2 111   4   1   1   1]\n [  0   1   0   0   0   3 117   1   1   5]\n [  0   5   2   0   0   0   2 129   0   1]\n [  0   0   0   0   0   0   4   0 126   0]\n [  0   2   0   0   0   1   5   2   2 150]]\nFold:  6\nEpoch: 1, Train Loss:  1.651, Train Acc: 50.54%, Val Loss: 0.8604, Val Acc: 74.63%, Time: 54.26s *\nEpoch: 2, Train Loss: 0.6414, Train Acc: 81.14%, Val Loss: 0.5591, Val Acc: 82.89%, Time: 53.85s *\nEpoch: 3, Train Loss: 0.3879, Train Acc: 88.81%, Val Loss: 0.3742, Val Acc: 88.45%, Time: 54.70s *\nEpoch: 4, Train Loss:  0.256, Train Acc: 92.40%, Val Loss: 0.3315, Val Acc: 89.88%, Time: 54.26s *\nEpoch: 5, Train Loss: 0.1755, Train Acc: 95.21%, Val Loss:  0.297, Val Acc: 90.88%, Time: 53.73s *\nEpoch: 6, Train Loss: 0.1287, Train Acc: 96.41%, Val Loss:  0.273, Val Acc: 92.02%, Time: 54.21s *\nEpoch: 7, Train Loss: 0.09793, Train Acc: 97.42%, Val Loss: 0.2621, Val Acc: 92.44%, Time: 54.42s *\nEpoch: 8, Train Loss: 0.08385, Train Acc: 97.59%, Val Loss: 0.2143, Val Acc: 93.87%, Time: 54.19s *\nEpoch: 9, Train Loss: 0.06421, Train Acc: 98.20%, Val Loss: 0.2583, Val Acc: 92.59%, Time: 54.23s \nEpoch: 10, Train Loss: 0.05536, Train Acc: 98.49%, Val Loss: 0.2441, Val Acc: 92.73%, Time: 54.85s \nEpoch: 11, Train Loss: 0.05228, Train Acc: 98.48%, Val Loss: 0.2297, Val Acc: 93.44%, Time: 54.32s \nEpoch: 12, Train Loss: 0.04506, Train Acc: 98.72%, Val Loss: 0.2238, Val Acc: 94.16%, Time: 54.46s *\nEpoch: 13, Train Loss: 0.04032, Train Acc: 98.82%, Val Loss: 0.2242, Val Acc: 94.08%, Time: 55.91s \nEpoch: 14, Train Loss: 0.03702, Train Acc: 98.83%, Val Loss: 0.2016, Val Acc: 94.30%, Time: 55.38s *\nEpoch: 15, Train Loss: 0.02957, Train Acc: 99.07%, Val Loss: 0.1858, Val Acc: 95.30%, Time: 54.37s *\nEpoch: 16, Train Loss: 0.03032, Train Acc: 99.08%, Val Loss: 0.1964, Val Acc: 94.94%, Time: 66.54s \nEpoch: 17, Train Loss: 0.02565, Train Acc: 99.24%, Val Loss: 0.2042, Val Acc: 94.65%, Time: 54.14s \nEpoch: 18, Train Loss: 0.02628, Train Acc: 99.18%, Val Loss: 0.2756, Val Acc: 94.65%, Time: 54.56s \nEpoch: 19, Train Loss: 0.02387, Train Acc: 99.30%, Val Loss: 0.2272, Val Acc: 94.23%, Time: 49.13s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.98      0.97      0.97       123\n                   Filter       0.93      0.90      0.91       139\n    Compute Derived Value       0.94      0.96      0.95       156\n            Find Extremum       0.97      0.97      0.97       192\n                     Sort       0.97      0.99      0.98       119\n          Determine Range       0.97      0.97      0.97       128\nCharacterize Distribution       0.94      0.96      0.95       137\n           Find Anomalies       0.92      0.94      0.93       154\n                  Cluster       0.93      0.94      0.93       105\n                Correlate       0.98      0.93      0.95       150\n\n                micro avg       0.95      0.95      0.95      1403\n                macro avg       0.95      0.95      0.95      1403\n             weighted avg       0.95      0.95      0.95      1403\n\nConfusion Matrix...\n[[119   1   0   0   0   0   2   1   0   0]\n [  1 125   1   3   0   1   1   4   2   1]\n [  0   2 149   1   1   1   0   1   0   1]\n [  0   0   0 187   1   0   1   3   0   0]\n [  0   0   0   0 118   0   0   0   1   0]\n [  0   2   0   0   1 124   1   0   0   0]\n [  0   0   4   0   0   1 131   1   0   0]\n [  1   4   2   0   0   1   0 144   2   0]\n [  0   0   1   1   1   0   1   1  99   1]\n [  1   1   1   0   0   0   3   2   3 139]]\nFold:  7\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.627, Train Acc: 50.55%, Val Loss: 0.9099, Val Acc: 70.14%, Time: 53.98s *\nEpoch: 2, Train Loss: 0.6371, Train Acc: 80.31%, Val Loss:  0.591, Val Acc: 81.40%, Time: 53.24s *\nEpoch: 3, Train Loss: 0.3915, Train Acc: 88.41%, Val Loss: 0.3932, Val Acc: 86.60%, Time: 53.93s *\nEpoch: 4, Train Loss: 0.2603, Train Acc: 92.18%, Val Loss: 0.3294, Val Acc: 89.09%, Time: 53.47s *\nEpoch: 5, Train Loss: 0.1804, Train Acc: 94.80%, Val Loss: 0.2738, Val Acc: 91.80%, Time: 54.73s *\nEpoch: 6, Train Loss:  0.136, Train Acc: 96.07%, Val Loss: 0.2636, Val Acc: 91.59%, Time: 54.16s \nEpoch: 7, Train Loss: 0.1057, Train Acc: 97.04%, Val Loss: 0.2308, Val Acc: 93.01%, Time: 54.03s *\nEpoch: 8, Train Loss: 0.08638, Train Acc: 97.60%, Val Loss: 0.2151, Val Acc: 93.16%, Time: 54.15s *\nEpoch: 9, Train Loss: 0.06926, Train Acc: 98.07%, Val Loss: 0.1964, Val Acc: 93.80%, Time: 53.71s *\nEpoch: 10, Train Loss: 0.05776, Train Acc: 98.25%, Val Loss: 0.1891, Val Acc: 94.58%, Time: 53.81s *\nEpoch: 11, Train Loss: 0.04543, Train Acc: 98.75%, Val Loss: 0.2037, Val Acc: 93.87%, Time: 53.87s \nEpoch: 12, Train Loss: 0.04302, Train Acc: 98.81%, Val Loss: 0.2213, Val Acc: 93.30%, Time: 54.31s \nEpoch: 13, Train Loss: 0.03645, Train Acc: 99.00%, Val Loss: 0.2128, Val Acc: 94.30%, Time: 54.09s \nEpoch: 14, Train Loss: 0.03889, Train Acc: 98.95%, Val Loss: 0.2411, Val Acc: 93.30%, Time: 54.14s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.95      0.99      0.97       179\n                   Filter       0.92      0.95      0.93       133\n    Compute Derived Value       0.89      0.94      0.91       159\n            Find Extremum       0.98      0.92      0.95       171\n                     Sort       0.94      0.95      0.94       123\n          Determine Range       0.91      0.93      0.92       118\nCharacterize Distribution       0.95      0.89      0.92       112\n           Find Anomalies       0.95      0.90      0.92       140\n                  Cluster       0.94      0.94      0.94       125\n                Correlate       0.96      0.95      0.96       143\n\n                micro avg       0.94      0.94      0.94      1403\n                macro avg       0.94      0.94      0.94      1403\n             weighted avg       0.94      0.94      0.94      1403\n\nConfusion Matrix...\n[[177   0   2   0   0   0   0   0   0   0]\n [  2 126   2   0   0   1   0   0   2   0]\n [  4   2 150   1   0   0   2   0   0   0]\n [  1   1   2 157   1   4   1   3   0   1]\n [  0   0   0   1 117   2   0   0   2   1]\n [  1   2   1   1   2 110   1   0   0   0]\n [  1   1   6   0   1   2 100   1   0   0]\n [  0   5   3   0   0   1   1 126   2   2]\n [  0   0   1   0   4   1   0   0 118   1]\n [  1   0   2   0   0   0   0   3   1 136]]\nFold:  8\nEpoch: 1, Train Loss:  1.669, Train Acc: 50.53%, Val Loss: 0.8751, Val Acc: 71.70%, Time: 55.14s *\nEpoch: 2, Train Loss: 0.6366, Train Acc: 80.68%, Val Loss: 0.5927, Val Acc: 82.61%, Time: 53.85s *\nEpoch: 3, Train Loss: 0.3848, Train Acc: 88.64%, Val Loss: 0.4242, Val Acc: 87.03%, Time: 54.60s *\nEpoch: 4, Train Loss: 0.2655, Train Acc: 92.83%, Val Loss: 0.3705, Val Acc: 89.52%, Time: 53.99s *\nEpoch: 5, Train Loss: 0.1891, Train Acc: 94.51%, Val Loss: 0.3293, Val Acc: 90.45%, Time: 54.26s *\nEpoch: 6, Train Loss: 0.1319, Train Acc: 96.25%, Val Loss: 0.3122, Val Acc: 90.52%, Time: 48.37s *\nEpoch: 7, Train Loss: 0.1099, Train Acc: 96.92%, Val Loss: 0.2727, Val Acc: 92.02%, Time: 54.20s *\nEpoch: 8, Train Loss: 0.08572, Train Acc: 97.54%, Val Loss: 0.2405, Val Acc: 93.01%, Time: 54.49s *\nEpoch: 9, Train Loss: 0.06888, Train Acc: 98.09%, Val Loss: 0.2508, Val Acc: 92.80%, Time: 53.91s \nEpoch: 10, Train Loss: 0.05338, Train Acc: 98.52%, Val Loss: 0.2542, Val Acc: 92.73%, Time: 54.23s \nEpoch: 11, Train Loss: 0.04954, Train Acc: 98.52%, Val Loss: 0.2404, Val Acc: 93.44%, Time: 54.44s *\nEpoch: 12, Train Loss: 0.04446, Train Acc: 98.67%, Val Loss: 0.2448, Val Acc: 93.80%, Time: 54.10s *\nEpoch: 13, Train Loss: 0.03496, Train Acc: 99.05%, Val Loss: 0.2627, Val Acc: 93.73%, Time: 53.54s \nEpoch: 14, Train Loss: 0.0386, Train Acc: 98.81%, Val Loss: 0.2454, Val Acc: 93.51%, Time: 53.92s \nEpoch: 15, Train Loss: 0.02507, Train Acc: 99.38%, Val Loss: 0.2324, Val Acc: 93.73%, Time: 54.23s \nEpoch: 16, Train Loss: 0.0333, Train Acc: 98.86%, Val Loss: 0.2282, Val Acc: 94.01%, Time: 54.11s *\nEpoch: 17, Train Loss: 0.02534, Train Acc: 99.27%, Val Loss: 0.2267, Val Acc: 94.23%, Time: 54.17s *\nEpoch: 18, Train Loss: 0.02432, Train Acc: 99.24%, Val Loss: 0.2431, Val Acc: 94.30%, Time: 54.46s *\nEpoch: 19, Train Loss: 0.02488, Train Acc: 99.35%, Val Loss: 0.2681, Val Acc: 94.44%, Time: 48.89s *\nEpoch: 20, Train Loss: 0.02827, Train Acc: 99.12%, Val Loss: 0.2753, Val Acc: 94.23%, Time: 54.03s \nEpoch: 21, Train Loss: 0.0238, Train Acc: 99.32%, Val Loss: 0.2785, Val Acc: 92.80%, Time: 54.20s \nEpoch: 22, Train Loss: 0.02116, Train Acc: 99.27%, Val Loss:  0.238, Val Acc: 94.44%, Time: 53.82s \nEpoch: 23, Train Loss: 0.01747, Train Acc: 99.42%, Val Loss: 0.3251, Val Acc: 93.44%, Time: 53.53s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.96      0.98      0.97       118\n                   Filter       0.96      0.94      0.95       148\n    Compute Derived Value       0.90      0.96      0.93       142\n            Find Extremum       0.95      0.92      0.93       194\n                     Sort       0.94      0.93      0.94       123\n          Determine Range       0.88      0.93      0.90       130\nCharacterize Distribution       0.95      0.96      0.96       137\n           Find Anomalies       0.91      0.95      0.93       132\n                  Cluster       0.96      0.95      0.95       119\n                Correlate       1.00      0.88      0.94       160\n\n                micro avg       0.94      0.94      0.94      1403\n                macro avg       0.94      0.94      0.94      1403\n             weighted avg       0.94      0.94      0.94      1403\n\nConfusion Matrix...\n[[116   0   1   1   0   0   0   0   0   0]\n [  0 139   3   0   0   2   0   4   0   0]\n [  2   1 136   0   0   2   1   0   0   0]\n [  2   3   3 179   3   3   1   0   0   0]\n [  0   0   0   2 115   5   0   1   0   0]\n [  0   0   4   2   2 121   1   0   0   0]\n [  0   0   2   1   0   1 132   1   0   0]\n [  0   0   0   3   0   2   1 126   0   0]\n [  0   0   1   0   1   1   1   2 113   0]\n [  1   2   1   1   1   1   2   5   5 141]]\nFold:  9\nEpoch: 1, Train Loss:  1.651, Train Acc: 49.60%, Val Loss: 0.8938, Val Acc: 72.06%, Time: 54.19s *\nEpoch: 2, Train Loss: 0.6582, Train Acc: 79.83%, Val Loss: 0.5434, Val Acc: 83.39%, Time: 53.58s *\nEpoch: 3, Train Loss: 0.3942, Train Acc: 88.25%, Val Loss: 0.4085, Val Acc: 88.10%, Time: 53.65s *\nEpoch: 4, Train Loss: 0.2665, Train Acc: 92.34%, Val Loss: 0.3606, Val Acc: 89.17%, Time: 53.69s *\nEpoch: 5, Train Loss:   0.19, Train Acc: 94.79%, Val Loss: 0.2974, Val Acc: 90.81%, Time: 54.23s *\nEpoch: 6, Train Loss: 0.1401, Train Acc: 96.05%, Val Loss: 0.2692, Val Acc: 92.02%, Time: 54.01s *\nEpoch: 7, Train Loss: 0.1094, Train Acc: 97.00%, Val Loss: 0.2587, Val Acc: 92.44%, Time: 53.87s *\nEpoch: 8, Train Loss: 0.08922, Train Acc: 97.43%, Val Loss:  0.266, Val Acc: 92.87%, Time: 53.30s *\nEpoch: 9, Train Loss: 0.07327, Train Acc: 97.96%, Val Loss: 0.2399, Val Acc: 92.87%, Time: 54.01s \nEpoch: 10, Train Loss: 0.05611, Train Acc: 98.37%, Val Loss: 0.2391, Val Acc: 93.94%, Time: 54.02s *\nEpoch: 11, Train Loss: 0.05141, Train Acc: 98.50%, Val Loss: 0.2636, Val Acc: 92.94%, Time: 53.52s \nEpoch: 12, Train Loss: 0.04541, Train Acc: 98.68%, Val Loss: 0.2331, Val Acc: 94.51%, Time: 54.97s *\nEpoch: 13, Train Loss: 0.04113, Train Acc: 98.80%, Val Loss: 0.2573, Val Acc: 94.23%, Time: 53.47s \nEpoch: 14, Train Loss: 0.03612, Train Acc: 98.98%, Val Loss: 0.2633, Val Acc: 93.80%, Time: 54.17s \nEpoch: 15, Train Loss: 0.03415, Train Acc: 98.96%, Val Loss: 0.2642, Val Acc: 93.94%, Time: 53.92s \nEpoch: 16, Train Loss: 0.02687, Train Acc: 99.21%, Val Loss: 0.2274, Val Acc: 94.80%, Time: 53.43s *\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 17, Train Loss:  0.033, Train Acc: 99.03%, Val Loss: 0.2975, Val Acc: 93.16%, Time: 53.95s \nEpoch: 18, Train Loss: 0.02896, Train Acc: 99.07%, Val Loss: 0.2561, Val Acc: 94.30%, Time: 53.95s \nEpoch: 19, Train Loss: 0.02432, Train Acc: 99.22%, Val Loss: 0.2479, Val Acc: 95.01%, Time: 54.58s *\nEpoch: 20, Train Loss: 0.02423, Train Acc: 99.30%, Val Loss: 0.2445, Val Acc: 95.22%, Time: 53.91s *\nEpoch: 21, Train Loss: 0.02087, Train Acc: 99.37%, Val Loss: 0.2955, Val Acc: 94.30%, Time: 53.84s \nEpoch: 22, Train Loss: 0.02574, Train Acc: 99.20%, Val Loss: 0.2114, Val Acc: 95.65%, Time: 54.00s *\nEpoch: 23, Train Loss: 0.01908, Train Acc: 99.36%, Val Loss: 0.2734, Val Acc: 94.65%, Time: 54.04s \nEpoch: 24, Train Loss: 0.01963, Train Acc: 99.45%, Val Loss:  0.303, Val Acc: 94.08%, Time: 48.68s \nEpoch: 25, Train Loss: 0.02071, Train Acc: 99.38%, Val Loss: 0.2925, Val Acc: 94.44%, Time: 54.33s \nEpoch: 26, Train Loss: 0.02078, Train Acc: 99.36%, Val Loss: 0.2674, Val Acc: 95.08%, Time: 53.78s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.97      0.95      0.96       126\n                   Filter       0.96      0.93      0.94       157\n    Compute Derived Value       0.96      0.95      0.95       156\n            Find Extremum       0.93      0.90      0.92       152\n                     Sort       0.92      0.97      0.94       129\n          Determine Range       0.97      0.92      0.95       144\nCharacterize Distribution       0.96      0.94      0.95       139\n           Find Anomalies       0.98      0.96      0.97       114\n                  Cluster       0.88      0.98      0.93       121\n                Correlate       0.94      0.98      0.96       165\n\n                micro avg       0.95      0.95      0.95      1403\n                macro avg       0.95      0.95      0.95      1403\n             weighted avg       0.95      0.95      0.95      1403\n\nConfusion Matrix...\n[[120   0   0   2   0   1   0   1   0   2]\n [  0 146   3   1   2   0   0   1   3   1]\n [  2   2 148   1   0   1   1   0   1   0]\n [  0   2   1 137   6   1   0   0   3   2]\n [  0   1   0   2 125   0   0   0   1   0]\n [  0   1   0   2   2 133   1   0   3   2]\n [  1   0   1   0   1   1 131   0   2   2]\n [  0   0   0   1   0   0   1 109   1   2]\n [  0   0   0   1   0   0   2   0 118   0]\n [  1   0   1   0   0   0   0   0   2 161]]\nFold:  10\nEpoch: 1, Train Loss:  1.677, Train Acc: 50.20%, Val Loss: 0.9142, Val Acc: 71.77%, Time: 54.14s *\nEpoch: 2, Train Loss: 0.6486, Train Acc: 80.17%, Val Loss: 0.5694, Val Acc: 82.39%, Time: 54.13s *\nEpoch: 3, Train Loss: 0.3864, Train Acc: 88.64%, Val Loss: 0.4563, Val Acc: 85.96%, Time: 53.79s *\nEpoch: 4, Train Loss: 0.2564, Train Acc: 92.45%, Val Loss: 0.3623, Val Acc: 89.52%, Time: 53.56s *\nEpoch: 5, Train Loss: 0.1894, Train Acc: 94.63%, Val Loss:  0.312, Val Acc: 90.81%, Time: 53.51s *\nEpoch: 6, Train Loss: 0.1343, Train Acc: 96.28%, Val Loss: 0.2702, Val Acc: 91.87%, Time: 53.89s *\nEpoch: 7, Train Loss: 0.1056, Train Acc: 96.94%, Val Loss:  0.236, Val Acc: 93.44%, Time: 53.85s *\nEpoch: 8, Train Loss: 0.0839, Train Acc: 97.59%, Val Loss: 0.2243, Val Acc: 92.59%, Time: 53.61s \nEpoch: 9, Train Loss: 0.06286, Train Acc: 98.20%, Val Loss: 0.2203, Val Acc: 93.30%, Time: 54.05s \nEpoch: 10, Train Loss: 0.05708, Train Acc: 98.58%, Val Loss: 0.2012, Val Acc: 93.94%, Time: 53.22s *\nEpoch: 11, Train Loss: 0.04817, Train Acc: 98.68%, Val Loss: 0.2454, Val Acc: 92.59%, Time: 53.82s \nEpoch: 12, Train Loss: 0.04106, Train Acc: 98.75%, Val Loss: 0.2059, Val Acc: 93.80%, Time: 53.49s \nEpoch: 13, Train Loss: 0.04059, Train Acc: 98.95%, Val Loss:  0.208, Val Acc: 94.23%, Time: 53.53s *\nEpoch: 14, Train Loss: 0.03916, Train Acc: 98.76%, Val Loss: 0.1965, Val Acc: 94.44%, Time: 53.68s *\nEpoch: 15, Train Loss: 0.03388, Train Acc: 98.98%, Val Loss: 0.2193, Val Acc: 94.58%, Time: 53.78s *\nEpoch: 16, Train Loss: 0.02978, Train Acc: 99.11%, Val Loss:   0.24, Val Acc: 93.73%, Time: 54.01s \nEpoch: 17, Train Loss: 0.02694, Train Acc: 99.08%, Val Loss: 0.2088, Val Acc: 93.44%, Time: 48.45s \nEpoch: 18, Train Loss: 0.02656, Train Acc: 99.19%, Val Loss:  0.201, Val Acc: 95.30%, Time: 53.25s *\nEpoch: 19, Train Loss: 0.02298, Train Acc: 99.37%, Val Loss: 0.2384, Val Acc: 94.65%, Time: 53.60s \nEpoch: 20, Train Loss:  0.023, Train Acc: 99.30%, Val Loss: 0.2383, Val Acc: 93.30%, Time: 53.45s \nEpoch: 21, Train Loss: 0.02508, Train Acc: 99.17%, Val Loss: 0.2326, Val Acc: 94.30%, Time: 53.33s \nEpoch: 22, Train Loss: 0.02468, Train Acc: 99.19%, Val Loss: 0.1852, Val Acc: 95.15%, Time: 54.04s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.95      0.97      0.96       142\n                   Filter       0.92      0.95      0.93       143\n    Compute Derived Value       0.92      0.97      0.95       159\n            Find Extremum       0.97      0.96      0.97       144\n                     Sort       0.93      0.96      0.95       109\n          Determine Range       0.98      0.95      0.96       168\nCharacterize Distribution       0.95      0.90      0.92       136\n           Find Anomalies       0.95      0.94      0.94       131\n                  Cluster       0.97      0.94      0.96       138\n                Correlate       0.96      0.95      0.95       133\n\n                micro avg       0.95      0.95      0.95      1403\n                macro avg       0.95      0.95      0.95      1403\n             weighted avg       0.95      0.95      0.95      1403\n\nConfusion Matrix...\n[[138   0   1   1   0   0   1   0   0   1]\n [  2 136   0   1   0   0   0   2   0   2]\n [  0   3 155   0   0   0   1   0   0   0]\n [  0   2   1 138   1   0   0   2   0   0]\n [  1   1   0   0 105   1   0   0   1   0]\n [  0   0   5   1   3 159   0   0   0   0]\n [  2   1   4   1   2   2 122   0   2   0]\n [  3   1   0   0   1   0   3 123   0   0]\n [  0   2   1   0   1   1   0   1 130   2]\n [  0   2   1   0   0   0   1   2   1 126]]\n[0.9330484330484331, 0.9394586894586895, 0.9437321937321937, 0.9373219373219374, 0.9387464387464387, 0.9515324305060584, 0.9387027797576621, 0.9394155381325731, 0.9465431218816821, 0.9493941553813258]\n0.9417895717966994, 0.005525832627787721, 0.005824739024227547, 3.053482623032335e-05\nexpert\n20 617 475 41\nFold:  1\nEpoch: 1, Train Loss:  1.761, Train Acc: 46.91%, Val Loss:  1.623, Val Acc: 50.00%, Time: 55.32s *\nEpoch: 2, Train Loss: 0.7145, Train Acc: 78.12%, Val Loss:  1.657, Val Acc: 53.57%, Time: 54.31s *\nEpoch: 3, Train Loss: 0.4361, Train Acc: 87.27%, Val Loss:  1.719, Val Acc: 55.86%, Time: 55.53s *\nEpoch: 4, Train Loss: 0.2902, Train Acc: 91.64%, Val Loss:  1.737, Val Acc: 57.05%, Time: 55.36s *\nEpoch: 5, Train Loss:  0.201, Train Acc: 94.19%, Val Loss:  1.854, Val Acc: 58.33%, Time: 55.11s *\nEpoch: 6, Train Loss:  0.145, Train Acc: 95.89%, Val Loss:  1.931, Val Acc: 57.97%, Time: 55.25s \nEpoch: 7, Train Loss: 0.1069, Train Acc: 97.08%, Val Loss:  1.891, Val Acc: 60.53%, Time: 55.05s *\nEpoch: 8, Train Loss: 0.0835, Train Acc: 97.82%, Val Loss:  2.217, Val Acc: 56.59%, Time: 55.10s \nEpoch: 9, Train Loss: 0.0713, Train Acc: 97.86%, Val Loss:  2.224, Val Acc: 59.25%, Time: 49.19s \nEpoch: 10, Train Loss: 0.05991, Train Acc: 98.41%, Val Loss:  2.261, Val Acc: 59.34%, Time: 54.90s \nEpoch: 11, Train Loss: 0.04682, Train Acc: 98.69%, Val Loss:   2.49, Val Acc: 58.61%, Time: 55.43s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.80      0.17      0.28       118\n                   Filter       0.50      0.33      0.40       115\n    Compute Derived Value       0.55      0.55      0.55       127\n            Find Extremum       0.45      0.66      0.53       112\n                     Sort       0.81      0.86      0.83       122\n          Determine Range       0.72      0.47      0.57        94\nCharacterize Distribution       0.61      0.48      0.54        97\n           Find Anomalies       0.45      0.70      0.55        94\n                  Cluster       0.68      0.78      0.72        98\n                Correlate       0.61      0.90      0.73       115\n\n                micro avg       0.59      0.59      0.59      1092\n                macro avg       0.62      0.59      0.57      1092\n             weighted avg       0.62      0.59      0.57      1092\n\nConfusion Matrix...\n[[ 20   2  32  30   7   5   2  11   0   9]\n [  3  38   3  18   1   5   2  31   8   6]\n [  1   6  70  33   0   2   2   5   1   7]\n [  1   4   1  74  11   1   3  14   1   2]\n [  0   1   0   0 105   0   3   0  12   1]\n [  0  20  12   0   0  44  15   0   3   0]\n [  0   0  10   6   0   3  47  13   0  18]\n [  0   2   0   3   0   0   1  66   6  16]\n [  0   2   0   0   6   1   2   4  76   7]\n [  0   1   0   2   0   0   0   4   5 103]]\nFold:  2\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.768, Train Acc: 46.95%, Val Loss:   1.67, Val Acc: 50.64%, Time: 54.48s *\nEpoch: 2, Train Loss: 0.7039, Train Acc: 78.40%, Val Loss:  1.658, Val Acc: 55.14%, Time: 54.53s *\nEpoch: 3, Train Loss: 0.4165, Train Acc: 87.73%, Val Loss:  1.649, Val Acc: 57.80%, Time: 55.26s *\nEpoch: 4, Train Loss: 0.2687, Train Acc: 92.45%, Val Loss:  1.773, Val Acc: 59.08%, Time: 53.96s *\nEpoch: 5, Train Loss: 0.1826, Train Acc: 94.74%, Val Loss:  1.907, Val Acc: 59.73%, Time: 53.71s *\nEpoch: 6, Train Loss: 0.1387, Train Acc: 96.12%, Val Loss:  1.997, Val Acc: 59.57%, Time: 54.64s \nEpoch: 7, Train Loss: 0.1061, Train Acc: 96.99%, Val Loss:  2.077, Val Acc: 59.32%, Time: 55.07s \nEpoch: 8, Train Loss: 0.08586, Train Acc: 97.62%, Val Loss:  2.093, Val Acc: 61.41%, Time: 54.15s *\nEpoch: 9, Train Loss: 0.06717, Train Acc: 98.15%, Val Loss:  2.311, Val Acc: 58.28%, Time: 54.46s \nEpoch: 10, Train Loss: 0.05434, Train Acc: 98.59%, Val Loss:   2.25, Val Acc: 60.05%, Time: 54.37s \nEpoch: 11, Train Loss: 0.04471, Train Acc: 98.72%, Val Loss:  2.504, Val Acc: 59.57%, Time: 48.20s \nEpoch: 12, Train Loss: 0.04327, Train Acc: 98.80%, Val Loss:  2.441, Val Acc: 60.85%, Time: 54.35s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.60      0.54      0.56       110\n                   Filter       0.60      0.44      0.51       151\n    Compute Derived Value       0.48      0.59      0.53       119\n            Find Extremum       0.43      0.75      0.55       123\n                     Sort       0.81      0.90      0.85       117\n          Determine Range       0.65      0.55      0.59       143\nCharacterize Distribution       0.60      0.54      0.57       119\n           Find Anomalies       0.73      0.71      0.72       124\n                  Cluster       0.78      0.59      0.67       120\n                Correlate       0.73      0.66      0.69       118\n\n                micro avg       0.62      0.62      0.62      1244\n                macro avg       0.64      0.63      0.62      1244\n             weighted avg       0.64      0.62      0.62      1244\n\nConfusion Matrix...\n[[ 59   1  17   9   2   5  16   0   1   0]\n [ 22  66  20  16   3  11   3  10   0   0]\n [  6   4  70  26   1   0   3   4   0   5]\n [  5   2  16  92   1   1   1   2   2   1]\n [  1   1   1   6 105   1   1   0   1   0]\n [  1   0  18  15  11  78   8   2   0  10]\n [  0   9   4  16   1   8  64   5  10   2]\n [  1   8   0   9   0   3   4  88   5   6]\n [  4  11   0   5   1  13   5   5  71   5]\n [  0   8   1  19   4   0   2   5   1  78]]\nFold:  3\nEpoch: 1, Train Loss:  1.772, Train Acc: 45.64%, Val Loss:  1.562, Val Acc: 48.73%, Time: 54.48s *\nEpoch: 2, Train Loss: 0.7242, Train Acc: 77.97%, Val Loss:  1.466, Val Acc: 52.85%, Time: 54.73s *\nEpoch: 3, Train Loss: 0.4401, Train Acc: 87.14%, Val Loss:  1.454, Val Acc: 56.57%, Time: 54.32s *\nEpoch: 4, Train Loss: 0.3031, Train Acc: 91.34%, Val Loss:  1.501, Val Acc: 57.83%, Time: 54.59s *\nEpoch: 5, Train Loss: 0.2069, Train Acc: 94.09%, Val Loss:  1.694, Val Acc: 58.07%, Time: 54.66s *\nEpoch: 6, Train Loss: 0.1543, Train Acc: 95.55%, Val Loss:  1.817, Val Acc: 56.80%, Time: 54.38s \nEpoch: 7, Train Loss: 0.1122, Train Acc: 96.69%, Val Loss:  1.873, Val Acc: 56.17%, Time: 54.42s \nEpoch: 8, Train Loss: 0.08644, Train Acc: 97.60%, Val Loss:   1.87, Val Acc: 57.52%, Time: 54.59s \nEpoch: 9, Train Loss: 0.0762, Train Acc: 97.79%, Val Loss:  1.918, Val Acc: 57.36%, Time: 54.39s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.31      0.27      0.29       124\n                   Filter       0.48      0.58      0.52       118\n    Compute Derived Value       0.40      0.48      0.44       132\n            Find Extremum       0.66      0.75      0.71       130\n                     Sort       0.80      0.84      0.82       131\n          Determine Range       0.72      0.29      0.42       129\nCharacterize Distribution       0.55      0.81      0.65       132\n           Find Anomalies       0.75      0.49      0.59       115\n                  Cluster       0.77      0.69      0.73       131\n                Correlate       0.54      0.57      0.55       122\n\n                micro avg       0.58      0.58      0.58      1264\n                macro avg       0.60      0.58      0.57      1264\n             weighted avg       0.60      0.58      0.57      1264\n\nConfusion Matrix...\n[[ 34  26  27  16   1   2  16   0   1   1]\n [  9  68  13   3   1   1  11   2   2   8]\n [ 27   4  63   5   2   2  13   2   0  14]\n [ 11   0  12  98   2   0   7   0   0   0]\n [  0   1   8   5 110   3   2   0   1   1]\n [ 23  14  11   9  11  38  16   1   2   4]\n [  6   0   9   3   2   0 107   0   0   5]\n [  0  20   5   6   3   0   4  56   3  18]\n [  1   0   4   2   4   3  14   5  91   7]\n [  0  10   4   1   1   4   6   9  18  69]]\nFold:  4\nEpoch: 1, Train Loss:   1.74, Train Acc: 46.55%, Val Loss:  1.199, Val Acc: 62.97%, Time: 54.95s *\nEpoch: 2, Train Loss: 0.7593, Train Acc: 76.78%, Val Loss:  1.145, Val Acc: 65.56%, Time: 54.20s *\nEpoch: 3, Train Loss:  0.465, Train Acc: 86.04%, Val Loss:  1.135, Val Acc: 66.94%, Time: 49.54s *\nEpoch: 4, Train Loss: 0.3057, Train Acc: 91.01%, Val Loss:  1.217, Val Acc: 67.75%, Time: 54.51s *\nEpoch: 5, Train Loss: 0.2187, Train Acc: 93.49%, Val Loss:  1.138, Val Acc: 69.53%, Time: 55.37s *\nEpoch: 6, Train Loss: 0.1554, Train Acc: 95.57%, Val Loss:  1.089, Val Acc: 70.91%, Time: 54.56s *\nEpoch: 7, Train Loss: 0.1197, Train Acc: 96.66%, Val Loss:  1.135, Val Acc: 72.77%, Time: 54.62s *\nEpoch: 8, Train Loss: 0.08991, Train Acc: 97.34%, Val Loss:  1.257, Val Acc: 71.64%, Time: 54.02s \nEpoch: 9, Train Loss: 0.07657, Train Acc: 97.81%, Val Loss:  1.275, Val Acc: 70.18%, Time: 55.06s \nEpoch: 10, Train Loss: 0.06063, Train Acc: 98.18%, Val Loss:  1.182, Val Acc: 71.72%, Time: 54.10s \nEpoch: 11, Train Loss: 0.05135, Train Acc: 98.46%, Val Loss:  1.237, Val Acc: 71.88%, Time: 54.40s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.72      0.27      0.39       134\n                   Filter       0.83      0.46      0.59       116\n    Compute Derived Value       0.56      0.76      0.64       127\n            Find Extremum       0.82      0.79      0.81       118\n                     Sort       0.74      0.80      0.77       113\n          Determine Range       0.65      0.69      0.67       122\nCharacterize Distribution       0.80      0.91      0.85       119\n           Find Anomalies       0.70      0.82      0.76       124\n                  Cluster       0.90      0.83      0.87       139\n                Correlate       0.66      0.94      0.78       122\n\n                micro avg       0.72      0.72      0.72      1234\n                macro avg       0.74      0.73      0.71      1234\n             weighted avg       0.74      0.72      0.71      1234\n\nConfusion Matrix...\n[[ 36   2  55   5   3   6   8   6   0  13]\n [  7  53   6   6   5   5   2  16   4  12]\n [  3   2  96   1   2   9   6   0   1   7]\n [  0   1   2  93   4   3   1  12   1   1]\n [  0   1   0   2  90  15   0   1   3   1]\n [  3   0   7   5   1  84   7   2   2  11]\n [  0   0   2   0   4   0 108   1   1   3]\n [  0   3   3   1   0   4   1 102   1   9]\n [  1   2   1   0  12   3   0   2 116   2]\n [  0   0   0   0   0   1   2   4   0 115]]\nFold:  5\nEpoch: 1, Train Loss:  1.717, Train Acc: 47.61%, Val Loss:  1.373, Val Acc: 58.81%, Time: 52.37s *\nEpoch: 2, Train Loss: 0.6895, Train Acc: 78.53%, Val Loss:  1.297, Val Acc: 61.88%, Time: 53.33s *\nEpoch: 3, Train Loss:  0.431, Train Acc: 87.06%, Val Loss:  1.378, Val Acc: 63.50%, Time: 52.41s *\nEpoch: 4, Train Loss: 0.2846, Train Acc: 91.51%, Val Loss:  1.344, Val Acc: 66.81%, Time: 52.71s *\nEpoch: 5, Train Loss: 0.2081, Train Acc: 93.83%, Val Loss:  1.439, Val Acc: 66.39%, Time: 52.35s \nEpoch: 6, Train Loss: 0.1434, Train Acc: 95.82%, Val Loss:  1.502, Val Acc: 66.75%, Time: 52.29s \n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 7, Train Loss: 0.1107, Train Acc: 96.99%, Val Loss:  1.707, Val Acc: 66.03%, Time: 52.83s \nEpoch: 8, Train Loss: 0.09013, Train Acc: 97.32%, Val Loss:  1.605, Val Acc: 68.01%, Time: 52.35s *\nEpoch: 9, Train Loss: 0.06861, Train Acc: 98.03%, Val Loss:  1.677, Val Acc: 66.69%, Time: 52.79s \nEpoch: 10, Train Loss: 0.06077, Train Acc: 98.34%, Val Loss:  1.788, Val Acc: 66.81%, Time: 46.03s \nEpoch: 11, Train Loss: 0.04691, Train Acc: 98.69%, Val Loss:  1.782, Val Acc: 69.03%, Time: 52.66s *\nEpoch: 12, Train Loss: 0.03792, Train Acc: 98.83%, Val Loss:  1.984, Val Acc: 68.49%, Time: 52.30s \nEpoch: 13, Train Loss: 0.0403, Train Acc: 98.68%, Val Loss:  1.959, Val Acc: 66.09%, Time: 52.07s \nEpoch: 14, Train Loss: 0.03804, Train Acc: 98.76%, Val Loss:  2.026, Val Acc: 66.45%, Time: 53.15s \nEpoch: 15, Train Loss: 0.0331, Train Acc: 98.99%, Val Loss:  2.121, Val Acc: 68.67%, Time: 52.39s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.65      0.49      0.56       112\n                   Filter       0.67      0.54      0.59       127\n    Compute Derived Value       0.77      0.54      0.64       208\n            Find Extremum       0.75      0.86      0.80       329\n                     Sort       0.71      0.81      0.76       120\n          Determine Range       0.60      0.42      0.49       118\nCharacterize Distribution       0.52      0.69      0.59       180\n           Find Anomalies       0.77      0.63      0.69       145\n                  Cluster       0.72      0.65      0.68       141\n                Correlate       0.62      0.84      0.71       183\n\n                micro avg       0.68      0.68      0.68      1663\n                macro avg       0.68      0.65      0.65      1663\n             weighted avg       0.68      0.68      0.67      1663\n\nConfusion Matrix...\n[[ 55   5  11   2   2   0  21  10   0   6]\n [  1  68   8   4   7  11   4   5   2  17]\n [ 13   2 113  15   3  10  24   0   8  20]\n [  5   3   5 282  13   4   9   2   4   2]\n [  0   0   0  14  97   2   4   0   2   1]\n [  1  16   2  29  12  49   5   0   4   0]\n [  8   2   2   3   1   1 125   7   4  27]\n [  0   4   3  25   0   0   1  92   5  15]\n [  0   0   2   1   1   2  36   2  91   6]\n [  2   2   1   2   0   3  12   2   6 153]]\nFold:  6\nEpoch: 1, Train Loss:    1.8, Train Acc: 45.89%, Val Loss:  1.269, Val Acc: 60.66%, Time: 54.58s *\nEpoch: 2, Train Loss: 0.7279, Train Acc: 77.69%, Val Loss:  1.062, Val Acc: 67.21%, Time: 54.16s *\nEpoch: 3, Train Loss:  0.443, Train Acc: 86.71%, Val Loss:  1.109, Val Acc: 69.92%, Time: 54.57s *\nEpoch: 4, Train Loss: 0.2962, Train Acc: 91.20%, Val Loss:  1.095, Val Acc: 71.15%, Time: 54.14s *\nEpoch: 5, Train Loss: 0.2076, Train Acc: 94.07%, Val Loss:  1.126, Val Acc: 71.15%, Time: 54.58s \nEpoch: 6, Train Loss: 0.1478, Train Acc: 95.89%, Val Loss:   1.08, Val Acc: 73.03%, Time: 54.47s *\nEpoch: 7, Train Loss: 0.1165, Train Acc: 96.56%, Val Loss:  1.184, Val Acc: 72.46%, Time: 54.42s \nEpoch: 8, Train Loss: 0.08515, Train Acc: 97.67%, Val Loss:  1.238, Val Acc: 70.98%, Time: 54.34s \nEpoch: 9, Train Loss: 0.06662, Train Acc: 98.15%, Val Loss:  1.317, Val Acc: 72.05%, Time: 54.57s \nEpoch: 10, Train Loss: 0.05974, Train Acc: 98.25%, Val Loss:  1.285, Val Acc: 72.62%, Time: 54.32s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.74      0.75      0.74       115\n                   Filter       0.62      0.77      0.69       124\n    Compute Derived Value       0.68      0.49      0.57       120\n            Find Extremum       0.81      0.80      0.81       122\n                     Sort       0.78      0.79      0.79       114\n          Determine Range       0.76      0.48      0.59       122\nCharacterize Distribution       0.85      0.94      0.89       128\n           Find Anomalies       0.65      0.59      0.62       128\n                  Cluster       0.76      0.92      0.83       121\n                Correlate       0.66      0.75      0.70       126\n\n                micro avg       0.73      0.73      0.73      1220\n                macro avg       0.73      0.73      0.72      1220\n             weighted avg       0.73      0.73      0.72      1220\n\nConfusion Matrix...\n[[ 86   1  15   3   1   0   1   3   2   3]\n [  0  96   0   2   4   4   0  13   4   1]\n [ 13   8  59   2   7   5   1   8   2  15]\n [  1   8   4  98   1   4   2   1   0   3]\n [  1   4   1   9  90   1   0   2   5   1]\n [ 12   8   4   2   5  59  15   5   1  11]\n [  3   0   0   1   0   1 120   0   1   2]\n [  0  24   1   1   5   4   2  75   5  11]\n [  0   2   1   0   1   0   0   3 111   3]\n [  0   4   2   3   1   0   1   5  15  95]]\nFold:  7\nEpoch: 1, Train Loss:  1.814, Train Acc: 44.74%, Val Loss:  1.395, Val Acc: 56.28%, Time: 53.20s *\nEpoch: 2, Train Loss: 0.7426, Train Acc: 77.14%, Val Loss:  1.332, Val Acc: 62.12%, Time: 52.70s *\nEpoch: 3, Train Loss: 0.4612, Train Acc: 86.49%, Val Loss:  1.327, Val Acc: 62.24%, Time: 48.45s *\nEpoch: 4, Train Loss: 0.2978, Train Acc: 91.14%, Val Loss:  1.283, Val Acc: 65.58%, Time: 52.25s *\nEpoch: 5, Train Loss: 0.2053, Train Acc: 94.09%, Val Loss:  1.382, Val Acc: 64.23%, Time: 52.80s \nEpoch: 6, Train Loss: 0.1522, Train Acc: 95.90%, Val Loss:  1.322, Val Acc: 66.47%, Time: 52.79s *\nEpoch: 7, Train Loss: 0.1181, Train Acc: 96.61%, Val Loss:  1.568, Val Acc: 63.85%, Time: 53.01s \nEpoch: 8, Train Loss: 0.09142, Train Acc: 97.44%, Val Loss:  1.494, Val Acc: 65.58%, Time: 52.71s \nEpoch: 9, Train Loss: 0.07952, Train Acc: 97.75%, Val Loss:  1.585, Val Acc: 65.26%, Time: 52.62s \nEpoch: 10, Train Loss: 0.06416, Train Acc: 98.04%, Val Loss:  1.652, Val Acc: 67.44%, Time: 52.89s *\nEpoch: 11, Train Loss: 0.05633, Train Acc: 98.47%, Val Loss:  1.752, Val Acc: 66.35%, Time: 53.45s \nEpoch: 12, Train Loss: 0.05056, Train Acc: 98.52%, Val Loss:  1.671, Val Acc: 67.82%, Time: 52.87s *\nEpoch: 13, Train Loss: 0.04204, Train Acc: 98.81%, Val Loss:   1.84, Val Acc: 66.60%, Time: 53.08s \nEpoch: 14, Train Loss: 0.03794, Train Acc: 98.74%, Val Loss:  1.903, Val Acc: 68.08%, Time: 53.29s *\nEpoch: 15, Train Loss: 0.03506, Train Acc: 99.02%, Val Loss:  1.965, Val Acc: 68.08%, Time: 53.29s *\nEpoch: 16, Train Loss: 0.03185, Train Acc: 99.00%, Val Loss:  2.055, Val Acc: 65.32%, Time: 53.08s \nEpoch: 17, Train Loss: 0.03102, Train Acc: 99.02%, Val Loss:  2.121, Val Acc: 66.09%, Time: 53.19s \nEpoch: 18, Train Loss: 0.0283, Train Acc: 99.13%, Val Loss:  2.003, Val Acc: 68.08%, Time: 53.23s \nEpoch: 19, Train Loss: 0.02393, Train Acc: 99.41%, Val Loss:  2.094, Val Acc: 67.12%, Time: 52.82s \nNo optimization for a long time, auto-stopping...\nPrecision, Recall and F1-Score...\n                           precision    recall  f1-score   support\n\n           Retrieve Value       0.79      0.55      0.64       121\n                   Filter       0.71      0.49      0.58       193\n    Compute Derived Value       0.48      0.65      0.55       156\n            Find Extremum       0.67      0.83      0.74       217\n                     Sort       0.79      0.66      0.72       134\n          Determine Range       0.51      0.47      0.49       133\nCharacterize Distribution       0.67      0.76      0.71       142\n           Find Anomalies       0.87      0.61      0.71       138\n                  Cluster       0.89      0.79      0.84       140\n                Correlate       0.63      0.82      0.71       186\n\n                micro avg       0.67      0.67      0.67      1560\n                macro avg       0.70      0.66      0.67      1560\n             weighted avg       0.69      0.67      0.67      1560\n\nConfusion Matrix...\n[[ 66   3  11  37   0   1   0   0   1   2]\n [  1  95  33  14   0  19   3   8   4  16]\n [  3   2 101  10   1  10  19   1   1   8]\n [  2   6   5 180  10   9   0   2   0   3]\n [  3   3   5  16  88  10   6   0   1   2]\n [  4  22   8  10   2  63  15   0   3   6]\n [  0   1   8   0   3   3 108   0   1  18]\n [  5   2  14   2   0   1   8  84   2  20]\n [  0   0   1   1   8   1   2   0 111  16]\n [  0   0  23   0   0   7   1   2   1 152]]\nFold:  8\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 1, Train Loss:  1.666, Train Acc: 48.52%, Val Loss:  1.562, Val Acc: 51.06%, Time: 54.12s *\nEpoch: 2, Train Loss: 0.7032, Train Acc: 78.77%, Val Loss:  1.416, Val Acc: 57.36%, Time: 54.70s *\nEpoch: 3, Train Loss: 0.4258, Train Acc: 87.64%, Val Loss:  1.464, Val Acc: 59.25%, Time: 49.70s *\nEpoch: 4, Train Loss: 0.2888, Train Acc: 91.68%, Val Loss:  1.552, Val Acc: 59.33%, Time: 54.42s *\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "raw", "source": "train_10_fold(trainData, categories)"}, {"metadata": {}, "cell_type": "raw", "source": "classifier.train(\n    X_train=X_train,\n    y_train=y_train,\n    X_eval=X_eval,\n    y_eval=y_eval,\n    epochs=30\n)"}], "metadata": {"kernelspec": {"name": "tensorflow-1.8", "display_name": "TensorFlow-1.8", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}