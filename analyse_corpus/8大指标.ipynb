{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sys\n",
    "import re\n",
    "# import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_v2 = pd.read_csv(\"majorApp_expertsentence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>task_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the population of Arkansas on July 1st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is Harvard University located?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many faculties are there in Harvard Univer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What type of school is Harvard University?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which county has more than 30,000 people?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Which university is in New York?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Which university has more than 30 faculties an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Which county has less than 2,000 people in 200...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the mean population in 2000?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the mean population of Ashley in 2000?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How many universities are located in New York?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Determine the standard deviation of the number...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Which county has the largest population in 2000?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Identify which university has the most teachers.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Identify which university has the most faculti...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Identify the county that has the least populat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Rank the county by population in 2000.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Order the universities according to the number...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Order the universities in New York based on th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Present the list that ranks all counties accor...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What is the population range in Ashley in 2000?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What locations do the universities cover?</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What are the upper and lower bounds of the num...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What are the upper and lower limits of the pop...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What is the distribution of the population in ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>How are the number of teachers distributed amo...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How are the different types of universities sc...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Illustrate the distribution of the population ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Which state has an abnormal population?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Determine which university has an anomalous nu...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Provide the range of the sale volume of 4225.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Show the distribution of the sales of type 404...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>Is the distribution of the sale volume of 4770...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Is there any day when the sum of the volume of...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Do we have outliers in the correlation between...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>What are the cluster groups of the average price?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Provide the groups of regions according to thr...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>How did the average price change in November 2...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>What is the correlation between the average pr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Find the user type of trip ID 17536702.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Retrieve the trip duration of trip ID 17536710.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Which trips are taken by females?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>List all the trips that take more than 1,000 m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Calculate the gender ratio of all users.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>How many users are female in this table?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>What is the birth year of the oldest user?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>I would like to know the longest travel time.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Present two ranking lists of stations ordered ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Rank the trips by travel time.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Compute the range of the birth years of all us...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Determine the range of the travel times.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>How are the birth years of users distributed?</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>What is the distribution of the travel time be...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>Is there any trip that takes more than 1,000 m...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Identify the outlier of the travel between the...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>Cluster the trip duration according to the sta...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>Is there any clustering of travel times?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>Is there any trend in the frequency of using b...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>How about the correlation between age and trav...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>Is there a cluster of typical film lengths?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  task_id\n",
       "0    What is the population of Arkansas on July 1st...        1\n",
       "1                 Where is Harvard University located?        1\n",
       "2    How many faculties are there in Harvard Univer...        1\n",
       "3           What type of school is Harvard University?        1\n",
       "4            Which county has more than 30,000 people?        2\n",
       "5                     Which university is in New York?        2\n",
       "6    Which university has more than 30 faculties an...        2\n",
       "7    Which county has less than 2,000 people in 200...        2\n",
       "8                 What is the mean population in 2000?        3\n",
       "9       What is the mean population of Ashley in 2000?        3\n",
       "10      How many universities are located in New York?        3\n",
       "11   Determine the standard deviation of the number...        3\n",
       "12    Which county has the largest population in 2000?        4\n",
       "13    Identify which university has the most teachers.        4\n",
       "14   Identify which university has the most faculti...        4\n",
       "15   Identify the county that has the least populat...        4\n",
       "16              Rank the county by population in 2000.        5\n",
       "17   Order the universities according to the number...        5\n",
       "18   Order the universities in New York based on th...        5\n",
       "19   Present the list that ranks all counties accor...        5\n",
       "20     What is the population range in Ashley in 2000?        6\n",
       "21           What locations do the universities cover?        6\n",
       "22   What are the upper and lower bounds of the num...        6\n",
       "23   What are the upper and lower limits of the pop...        6\n",
       "24   What is the distribution of the population in ...        7\n",
       "25   How are the number of teachers distributed amo...        7\n",
       "26   How are the different types of universities sc...        7\n",
       "27   Illustrate the distribution of the population ...        7\n",
       "28             Which state has an abnormal population?        8\n",
       "29   Determine which university has an anomalous nu...        8\n",
       "..                                                 ...      ...\n",
       "890      Provide the range of the sale volume of 4225.        6\n",
       "891  Show the distribution of the sales of type 404...        7\n",
       "892  Is the distribution of the sale volume of 4770...        7\n",
       "893  Is there any day when the sum of the volume of...        8\n",
       "894  Do we have outliers in the correlation between...        8\n",
       "895  What are the cluster groups of the average price?        9\n",
       "896  Provide the groups of regions according to thr...        9\n",
       "897  How did the average price change in November 2...       10\n",
       "898  What is the correlation between the average pr...       10\n",
       "899            Find the user type of trip ID 17536702.        1\n",
       "900    Retrieve the trip duration of trip ID 17536710.        1\n",
       "901                  Which trips are taken by females?        2\n",
       "902  List all the trips that take more than 1,000 m...        2\n",
       "903           Calculate the gender ratio of all users.        3\n",
       "904           How many users are female in this table?        3\n",
       "905         What is the birth year of the oldest user?        4\n",
       "906      I would like to know the longest travel time.        4\n",
       "907  Present two ranking lists of stations ordered ...        5\n",
       "908                     Rank the trips by travel time.        5\n",
       "909  Compute the range of the birth years of all us...        6\n",
       "910           Determine the range of the travel times.        6\n",
       "911      How are the birth years of users distributed?        7\n",
       "912  What is the distribution of the travel time be...        7\n",
       "913  Is there any trip that takes more than 1,000 m...        8\n",
       "914  Identify the outlier of the travel between the...        8\n",
       "915  Cluster the trip duration according to the sta...        9\n",
       "916           Is there any clustering of travel times?        9\n",
       "917  Is there any trend in the frequency of using b...       10\n",
       "918  How about the correlation between age and trav...       10\n",
       "919        Is there a cluster of typical film lengths?        9\n",
       "\n",
       "[920 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_v2[(corpus_v2.Task == '1') | (corpus_v2.Task == 1) | corpus_v2.Task.str.contains('1,', case=False, na=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    Where is Barcelona – Sants?\n",
       "task_id                               1\n",
       "Name: 818, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_v2.iloc[818]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      What is the population of Arkansas on July 1st...\n",
       "1                   Where is Harvard University located?\n",
       "2      How many faculties are there in Harvard Univer...\n",
       "3             What type of school is Harvard University?\n",
       "42     What is the ranking of Iceland in the World Ha...\n",
       "43     How many dimensions describe the happiness score?\n",
       "44     How many students have had their grades recorded?\n",
       "45                  Indicate Kibo Mcgee's midterm score.\n",
       "83                  How much revenue did \"Titanic\" earn?\n",
       "84       How many goals did Liverpool score in the game?\n",
       "85     Find the score that Jack received in the final...\n",
       "86     How long would it take to arrive home from sch...\n",
       "127                  What region does Iceland belong to?\n",
       "128                   What is the 15th happiest country?\n",
       "129    How would people in Iceland rate their happiness?\n",
       "130    If Iceland wanted to enhance its happiness sco...\n",
       "154    Which publisher published \"The Queen of Nothing\"?\n",
       "155          Enumerate the books written by Brian Tracy.\n",
       "156    In what language was \"The Art of Super Mario O...\n",
       "157                Is Barbara Allan's book highly rated?\n",
       "159                      How long is \"Beautiful People\"?\n",
       "160           What is the length of \"Beautiful People\"? \n",
       "161               What pop songs has Sam Smith released?\n",
       "162    Can you give me some titles of pop songs by Sa...\n",
       "243    What is the current version of \"Coloring book ...\n",
       "244    Indicate the size of \"Kids Paint Free - Drawin...\n",
       "259                               State a random reason.\n",
       "260     What kind of jobs do the students' mothers have?\n",
       "294    How many likes does the video \"PLUSH - Bad Unb...\n",
       "295    Does the video \"PLUSH - Bad Unboxing Fan Mail\"...\n",
       "                             ...                        \n",
       "614    What rating score has the app \"CF.lumen\" recei...\n",
       "615    How many installations does the app \"CF SHOP!\"...\n",
       "634                 How many hospitals does Arusha have?\n",
       "635                  How many clinics are there in Mara?\n",
       "654                    What is the GDP of China in 2000?\n",
       "655    What is the number of male suicides in China i...\n",
       "674    Return WAJA SPRINGS PR. SCHOOL's CHANGE_PRE in...\n",
       "675    What is the CHANGE_PRE of PEACLAND ENGLISH MED...\n",
       "694    How many times has the CF Life app been instal...\n",
       "695                         How much is the CF Life app?\n",
       "714      How many residents in Orange County are Asians?\n",
       "715    Show the percentage of the white population in...\n",
       "737                                 How much is CF Life?\n",
       "738                      When was Unity CF last updated?\n",
       "757    What is the number of people exposed to albini...\n",
       "758                How many people have autism in Lindi?\n",
       "777    What is the PM10 reading in Sants on 2018/1/11...\n",
       "778                     Obtain the geolocation of Sants.\n",
       "797             How many hospitals are there in Manyara?\n",
       "798                         Show the population of Mara.\n",
       "817    How is the air quality in Barcelona 鈥?Sants on...\n",
       "818                          Where is Barcelona 鈥?Sants?\n",
       "839    Which movie won Best Original Score - Motion P...\n",
       "840    I want to know the release year of the movie \"...\n",
       "859    Indicate the pass rate of WAJA SPRINGS PR. SCH...\n",
       "860    In 2016, what is the pass rate of WAJA SPRINGS...\n",
       "879        What is the sale volume of 4046 on 2015/8/30?\n",
       "880                 How many 4225 were sold on 2015/7/5?\n",
       "899              Find the user type of trip ID 17536702.\n",
       "900      Retrieve the trip duration of trip ID 17536710.\n",
       "Name: sentence, Length: 93, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_v2[corpus_v2.task_id==1].sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im xiong kai how are you gg'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = \"I'm xiong kai-, how (are you? gg;)\"\n",
    "re.sub('[?,.\"()\\':;–-]','',sents).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentences(sentences):\n",
    "    new_sents = []\n",
    "    for sentence in list(sentences):\n",
    "        # remove punctuation and ignore cases\n",
    "        new_sents.append(re.sub('[?,.\"()\\':;–-]','',sentence).lower())\n",
    "    return new_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_group_by_task(corpus):\n",
    "    tasks_sentences = {}\n",
    "    for i in range(1,11):\n",
    "        tasks_sentences[i] = preprocess_sentences(corpus[corpus.task_id==i].sentence)\n",
    "        \n",
    "    return tasks_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_sentences = sentences_group_by_task(corpus_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is the population of arkansas on july 1st 2002',\n",
       " 'where is harvard university located']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_sentences[1][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is the population in 2000 related to that in 2001',\n",
       " 'does the number of teachers affect the number of faculties']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_sentences[10][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.726935353908751e-155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\study\\python37\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = [\"open\", \"the\", \"file\"]\n",
    "reference = [\"please\", \"open\", \"this\",\"file\"]\n",
    "#the maximum is bigram, so assign the weight into 2 half.\n",
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis, weights = (0.5, 0.5))\n",
    "print(BLEUscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('reference', 'ha')}\n"
     ]
    }
   ],
   "source": [
    "print(set(nltk.ngrams([\"reference\", \"ha\"],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indices(object):\n",
    "    def __init__(self):\n",
    "        self.unigram = {}\n",
    "        self.bigram = {}\n",
    "        self.trigram = {}\n",
    "        self.sentence_len = []\n",
    "\n",
    "        self.levenshtein = []\n",
    "        self.bleu_score = []\n",
    "        \n",
    "        self.uni_overlap = []\n",
    "        self.bi_overlap = []\n",
    "        self.tri_overlap = []\n",
    "\n",
    "        self.uni_set = []\n",
    "        self.bi_set = []\n",
    "        self.tri_set = []\n",
    "        \n",
    "    \n",
    "    # caluclate the ngram of the words\n",
    "    #\n",
    "    # @param    words       list{str}\n",
    "    # @return   none\n",
    "    def ngram(self, words):\n",
    "        wlen = len(words)\n",
    "                  \n",
    "        for i in range(wlen):\n",
    "            word = words[i]\n",
    "                  \n",
    "            if word not in self.unigram:\n",
    "                self.unigram[word] = 1\n",
    "            else:\n",
    "                self.unigram[word] = self.unigram[word] + 1\n",
    "            \n",
    "            if i < (wlen - 1):\n",
    "                bi_words = ' '.join([word, words[i+1]])\n",
    "                if bi_words not in self.bigram:\n",
    "                    self.bigram[bi_words] = 1\n",
    "                else:\n",
    "                    self.bigram[bi_words] = self.bigram[bi_words] + 1\n",
    "                \n",
    "                if i < (wlen - 2):\n",
    "                    tri_words = ' '.join([word, words[i+1], words[i+2]])\n",
    "                    if tri_words not in self.trigram:\n",
    "                        self.trigram[tri_words] = 1\n",
    "                    else:\n",
    "                        self.trigram[tri_words] = self.trigram[tri_words] + 1\n",
    "                        \n",
    "        \n",
    "    def lev_dist(self, source, target):\n",
    "        '''\n",
    "            Compute Levenshtein Distance, Edit Distance\n",
    "        '''\n",
    "        len_source = len(source)\n",
    "        len_target = len(target)\n",
    "        edit = [[i + j for j in range(len_target + 1)] for i in range(len_source + 1)]\n",
    "        for i in range(1, len_source + 1):\n",
    "            for j in range(1, len_target + 1):\n",
    "                if source[i - 1] == target[j - 1]:\n",
    "                    d = 0\n",
    "                else:\n",
    "                    d = 1\n",
    "                edit[i][j] = min(edit[i - 1][j] + 1, edit[i][j - 1] + 1, edit[i - 1][j - 1] + d)\n",
    "\n",
    "        max_len = max(len_source, len_target)\n",
    "        edit_score = edit[len_source][len_target]\n",
    "        return (max_len - edit_score)/ max_len\n",
    "\n",
    "\n",
    "    def overlap(self, s_num):\n",
    "        for si in range(s_num - 1):\n",
    "            for sj in range(si + 1, s_num):\n",
    "                try:\n",
    "                    self.uni_overlap.append(len(self.uni_set[si] & self.uni_set[sj]) / len(self.uni_set[si] | self.uni_set[sj]))\n",
    "                    self.bi_overlap.append(len(self.bi_set[si] & self.bi_set[sj]) / len(self.bi_set[si] | self.bi_set[sj]))\n",
    "                    self.tri_overlap.append(len(self.tri_set[si] & self.tri_set[sj]) / len(self.tri_set[si] | self.tri_set[sj]))\n",
    "                except Exception as e:\n",
    "                    print(self.uni_set[si], self.uni_set[sj])\n",
    "                    print(self.bi_set[si], self.bi_set[sj])\n",
    "                    print(self.tri_set[si], self.tri_set[sj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for taski, ri in analyse_corpus.result.items():\n",
    "    result[taski] = {\"unigram\": ri.unigram, \"bigram\": ri.bigram, \"trigram\": ri.trigram, \"sentences_len\": ri.sentence_len, \n",
    "                     \"levenshtein\": ri.levenshtein, \"bleu_score\": ri.bleu_score, \n",
    "                     \"uni_overlap\": ri.uni_overlap, \"bi_overlap\": ri.bi_overlap, \"tri_overlap\": ri.tri_overlap}\n",
    "with open('./CorpusAnalysisResult2.json','w',encoding='utf-8') as fObj:\n",
    "    json.dump(result,fObj,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'is',\n",
       " 'the',\n",
       " 'population',\n",
       " 'of',\n",
       " 'arkansas',\n",
       " 'on',\n",
       " 'july',\n",
       " '1st',\n",
       " '2002']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_sentences[1][0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyseCorpus(object):\n",
    "\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus  # corpus: {1:[], 2:[]}\n",
    "        self.result = {}\n",
    "\n",
    "\n",
    "    def analyse(self):\n",
    "        for taski, ci in self.corpus.items():  # 每一个task的sentences：ci\n",
    "            indices = Indices()\n",
    "            \n",
    "            s_num = len(ci)   # 此task下共有多少句sentence\n",
    "            for si in range(s_num):\n",
    "                words = ci[si].split()\n",
    "                indices.sentence_len.append(len(words))\n",
    "\n",
    "                indices.uni_set.append(set(nltk.ngrams(words,1)))\n",
    "                indices.bi_set.append(set(nltk.ngrams(words,2)))\n",
    "                indices.tri_set.append(set(nltk.ngrams(words,3)))\n",
    "\n",
    "                indices.ngram(words)\n",
    "                if si < s_num - 1:\n",
    "                    for sj in range(si + 1, s_num):\n",
    "                        words2 = ci[sj].split()\n",
    "                        indices.levenshtein.append(indices.lev_dist(words, words2))\n",
    "                        indices.bleu_score.append(nltk.translate.bleu_score.sentence_bleu([words], words2, weights = (0.5, 0.5)))\n",
    "\n",
    "            indices.overlap(s_num)\n",
    "            self.result[taski] = indices\n",
    "        \n",
    "        '''\n",
    "        # unigram\n",
    "        \n",
    "        try:\n",
    "            fip = open(self.name + \"uni\", \"w\", encoding='utf-8')\n",
    "        except:\n",
    "            print(sys.stderr, \"failed to open data.uni\")\n",
    "        tmp = zip(self.unigram.values(),self.unigram.keys())\n",
    "        for i in sorted(tmp,reverse=True):\n",
    "            fip.write(\"%s %d\\n\" % (i[1], i[0]))\n",
    "            \n",
    "        # bigram\n",
    "        try:\n",
    "            fip = open(self.name + \"bi\", \"w\", encoding='utf-8')\n",
    "        except:\n",
    "            print(sys.stderr, \"failed to open data.bi\")\n",
    "        tmp = zip(self.bigram.values(),self.bigram.keys())\n",
    "        for i in sorted(tmp,reverse=True):\n",
    "            fip.write(\"%s %d\\n\" % (i[1], i[0]))\n",
    "            \n",
    "        # trigram\n",
    "        try:\n",
    "            fip = open(self.name + \"tri\", \"w\", encoding='utf-8')\n",
    "        except:\n",
    "            print(sys.stderr, \"failed to open data.tri\")\n",
    "        tmp = zip(self.trigram.values(),self.trigram.keys())\n",
    "        for i in sorted(tmp,reverse=True):\n",
    "            fip.write(\"%s %d\\n\" % (i[1], i[0]))\n",
    "        \n",
    "        try:\n",
    "            fip = open(self.name + \"len\", \"w\", encoding='utf-8')\n",
    "            fip.write(\"Sentences Num: %d\\n\" % (len(self.sentence_len)))\n",
    "        except:\n",
    "            print(sys.stderr, \"failed to open data.len\")\n",
    "        for i in self.sentence_len:\n",
    "            fip.write(\"%d, \" % (i))\n",
    "            \n",
    "        '''\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_corpus = AnalyseCorpus(tasks_sentences)\n",
    "analyse_corpus.analyse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1, 0.0, 0.2, 0.36363636363636365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(analyse_corpus.result[1].levenshtein))\n",
    "analyse_corpus.result[1].levenshtein[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9, 10, 6, 7, 10, 10, 10, 6, 10, 8]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ngram.levenshtein))\n",
    "ngram.levenshtein[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07142857142857142,\n",
       " 0.0,\n",
       " 0.21428571428571427,\n",
       " 0.25,\n",
       " 0.0625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.05555555555555555,\n",
       " 0.05555555555555555]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(analyse_corpus.result[1].uni_overlap))\n",
    "analyse_corpus.result[1].uni_overlap[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.07692307692307693,\n",
       "  0.0,\n",
       "  0.3076923076923077,\n",
       "  0.3076923076923077,\n",
       "  0.0,\n",
       "  0.0625,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0.05555555555555555,\n",
       "  0.125],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.15384615384615385,\n",
       "  0.15384615384615385,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.16666666666666666,\n",
       "  0.0,\n",
       "  0.0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ngram.uni_overlap))\n",
    "ngram.uni_overlap[:10], ngram.bi_overlap[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 4, 8, 7, 7, 7, 7, 6, 6, 9]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram.sentence_len[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Levenshtein.distance(string1, string2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3076923076923077"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = set(nltk.ngrams(\"What is the popularity of Arkansas on July 1st 2002\".split(),1))\n",
    "hyp = set(nltk.ngrams(\"What is the happiness rank of Iceland\".split(),1))\n",
    "len(hyp&ref) / len(hyp|ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_csv(r\"D:\\lab_data\\之江lab\\AIforVis\\main\\static\\table\\movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2781505847,\n",
       " 1835300000,\n",
       " 1327655619,\n",
       " 1062984497,\n",
       " 1023285206,\n",
       " 1001921825,\n",
       " 919700000,\n",
       " 892194397,\n",
       " 887773705,\n",
       " 885430303,\n",
       " 880871036,\n",
       " 866300000,\n",
       " 865000000,\n",
       " 836276689,\n",
       " 817068851]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(table[\"Revenue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = table[[\"Release Year\",\"Revenue\"]][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>2781505847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>1835300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>1327655619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year     Revenue\n",
       "0          2009  2781505847\n",
       "1          1997  1835300000\n",
       "2          2011  1327655619"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Release Year\":{\"0\":2009,\"1\":1997,\"2\":2011},\"Revenue\":{\"0\":2781505847,\"1\":1835300000,\"2\":1327655619}}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.to_json(orient=\"columns\")  # 默认是columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"columns\":[\"Release Year\",\"Revenue\"],\"index\":[0,1,2],\"data\":[[2009,2781505847],[1997,1835300000],[2011,1327655619]]}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.to_json(orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"Release Year\":2009,\"Revenue\":2781505847},{\"Release Year\":1997,\"Revenue\":1835300000},{\"Release Year\":2011,\"Revenue\":1327655619}]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\":{\"Release Year\":2009,\"Revenue\":2781505847},\"1\":{\"Release Year\":1997,\"Revenue\":1835300000},\"2\":{\"Release Year\":2011,\"Revenue\":1327655619}}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.to_json(orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[2009,2781505847],[1997,1835300000],[2011,1327655619]]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.to_json(orient=\"values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
